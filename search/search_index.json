{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"Quality Control for the AI Lifecycle <p><code>OpsML</code> is a developer-first ML operations platform focused on injecting quality control into machine learning artifact management. <code>OpsML</code> provides a unified and ergonomic interface and experience for managing ML artifacts, enabling teams to collaborate more effectively and deploy with confidence, all while reducing engineering overhead and providing peace of mind.</p>"},{"location":"#highlights","title":"Highlights","text":"<ul> <li>Consistency: OpsML provides a foundation layer for managing ML artifacts across the entire lifecycle.</li> <li>Built from Insanity: Built by those who've been there before and have experienced the pain of managing ML artifacts in enterprise environments. We're also obsessed with quality control and providing a developer-first experience.</li> <li>Performance: OpsML is built in Rust and is designed to be fast, reliable, and efficient, giving you peace of mind that your ML artifacts are in good hands.</li> <li>Integrations: OpsML is designed to be easy to integrate into your existing workflows and tech stack. In addition, we're continually adding integrations to third-party libraries, providing developers with a holistic and singular experience.</li> <li>No Auto Magic: OpsML is designed to be easy to use and understand, with no hidden magic or black boxes. Sure, we abstract things to make the experience consistent, but these abstractions are thin and transparent with accompanying documentation and code, so you know what's going on under the hood. </li> </ul>"},{"location":"#do-any-of-the-following-apply-to-you","title":"Do any of the following apply to you?","text":"<ul> <li>You don't currently have a consistent way to manage ML artifacts.</li> <li>You're using a variety of tools to manage ML artifacts across the entire lifecycle (why use many tool when few do trick?).</li> <li>You're tired of spending time on boilerplate code and want to focus on building models and applications.</li> <li>You want something that is easy to use and integrate into your existing workflows/tech stack.</li> <li>You are a developer, team, small company, large enterprise?</li> <li>You want a tool that has consistent support and maintenance and a team that is obsessed with quality control.</li> <li>You don't want to spend the brain power on figuring out how to manage all of your ML artifacts (you've got better things to do).</li> </ul> <p>If you answered yes to any of the above, then <code>OpsML</code> is for you.</p>"},{"location":"#see-it-in-action","title":"See it in Action","text":""},{"location":"#traditional-ml-workflow","title":"Traditional ML Workflow","text":"ML Workflow Quickstart<pre><code># create_fake_data requires polars and pandas to be installed \nfrom opsml.helpers.data import create_fake_data\nfrom opsml import SklearnModel, CardRegistry, TaskType,  ModelCard, RegistryType\nfrom sklearn import ensemble  # type: ignore\n\n# start registries\nreg = CardRegistry(RegistryType.Model) # (1)\n\n# create data\nX, y = create_fake_data(n_samples=1200)\n\n# Create and train model\nclassifier = ensemble.RandomForestClassifier(n_estimators=5)\nclassifier.fit(X.to_numpy(), y.to_numpy().ravel())\n\nmodel_interface = SklearnModel(  # (2)\n    model=classifier,\n    sample_data=X[0:10],\n    task_type=TaskType.Classification,\n)\nmodel_interface.create_drift_profile(alias=\"drift\", data=X) # (3)\n\nmodelcard = ModelCard( # (4)\n    interface=model_interface,\n    space=\"opsml\",\n    name=\"my_model\",\n)\n\n# register model\nreg.register_card(modelcard)\n\n# This code will run as is\n</code></pre> <ol> <li>Create, read, update, and delete Cards via CardRegistries.</li> <li>The SklearnModel is one of several interfaces for storing models in OpsML.</li> <li>OpsML is integrated with our model monitoring library, Scouter, which allows you to create drift and data profiles and monitor your models in production.</li> <li>The ModelCard is the primary interface for storing models in OpsML. It is a wrapper around the model interface and provides additional functionality such as versioning, metadata, and artifact management.</li> </ol> Example ModelCard Output <pre><code>{\n  \"name\": \"my-model\",\n  \"space\": \"opsml\",\n  \"version\": \"0.3.0\",\n  \"uid\": \"01962a48-e0cc-7961-9969-8b75eac4b0de\",\n  \"tags\": [\n    \"foo:bar\",\n    \"baz:qux\"\n  ],\n  \"metadata\": {\n    \"datacard_uid\": \"01962a48-e08c-7792-8a3a-6ecd6ad46d19\",\n    \"experimentcard_uid\": null,\n    \"auditcard_uid\": null,\n    \"interface_metadata\": {\n      \"task_type\": \"Classification\",\n      \"model_type\": \"SklearnEstimator\",\n      \"data_type\": \"Pandas\",\n      \"onnx_session\": null,\n      \"schema\": {\n        \"items\": {\n          \"col_8\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          },\n          \"col_1\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          },\n          \"col_3\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          },\n          \"col_2\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          },\n          \"col_4\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          },\n          \"col_5\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          },\n          \"col_6\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          },\n          \"col_9\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          },\n          \"col_7\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          },\n          \"col_0\": {\n            \"feature_type\": \"float64\",\n            \"shape\": [\n              1\n            ],\n            \"extra_args\": {}\n          }\n        }\n      },\n      \"save_metadata\": {\n        \"model_uri\": \"model.joblib\",\n        \"data_processor_map\": {},\n        \"sample_data_uri\": \"data.parquet\",\n        \"onnx_model_uri\": \"onnx-model.onnx\",\n        \"drift_profile_uri\": \"drift\"\n      },\n      \"extra_metadata\": {},\n      \"interface_type\": \"Sklearn\",\n      \"model_specific_metadata\": {\n        \"classes_\": \"[0 1]\",\n        \"feature_importances_\": \"[0.10789112 0.09341817 0.09390145 0.10334441 0.08558507 0.10508047\\n 0.09082737 0.10868374 0.10699015 0.10427807]\",\n        \"n_classes_\": 2,\n        \"n_features_in_\": 10,\n        \"n_outputs_\": 1,\n        \"params\": {\n          \"bootstrap\": true,\n          \"ccp_alpha\": 0.0,\n          \"class_weight\": null,\n          \"criterion\": \"gini\",\n          \"max_depth\": null,\n          \"max_features\": \"sqrt\",\n          \"max_leaf_nodes\": null,\n          \"max_samples\": null,\n          \"min_impurity_decrease\": 0.0,\n          \"min_samples_leaf\": 1,\n          \"min_samples_split\": 2,\n          \"min_weight_fraction_leaf\": 0.0,\n          \"monotonic_cst\": null,\n          \"n_estimators\": 5,\n          \"n_jobs\": null,\n          \"oob_score\": false,\n          \"random_state\": null,\n          \"verbose\": 0,\n          \"warm_start\": false\n        }\n      },\n      \"drift_type\": [\n        \"Spc\"\n      ]\n    }\n  },\n  \"registry_type\": \"Model\",\n  \"created_at\": \"2025-04-12T13:55:41.388075Z\",\n  \"app_env\": \"development\",\n  \"is_card\": true,\n  \"opsml_version\": \"0.1.0\"\n}\n</code></pre>"},{"location":"#genai","title":"GenAI","text":"GenAI - OpenAI<pre><code>from openai import OpenAI\nfrom opsml import PromptCard, Prompt, CardRegistry\n\nclient = OpenAI()\n\ncard = PromptCard(\n    space=\"opsml\",\n    name=\"my_prompt\",\n    prompt=Prompt(\n        model=\"o4-mini\",\n        provider=\"openai\",\n        message=\"Provide a brief summary of the programming language ${language}.\", # (1)\n        system_instruction=\"Be concise, reply with one sentence.\",\n    ),\n)\n\ndef chat_app(language: str):\n\n    # create the prompt and bind the context\n    user_message = card.prompt.bind(language=language).message[0].unwrap()\n    system_instruction = card.prompt.system_instruction[0].unwrap()\n\n    response = client.chat.completions.create(\n        model=card.prompt.model,\n        messages=[\n            {\"role\": \"system\", \"content\": system_instruction},\n            {\"role\": \"user\", \"content\": user_message},\n        ],\n    )\n\n    return response.choices[0].message.content\n\nif __name__ == \"__main__\":\n    result = chat_app(\"Python\")\n    print(result)\n\n    # Register the card in the registry\n    registry = CardRegistry(\"prompt\") # (2)\n    registry.register_card(card)\n\n# This code will run as is\n</code></pre> <ol> <li>OpsML prompts allow you to bind context and santize prompt messages.</li> <li>A CardRegistry can accept a string or a RegistryType (RegistryType.Prompt).</li> </ol>"},{"location":"#agentic-workflow-via-pydanticai","title":"Agentic Workflow via PydanticAI","text":"Agent - PydanticAI<pre><code>from pydantic_ai import Agent\nfrom opsml import PromptCard, Prompt, CardRegistry, RegistryType\n\n# Creating the card here for demonstration purposes\n# In practice, you would create the card, register it and then load it from the registry\n# whenever you need it for your application.\ncard = PromptCard(\n    space=\"opsml\",\n    name=\"my_prompt\",\n    prompt=Prompt(\n        model=\"gpt-4o\",\n        provider=\"openai\",\n        message='Where does \"hello world\" come from?',\n        system_instruction=\"Be concise, reply with one sentence.\",\n    ),\n)\n\nagent = Agent(\n    card.prompt.model_identifier,\n    system_instruction=card.prompt.system_instruction[0].unwrap(),\n)\n\nresult = agent.run_sync(card.prompt.message[0].unwrap())\nprint(result.output)\n\nregistry = CardRegistry(RegistryType.Prompt)\nregistry.register_card(card)\n\n# This code will run as is\n</code></pre>"},{"location":"#us-vs-others","title":"Us vs Others","text":"Feature OpsML Others Artifact-First Approach \u2705 \u274c SemVer for All Artifacts \u2705 \u274c (rare) Multi-Cloud Compatibility \u2705 \u2705 Multi-Database Support \u2705 \u2705 Authentication \u2705 \u2705 Encryption \u2705 \u274c (rare) Artifact Lineage \u2705 \u274c (uncommon) Out-of-the-Box Model Monitoring &amp; Data Profiling \u2705 \u274c Isolated Environments (No Staging/Prod Conflicts) \u2705 \u274c Single Dependency \u2705 \u274c Low-friction Integration Into Your Current Tech Stack \u2705 \u274c Standardized Patterns and Workflows \u2705 \u274c Open Source \u2705 \u274c (some)"},{"location":"contributing/","title":"Contributing to demml/opsml","text":""},{"location":"contributing/#welcome","title":"Welcome","text":"<p>Hello! We're glad and grateful that you're interested in contributing to opsml ! Below you will find the general guidelines for setting up your environment and creating/submitting <code>pull requests</code> and <code>issues</code>.</p>"},{"location":"contributing/#table-of-contents","title":"Table of contents","text":"<ul> <li>Contributing to demml/opsml</li> <li>Welcome</li> <li>Table of contents</li> <li>Submitting Issues</li> <li>Finding Issues to Work On</li> <li>Pull Requests<ul> <li>Environment Setup</li> <li>Contributing Changes</li> <li>Community Guidelines</li> </ul> </li> <li>Thank you!</li> </ul>"},{"location":"contributing/#submitting-issues","title":"Submitting Issues","text":"<p>Documentation issues, bugs, and feature requests are all welcome! We want to make opsml as useful as possible, so please let us know if you find something that doesn't work or if you have an idea for a new feature. To create a new issue, click here and select the appropriate issue template.</p>"},{"location":"contributing/#finding-issues-to-work-on","title":"Finding Issues to Work On","text":"<p>If you are interested in taking on one of our existing backlog items, check out our project backlog here</p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>There's always something to improve in opsml, and we want to make it as easy as possible for you to contribute. We welcome all contributions, big or small, and we appreciate your help in making opsml better. The following sections will guide you through the process of contributing to opsml.</p>"},{"location":"contributing/#environment-setup","title":"Environment Setup","text":"<p>Depending on what area you're interested in contributing to, you may need to set up your environment differently. Opsml primarily uses a Rust backend and exposes a Python API via PyO3. For python environment management, OpsML leverages uv. For the frontend, opsml exposes a static SPA built with Svelte and SvelteKit.</p> <ol> <li>Install Rust and Cargo by following the instructions here.</li> <li>Install uv by following the instructions here.</li> <li>Install python 3.10 or higher (e.g. <code>uv python install 3.12</code>).</li> <li>Install docker (needed for postgres and mysql unit tests)</li> <li>(Optional for UI contributions) Make sure npm and pnpm are installed on your system.</li> </ol> <p>Ensure everything works:</p> <p>From the root directory of the project, run the following commands to ensure everything is working correctly:</p> <pre><code>$ make start.server\n</code></pre> <p>This should start the OpsML server, after which you should be able to access the UI on your localhost. The following will shutdown the server:</p> <pre><code>$ make stop.server\n</code></pre> <p>To make sure the python client is working, run the following commands:</p> <pre><code>$ cd py-opsml\n$ make setup.project\n$ make test.unit\n</code></pre> <p>The above will cd into the py-opsml directory, setup the python environment, build the python wheel and run the unit tests.</p> <p>** You're now ready to start contributing! **</p> <p>Feel free to explore more of the makefile and codebase to get a better sense of how we run some of our tests and lints, but the above commands should be enough to get you started.</p>"},{"location":"contributing/#contributing-changes","title":"Contributing Changes","text":"<ol> <li>Create a new branch for your addition</li> <li>General naming conventions (we're not picky):<ul> <li><code>/name/&lt;short-description&gt;</code>: for features</li> <li><code>/name/&lt;short-description&gt;</code>: for general refactoring or bug fixes</li> <li><code>/name/&lt;issueNumber&gt;/&lt;short-description&gt;</code>: for fixes related to an issue</li> </ul> </li> <li>Test your changes:</li> <li>Testing Rust changes:<ul> <li>make sure you are in the <code>opsml</code> directory</li> <li>run <code>make format</code> to format the code</li> <li>run <code>make lints</code> to run the linter</li> <li>run <code>make test.unit</code> to run util, sql, and server-side storage tests</li> </ul> </li> <li>Testing Python changes:<ul> <li>make sure you are in the <code>py-opsml</code> directory</li> <li>run <code>make setup.project</code> to setup the python environment and build the python wheel</li> <li>run <code>make format</code> to format the code</li> <li>run <code>make lints</code> to run the linter</li> <li>run <code>make test.unit</code> to run the python unit tests</li> </ul> </li> <li>Submit a Draft Pull Request. Do it early and mark it <code>WIP</code> so a maintainer knows it's not ready for review just yet. You can also add a label to it if you feel like it.</li> <li>Move the <code>pull_request</code> out of draft state.</li> <li>Make sure you fill out the <code>pull_request</code> template (included with every <code>pull_request</code>)</li> <li>Request review from one of our maintainers (this should happen automatically via <code>.github/CODEOWNERS</code>). </li> <li>Get Approval. We'll let you know if there are any changes that are needed. </li> <li>Merge your changes into opsml!</li> </ol>"},{"location":"contributing/#community-guidelines","title":"Community Guidelines","text":"<ol> <li>Be Kind<ul> <li>Working with us should be a fun learning opportunity (for all parties!), and we want it to be a good experience for everyone. Please treat each other with respect.  </li> <li>If something looks outdated or incorrect, please let us know! We want to make opsml as useful as possible. </li> </ul> </li> <li>Own Your Work<ul> <li>Creating a PR for opsml is your first step to becoming a contributor, so make sure that you own your changes. </li> <li>Our maintainers will do their best to respond to you in a timely manner, but we ask the same from you as the contributor. </li> </ul> </li> </ol>"},{"location":"contributing/#thank-you","title":"Thank you!","text":""},{"location":"installation/","title":"Installation","text":"<p>Install OpsML with your preferred package manager. OpsML is built and distributed through PyPi and comes in 2 flavors: client and server.</p>"},{"location":"installation/#server-and-client-installation","title":"Server and client installation","text":"<p>If you want to work in a development environment and don't want to setup an independent server (we recommend that you do!), you can install both the client and server components with the following command:</p> uvpip <pre><code>$ uv add opsml\n</code></pre> <pre><code>$ pip install opsml\n</code></pre>"},{"location":"installation/#client-installation","title":"Client installation","text":"<p>If you already have a server up and running, as you would in an enterprise environment, you can install the client components with the following command:</p> uvpip <pre><code>$ uv add opsml-client\n</code></pre> <pre><code>$ pip install opsml-client\n</code></pre>"},{"location":"installation/#basic-usage","title":"Basic Usage","text":"<p>OpsML is designed for both development and production use cases, meaning you can run it in either server mode or client mode. </p> <ul> <li>Server mode: You are directly connecting to both the database and storage backends. </li> <li>Client mode: You are connecting to an OpsML server that is already running and managing the database and storage backends for you. </li> </ul> <p>While it's recommended to setup the server separately for production and enterprise use cases, we understand sometimes you just want to get up and running quickly to test things out or work locally.</p> Server Mode <p>The OpsML server is written in 100% Rust using the Axum framework. On every release of OpsML, we build, tag and publish new docker images that you can use to run the server. You can also build the server from source or download the pre-built binary from our release artifacts.</p>"},{"location":"installation/#run-before-walking","title":"Run Before Walking","text":"<p>Let's make sure everything is setup correctly before moving on to other sections. The following demo will populate a few Cards into a database that you can then visualize in the UI. You will also need to make sure you install sklearn and pandas if you haven't already. You can do this with the following command:</p> <pre><code>pip install pandas scikit-learn\n</code></pre> Warning <p>This is intended for demo purposes only. When you are ready to use OpsML in a production environment, take a look at the Server Setup section to learn how to setup the server and connect to it from your client.</p> <p>Run the following CLI commands from within your python environment to make sure everything is working as expected.</p> <p>Note: This will create a new SQLite database in the current directory.</p> <p>This command will create a local cache, pull the latest version of the UI from the OpsML repository and run the server. The server is written entirely in Rust and is exposed as a SvelteKit SPA and does not come prepackaged with OpsML.</p> <pre><code>opsml ui start\n</code></pre> <p>This will create a new SQLite database in the current directory and populate it with a few Cards. You can then visualize the Cards in the UI by running the following command:</p> <pre><code>opsml demo\n</code></pre>"},{"location":"quality_control/","title":"Quality Control","text":"<p>Quality control in OpsML encompasses the essential processes and best practices that ensure the reliability, integrity, availability, and governance of machine learning artifacts. OpsML streamlines these critical tasks so data scientists can focus on modeling, and engineers get the robust controls they need for production environments.</p>"},{"location":"quality_control/#developer-first-experience","title":"Developer-First Experience","text":"<ul> <li>Zero-friction Integration: Drop into existing ML workflows in minutes</li> <li>Type-safe and efficient by Design: Rust in the back, python in the front<sup>*</sup>. Catch errors before they hit production</li> <li>Unified API: One consistent interface for all ML frameworks</li> <li>Environment Parity: Same experience from development to production</li> <li>Dependency Overhead: One dependency for all ML artifact management</li> </ul>"},{"location":"quality_control/#built-to-scale","title":"Built to Scale","text":"<ul> <li>Trading Cards for ML: Manage ML artifacts like trading cards - collect, organize, share</li> <li>Cloud-Ready: Native support for AWS, GCP, Azure</li> <li>Database Agnostic: Support for SQLite, MySQL, Postgres</li> <li>Modular Design: Use what you need, leave what you don't</li> </ul>"},{"location":"quality_control/#production-ready","title":"Production Ready","text":"<ul> <li>High-Performance Server: Built in Rust for speed, reliability, and concurrency</li> <li>Built-in Security: Authentication and encryption out of the box</li> <li>Audit-Ready: Complete artifact lineage and versioning</li> <li>Standardized Governance Workflows: Consistent patterns to use across teams</li> <li>Built-in Monitoring: Integrated with Scouter</li> </ul> <p><sup> *OpsML is written in Rust and is exposed via a Python API built with PyO3. </sup></p>"},{"location":"docs/api/app/","title":"App","text":""},{"location":"docs/api/app/#opsml.app._app.AppState","title":"<code>AppState</code>","text":"<p>OpsML application state object. This is typically used in API workflows where you wish create a shared state to share among all requests. The OpsML app state provides a convenient way to load and store artifacts. Most notably, it provides an integration with Scouter so that you can load a <code>ServiceCard</code> along with a <code>ScouterQueue</code> for drift detection. Future iterations of this class may include other convenience methods that simplify common API tasks.</p> Source code in <code>python/opsml/app/_app.pyi</code> <pre><code>class AppState:\n    \"\"\"OpsML application state object. This is typically used in API\n    workflows where you wish create a shared state to share among all requests.\n    The OpsML app state provides a convenient way to load and store artifacts.\n    Most notably, it provides an integration with Scouter so that you can load a `ServiceCard`\n    along with a `ScouterQueue` for drift detection. Future iterations of this class may\n    include other convenience methods that simplify common API tasks.\n    \"\"\"\n\n    @staticmethod\n    def from_path(\n        path: Path,\n        transport_config: Optional[\n            Union[\n                KafkaConfig,\n                RabbitMQConfig,\n                RedisConfig,\n                HTTPConfig,\n            ]\n        ] = None,\n        reload_config: Optional[ReloadConfig] = None,\n        load_kwargs: Optional[Dict[str, Dict[str, Any]]] = None,\n    ) -&gt; \"AppState\":\n        \"\"\"\n        Load the AppState from a file path.\n\n        Args:\n            path (str):\n                The file path to load the AppState from. This is typically the path\n                pointing to the directory containing the `ServiceCard`.\n\n            transport_config (KafkaConfig | RabbitMQConfig | RedisConfig | HTTPConfig | None):\n                Optional transport configuration for the queue publisher\n                Can be KafkaConfig, RabbitMQConfig RedisConfig, or HTTPConfig. If not provided,\n                the queue will not be initialized.\n\n            load_kwargs (Dict[str, Dict[str, Any]]):\n                Optional kwargs for loading cards. Expected format:\n                {\n                    \"card_alias\": {\n                        \"interface\": interface_object,\n                        \"load_kwargs\": DataLoadKwargs | ModelLoadKwargs\n                    }\n                }\n\n        Example:\n            ```python\n            from opsml.app import AppState\n            from opsml.scouter import KafkaConfig\n\n            app_state = AppState.from_path(\n                \"/path/to/service\",\n                transport_config=KafkaConfig(),\n                )\n\n            # Access the service card and queue\n            service = app_state.service\n            queue = app_state.queue\n            ```\n\n        Returns:\n            AppState: The loaded AppState.\n        \"\"\"\n\n    @property\n    def service(self) -&gt; ServiceCard:\n        \"\"\"Get the service card.\"\"\"\n\n    @property\n    def queue(self) -&gt; ScouterQueue:\n        \"\"\"Get the Scouter queue.\"\"\"\n\n    @property\n    def reloader_running(self) -&gt; bool:\n        \"\"\"Check if the ServiceReloader is currently running.\"\"\"\n\n    def reload(self) -&gt; None:\n        \"\"\"Forces `AppState` to check for new `ServiceCards` and reload if necessary.\"\"\"\n\n    def start_reloader(self) -&gt; None:\n        \"\"\"Starts the `AppState` reloader.\"\"\"\n\n    def stop_reloader(self) -&gt; None:\n        \"\"\"Stops the `AppState` reloader.\"\"\"\n\n    def shutdown(self) -&gt; None:\n        \"\"\"Shuts down the `AppState` `ScouterQueue` and reloader if running.\n        This is a destructive operation and will attempt to close all background threads\n        associated with the `ScouterQueue` and reloader. Only use this method with graceful\n        shutdown procedures in mind.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/app/#opsml.app._app.AppState.queue","title":"<code>queue</code>  <code>property</code>","text":"<p>Get the Scouter queue.</p>"},{"location":"docs/api/app/#opsml.app._app.AppState.reloader_running","title":"<code>reloader_running</code>  <code>property</code>","text":"<p>Check if the ServiceReloader is currently running.</p>"},{"location":"docs/api/app/#opsml.app._app.AppState.service","title":"<code>service</code>  <code>property</code>","text":"<p>Get the service card.</p>"},{"location":"docs/api/app/#opsml.app._app.AppState.from_path","title":"<code>from_path(path, transport_config=None, reload_config=None, load_kwargs=None)</code>  <code>staticmethod</code>","text":"<p>Load the AppState from a file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The file path to load the AppState from. This is typically the path pointing to the directory containing the <code>ServiceCard</code>.</p> required <code>transport_config</code> <code>KafkaConfig | RabbitMQConfig | RedisConfig | HTTPConfig | None</code> <p>Optional transport configuration for the queue publisher Can be KafkaConfig, RabbitMQConfig RedisConfig, or HTTPConfig. If not provided, the queue will not be initialized.</p> <code>None</code> <code>load_kwargs</code> <code>Dict[str, Dict[str, Any]]</code> <p>Optional kwargs for loading cards. Expected format: {     \"card_alias\": {         \"interface\": interface_object,         \"load_kwargs\": DataLoadKwargs | ModelLoadKwargs     } }</p> <code>None</code> Example <pre><code>from opsml.app import AppState\nfrom opsml.scouter import KafkaConfig\n\napp_state = AppState.from_path(\n    \"/path/to/service\",\n    transport_config=KafkaConfig(),\n    )\n\n# Access the service card and queue\nservice = app_state.service\nqueue = app_state.queue\n</code></pre> <p>Returns:</p> Name Type Description <code>AppState</code> <code>AppState</code> <p>The loaded AppState.</p> Source code in <code>python/opsml/app/_app.pyi</code> <pre><code>@staticmethod\ndef from_path(\n    path: Path,\n    transport_config: Optional[\n        Union[\n            KafkaConfig,\n            RabbitMQConfig,\n            RedisConfig,\n            HTTPConfig,\n        ]\n    ] = None,\n    reload_config: Optional[ReloadConfig] = None,\n    load_kwargs: Optional[Dict[str, Dict[str, Any]]] = None,\n) -&gt; \"AppState\":\n    \"\"\"\n    Load the AppState from a file path.\n\n    Args:\n        path (str):\n            The file path to load the AppState from. This is typically the path\n            pointing to the directory containing the `ServiceCard`.\n\n        transport_config (KafkaConfig | RabbitMQConfig | RedisConfig | HTTPConfig | None):\n            Optional transport configuration for the queue publisher\n            Can be KafkaConfig, RabbitMQConfig RedisConfig, or HTTPConfig. If not provided,\n            the queue will not be initialized.\n\n        load_kwargs (Dict[str, Dict[str, Any]]):\n            Optional kwargs for loading cards. Expected format:\n            {\n                \"card_alias\": {\n                    \"interface\": interface_object,\n                    \"load_kwargs\": DataLoadKwargs | ModelLoadKwargs\n                }\n            }\n\n    Example:\n        ```python\n        from opsml.app import AppState\n        from opsml.scouter import KafkaConfig\n\n        app_state = AppState.from_path(\n            \"/path/to/service\",\n            transport_config=KafkaConfig(),\n            )\n\n        # Access the service card and queue\n        service = app_state.service\n        queue = app_state.queue\n        ```\n\n    Returns:\n        AppState: The loaded AppState.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/app/#opsml.app._app.AppState.reload","title":"<code>reload()</code>","text":"<p>Forces <code>AppState</code> to check for new <code>ServiceCards</code> and reload if necessary.</p> Source code in <code>python/opsml/app/_app.pyi</code> <pre><code>def reload(self) -&gt; None:\n    \"\"\"Forces `AppState` to check for new `ServiceCards` and reload if necessary.\"\"\"\n</code></pre>"},{"location":"docs/api/app/#opsml.app._app.AppState.shutdown","title":"<code>shutdown()</code>","text":"<p>Shuts down the <code>AppState</code> <code>ScouterQueue</code> and reloader if running. This is a destructive operation and will attempt to close all background threads associated with the <code>ScouterQueue</code> and reloader. Only use this method with graceful shutdown procedures in mind.</p> Source code in <code>python/opsml/app/_app.pyi</code> <pre><code>def shutdown(self) -&gt; None:\n    \"\"\"Shuts down the `AppState` `ScouterQueue` and reloader if running.\n    This is a destructive operation and will attempt to close all background threads\n    associated with the `ScouterQueue` and reloader. Only use this method with graceful\n    shutdown procedures in mind.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/app/#opsml.app._app.AppState.start_reloader","title":"<code>start_reloader()</code>","text":"<p>Starts the <code>AppState</code> reloader.</p> Source code in <code>python/opsml/app/_app.pyi</code> <pre><code>def start_reloader(self) -&gt; None:\n    \"\"\"Starts the `AppState` reloader.\"\"\"\n</code></pre>"},{"location":"docs/api/app/#opsml.app._app.AppState.stop_reloader","title":"<code>stop_reloader()</code>","text":"<p>Stops the <code>AppState</code> reloader.</p> Source code in <code>python/opsml/app/_app.pyi</code> <pre><code>def stop_reloader(self) -&gt; None:\n    \"\"\"Stops the `AppState` reloader.\"\"\"\n</code></pre>"},{"location":"docs/api/app/#opsml.app._app.ReloadConfig","title":"<code>ReloadConfig</code>","text":"<p>Reload configuation to use with an Opsml AppState object. Defines the reload logic for checking, downloading and reloading ServiceCards and ScouterQueues associated with an AppState</p> Source code in <code>python/opsml/app/_app.pyi</code> <pre><code>class ReloadConfig:\n    \"\"\"Reload configuation to use with an Opsml AppState object. Defines the reload logic\n    for checking, downloading and reloading ServiceCards and ScouterQueues associated with\n    an AppState\n    \"\"\"\n\n    def __init__(\n        self,\n        cron: str,\n        max_retries: int = 3,\n        write_path: Optional[Path] = None,\n    ):\n        \"\"\"Initialize the reload configuration.\n\n        Args:\n            cron (str):\n                The cron expression for the reload schedule.\n            max_retries (int):\n                The maximum number of retries for loading the service card.\n                Defaults to 3.\n            write_path (Optional[Path]):\n                The optional path to write the service card. Defaults to Path({current directory})/ service_reload\n        \"\"\"\n        ...\n\n    @property\n    def cron(self) -&gt; str:\n        \"\"\"Get the cron expression for the reload schedule.\"\"\"\n\n    @cron.setter\n    def cron(self, value: str):\n        \"\"\"Set the cron expression for the reload schedule.\"\"\"\n</code></pre>"},{"location":"docs/api/app/#opsml.app._app.ReloadConfig.cron","title":"<code>cron</code>  <code>property</code> <code>writable</code>","text":"<p>Get the cron expression for the reload schedule.</p>"},{"location":"docs/api/app/#opsml.app._app.ReloadConfig.__init__","title":"<code>__init__(cron, max_retries=3, write_path=None)</code>","text":"<p>Initialize the reload configuration.</p> <p>Parameters:</p> Name Type Description Default <code>cron</code> <code>str</code> <p>The cron expression for the reload schedule.</p> required <code>max_retries</code> <code>int</code> <p>The maximum number of retries for loading the service card. Defaults to 3.</p> <code>3</code> <code>write_path</code> <code>Optional[Path]</code> <p>The optional path to write the service card. Defaults to Path({current directory})/ service_reload</p> <code>None</code> Source code in <code>python/opsml/app/_app.pyi</code> <pre><code>def __init__(\n    self,\n    cron: str,\n    max_retries: int = 3,\n    write_path: Optional[Path] = None,\n):\n    \"\"\"Initialize the reload configuration.\n\n    Args:\n        cron (str):\n            The cron expression for the reload schedule.\n        max_retries (int):\n            The maximum number of retries for loading the service card.\n            Defaults to 3.\n        write_path (Optional[Path]):\n            The optional path to write the service card. Defaults to Path({current directory})/ service_reload\n    \"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/cards/","title":"Cards","text":""},{"location":"docs/api/cards/#opsml.card._card.Card","title":"<code>Card</code>","text":"<p>Represents a card from a given registry that can be used in a service card</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class Card:\n    \"\"\"Represents a card from a given registry that can be used in a service card\"\"\"\n\n    def __init__(\n        self,\n        alias: str,\n        registry_type: Optional[RegistryType] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        uid: Optional[str] = None,\n        card: Optional[CardType] = None,\n    ) -&gt; None:\n        \"\"\"Initialize the service card. Card accepts either a combination of\n        space and name (with version as optional) or a uid. If only space and name are\n        provided with no version, the latest version for a given space and name will be used\n        (e.g. {space}/{name}/v*). If a version is provided, it must follow semver rules that\n        are compatible with opsml (e.g. v1.*, v1.2.3, v2.3.4-alpha, etc.). If both space/name and uid\n        are provided, the uid will take precedence. If neither space/name nor uid are provided,\n        an error will be raised.\n\n        Alias is used to identify the card in the service card and is not necessarily the name of\n        the card. It is recommended to use a short and descriptive alias that is easy to remember.\n\n        Example:\n\n        ```python\n        service = ServiceCard(...)\n        service[\"my_alias\"]\n        ```\n\n\n        Args:\n            alias (str):\n                The alias of the card\n            registry_type (RegistryType):\n                The type of registry the service card belongs to. This is\n                required if no card is provided.\n            space (str):\n                The space of the service card\n            name (str):\n                The name of the service card\n            version (str):\n                The version of the service card\n            uid (str):\n                The uid of the service card\n            card (Union[DataCard, ModelCard, PromptCard, ExperimentCard]):\n                Optional card to add to the service. If provided, arguments will\n                be extracted from the card. This card must be registered in a registry.\n\n\n        Example:\n\n        ```python\n        from opsml import Card, ServiceCard, RegistryType\n\n        # With arguments\n        card = Card(\n            alias=\"my_alias\",\n            registry_type=RegistryType.Model,\n            space=\"my_space\",\n            name=\"my_name\",\n            version=\"1.0.0\",\n        )\n\n        # With card uid\n        card = Card(\n            alias=\"my_alias\",\n            registry_type=RegistryType.Model,\n            uid=\"my_uid\",\n        )\n\n        # With registered card\n        card = Card(\n            alias=\"my_alias\",\n            card=model_card,  # ModelCard object\n        )\n        ```\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.Card.__init__","title":"<code>__init__(alias, registry_type=None, space=None, name=None, version=None, uid=None, card=None)</code>","text":"<p>Initialize the service card. Card accepts either a combination of space and name (with version as optional) or a uid. If only space and name are provided with no version, the latest version for a given space and name will be used (e.g. {space}/{name}/v). If a version is provided, it must follow semver rules that are compatible with opsml (e.g. v1., v1.2.3, v2.3.4-alpha, etc.). If both space/name and uid are provided, the uid will take precedence. If neither space/name nor uid are provided, an error will be raised.</p> <p>Alias is used to identify the card in the service card and is not necessarily the name of the card. It is recommended to use a short and descriptive alias that is easy to remember.</p> <p>Example:</p> <pre><code>service = ServiceCard(...)\nservice[\"my_alias\"]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>alias</code> <code>str</code> <p>The alias of the card</p> required <code>registry_type</code> <code>RegistryType</code> <p>The type of registry the service card belongs to. This is required if no card is provided.</p> <code>None</code> <code>space</code> <code>str</code> <p>The space of the service card</p> <code>None</code> <code>name</code> <code>str</code> <p>The name of the service card</p> <code>None</code> <code>version</code> <code>str</code> <p>The version of the service card</p> <code>None</code> <code>uid</code> <code>str</code> <p>The uid of the service card</p> <code>None</code> <code>card</code> <code>Union[DataCard, ModelCard, PromptCard, ExperimentCard]</code> <p>Optional card to add to the service. If provided, arguments will be extracted from the card. This card must be registered in a registry.</p> <code>None</code> <p>Example:</p> <pre><code>from opsml import Card, ServiceCard, RegistryType\n\n# With arguments\ncard = Card(\n    alias=\"my_alias\",\n    registry_type=RegistryType.Model,\n    space=\"my_space\",\n    name=\"my_name\",\n    version=\"1.0.0\",\n)\n\n# With card uid\ncard = Card(\n    alias=\"my_alias\",\n    registry_type=RegistryType.Model,\n    uid=\"my_uid\",\n)\n\n# With registered card\ncard = Card(\n    alias=\"my_alias\",\n    card=model_card,  # ModelCard object\n)\n</code></pre> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __init__(\n    self,\n    alias: str,\n    registry_type: Optional[RegistryType] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    uid: Optional[str] = None,\n    card: Optional[CardType] = None,\n) -&gt; None:\n    \"\"\"Initialize the service card. Card accepts either a combination of\n    space and name (with version as optional) or a uid. If only space and name are\n    provided with no version, the latest version for a given space and name will be used\n    (e.g. {space}/{name}/v*). If a version is provided, it must follow semver rules that\n    are compatible with opsml (e.g. v1.*, v1.2.3, v2.3.4-alpha, etc.). If both space/name and uid\n    are provided, the uid will take precedence. If neither space/name nor uid are provided,\n    an error will be raised.\n\n    Alias is used to identify the card in the service card and is not necessarily the name of\n    the card. It is recommended to use a short and descriptive alias that is easy to remember.\n\n    Example:\n\n    ```python\n    service = ServiceCard(...)\n    service[\"my_alias\"]\n    ```\n\n\n    Args:\n        alias (str):\n            The alias of the card\n        registry_type (RegistryType):\n            The type of registry the service card belongs to. This is\n            required if no card is provided.\n        space (str):\n            The space of the service card\n        name (str):\n            The name of the service card\n        version (str):\n            The version of the service card\n        uid (str):\n            The uid of the service card\n        card (Union[DataCard, ModelCard, PromptCard, ExperimentCard]):\n            Optional card to add to the service. If provided, arguments will\n            be extracted from the card. This card must be registered in a registry.\n\n\n    Example:\n\n    ```python\n    from opsml import Card, ServiceCard, RegistryType\n\n    # With arguments\n    card = Card(\n        alias=\"my_alias\",\n        registry_type=RegistryType.Model,\n        space=\"my_space\",\n        name=\"my_name\",\n        version=\"1.0.0\",\n    )\n\n    # With card uid\n    card = Card(\n        alias=\"my_alias\",\n        registry_type=RegistryType.Model,\n        uid=\"my_uid\",\n    )\n\n    # With registered card\n    card = Card(\n        alias=\"my_alias\",\n        card=model_card,  # ModelCard object\n    )\n    ```\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardList","title":"<code>CardList</code>","text":"Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class CardList:\n    cards: List[CardRecord]\n\n    def __getitem__(self, key: int) -&gt; Optional[CardRecord]:\n        \"\"\"Return the card at the specified index\"\"\"\n\n    def __iter__(self) -&gt; CardRecord:\n        \"\"\"Return an iterator for the card list\"\"\"\n\n    def as_table(self) -&gt; None:\n        \"\"\"Print cards as a table\"\"\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of the card list\"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardList.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return the card at the specified index</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __getitem__(self, key: int) -&gt; Optional[CardRecord]:\n    \"\"\"Return the card at the specified index\"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardList.__iter__","title":"<code>__iter__()</code>","text":"<p>Return an iterator for the card list</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __iter__(self) -&gt; CardRecord:\n    \"\"\"Return an iterator for the card list\"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardList.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the card list</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of the card list\"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardList.as_table","title":"<code>as_table()</code>","text":"<p>Print cards as a table</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def as_table(self) -&gt; None:\n    \"\"\"Print cards as a table\"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardRecord","title":"<code>CardRecord</code>","text":"Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class CardRecord:\n    uid: Optional[str]\n    created_at: Optional[str]\n    app_env: Optional[str]\n    name: str\n    space: str\n    version: str\n    tags: Dict[str, str]\n    datacard_uids: Optional[List[str]]\n    modelcard_uids: Optional[List[str]]\n    experimentcard_uids: Optional[List[str]]\n    auditcard_uid: Optional[str]\n    interface_type: Optional[str]\n    data_type: Optional[str]\n    model_type: Optional[str]\n    task_type: Optional[str]\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the Card.\n\n        Returns:\n            String representation of the Card.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardRecord.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the Card.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the Card.</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the Card.\n\n    Returns:\n        String representation of the Card.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry","title":"<code>CardRegistry</code>","text":"<p>               Bases: <code>Generic[CardType]</code></p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class CardRegistry(Generic[CardType]):\n    @overload\n    def __init__(self, registry_type: Literal[RegistryType.Data]) -&gt; \"CardRegistry[DataCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[RegistryType.Model]) -&gt; \"CardRegistry[ModelCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[RegistryType.Prompt]) -&gt; \"CardRegistry[PromptCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[RegistryType.Experiment]) -&gt; \"CardRegistry[ExperimentCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[RegistryType.Service]) -&gt; \"CardRegistry[ServiceCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[RegistryType.Audit]) -&gt; \"CardRegistry[Any]\": ...\n\n    # String literal overloads\n    @overload\n    def __init__(self, registry_type: Literal[\"data\"]) -&gt; \"CardRegistry[DataCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[\"model\"]) -&gt; \"CardRegistry[ModelCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[\"prompt\"]) -&gt; \"CardRegistry[PromptCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[\"experiment\"]) -&gt; \"CardRegistry[ExperimentCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[\"service\"]) -&gt; \"CardRegistry[ServiceCard]\": ...\n    @overload\n    def __init__(self, registry_type: Literal[\"audit\"]) -&gt; \"CardRegistry[Any]\": ...\n    def __init__(self, registry_type: Union[RegistryType, str]) -&gt; None:\n        \"\"\"Interface for connecting to any of the Card registries\n\n        Args:\n            registry_type (RegistryType | str):\n                The type of registry to connect to. Can be a `RegistryType` or a string\n\n        Returns:\n            Instantiated connection to specific Card registry\n\n\n        Example:\n        ```python\n            data_registry = CardRegistry(RegistryType.Data)\n            data_registry.list_cards()\n\n            or\n            data_registry = CardRegistry(\"data\")\n            data_registry.list_cards()\n        ```\n        \"\"\"\n\n    @property\n    def registry_type(self) -&gt; RegistryType:\n        \"\"\"Returns the type of registry\"\"\"\n\n    @property\n    def table_name(self) -&gt; str:\n        \"\"\"Returns the table name for the registry\"\"\"\n\n    @property\n    def mode(self) -&gt; RegistryMode:\n        \"\"\"Returns the mode of the registry\"\"\"\n\n    def list_cards(\n        self,\n        uid: Optional[str] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        max_date: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n        sort_by_timestamp: Optional[bool] = False,\n        limit: int = 25,\n    ) -&gt; CardList:\n        \"\"\"Retrieves records from registry\n\n        Args:\n            uid (str):\n                Unique identifier for Card. If present, the uid takes precedence\n            space (str):\n                Optional space associated with card\n            name (str):\n                Optional name of card\n            version (str):\n                Optional version number of existing data. If not specified, the\n                most recent version will be used\n            tags (List[str]):\n                Optional list of tags to search for\n            max_date (str):\n                Optional max date to search. (e.g. \"2023-05-01\" would search for cards up to and including \"2023-05-01\").\n                Must be in the format \"YYYY-MM-DD\"\n            sort_by_timestamp:\n                If True, sorts by timestamp descending\n            limit (int):\n                Places a limit on result list. Results are sorted by SemVer.\n                Defaults to 25.\n\n        Returns:\n            List of Cards\n        \"\"\"\n\n    def register_card(\n        self,\n        card: CardType,\n        version_type: VersionType = VersionType.Minor,\n        pre_tag: Optional[str] = None,\n        build_tag: Optional[str] = None,\n        save_kwargs=Optional[ModelSaveKwargs | DataSaveKwargs],\n    ) -&gt; None:\n        \"\"\"Register a Card\n\n        Args:\n            card (ArtifactCard):\n                Card to register. Can be a DataCard, ModelCard,\n                experimentcard.\n            version_type (VersionType):\n                How to increment the version SemVer.\n            pre_tag (str):\n                Optional pre tag to associate with the version.\n            build_tag (str):\n                Optional build_tag to associate with the version.\n            save_kwargs (SaveKwargs):\n                Optional SaveKwargs to pass to the Card interface (If using DataCards\n                and ModelCards).\n\n        \"\"\"\n\n    @overload\n    def load_card(\n        self: \"CardRegistry[DataCard]\",\n        uid: Optional[str] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        interface: Optional[DataInterface] = None,\n    ) -&gt; DataCard: ...\n    @overload\n    def load_card(\n        self: \"CardRegistry[ServiceCard]\",\n        uid: Optional[str] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        interface=Optional[ServiceCardInterfaceType],\n    ) -&gt; ServiceCard: ...\n    @overload\n    def load_card(\n        self: \"CardRegistry[ModelCard]\",\n        uid: Optional[str] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        interface: Optional[ModelInterface] = None,\n    ) -&gt; ModelCard: ...\n    @overload\n    def load_card(\n        self: \"CardRegistry[PromptCard]\",\n        uid: Optional[str] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        interface: None = None,\n    ) -&gt; PromptCard: ...\n    @overload\n    def load_card(\n        self: \"CardRegistry[ExperimentCard]\",\n        uid: Optional[str] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        interface: None = None,\n    ) -&gt; ExperimentCard: ...\n    def load_card(\n        self,\n        uid: Optional[str] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        interface: Optional[LoadInterfaceType] = None,\n    ) -&gt; Union[DataCard, ModelCard, PromptCard, ExperimentCard, ServiceCard]:\n        \"\"\"Load a Card from the registry\n\n        Args:\n            uid (str, optional):\n                Unique identifier for Card. If present, the uid takes precedence over space/name/version.\n            space (str, optional):\n                Space associated with the card.\n            name (str, optional):\n                Name of the card.\n            version (str, optional):\n                Version number of existing card. If not specified, the most recent version will be used.\n            interface (LoadInterfaceType, optional):\n                Interface to load the card with. Required for cards registered with custom interfaces.\n                The expected interface type depends on the registry:\n\n                - DataCard registry: DataInterface\n                - ModelCard registry: ModelInterface\n                - ExperimentCard registry: Not used\n                - PromptCard registry: Not used\n                - ServiceCard registry: Dict[str, Union[DataInterface, ModelInterface]]\n                  Keys should be card aliases within the service.\n\n        Returns:\n            Union[DataCard, ModelCard, PromptCard, ExperimentCard, ServiceCard]:\n                The loaded card instance from the registry.\n        \"\"\"\n\n    def update_card(\n        self,\n        card: CardType,\n    ) -&gt; None:\n        \"\"\"Update a Card in the registry.\n        Note: This will only update the registry record for a given card. It\n        will not re-save/update the underlying artifacts (except for metadata).\n\n        Args:\n            card (ArtifactCard):\n                Card to update. Can be a DataCard, ModelCard,\n                experimentcard.\n        \"\"\"\n\n    def delete_card(\n        self,\n        card: CardType,\n    ) -&gt; None:\n        \"\"\"Delete a Card from the registry. This will also remove\n        the underlying artifacts associated with the card.\n\n        Args:\n            card (ArtifactCard):\n                Card to delete. Can be a DataCard, ModelCard,\n                experimentcard.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry.mode","title":"<code>mode</code>  <code>property</code>","text":"<p>Returns the mode of the registry</p>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry.registry_type","title":"<code>registry_type</code>  <code>property</code>","text":"<p>Returns the type of registry</p>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry.table_name","title":"<code>table_name</code>  <code>property</code>","text":"<p>Returns the table name for the registry</p>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry.__init__","title":"<code>__init__(registry_type)</code>","text":"<pre><code>__init__(\n    registry_type: Literal[RegistryType.Data],\n) -&gt; CardRegistry[DataCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[RegistryType.Model],\n) -&gt; CardRegistry[ModelCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[RegistryType.Prompt],\n) -&gt; CardRegistry[PromptCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[RegistryType.Experiment],\n) -&gt; CardRegistry[ExperimentCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[RegistryType.Service],\n) -&gt; CardRegistry[ServiceCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[RegistryType.Audit],\n) -&gt; CardRegistry[Any]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[\"data\"],\n) -&gt; CardRegistry[DataCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[\"model\"],\n) -&gt; CardRegistry[ModelCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[\"prompt\"],\n) -&gt; CardRegistry[PromptCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[\"experiment\"],\n) -&gt; CardRegistry[ExperimentCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[\"service\"],\n) -&gt; CardRegistry[ServiceCard]\n</code></pre><pre><code>__init__(\n    registry_type: Literal[\"audit\"],\n) -&gt; CardRegistry[Any]\n</code></pre> <p>Interface for connecting to any of the Card registries</p> <p>Parameters:</p> Name Type Description Default <code>registry_type</code> <code>RegistryType | str</code> <p>The type of registry to connect to. Can be a <code>RegistryType</code> or a string</p> required <p>Returns:</p> Type Description <code>None</code> <p>Instantiated connection to specific Card registry</p> <p>Example: <pre><code>    data_registry = CardRegistry(RegistryType.Data)\n    data_registry.list_cards()\n\n    or\n    data_registry = CardRegistry(\"data\")\n    data_registry.list_cards()\n</code></pre></p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __init__(self, registry_type: Union[RegistryType, str]) -&gt; None:\n    \"\"\"Interface for connecting to any of the Card registries\n\n    Args:\n        registry_type (RegistryType | str):\n            The type of registry to connect to. Can be a `RegistryType` or a string\n\n    Returns:\n        Instantiated connection to specific Card registry\n\n\n    Example:\n    ```python\n        data_registry = CardRegistry(RegistryType.Data)\n        data_registry.list_cards()\n\n        or\n        data_registry = CardRegistry(\"data\")\n        data_registry.list_cards()\n    ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry.delete_card","title":"<code>delete_card(card)</code>","text":"<p>Delete a Card from the registry. This will also remove the underlying artifacts associated with the card.</p> <p>Parameters:</p> Name Type Description Default <code>card</code> <code>ArtifactCard</code> <p>Card to delete. Can be a DataCard, ModelCard, experimentcard.</p> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def delete_card(\n    self,\n    card: CardType,\n) -&gt; None:\n    \"\"\"Delete a Card from the registry. This will also remove\n    the underlying artifacts associated with the card.\n\n    Args:\n        card (ArtifactCard):\n            Card to delete. Can be a DataCard, ModelCard,\n            experimentcard.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry.list_cards","title":"<code>list_cards(uid=None, space=None, name=None, version=None, max_date=None, tags=None, sort_by_timestamp=False, limit=25)</code>","text":"<p>Retrieves records from registry</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>Unique identifier for Card. If present, the uid takes precedence</p> <code>None</code> <code>space</code> <code>str</code> <p>Optional space associated with card</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional name of card</p> <code>None</code> <code>version</code> <code>str</code> <p>Optional version number of existing data. If not specified, the most recent version will be used</p> <code>None</code> <code>tags</code> <code>List[str]</code> <p>Optional list of tags to search for</p> <code>None</code> <code>max_date</code> <code>str</code> <p>Optional max date to search. (e.g. \"2023-05-01\" would search for cards up to and including \"2023-05-01\"). Must be in the format \"YYYY-MM-DD\"</p> <code>None</code> <code>sort_by_timestamp</code> <code>Optional[bool]</code> <p>If True, sorts by timestamp descending</p> <code>False</code> <code>limit</code> <code>int</code> <p>Places a limit on result list. Results are sorted by SemVer. Defaults to 25.</p> <code>25</code> <p>Returns:</p> Type Description <code>CardList</code> <p>List of Cards</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def list_cards(\n    self,\n    uid: Optional[str] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    max_date: Optional[str] = None,\n    tags: Optional[List[str]] = None,\n    sort_by_timestamp: Optional[bool] = False,\n    limit: int = 25,\n) -&gt; CardList:\n    \"\"\"Retrieves records from registry\n\n    Args:\n        uid (str):\n            Unique identifier for Card. If present, the uid takes precedence\n        space (str):\n            Optional space associated with card\n        name (str):\n            Optional name of card\n        version (str):\n            Optional version number of existing data. If not specified, the\n            most recent version will be used\n        tags (List[str]):\n            Optional list of tags to search for\n        max_date (str):\n            Optional max date to search. (e.g. \"2023-05-01\" would search for cards up to and including \"2023-05-01\").\n            Must be in the format \"YYYY-MM-DD\"\n        sort_by_timestamp:\n            If True, sorts by timestamp descending\n        limit (int):\n            Places a limit on result list. Results are sorted by SemVer.\n            Defaults to 25.\n\n    Returns:\n        List of Cards\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry.load_card","title":"<code>load_card(uid=None, space=None, name=None, version=None, interface=None)</code>","text":"<pre><code>load_card(\n    uid: Optional[str] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    interface: Optional[DataInterface] = None,\n) -&gt; DataCard\n</code></pre><pre><code>load_card(\n    uid: Optional[str] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    interface=Optional[ServiceCardInterfaceType],\n) -&gt; ServiceCard\n</code></pre><pre><code>load_card(\n    uid: Optional[str] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    interface: Optional[ModelInterface] = None,\n) -&gt; ModelCard\n</code></pre><pre><code>load_card(\n    uid: Optional[str] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    interface: None = None,\n) -&gt; PromptCard\n</code></pre><pre><code>load_card(\n    uid: Optional[str] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    interface: None = None,\n) -&gt; ExperimentCard\n</code></pre> <p>Load a Card from the registry</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>Unique identifier for Card. If present, the uid takes precedence over space/name/version.</p> <code>None</code> <code>space</code> <code>str</code> <p>Space associated with the card.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the card.</p> <code>None</code> <code>version</code> <code>str</code> <p>Version number of existing card. If not specified, the most recent version will be used.</p> <code>None</code> <code>interface</code> <code>LoadInterfaceType</code> <p>Interface to load the card with. Required for cards registered with custom interfaces. The expected interface type depends on the registry:</p> <ul> <li>DataCard registry: DataInterface</li> <li>ModelCard registry: ModelInterface</li> <li>ExperimentCard registry: Not used</li> <li>PromptCard registry: Not used</li> <li>ServiceCard registry: Dict[str, Union[DataInterface, ModelInterface]]   Keys should be card aliases within the service.</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>Union[DataCard, ModelCard, PromptCard, ExperimentCard, ServiceCard]</code> <p>Union[DataCard, ModelCard, PromptCard, ExperimentCard, ServiceCard]: The loaded card instance from the registry.</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def load_card(\n    self,\n    uid: Optional[str] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    interface: Optional[LoadInterfaceType] = None,\n) -&gt; Union[DataCard, ModelCard, PromptCard, ExperimentCard, ServiceCard]:\n    \"\"\"Load a Card from the registry\n\n    Args:\n        uid (str, optional):\n            Unique identifier for Card. If present, the uid takes precedence over space/name/version.\n        space (str, optional):\n            Space associated with the card.\n        name (str, optional):\n            Name of the card.\n        version (str, optional):\n            Version number of existing card. If not specified, the most recent version will be used.\n        interface (LoadInterfaceType, optional):\n            Interface to load the card with. Required for cards registered with custom interfaces.\n            The expected interface type depends on the registry:\n\n            - DataCard registry: DataInterface\n            - ModelCard registry: ModelInterface\n            - ExperimentCard registry: Not used\n            - PromptCard registry: Not used\n            - ServiceCard registry: Dict[str, Union[DataInterface, ModelInterface]]\n              Keys should be card aliases within the service.\n\n    Returns:\n        Union[DataCard, ModelCard, PromptCard, ExperimentCard, ServiceCard]:\n            The loaded card instance from the registry.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry.register_card","title":"<code>register_card(card, version_type=VersionType.Minor, pre_tag=None, build_tag=None, save_kwargs=Optional[ModelSaveKwargs | DataSaveKwargs])</code>","text":"<p>Register a Card</p> <p>Parameters:</p> Name Type Description Default <code>card</code> <code>ArtifactCard</code> <p>Card to register. Can be a DataCard, ModelCard, experimentcard.</p> required <code>version_type</code> <code>VersionType</code> <p>How to increment the version SemVer.</p> <code>Minor</code> <code>pre_tag</code> <code>str</code> <p>Optional pre tag to associate with the version.</p> <code>None</code> <code>build_tag</code> <code>str</code> <p>Optional build_tag to associate with the version.</p> <code>None</code> <code>save_kwargs</code> <code>SaveKwargs</code> <p>Optional SaveKwargs to pass to the Card interface (If using DataCards and ModelCards).</p> <code>Optional[ModelSaveKwargs | DataSaveKwargs]</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def register_card(\n    self,\n    card: CardType,\n    version_type: VersionType = VersionType.Minor,\n    pre_tag: Optional[str] = None,\n    build_tag: Optional[str] = None,\n    save_kwargs=Optional[ModelSaveKwargs | DataSaveKwargs],\n) -&gt; None:\n    \"\"\"Register a Card\n\n    Args:\n        card (ArtifactCard):\n            Card to register. Can be a DataCard, ModelCard,\n            experimentcard.\n        version_type (VersionType):\n            How to increment the version SemVer.\n        pre_tag (str):\n            Optional pre tag to associate with the version.\n        build_tag (str):\n            Optional build_tag to associate with the version.\n        save_kwargs (SaveKwargs):\n            Optional SaveKwargs to pass to the Card interface (If using DataCards\n            and ModelCards).\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.CardRegistry.update_card","title":"<code>update_card(card)</code>","text":"<p>Update a Card in the registry. Note: This will only update the registry record for a given card. It will not re-save/update the underlying artifacts (except for metadata).</p> <p>Parameters:</p> Name Type Description Default <code>card</code> <code>ArtifactCard</code> <p>Card to update. Can be a DataCard, ModelCard, experimentcard.</p> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def update_card(\n    self,\n    card: CardType,\n) -&gt; None:\n    \"\"\"Update a Card in the registry.\n    Note: This will only update the registry record for a given card. It\n    will not re-save/update the underlying artifacts (except for metadata).\n\n    Args:\n        card (ArtifactCard):\n            Card to update. Can be a DataCard, ModelCard,\n            experimentcard.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.DataCard","title":"<code>DataCard</code>","text":"Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class DataCard:\n    def __init__(  # pylint: disable=dangerous-default-value\n        self,\n        interface: Optional[DataInterface] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        uid: Optional[str] = None,\n        tags: List[str] = [],\n    ) -&gt; None:\n        \"\"\"Define a data card\n\n        Args:\n            interface (DataInterface | None):\n                The data interface\n            space (str | None):\n                The space of the card\n            name (str | None):\n                The name of the card\n            version (str | None):\n                The version of the card\n            uid (str | None):\n                The uid of the card\n            tags (List[str]):\n                The tags of the card\n\n        Example:\n        ```python\n        from opsml import DataCard, CardRegistry, RegistryType, PandasData\n\n        # for testing purposes\n        from opsml.helpers.data import create_fake_data\n\n        # pandas data\n        X, _ = create_fake_data(n_samples=1200)\n\n        interface = PandasData(data=X)\n        datacard = DataCard(\n            interface=interface,\n            space=\"my-repo\",\n            name=\"my-name\",\n            tags=[\"foo:bar\", \"baz:qux\"],\n        )\n\n        # register card\n        registry = CardRegistry(RegistryType.Data)\n        registry.register_card(datacard)\n        ```\n        \"\"\"\n\n    @property\n    def data(self) -&gt; Any:\n        \"\"\"Return the data. This is a special property that is used to\n        access the data from the interface. It is not settable. It will also\n        raise an error if the interface is not set or if the data\n        has not been loaded.\n        \"\"\"\n\n    @property\n    def experimentcard_uid(self) -&gt; Optional[str]:\n        \"\"\"Return the experimentcard uid\"\"\"\n\n    @experimentcard_uid.setter\n    def experimentcard_uid(self, experimentcard_uid: Optional[str]) -&gt; None:\n        \"\"\"Set the experimentcard uid\"\"\"\n\n    @property\n    def interface(self) -&gt; Optional[DataInterface]:\n        \"\"\"Return the data interface\"\"\"\n\n    @interface.setter\n    def interface(self, interface: Any) -&gt; None:\n        \"\"\"Set the data interface\n\n        Args:\n            interface (DataInterface):\n                The data interface to set. Must inherit from DataInterface\n        \"\"\"\n\n    @property\n    def app_env(self) -&gt; str:\n        \"\"\"Returns the app env\"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime:\n        \"\"\"Returns the created at timestamp\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name of the data card\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set the name of the data card\n\n        Args:\n            name (str):\n                The name of the data card\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space of the data card\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set the space of the data card\n\n        Args:\n            space (str):\n                The space of the data card\n        \"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version of the data card\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set the version of the data card\n\n        Args:\n            version (str):\n                The version of the data card\n        \"\"\"\n\n    @property\n    def uid(self) -&gt; str:\n        \"\"\"Return the uid of the data card\"\"\"\n\n    @property\n    def tags(self) -&gt; List[str]:\n        \"\"\"Return the tags of the data card\"\"\"\n\n    @tags.setter\n    def tags(self, tags: List[str]) -&gt; None:\n        \"\"\"Set the tags of the data card\n\n        Args:\n            tags (List[str]):\n                The tags of the data card\n        \"\"\"\n\n    @property\n    def metadata(self) -&gt; DataCardMetadata:  # pylint: disable=used-before-assignment\n        \"\"\"Return the metadata of the data card\"\"\"\n\n    @property\n    def registry_type(self) -&gt; RegistryType:\n        \"\"\"Return the card type of the data card\"\"\"\n\n    @property\n    def data_type(self) -&gt; DataType:\n        \"\"\"Return the data type\"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: Optional[DataSaveKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Save the data card\n\n        Args:\n            path (Path):\n                The path to save the data card to\n            save_kwargs (DataSaveKwargs | None):\n                Optional save kwargs to that will be passed to the\n                data interface save method\n\n        Acceptable save kwargs:\n            Kwargs are passed to the underlying data interface for saving.\n            For a complete list of options see the save method of the data interface and\n            their associated libraries.\n        \"\"\"\n\n    def load(\n        self,\n        path: Optional[Path] = None,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data card\n\n        Args:\n            path (Path | None):\n                The path to load the data card from. If no path is provided,\n                the data interface will be loaded from the server.\n            load_kwargs (DataLoadKwargs | None):\n                Optional load kwargs to that will be passed to the\n                data interface load method\n        \"\"\"\n\n    def download_artifacts(self, path: Optional[Path] = None) -&gt; None:\n        \"\"\"Download artifacts associated with the DataCard\n\n        Args:\n            path (Path):\n                Path to save the artifacts. If not provided, the artifacts will be saved\n                to a directory called \"card_artifacts\"\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the model dump as a json string\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str, interface: Optional[DataInterface] = None) -&gt; \"ModelCard\":\n        \"\"\"Validate the model json string\n\n        Args:\n            json_string (str):\n                The json string to validate\n            interface (DataInterface):\n                By default, the interface will be inferred and instantiated\n                from the interface metadata. If an interface is provided\n                (as in the case of custom interfaces), it will be used.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.app_env","title":"<code>app_env</code>  <code>property</code>","text":"<p>Returns the app env</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Returns the created at timestamp</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.data","title":"<code>data</code>  <code>property</code>","text":"<p>Return the data. This is a special property that is used to access the data from the interface. It is not settable. It will also raise an error if the interface is not set or if the data has not been loaded.</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.data_type","title":"<code>data_type</code>  <code>property</code>","text":"<p>Return the data type</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.experimentcard_uid","title":"<code>experimentcard_uid</code>  <code>property</code> <code>writable</code>","text":"<p>Return the experimentcard uid</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.interface","title":"<code>interface</code>  <code>property</code> <code>writable</code>","text":"<p>Return the data interface</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.metadata","title":"<code>metadata</code>  <code>property</code>","text":"<p>Return the metadata of the data card</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Return the name of the data card</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.registry_type","title":"<code>registry_type</code>  <code>property</code>","text":"<p>Return the card type of the data card</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Return the space of the data card</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.tags","title":"<code>tags</code>  <code>property</code> <code>writable</code>","text":"<p>Return the tags of the data card</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.uid","title":"<code>uid</code>  <code>property</code>","text":"<p>Return the uid of the data card</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Return the version of the data card</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.__init__","title":"<code>__init__(interface=None, space=None, name=None, version=None, uid=None, tags=[])</code>","text":"<p>Define a data card</p> <p>Parameters:</p> Name Type Description Default <code>interface</code> <code>DataInterface | None</code> <p>The data interface</p> <code>None</code> <code>space</code> <code>str | None</code> <p>The space of the card</p> <code>None</code> <code>name</code> <code>str | None</code> <p>The name of the card</p> <code>None</code> <code>version</code> <code>str | None</code> <p>The version of the card</p> <code>None</code> <code>uid</code> <code>str | None</code> <p>The uid of the card</p> <code>None</code> <code>tags</code> <code>List[str]</code> <p>The tags of the card</p> <code>[]</code> <p>Example: <pre><code>from opsml import DataCard, CardRegistry, RegistryType, PandasData\n\n# for testing purposes\nfrom opsml.helpers.data import create_fake_data\n\n# pandas data\nX, _ = create_fake_data(n_samples=1200)\n\ninterface = PandasData(data=X)\ndatacard = DataCard(\n    interface=interface,\n    space=\"my-repo\",\n    name=\"my-name\",\n    tags=[\"foo:bar\", \"baz:qux\"],\n)\n\n# register card\nregistry = CardRegistry(RegistryType.Data)\nregistry.register_card(datacard)\n</code></pre></p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __init__(  # pylint: disable=dangerous-default-value\n    self,\n    interface: Optional[DataInterface] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    uid: Optional[str] = None,\n    tags: List[str] = [],\n) -&gt; None:\n    \"\"\"Define a data card\n\n    Args:\n        interface (DataInterface | None):\n            The data interface\n        space (str | None):\n            The space of the card\n        name (str | None):\n            The name of the card\n        version (str | None):\n            The version of the card\n        uid (str | None):\n            The uid of the card\n        tags (List[str]):\n            The tags of the card\n\n    Example:\n    ```python\n    from opsml import DataCard, CardRegistry, RegistryType, PandasData\n\n    # for testing purposes\n    from opsml.helpers.data import create_fake_data\n\n    # pandas data\n    X, _ = create_fake_data(n_samples=1200)\n\n    interface = PandasData(data=X)\n    datacard = DataCard(\n        interface=interface,\n        space=\"my-repo\",\n        name=\"my-name\",\n        tags=[\"foo:bar\", \"baz:qux\"],\n    )\n\n    # register card\n    registry = CardRegistry(RegistryType.Data)\n    registry.register_card(datacard)\n    ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.download_artifacts","title":"<code>download_artifacts(path=None)</code>","text":"<p>Download artifacts associated with the DataCard</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to save the artifacts. If not provided, the artifacts will be saved to a directory called \"card_artifacts\"</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def download_artifacts(self, path: Optional[Path] = None) -&gt; None:\n    \"\"\"Download artifacts associated with the DataCard\n\n    Args:\n        path (Path):\n            Path to save the artifacts. If not provided, the artifacts will be saved\n            to a directory called \"card_artifacts\"\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.load","title":"<code>load(path=None, load_kwargs=None)</code>","text":"<p>Load the data card</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | None</code> <p>The path to load the data card from. If no path is provided, the data interface will be loaded from the server.</p> <code>None</code> <code>load_kwargs</code> <code>DataLoadKwargs | None</code> <p>Optional load kwargs to that will be passed to the data interface load method</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def load(\n    self,\n    path: Optional[Path] = None,\n    load_kwargs: Optional[DataLoadKwargs] = None,\n) -&gt; None:\n    \"\"\"Load the data card\n\n    Args:\n        path (Path | None):\n            The path to load the data card from. If no path is provided,\n            the data interface will be loaded from the server.\n        load_kwargs (DataLoadKwargs | None):\n            Optional load kwargs to that will be passed to the\n            data interface load method\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the model dump as a json string</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the model dump as a json string\"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.model_validate_json","title":"<code>model_validate_json(json_string, interface=None)</code>  <code>staticmethod</code>","text":"<p>Validate the model json string</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The json string to validate</p> required <code>interface</code> <code>DataInterface</code> <p>By default, the interface will be inferred and instantiated from the interface metadata. If an interface is provided (as in the case of custom interfaces), it will be used.</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str, interface: Optional[DataInterface] = None) -&gt; \"ModelCard\":\n    \"\"\"Validate the model json string\n\n    Args:\n        json_string (str):\n            The json string to validate\n        interface (DataInterface):\n            By default, the interface will be inferred and instantiated\n            from the interface metadata. If an interface is provided\n            (as in the case of custom interfaces), it will be used.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.DataCard.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Save the data card</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to save the data card to</p> required <code>save_kwargs</code> <code>DataSaveKwargs | None</code> <p>Optional save kwargs to that will be passed to the data interface save method</p> <code>None</code> Acceptable save kwargs <p>Kwargs are passed to the underlying data interface for saving. For a complete list of options see the save method of the data interface and their associated libraries.</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def save(\n    self,\n    path: Path,\n    save_kwargs: Optional[DataSaveKwargs] = None,\n) -&gt; None:\n    \"\"\"Save the data card\n\n    Args:\n        path (Path):\n            The path to save the data card to\n        save_kwargs (DataSaveKwargs | None):\n            Optional save kwargs to that will be passed to the\n            data interface save method\n\n    Acceptable save kwargs:\n        Kwargs are passed to the underlying data interface for saving.\n        For a complete list of options see the save method of the data interface and\n        their associated libraries.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.DataCardMetadata","title":"<code>DataCardMetadata</code>","text":"Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class DataCardMetadata:\n    @property\n    def schema(self) -&gt; FeatureSchema:\n        \"\"\"Return the feature map\"\"\"\n\n    @property\n    def experimentcard_uid(self) -&gt; Optional[str]:\n        \"\"\"Return the experimentcard uid\"\"\"\n\n    @property\n    def auditcard_uid(self) -&gt; Optional[str]:\n        \"\"\"Return the experimentcard uid\"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.DataCardMetadata.auditcard_uid","title":"<code>auditcard_uid</code>  <code>property</code>","text":"<p>Return the experimentcard uid</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCardMetadata.experimentcard_uid","title":"<code>experimentcard_uid</code>  <code>property</code>","text":"<p>Return the experimentcard uid</p>"},{"location":"docs/api/cards/#opsml.card._card.DataCardMetadata.schema","title":"<code>schema</code>  <code>property</code>","text":"<p>Return the feature map</p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard","title":"<code>ExperimentCard</code>","text":"Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class ExperimentCard:\n    def __init__(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        uid: Optional[str] = None,\n        tags: List[str] = [],\n    ) -&gt; None:\n        \"\"\"Instantiates a ExperimentCard.\n\n        Cards are stored in the ExperimentCard Registry and follow the naming convention of:\n        {registry}/{space}/{name}/v{version}\n\n        Args:\n            space (str | None):\n                space to associate with `ExperimentCard`\n            name (str | None):\n                Name to associate with `ExperimentCard`\n            version (str | None):\n                Current version (assigned if card has been registered). Follows\n                semantic versioning.\n            uid (str | None):\n                Unique id (assigned if card has been registered)\n            tags (List[str]):\n                Tags to associate with `ExperimentCard`. Can be a dictionary of strings or\n                a `Tags` object.\n\n        Example:\n        ```python\n        from opsml import start_experiment\n\n        # start an experiment\n        with start_experiment(space=\"test\", log_hardware=True) as exp:\n            exp.log_metric(\"accuracy\", 0.95)\n            exp.log_parameter(\"epochs\", 10)\n        ```\n        \"\"\"\n\n    def get_metrics(\n        self,\n        names: Optional[list[str]] = None,\n    ) -&gt; Metrics:\n        \"\"\"\n        Get metrics of an experiment\n\n        Args:\n            names (list[str] | None):\n                Names of the metrics to get. If None, all metrics will be returned.\n\n        Returns:\n            Metrics\n        \"\"\"\n\n    def get_parameters(\n        self,\n        names: Optional[list[str]] = None,\n    ) -&gt; Parameters:\n        \"\"\"\n        Get parameters of an experiment\n\n        Args:\n            names (list[str] | None):\n                Names of the parameters to get. If None, all parameters will be returned.\n\n        Returns:\n            Parameters\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Returns the name of the `ModelCard`\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set the name of the `ModelCard`\n\n        Args:\n            name (str):\n                The name of the `ModelCard`\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Returns the space of the `experimentcard`\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set the space of the `experimentcard`\n\n        Args:\n            space (str):\n                The space of the `experimentcard`\n        \"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Returns the version of the `experimentcard`\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set the version of the `experimentcard`\n\n        Args:\n            version (str):\n                The version of the `experimentcard`\n        \"\"\"\n\n    @property\n    def eval_metrics(self) -&gt; EvalMetrics:\n        \"\"\"Returns the eval metrics of the `experimentcard`\"\"\"\n\n    @eval_metrics.setter\n    def eval_metrics(self, metrics: EvalMetrics) -&gt; None:\n        \"\"\"Set the eval metrics of the `experimentcard`\n\n        Args:\n            metrics (EvalMetrics):\n                The eval metrics of the `experimentcard`\n        \"\"\"\n\n    @property\n    def uid(self) -&gt; str:\n        \"\"\"Returns the uid of the `experimentcard`\"\"\"\n\n    @property\n    def uids(self) -&gt; UidMetadata:\n        \"\"\"Returns the uids of the `experimentcard`\"\"\"\n\n    @property\n    def tags(self) -&gt; List[str]:\n        \"\"\"Returns the tags of the `ExperimentCard`\"\"\"\n\n    @property\n    def artifacts(self) -&gt; List[str]:\n        \"\"\"Returns the artifact names\"\"\"\n\n    @property\n    def compute_environment(self) -&gt; ComputeEnvironment:\n        \"\"\"Returns the compute env\"\"\"\n\n    @property\n    def registry_type(self) -&gt; RegistryType:\n        \"\"\"Returns the card type of the `experimentcard`\"\"\"\n\n    @property\n    def app_env(self) -&gt; str:\n        \"\"\"Returns the app env\"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime:\n        \"\"\"Returns the created at timestamp\"\"\"\n\n    def add_child_experiment(self, uid: str) -&gt; None:\n        \"\"\"Add a child experiment to the experiment card\n\n        Args:\n            uid (str):\n                The experiment card uid to add\n        \"\"\"\n\n    def list_artifacts(self, path: Optional[Path]) -&gt; List[str]:\n        \"\"\"List the artifacts associated with the experiment card\n\n        Args:\n            path (Path):\n                Specific path you wish to list artifacts from. If not provided,\n                all artifacts will be listed.\n\n                Example:\n                    You logged artifacts with the following paths:\n                    - \"data/processed/my_data.csv\"\n                    - \"model/my_model.pkl\"\n\n                    If you wanted to list all artifacts in the \"data\" directory,\n                    you would pass Path(\"data\") as the path.\n        \"\"\"\n\n    def download_artifacts(\n        self,\n        path: Optional[Path] = None,\n        lpath: Optional[Path] = None,\n    ) -&gt; None:\n        \"\"\"Download artifacts associated with the ExperimentCard\n\n        Args:\n            path (Path | None):\n                Specific path you wish to download artifacts from. If not provided,\n                all artifacts will be downloaded.\n\n            lpath (Path | None):\n                Local path to save the artifacts. If not provided, the artifacts will be saved\n                to a directory called \"artifacts\"\n        \"\"\"\n\n    def download_artifact(\n        path: Path,\n        lpath: Optional[Path] = None,\n    ) -&gt; None:\n        \"\"\"Download a specific artifact associated with the ExperimentCard\n\n        Args:\n            path (Path):\n                Path to the artifact to download\n            lpath (Path | None):\n                Local path to save the artifact. If not provided, the artifact will be saved\n                to a directory called \"artifacts\"\n\n        Examples:\n\n        ```python\n        # artifact logged to artifacts/data.csv\n        download_artifact(Path(\"artifacts/data.csv\"))\n        #or\n        download_artifact(Path(\"data.csv\"))\n        ```\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"ExperimentCard\":\n        \"\"\"Load card from json string\n\n        Args:\n            json_string (str):\n                The json string to validate\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the `ExperimentCard`.\n\n        Returns:\n            String representation of the ModelCard.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.app_env","title":"<code>app_env</code>  <code>property</code>","text":"<p>Returns the app env</p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.artifacts","title":"<code>artifacts</code>  <code>property</code>","text":"<p>Returns the artifact names</p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.compute_environment","title":"<code>compute_environment</code>  <code>property</code>","text":"<p>Returns the compute env</p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Returns the created at timestamp</p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.eval_metrics","title":"<code>eval_metrics</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the eval metrics of the <code>experimentcard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the name of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.registry_type","title":"<code>registry_type</code>  <code>property</code>","text":"<p>Returns the card type of the <code>experimentcard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the space of the <code>experimentcard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.tags","title":"<code>tags</code>  <code>property</code>","text":"<p>Returns the tags of the <code>ExperimentCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.uid","title":"<code>uid</code>  <code>property</code>","text":"<p>Returns the uid of the <code>experimentcard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.uids","title":"<code>uids</code>  <code>property</code>","text":"<p>Returns the uids of the <code>experimentcard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the version of the <code>experimentcard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.__init__","title":"<code>__init__(space=None, name=None, version=None, uid=None, tags=[])</code>","text":"<p>Instantiates a ExperimentCard.</p> <p>Cards are stored in the ExperimentCard Registry and follow the naming convention of: {registry}/{space}/{name}/v{version}</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str | None</code> <p>space to associate with <code>ExperimentCard</code></p> <code>None</code> <code>name</code> <code>str | None</code> <p>Name to associate with <code>ExperimentCard</code></p> <code>None</code> <code>version</code> <code>str | None</code> <p>Current version (assigned if card has been registered). Follows semantic versioning.</p> <code>None</code> <code>uid</code> <code>str | None</code> <p>Unique id (assigned if card has been registered)</p> <code>None</code> <code>tags</code> <code>List[str]</code> <p>Tags to associate with <code>ExperimentCard</code>. Can be a dictionary of strings or a <code>Tags</code> object.</p> <code>[]</code> <p>Example: <pre><code>from opsml import start_experiment\n\n# start an experiment\nwith start_experiment(space=\"test\", log_hardware=True) as exp:\n    exp.log_metric(\"accuracy\", 0.95)\n    exp.log_parameter(\"epochs\", 10)\n</code></pre></p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __init__(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    uid: Optional[str] = None,\n    tags: List[str] = [],\n) -&gt; None:\n    \"\"\"Instantiates a ExperimentCard.\n\n    Cards are stored in the ExperimentCard Registry and follow the naming convention of:\n    {registry}/{space}/{name}/v{version}\n\n    Args:\n        space (str | None):\n            space to associate with `ExperimentCard`\n        name (str | None):\n            Name to associate with `ExperimentCard`\n        version (str | None):\n            Current version (assigned if card has been registered). Follows\n            semantic versioning.\n        uid (str | None):\n            Unique id (assigned if card has been registered)\n        tags (List[str]):\n            Tags to associate with `ExperimentCard`. Can be a dictionary of strings or\n            a `Tags` object.\n\n    Example:\n    ```python\n    from opsml import start_experiment\n\n    # start an experiment\n    with start_experiment(space=\"test\", log_hardware=True) as exp:\n        exp.log_metric(\"accuracy\", 0.95)\n        exp.log_parameter(\"epochs\", 10)\n    ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the <code>ExperimentCard</code>.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the ModelCard.</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the `ExperimentCard`.\n\n    Returns:\n        String representation of the ModelCard.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.add_child_experiment","title":"<code>add_child_experiment(uid)</code>","text":"<p>Add a child experiment to the experiment card</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>The experiment card uid to add</p> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def add_child_experiment(self, uid: str) -&gt; None:\n    \"\"\"Add a child experiment to the experiment card\n\n    Args:\n        uid (str):\n            The experiment card uid to add\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.download_artifact","title":"<code>download_artifact(path, lpath=None)</code>","text":"<p>Download a specific artifact associated with the ExperimentCard</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the artifact to download</p> required <code>lpath</code> <code>Path | None</code> <p>Local path to save the artifact. If not provided, the artifact will be saved to a directory called \"artifacts\"</p> <code>None</code> <p>Examples:</p> <pre><code># artifact logged to artifacts/data.csv\ndownload_artifact(Path(\"artifacts/data.csv\"))\n#or\ndownload_artifact(Path(\"data.csv\"))\n</code></pre> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def download_artifact(\n    path: Path,\n    lpath: Optional[Path] = None,\n) -&gt; None:\n    \"\"\"Download a specific artifact associated with the ExperimentCard\n\n    Args:\n        path (Path):\n            Path to the artifact to download\n        lpath (Path | None):\n            Local path to save the artifact. If not provided, the artifact will be saved\n            to a directory called \"artifacts\"\n\n    Examples:\n\n    ```python\n    # artifact logged to artifacts/data.csv\n    download_artifact(Path(\"artifacts/data.csv\"))\n    #or\n    download_artifact(Path(\"data.csv\"))\n    ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.download_artifacts","title":"<code>download_artifacts(path=None, lpath=None)</code>","text":"<p>Download artifacts associated with the ExperimentCard</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | None</code> <p>Specific path you wish to download artifacts from. If not provided, all artifacts will be downloaded.</p> <code>None</code> <code>lpath</code> <code>Path | None</code> <p>Local path to save the artifacts. If not provided, the artifacts will be saved to a directory called \"artifacts\"</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def download_artifacts(\n    self,\n    path: Optional[Path] = None,\n    lpath: Optional[Path] = None,\n) -&gt; None:\n    \"\"\"Download artifacts associated with the ExperimentCard\n\n    Args:\n        path (Path | None):\n            Specific path you wish to download artifacts from. If not provided,\n            all artifacts will be downloaded.\n\n        lpath (Path | None):\n            Local path to save the artifacts. If not provided, the artifacts will be saved\n            to a directory called \"artifacts\"\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.get_metrics","title":"<code>get_metrics(names=None)</code>","text":"<p>Get metrics of an experiment</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>list[str] | None</code> <p>Names of the metrics to get. If None, all metrics will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <code>Metrics</code> <p>Metrics</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def get_metrics(\n    self,\n    names: Optional[list[str]] = None,\n) -&gt; Metrics:\n    \"\"\"\n    Get metrics of an experiment\n\n    Args:\n        names (list[str] | None):\n            Names of the metrics to get. If None, all metrics will be returned.\n\n    Returns:\n        Metrics\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.get_parameters","title":"<code>get_parameters(names=None)</code>","text":"<p>Get parameters of an experiment</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>list[str] | None</code> <p>Names of the parameters to get. If None, all parameters will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <code>Parameters</code> <p>Parameters</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def get_parameters(\n    self,\n    names: Optional[list[str]] = None,\n) -&gt; Parameters:\n    \"\"\"\n    Get parameters of an experiment\n\n    Args:\n        names (list[str] | None):\n            Names of the parameters to get. If None, all parameters will be returned.\n\n    Returns:\n        Parameters\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.list_artifacts","title":"<code>list_artifacts(path)</code>","text":"<p>List the artifacts associated with the experiment card</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Specific path you wish to list artifacts from. If not provided, all artifacts will be listed.</p> <p>Example:     You logged artifacts with the following paths:     - \"data/processed/my_data.csv\"     - \"model/my_model.pkl\"</p> <pre><code>If you wanted to list all artifacts in the \"data\" directory,\nyou would pass Path(\"data\") as the path.\n</code></pre> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def list_artifacts(self, path: Optional[Path]) -&gt; List[str]:\n    \"\"\"List the artifacts associated with the experiment card\n\n    Args:\n        path (Path):\n            Specific path you wish to list artifacts from. If not provided,\n            all artifacts will be listed.\n\n            Example:\n                You logged artifacts with the following paths:\n                - \"data/processed/my_data.csv\"\n                - \"model/my_model.pkl\"\n\n                If you wanted to list all artifacts in the \"data\" directory,\n                you would pass Path(\"data\") as the path.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ExperimentCard.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load card from json string</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The json string to validate</p> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"ExperimentCard\":\n    \"\"\"Load card from json string\n\n    Args:\n        json_string (str):\n            The json string to validate\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard","title":"<code>ModelCard</code>","text":"Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class ModelCard:\n    def __init__(\n        self,\n        interface: Optional[ModelInterface] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        uid: Optional[str] = None,\n        tags: List[str] = [],\n        datacard_uid: Optional[str] = None,\n        metadata: ModelCardMetadata = ModelCardMetadata(),\n    ) -&gt; None:\n        \"\"\"Create a ModelCard from a machine learning model.\n\n        Cards are stored in the ModelCardRegistry and follow the naming convention of:\n        {registry}/{space}/{name}/v{version}\n\n        Args:\n            interface (ModelInterface | None):\n                `ModelInterface` class containing trained model\n            space (str | None):\n                space to associate with `ModelCard`\n            name (str | None):\n                Name to associate with `ModelCard`\n            version (str | None):\n                Current version (assigned if card has been registered). Follows\n                semantic versioning.\n            uid (str | None):\n                Unique id (assigned if card has been registered)\n            tags (List[str]):\n                Tags to associate with `ModelCard`. Can be a dictionary of strings or\n                a `Tags` object.\n            datacard_uid (str | None):\n                The datacard uid to associate with the model card. This is used to link the\n                model card to the data card. Datacard uid can also be set in card metadata.\n            metadata (ModelCardMetadata):\n                Metadata to associate with the `ModelCard. Defaults to an empty `ModelCardMetadata` object.\n\n        Example:\n        ```python\n        from opsml import ModelCard, CardRegistry, RegistryType, SklearnModel, TaskType\n        from sklearn import ensemble\n\n        # for testing purposes\n        from opsml.helpers.data import create_fake_data\n\n        # pandas data\n        X, y = create_fake_data(n_samples=1200)\n\n        # train model\n        reg = ensemble.RandomForestClassifier(n_estimators=5)\n        reg.fit(X_train.to_numpy(), y_train)\n\n        # create interface and card\n        interface = SklearnModel(\n            model=reg,\n            sample_data=X_train,\n            task_type=TaskType.Classification,\n        )\n\n        modelcard = ModelCard(\n            interface=random_forest_classifier,\n            space=\"my-repo\",\n            name=\"my-model\",\n            tags=[\"foo:bar\", \"baz:qux\"],\n        )\n\n        # register card\n        registry = CardRegistry(RegistryType.Model, save_kwargs=ModelSaveKwargs(save_onnx=True)) # convert to onnx\n        registry.register_card(modelcard)\n        ```\n        \"\"\"\n\n    @property\n    def model(self) -&gt; Any:\n        \"\"\"Returns the model. This is a special property that is used to\n        access the model from the interface. It is not settable. It will also\n        raise an error if the interface is not set or if the model\n        has not been loaded.\n        \"\"\"\n\n    @property\n    def onnx_session(self) -&gt; Optional[OnnxSession]:\n        \"\"\"Returns the onnx session. This is a special property that is used to\n        access the onnx session from the interface. It is not settable. It will also\n        raise an error if the interface is not set or if the model\n        has not been loaded.\n        \"\"\"\n\n    @property\n    def app_env(self) -&gt; str:\n        \"\"\"Returns the app env\"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime:\n        \"\"\"Returns the created at timestamp\"\"\"\n\n    @property\n    def datacard_uid(self) -&gt; str:\n        \"\"\"Returns the datacard uid\"\"\"\n\n    @datacard_uid.setter\n    def datacard_uid(self, datacard_uid: str) -&gt; None:\n        \"\"\"Set the datacard uid\"\"\"\n\n    @property\n    def experimentcard_uid(self) -&gt; str:\n        \"\"\"Returns the experimentcard uid\"\"\"\n\n    @experimentcard_uid.setter\n    def experimentcard_uid(self, experimentcard_uid: str) -&gt; None:\n        \"\"\"Set the experimentcard uid\"\"\"\n\n    @property\n    def uri(self) -&gt; Path:\n        \"\"\"Returns the uri of the `ModelCard` in the\n        format of {registry}/{space}/{name}/v{version}\n        \"\"\"\n\n    @property\n    def interface(self) -&gt; Optional[ModelInterface]:\n        \"\"\"Returns the `ModelInterface` associated with the `ModelCard`\"\"\"\n\n    @interface.setter\n    def interface(self, interface: Any) -&gt; None:\n        \"\"\"Set the `ModelInterface` associated with the `ModelCard`\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Returns the name of the `ModelCard`\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set the name of the `ModelCard`\n\n        Args:\n            name (str):\n                The name of the `ModelCard`\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Returns the space of the `ModelCard`\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set the space of the `ModelCard`\n\n        Args:\n            space (str):\n                The space of the `ModelCard`\n        \"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Returns the version of the `ModelCard`\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set the version of the `ModelCard`\n\n        Args:\n            version (str):\n                The version of the `ModelCard`\n        \"\"\"\n\n    @property\n    def uid(self) -&gt; str:\n        \"\"\"Returns the uid of the `ModelCard`\"\"\"\n\n    @property\n    def tags(self) -&gt; List[str]:\n        \"\"\"Returns the tags of the `ModelCard`\"\"\"\n\n    @property\n    def metadata(self) -&gt; ModelCardMetadata:\n        \"\"\"Returns the metadata of the `ModelCard`\"\"\"\n\n    @property\n    def registry_type(self) -&gt; RegistryType:\n        \"\"\"Returns the card type of the `ModelCard`\"\"\"\n\n    def save(self, path: Path, save_kwargs: Optional[ModelSaveKwargs] = None) -&gt; None:\n        \"\"\"Save the model card to a directory\n\n        Args:\n            path (Path):\n                Path to save the model card.\n            save_kwargs (SaveKwargs):\n                Optional kwargs to pass to `ModelInterface` save method.\n        \"\"\"\n\n    def load(\n        self,\n        path: Optional[Path] = None,\n        load_kwargs: None | ModelLoadKwargs = None,\n    ) -&gt; None:\n        \"\"\"Load ModelCard interface components\n\n        Args:\n            path (Path | None):\n                The path to load the data card from. If no path is provided,\n                the model interface will be loaded from the server.\n            load_kwargs (ModelLoadKwargs):\n                Optional kwargs to pass to `ModelInterface` load method.\n        \"\"\"\n\n    @staticmethod\n    def load_from_path(\n        path: Path,\n        load_kwargs: None | ModelLoadKwargs = None,\n        interface: Optional[ModelInterface] = None,\n    ) -&gt; \"ModelCard\":\n        \"\"\"Staticmethod to load a ModelCard from a path. Typically used when\n        a `ModelCard`s artifacts have already been downloaded to a path.\n\n        This is commonly used in API workflows where a user may download artifacts to\n        a directory and load the contents during API/Application startup.\n\n        Args:\n            path (Path):\n                The path to load the ModelCard from.\n            load_kwargs (ModelLoadKwargs):\n                Optional kwargs to pass to `ModelInterface` load method.\n            interface (ModelInterface):\n                Optional interface for the model. Used with Custom interfaces.\n\n        Returns:\n            ModelCard:\n                The loaded ModelCard.\n\n        Example:\n\n            ```python\n            # shell command\n            opsml run get model --space &lt;space_name&gt; --name &lt;model_name&gt; --write-dir &lt;path&gt;\n\n            # Within python application\n            model_card = ModelCard.load_from_path(&lt;path&gt;)\n            ```\n        \"\"\"\n\n    def download_artifacts(self, path: Optional[Path] = None) -&gt; None:\n        \"\"\"Download artifacts associated with the ModelCard\n\n        Args:\n            path (Path):\n                Path to save the artifacts. If not provided, the artifacts will be saved\n                to a directory called \"card_artifacts\"\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the model dump as a json string\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str, interface: Optional[ModelInterface] = None) -&gt; \"ModelCard\":\n        \"\"\"Validate the model json string\n\n        Args:\n            json_string (str):\n                The json string to validate\n            interface (ModelInterface):\n                By default, the interface will be inferred and instantiated\n                from the interface metadata. If an interface is provided\n                (as in the case of custom interfaces), it will be used.\n        \"\"\"\n\n    def drift_profile_path(self, alias: str) -&gt; Path:\n        \"\"\"Helper method that returns the path to a specific drift profile.\n        This method will fail if there is no drift profile map or the alias\n        does not exist.\n\n        Args:\n            alias (str):\n                The alias of the drift profile\n\n        Returns:\n            Path to the drift profile\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the ModelCard.\n\n        Returns:\n            String representation of the ModelCard.\n        \"\"\"\n\n    @property\n    def drift_profile(self) -&gt; DriftProfileMap:\n        \"\"\"Return the drift profile map from the model interface.\n\n        Returns:\n            DriftProfileMap\n        \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.app_env","title":"<code>app_env</code>  <code>property</code>","text":"<p>Returns the app env</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Returns the created at timestamp</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.datacard_uid","title":"<code>datacard_uid</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the datacard uid</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.drift_profile","title":"<code>drift_profile</code>  <code>property</code>","text":"<p>Return the drift profile map from the model interface.</p> <p>Returns:</p> Type Description <code>DriftProfileMap</code> <p>DriftProfileMap</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.experimentcard_uid","title":"<code>experimentcard_uid</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the experimentcard uid</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.interface","title":"<code>interface</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the <code>ModelInterface</code> associated with the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.metadata","title":"<code>metadata</code>  <code>property</code>","text":"<p>Returns the metadata of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.model","title":"<code>model</code>  <code>property</code>","text":"<p>Returns the model. This is a special property that is used to access the model from the interface. It is not settable. It will also raise an error if the interface is not set or if the model has not been loaded.</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the name of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.onnx_session","title":"<code>onnx_session</code>  <code>property</code>","text":"<p>Returns the onnx session. This is a special property that is used to access the onnx session from the interface. It is not settable. It will also raise an error if the interface is not set or if the model has not been loaded.</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.registry_type","title":"<code>registry_type</code>  <code>property</code>","text":"<p>Returns the card type of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the space of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.tags","title":"<code>tags</code>  <code>property</code>","text":"<p>Returns the tags of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.uid","title":"<code>uid</code>  <code>property</code>","text":"<p>Returns the uid of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.uri","title":"<code>uri</code>  <code>property</code>","text":"<p>Returns the uri of the <code>ModelCard</code> in the format of {registry}/{space}/{name}/v{version}</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the version of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.__init__","title":"<code>__init__(interface=None, space=None, name=None, version=None, uid=None, tags=[], datacard_uid=None, metadata=ModelCardMetadata())</code>","text":"<p>Create a ModelCard from a machine learning model.</p> <p>Cards are stored in the ModelCardRegistry and follow the naming convention of: {registry}/{space}/{name}/v{version}</p> <p>Parameters:</p> Name Type Description Default <code>interface</code> <code>ModelInterface | None</code> <p><code>ModelInterface</code> class containing trained model</p> <code>None</code> <code>space</code> <code>str | None</code> <p>space to associate with <code>ModelCard</code></p> <code>None</code> <code>name</code> <code>str | None</code> <p>Name to associate with <code>ModelCard</code></p> <code>None</code> <code>version</code> <code>str | None</code> <p>Current version (assigned if card has been registered). Follows semantic versioning.</p> <code>None</code> <code>uid</code> <code>str | None</code> <p>Unique id (assigned if card has been registered)</p> <code>None</code> <code>tags</code> <code>List[str]</code> <p>Tags to associate with <code>ModelCard</code>. Can be a dictionary of strings or a <code>Tags</code> object.</p> <code>[]</code> <code>datacard_uid</code> <code>str | None</code> <p>The datacard uid to associate with the model card. This is used to link the model card to the data card. Datacard uid can also be set in card metadata.</p> <code>None</code> <code>metadata</code> <code>ModelCardMetadata</code> <p>Metadata to associate with the <code>ModelCard. Defaults to an empty</code>ModelCardMetadata` object.</p> <code>ModelCardMetadata()</code> <p>Example: <pre><code>from opsml import ModelCard, CardRegistry, RegistryType, SklearnModel, TaskType\nfrom sklearn import ensemble\n\n# for testing purposes\nfrom opsml.helpers.data import create_fake_data\n\n# pandas data\nX, y = create_fake_data(n_samples=1200)\n\n# train model\nreg = ensemble.RandomForestClassifier(n_estimators=5)\nreg.fit(X_train.to_numpy(), y_train)\n\n# create interface and card\ninterface = SklearnModel(\n    model=reg,\n    sample_data=X_train,\n    task_type=TaskType.Classification,\n)\n\nmodelcard = ModelCard(\n    interface=random_forest_classifier,\n    space=\"my-repo\",\n    name=\"my-model\",\n    tags=[\"foo:bar\", \"baz:qux\"],\n)\n\n# register card\nregistry = CardRegistry(RegistryType.Model, save_kwargs=ModelSaveKwargs(save_onnx=True)) # convert to onnx\nregistry.register_card(modelcard)\n</code></pre></p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __init__(\n    self,\n    interface: Optional[ModelInterface] = None,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    uid: Optional[str] = None,\n    tags: List[str] = [],\n    datacard_uid: Optional[str] = None,\n    metadata: ModelCardMetadata = ModelCardMetadata(),\n) -&gt; None:\n    \"\"\"Create a ModelCard from a machine learning model.\n\n    Cards are stored in the ModelCardRegistry and follow the naming convention of:\n    {registry}/{space}/{name}/v{version}\n\n    Args:\n        interface (ModelInterface | None):\n            `ModelInterface` class containing trained model\n        space (str | None):\n            space to associate with `ModelCard`\n        name (str | None):\n            Name to associate with `ModelCard`\n        version (str | None):\n            Current version (assigned if card has been registered). Follows\n            semantic versioning.\n        uid (str | None):\n            Unique id (assigned if card has been registered)\n        tags (List[str]):\n            Tags to associate with `ModelCard`. Can be a dictionary of strings or\n            a `Tags` object.\n        datacard_uid (str | None):\n            The datacard uid to associate with the model card. This is used to link the\n            model card to the data card. Datacard uid can also be set in card metadata.\n        metadata (ModelCardMetadata):\n            Metadata to associate with the `ModelCard. Defaults to an empty `ModelCardMetadata` object.\n\n    Example:\n    ```python\n    from opsml import ModelCard, CardRegistry, RegistryType, SklearnModel, TaskType\n    from sklearn import ensemble\n\n    # for testing purposes\n    from opsml.helpers.data import create_fake_data\n\n    # pandas data\n    X, y = create_fake_data(n_samples=1200)\n\n    # train model\n    reg = ensemble.RandomForestClassifier(n_estimators=5)\n    reg.fit(X_train.to_numpy(), y_train)\n\n    # create interface and card\n    interface = SklearnModel(\n        model=reg,\n        sample_data=X_train,\n        task_type=TaskType.Classification,\n    )\n\n    modelcard = ModelCard(\n        interface=random_forest_classifier,\n        space=\"my-repo\",\n        name=\"my-model\",\n        tags=[\"foo:bar\", \"baz:qux\"],\n    )\n\n    # register card\n    registry = CardRegistry(RegistryType.Model, save_kwargs=ModelSaveKwargs(save_onnx=True)) # convert to onnx\n    registry.register_card(modelcard)\n    ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the ModelCard.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the ModelCard.</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the ModelCard.\n\n    Returns:\n        String representation of the ModelCard.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.download_artifacts","title":"<code>download_artifacts(path=None)</code>","text":"<p>Download artifacts associated with the ModelCard</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to save the artifacts. If not provided, the artifacts will be saved to a directory called \"card_artifacts\"</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def download_artifacts(self, path: Optional[Path] = None) -&gt; None:\n    \"\"\"Download artifacts associated with the ModelCard\n\n    Args:\n        path (Path):\n            Path to save the artifacts. If not provided, the artifacts will be saved\n            to a directory called \"card_artifacts\"\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.drift_profile_path","title":"<code>drift_profile_path(alias)</code>","text":"<p>Helper method that returns the path to a specific drift profile. This method will fail if there is no drift profile map or the alias does not exist.</p> <p>Parameters:</p> Name Type Description Default <code>alias</code> <code>str</code> <p>The alias of the drift profile</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the drift profile</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def drift_profile_path(self, alias: str) -&gt; Path:\n    \"\"\"Helper method that returns the path to a specific drift profile.\n    This method will fail if there is no drift profile map or the alias\n    does not exist.\n\n    Args:\n        alias (str):\n            The alias of the drift profile\n\n    Returns:\n        Path to the drift profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.load","title":"<code>load(path=None, load_kwargs=None)</code>","text":"<p>Load ModelCard interface components</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | None</code> <p>The path to load the data card from. If no path is provided, the model interface will be loaded from the server.</p> <code>None</code> <code>load_kwargs</code> <code>ModelLoadKwargs</code> <p>Optional kwargs to pass to <code>ModelInterface</code> load method.</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def load(\n    self,\n    path: Optional[Path] = None,\n    load_kwargs: None | ModelLoadKwargs = None,\n) -&gt; None:\n    \"\"\"Load ModelCard interface components\n\n    Args:\n        path (Path | None):\n            The path to load the data card from. If no path is provided,\n            the model interface will be loaded from the server.\n        load_kwargs (ModelLoadKwargs):\n            Optional kwargs to pass to `ModelInterface` load method.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.load_from_path","title":"<code>load_from_path(path, load_kwargs=None, interface=None)</code>  <code>staticmethod</code>","text":"<p>Staticmethod to load a ModelCard from a path. Typically used when a <code>ModelCard</code>s artifacts have already been downloaded to a path.</p> <p>This is commonly used in API workflows where a user may download artifacts to a directory and load the contents during API/Application startup.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to load the ModelCard from.</p> required <code>load_kwargs</code> <code>ModelLoadKwargs</code> <p>Optional kwargs to pass to <code>ModelInterface</code> load method.</p> <code>None</code> <code>interface</code> <code>ModelInterface</code> <p>Optional interface for the model. Used with Custom interfaces.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ModelCard</code> <code>ModelCard</code> <p>The loaded ModelCard.</p> <p>Example:</p> <pre><code>```python\n# shell command\nopsml run get model --space &lt;space_name&gt; --name &lt;model_name&gt; --write-dir &lt;path&gt;\n\n# Within python application\nmodel_card = ModelCard.load_from_path(&lt;path&gt;)\n```\n</code></pre> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>@staticmethod\ndef load_from_path(\n    path: Path,\n    load_kwargs: None | ModelLoadKwargs = None,\n    interface: Optional[ModelInterface] = None,\n) -&gt; \"ModelCard\":\n    \"\"\"Staticmethod to load a ModelCard from a path. Typically used when\n    a `ModelCard`s artifacts have already been downloaded to a path.\n\n    This is commonly used in API workflows where a user may download artifacts to\n    a directory and load the contents during API/Application startup.\n\n    Args:\n        path (Path):\n            The path to load the ModelCard from.\n        load_kwargs (ModelLoadKwargs):\n            Optional kwargs to pass to `ModelInterface` load method.\n        interface (ModelInterface):\n            Optional interface for the model. Used with Custom interfaces.\n\n    Returns:\n        ModelCard:\n            The loaded ModelCard.\n\n    Example:\n\n        ```python\n        # shell command\n        opsml run get model --space &lt;space_name&gt; --name &lt;model_name&gt; --write-dir &lt;path&gt;\n\n        # Within python application\n        model_card = ModelCard.load_from_path(&lt;path&gt;)\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the model dump as a json string</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the model dump as a json string\"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.model_validate_json","title":"<code>model_validate_json(json_string, interface=None)</code>  <code>staticmethod</code>","text":"<p>Validate the model json string</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The json string to validate</p> required <code>interface</code> <code>ModelInterface</code> <p>By default, the interface will be inferred and instantiated from the interface metadata. If an interface is provided (as in the case of custom interfaces), it will be used.</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str, interface: Optional[ModelInterface] = None) -&gt; \"ModelCard\":\n    \"\"\"Validate the model json string\n\n    Args:\n        json_string (str):\n            The json string to validate\n        interface (ModelInterface):\n            By default, the interface will be inferred and instantiated\n            from the interface metadata. If an interface is provided\n            (as in the case of custom interfaces), it will be used.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCard.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Save the model card to a directory</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to save the model card.</p> required <code>save_kwargs</code> <code>SaveKwargs</code> <p>Optional kwargs to pass to <code>ModelInterface</code> save method.</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def save(self, path: Path, save_kwargs: Optional[ModelSaveKwargs] = None) -&gt; None:\n    \"\"\"Save the model card to a directory\n\n    Args:\n        path (Path):\n            Path to save the model card.\n        save_kwargs (SaveKwargs):\n            Optional kwargs to pass to `ModelInterface` save method.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCardMetadata","title":"<code>ModelCardMetadata</code>","text":"Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class ModelCardMetadata:\n    def __init__(\n        self,\n        datacard_uid: Optional[str] = None,\n        experimentcard_uid: Optional[str] = None,\n        auditcard_uid: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Create a ModelCardMetadata object\n\n        Args:\n            datacard_uid (str | None):\n                The datacard uid\n            experimentcard_uid (str | None):\n                The experimentcard uid\n            auditcard_uid (str | None):\n                The auditcard uid\n        \"\"\"\n\n    @property\n    def datacard_uid(self) -&gt; str:\n        \"\"\"Returns the datacard uid\"\"\"\n\n    @datacard_uid.setter\n    def datacard_uid(self, datacard_uid: str) -&gt; None:\n        \"\"\"Set the datacard uid\"\"\"\n\n    @property\n    def experimentcard_uid(self) -&gt; str:\n        \"\"\"Returns the experimentcard uid\"\"\"\n\n    @experimentcard_uid.setter\n    def experimentcard_uid(self, experimentcard_uid: str) -&gt; None:\n        \"\"\"Set the experimentcard uid\"\"\"\n\n    @property\n    def auditcard_uid(self) -&gt; str:\n        \"\"\"Returns the experimentcard uid\"\"\"\n\n    @auditcard_uid.setter\n    def auditcard_uid(self, auditcard_uid: str) -&gt; None:\n        \"\"\"Set the experimentcard uid\"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ModelCardMetadata.auditcard_uid","title":"<code>auditcard_uid</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the experimentcard uid</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCardMetadata.datacard_uid","title":"<code>datacard_uid</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the datacard uid</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCardMetadata.experimentcard_uid","title":"<code>experimentcard_uid</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the experimentcard uid</p>"},{"location":"docs/api/cards/#opsml.card._card.ModelCardMetadata.__init__","title":"<code>__init__(datacard_uid=None, experimentcard_uid=None, auditcard_uid=None)</code>","text":"<p>Create a ModelCardMetadata object</p> <p>Parameters:</p> Name Type Description Default <code>datacard_uid</code> <code>str | None</code> <p>The datacard uid</p> <code>None</code> <code>experimentcard_uid</code> <code>str | None</code> <p>The experimentcard uid</p> <code>None</code> <code>auditcard_uid</code> <code>str | None</code> <p>The auditcard uid</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __init__(\n    self,\n    datacard_uid: Optional[str] = None,\n    experimentcard_uid: Optional[str] = None,\n    auditcard_uid: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Create a ModelCardMetadata object\n\n    Args:\n        datacard_uid (str | None):\n            The datacard uid\n        experimentcard_uid (str | None):\n            The experimentcard uid\n        auditcard_uid (str | None):\n            The auditcard uid\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard","title":"<code>PromptCard</code>","text":"Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class PromptCard:\n    def __init__(\n        self,\n        prompt: Prompt,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        uid: Optional[str] = None,\n        tags: List[str] = [],\n        drift_profile: Optional[Dict[str, LLMDriftProfile]] = None,\n    ) -&gt; None:\n        \"\"\"Creates a `PromptCard`.\n\n        Cards are stored in the PromptCard Registry and follow the naming convention of:\n        {registry}/{space}/{name}/v{version}\n\n\n        Args:\n            prompt (Prompt):\n                Prompt to associate with `PromptCard`\n            space (str | None):\n                space to associate with `PromptCard`\n            name (str | None):\n                Name to associate with `PromptCard`\n            version (str | None):\n                Current version (assigned if card has been registered). Follows\n                semantic versioning.\n            uid (str | None):\n                Unique id (assigned if card has been registered)\n            tags (List[str]):\n                Tags to associate with `PromptCard`. Can be a dictionary of strings or\n                a `Tags` object.\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile. Currently supports LLM drift profiles.\n        Example:\n        ```python\n        from opsml import Prompt, PromptCard, CardRegistry, RegistryType\n\n        # create prompt\n        prompt = Prompt(\n            model=\"openai:gpt-4o\",\n            message=[\n                \"My prompt $1 is $2\",\n                \"My prompt $3 is $4\",\n            ],\n            system_instruction=\"system_prompt\",\n        )\n\n        # create card\n        card = PromptCard(\n            prompt=prompt,\n            space=\"my-repo\",\n            name=\"my-prompt\",\n            version=\"0.0.1\",\n            tags=[\"gpt-4o\", \"prompt\"],\n        )\n\n        # register card\n        registry = CardRegistry(RegistryType.Prompt)\n        registry.register_card(card)\n        ```\n        \"\"\"\n\n    @property\n    def prompt(self) -&gt; Prompt:\n        \"\"\"Returns the prompt\"\"\"\n\n    @prompt.setter\n    def prompt(self, prompt: Prompt) -&gt; None:\n        \"\"\"Set the prompt\n\n        Args:\n            prompt (Prompt):\n                The prompt to set\n        \"\"\"\n\n    @property\n    def experimentcard_uid(self) -&gt; str:\n        \"\"\"Returns the experimentcard uid\"\"\"\n\n    @experimentcard_uid.setter\n    def experimentcard_uid(self, experimentcard_uid: str) -&gt; None:\n        \"\"\"Set the experimentcard uid\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Returns the name of the `ModelCard`\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set the name of the `ModelCard`\n\n        Args:\n            name (str):\n                The name of the `ModelCard`\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Returns the space of the `ModelCard`\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set the space of the `ModelCard`\n\n        Args:\n            space (str):\n                The space of the `ModelCard`\n        \"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Returns the version of the `ModelCard`\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set the version of the `ModelCard`\n\n        Args:\n            version (str):\n                The version of the `ModelCard`\n        \"\"\"\n\n    @property\n    def uid(self) -&gt; str:\n        \"\"\"Returns the uid of the `ModelCard`\"\"\"\n\n    @property\n    def tags(self) -&gt; List[str]:\n        \"\"\"Returns the tags of the `ModelCard`\"\"\"\n\n    def save(self, path: Path) -&gt; None:\n        \"\"\"Save the `PromptCard` to a directory\n\n        Args:\n            path (Path):\n                Path to save the prompt card.\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"PromptCard\":\n        \"\"\"Load card from json string\n\n        Args:\n            json_string (str):\n                The json string to validate\n        \"\"\"\n\n    def __str__(self): ...\n    def create_drift_profile(\n        self,\n        alias: str,\n        config: LLMDriftConfig,\n        metrics: List[LLMDriftMetric],\n        workflow: Optional[Workflow] = None,\n    ) -&gt; None:\n        \"\"\"Create an LLMDriftProfile for LLM evaluation and drift detection.\n\n        LLM evaluations are run asynchronously on the scouter server.\n\n        Logic flow:\n            1. If only metrics are provided, a workflow will be created automatically\n               from the metrics. In this case a prompt is required for each metric.\n            2. If a workflow is provided, it will be parsed and validated for compatibility:\n               - A list of metrics to evaluate workflow output must be provided\n               - Metric names must correspond to the final task names in the workflow\n\n        Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n        Args:\n            config (LLMDriftConfig):\n                The configuration for the LLM drift profile containing space, name,\n                version, and alert settings.\n            metrics (list[LLMDriftMetric]):\n                A list of LLMDriftMetric objects representing the metrics to be monitored.\n                Each metric defines evaluation criteria and alert thresholds.\n            workflow (Optional[Workflow]):\n                Optional custom workflow for advanced evaluation scenarios. If provided,\n                the workflow will be validated to ensure proper parameter and response\n                type configuration.\n\n        Returns:\n            LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n        Raises:\n            ProfileError: If workflow validation fails, metrics are empty when no\n                workflow is provided, or if workflow tasks don't match metric names.\n\n        Examples:\n            Basic usage with metrics only:\n\n            &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n            &gt;&gt;&gt; metrics = [\n            ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n            ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n            ... ]\n            &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics)\n\n            Advanced usage with custom workflow:\n\n            &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n            &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n            &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics, workflow)\n\n        Note:\n            - When using custom workflows, ensure final tasks have Score response types\n            - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n            - All metric names must match corresponding workflow task names\n        \"\"\"\n\n    @property\n    def drift_profile(self) -&gt; DriftProfileMap:\n        \"\"\"Return the drift profile map from the model interface.\n\n        Returns:\n            DriftProfileMap\n        \"\"\"\n\n    @drift_profile.setter\n    def drift_profile(self, drift_profile: DriftProfileMap) -&gt; None:\n        \"\"\"Set the drift profile map for the prompt card.\n\n        Args:\n            drift_profile (DriftProfileMap):\n                The drift profile map to set.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.drift_profile","title":"<code>drift_profile</code>  <code>property</code> <code>writable</code>","text":"<p>Return the drift profile map from the model interface.</p> <p>Returns:</p> Type Description <code>DriftProfileMap</code> <p>DriftProfileMap</p>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.experimentcard_uid","title":"<code>experimentcard_uid</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the experimentcard uid</p>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the name of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.prompt","title":"<code>prompt</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the prompt</p>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the space of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.tags","title":"<code>tags</code>  <code>property</code>","text":"<p>Returns the tags of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.uid","title":"<code>uid</code>  <code>property</code>","text":"<p>Returns the uid of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the version of the <code>ModelCard</code></p>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.__init__","title":"<code>__init__(prompt, space=None, name=None, version=None, uid=None, tags=[], drift_profile=None)</code>","text":"<p>Creates a <code>PromptCard</code>.</p> <p>Cards are stored in the PromptCard Registry and follow the naming convention of: {registry}/{space}/{name}/v{version}</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>Prompt</code> <p>Prompt to associate with <code>PromptCard</code></p> required <code>space</code> <code>str | None</code> <p>space to associate with <code>PromptCard</code></p> <code>None</code> <code>name</code> <code>str | None</code> <p>Name to associate with <code>PromptCard</code></p> <code>None</code> <code>version</code> <code>str | None</code> <p>Current version (assigned if card has been registered). Follows semantic versioning.</p> <code>None</code> <code>uid</code> <code>str | None</code> <p>Unique id (assigned if card has been registered)</p> <code>None</code> <code>tags</code> <code>List[str]</code> <p>Tags to associate with <code>PromptCard</code>. Can be a dictionary of strings or a <code>Tags</code> object.</p> <code>[]</code> <code>drift_profile</code> <code>Optional[Dict[str, LLMDriftProfile]]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile. Currently supports LLM drift profiles.</p> <code>None</code> <p>Example: <pre><code>from opsml import Prompt, PromptCard, CardRegistry, RegistryType\n\n# create prompt\nprompt = Prompt(\n    model=\"openai:gpt-4o\",\n    message=[\n        \"My prompt $1 is $2\",\n        \"My prompt $3 is $4\",\n    ],\n    system_instruction=\"system_prompt\",\n)\n\n# create card\ncard = PromptCard(\n    prompt=prompt,\n    space=\"my-repo\",\n    name=\"my-prompt\",\n    version=\"0.0.1\",\n    tags=[\"gpt-4o\", \"prompt\"],\n)\n\n# register card\nregistry = CardRegistry(RegistryType.Prompt)\nregistry.register_card(card)\n</code></pre></p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __init__(\n    self,\n    prompt: Prompt,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    uid: Optional[str] = None,\n    tags: List[str] = [],\n    drift_profile: Optional[Dict[str, LLMDriftProfile]] = None,\n) -&gt; None:\n    \"\"\"Creates a `PromptCard`.\n\n    Cards are stored in the PromptCard Registry and follow the naming convention of:\n    {registry}/{space}/{name}/v{version}\n\n\n    Args:\n        prompt (Prompt):\n            Prompt to associate with `PromptCard`\n        space (str | None):\n            space to associate with `PromptCard`\n        name (str | None):\n            Name to associate with `PromptCard`\n        version (str | None):\n            Current version (assigned if card has been registered). Follows\n            semantic versioning.\n        uid (str | None):\n            Unique id (assigned if card has been registered)\n        tags (List[str]):\n            Tags to associate with `PromptCard`. Can be a dictionary of strings or\n            a `Tags` object.\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile. Currently supports LLM drift profiles.\n    Example:\n    ```python\n    from opsml import Prompt, PromptCard, CardRegistry, RegistryType\n\n    # create prompt\n    prompt = Prompt(\n        model=\"openai:gpt-4o\",\n        message=[\n            \"My prompt $1 is $2\",\n            \"My prompt $3 is $4\",\n        ],\n        system_instruction=\"system_prompt\",\n    )\n\n    # create card\n    card = PromptCard(\n        prompt=prompt,\n        space=\"my-repo\",\n        name=\"my-prompt\",\n        version=\"0.0.1\",\n        tags=[\"gpt-4o\", \"prompt\"],\n    )\n\n    # register card\n    registry = CardRegistry(RegistryType.Prompt)\n    registry.register_card(card)\n    ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.create_drift_profile","title":"<code>create_drift_profile(alias, config, metrics, workflow=None)</code>","text":"<p>Create an LLMDriftProfile for LLM evaluation and drift detection.</p> <p>LLM evaluations are run asynchronously on the scouter server.</p> Logic flow <ol> <li>If only metrics are provided, a workflow will be created automatically    from the metrics. In this case a prompt is required for each metric.</li> <li>If a workflow is provided, it will be parsed and validated for compatibility:</li> <li>A list of metrics to evaluate workflow output must be provided</li> <li>Metric names must correspond to the final task names in the workflow</li> </ol> <p>Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LLMDriftConfig</code> <p>The configuration for the LLM drift profile containing space, name, version, and alert settings.</p> required <code>metrics</code> <code>list[LLMDriftMetric]</code> <p>A list of LLMDriftMetric objects representing the metrics to be monitored. Each metric defines evaluation criteria and alert thresholds.</p> required <code>workflow</code> <code>Optional[Workflow]</code> <p>Optional custom workflow for advanced evaluation scenarios. If provided, the workflow will be validated to ensure proper parameter and response type configuration.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>LLMDriftProfile</code> <code>None</code> <p>Configured profile ready for LLM drift monitoring.</p> <p>Raises:</p> Type Description <code>ProfileError</code> <p>If workflow validation fails, metrics are empty when no workflow is provided, or if workflow tasks don't match metric names.</p> <p>Examples:</p> <p>Basic usage with metrics only:</p> <pre><code>&gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n&gt;&gt;&gt; metrics = [\n...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n... ]\n&gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics)\n</code></pre> <p>Advanced usage with custom workflow:</p> <pre><code>&gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n&gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n&gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics, workflow)\n</code></pre> Note <ul> <li>When using custom workflows, ensure final tasks have Score response types</li> <li>Initial workflow tasks must include \"input\" and/or \"response\" parameters</li> <li>All metric names must match corresponding workflow task names</li> </ul> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def create_drift_profile(\n    self,\n    alias: str,\n    config: LLMDriftConfig,\n    metrics: List[LLMDriftMetric],\n    workflow: Optional[Workflow] = None,\n) -&gt; None:\n    \"\"\"Create an LLMDriftProfile for LLM evaluation and drift detection.\n\n    LLM evaluations are run asynchronously on the scouter server.\n\n    Logic flow:\n        1. If only metrics are provided, a workflow will be created automatically\n           from the metrics. In this case a prompt is required for each metric.\n        2. If a workflow is provided, it will be parsed and validated for compatibility:\n           - A list of metrics to evaluate workflow output must be provided\n           - Metric names must correspond to the final task names in the workflow\n\n    Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n    Args:\n        config (LLMDriftConfig):\n            The configuration for the LLM drift profile containing space, name,\n            version, and alert settings.\n        metrics (list[LLMDriftMetric]):\n            A list of LLMDriftMetric objects representing the metrics to be monitored.\n            Each metric defines evaluation criteria and alert thresholds.\n        workflow (Optional[Workflow]):\n            Optional custom workflow for advanced evaluation scenarios. If provided,\n            the workflow will be validated to ensure proper parameter and response\n            type configuration.\n\n    Returns:\n        LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n    Raises:\n        ProfileError: If workflow validation fails, metrics are empty when no\n            workflow is provided, or if workflow tasks don't match metric names.\n\n    Examples:\n        Basic usage with metrics only:\n\n        &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n        &gt;&gt;&gt; metrics = [\n        ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n        ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n        ... ]\n        &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics)\n\n        Advanced usage with custom workflow:\n\n        &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n        &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n        &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics, workflow)\n\n    Note:\n        - When using custom workflows, ensure final tasks have Score response types\n        - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n        - All metric names must match corresponding workflow task names\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load card from json string</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The json string to validate</p> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"PromptCard\":\n    \"\"\"Load card from json string\n\n    Args:\n        json_string (str):\n            The json string to validate\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.PromptCard.save","title":"<code>save(path)</code>","text":"<p>Save the <code>PromptCard</code> to a directory</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to save the prompt card.</p> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def save(self, path: Path) -&gt; None:\n    \"\"\"Save the `PromptCard` to a directory\n\n    Args:\n        path (Path):\n            Path to save the prompt card.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard","title":"<code>ServiceCard</code>","text":"<p>Creates a ServiceCard to hold a collection of cards.</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>class ServiceCard:\n    \"\"\"Creates a ServiceCard to hold a collection of cards.\"\"\"\n\n    def __init__(\n        self,\n        space: str,\n        name: str,\n        cards: List[Card],\n        version: Optional[str] = None,\n        service_type: Optional[ServiceType] = None,\n        load_spec: bool = False,\n    ) -&gt; None:\n        \"\"\"Initialize the service card\n\n        Args:\n            space (str):\n                The space of the service card\n            name (str):\n                The name of the service card\n            cards (List[Card]):\n                The cards in the service card\n            version (str | None):\n                The version of the service card. If not provided, the latest version\n                for a given space and name will be used (e.g. {space}/{name}/v*).\n            service_type (ServiceType | None):\n                The type of service (Api, Mcp, Agent). If not provided, defaults to Api.\n            load_spec (bool):\n                Whether to load the opsmlspec.yaml file if it exists in the service card directory.\n                This is useful when you have additional metadata in the opsmlspec.yaml file that you want\n                to include in the service card. Defaults to False.\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space of the service card\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name of the service card\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version of the service card\"\"\"\n\n    @property\n    def uid(self) -&gt; str:\n        \"\"\"Return the uid of the service card\"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime:\n        \"\"\"Return the created at timestamp\"\"\"\n\n    @property\n    def cards(self) -&gt; List[CardType]:\n        \"\"\"Return the cards in the service card\"\"\"\n\n    @property\n    def opsml_version(self) -&gt; str:\n        \"\"\"Return the opsml version\"\"\"\n\n    def save(self, path: Path) -&gt; None:\n        \"\"\"Save the service card to a directory\n\n        Args:\n            path (Path):\n                Path to save the service card.\n        \"\"\"\n\n    def model_validate_json(self, json_string: str) -&gt; \"ServiceCard\":\n        \"\"\"Load service card from json string\n\n        Args:\n            json_string (str):\n                The json string to validate\n        \"\"\"\n\n    def load(\n        self,\n        load_kwargs: Optional[Dict[str, ModelLoadKwargs | DataLoadKwargs]] = None,\n    ) -&gt; None:\n        \"\"\"Call the load method on each Card that requires additional loading.\n        This applies to ModelCards and DataCards. PromptCards and ExperimentCards\n        do not require additional loading and are loaded automatically when loading\n        the ServiceCard from the registry.\n\n        Args:\n            load_kwargs (Dict[str, ModelLoadKwargs | DataLoadKwargs]):\n                Optional kwargs for loading cards. Expected format:\n                {\n                    \"card_alias\":  DataLoadKwargs | ModelLoadKwargs\n                }\n        \"\"\"\n\n    @staticmethod\n    def from_path(\n        path: Optional[Path] = None,\n        load_kwargs: Optional[Dict[str, Dict[str, Any]]] = None,\n    ) -&gt; \"ServiceCard\":\n        \"\"\"Loads a service card and its associated cards from a filesystem path.\n\n        Args:\n            path (Path):\n                Path to load the service card from. Defaults to \"service\".\n            load_kwargs (Dict[str, Dict[str, Any]]):\n                Optional kwargs for loading cards. Expected format:\n                {\n                    \"card_alias\": {\n                        \"interface\": interface_object,\n                        \"load_kwargs\": DataLoadKwargs | ModelLoadKwargs\n                    }\n                }\n\n        Returns:\n            ServiceCard: The loaded service card with all cards instantiated.\n\n        Raises:\n            PyError: If service card JSON cannot be read\n            PyError: If cards cannot be loaded\n            PyError: If invalid kwargs are provided\n\n        Example:\n            ```python\n            # Load with custom kwargs for model loading\n            load_kwargs = {\n                \"model_card\": {\n                    \"load_kwargs\": ModelLoadKwargs(load_onnx=True)\n                }\n            }\n            service = ServiceCard.from_path(load_kwargs=load_kwargs)\n            ```\n        \"\"\"\n\n    def __getitem__(self, alias: str) -&gt; CardType:\n        \"\"\"Get a card from the service card by alias\n\n        Args:\n            alias (str):\n                The alias of the card to get\n\n        Returns:\n            Card:\n                The card with the given alias\n        \"\"\"\n\n    def download_artifacts(self, path: Optional[Path] = None) -&gt; None:\n        \"\"\"Download artifacts associated with each card in the service card. This method\n        will always overwrite existing artifacts.\n\n        If the path is not provided, the artifacts will be saved to a directory.\n\n        ```\n        service/\n        |-- {name}-{version}/\n            |-- alias1/\n            |-- alias2/\n            |-- alias3/\n        `-- ...\n        ```\n\n        Args:\n            path (Path):\n                Top-level Path to download the artifacts to. If not provided, the artifacts will be saved\n                to a directory using the ServiceCard name.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.cards","title":"<code>cards</code>  <code>property</code>","text":"<p>Return the cards in the service card</p>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Return the created at timestamp</p>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the name of the service card</p>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.opsml_version","title":"<code>opsml_version</code>  <code>property</code>","text":"<p>Return the opsml version</p>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.space","title":"<code>space</code>  <code>property</code>","text":"<p>Return the space of the service card</p>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.uid","title":"<code>uid</code>  <code>property</code>","text":"<p>Return the uid of the service card</p>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.version","title":"<code>version</code>  <code>property</code>","text":"<p>Return the version of the service card</p>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.__getitem__","title":"<code>__getitem__(alias)</code>","text":"<p>Get a card from the service card by alias</p> <p>Parameters:</p> Name Type Description Default <code>alias</code> <code>str</code> <p>The alias of the card to get</p> required <p>Returns:</p> Name Type Description <code>Card</code> <code>CardType</code> <p>The card with the given alias</p> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __getitem__(self, alias: str) -&gt; CardType:\n    \"\"\"Get a card from the service card by alias\n\n    Args:\n        alias (str):\n            The alias of the card to get\n\n    Returns:\n        Card:\n            The card with the given alias\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.__init__","title":"<code>__init__(space, name, cards, version=None, service_type=None, load_spec=False)</code>","text":"<p>Initialize the service card</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>The space of the service card</p> required <code>name</code> <code>str</code> <p>The name of the service card</p> required <code>cards</code> <code>List[Card]</code> <p>The cards in the service card</p> required <code>version</code> <code>str | None</code> <p>The version of the service card. If not provided, the latest version for a given space and name will be used (e.g. {space}/{name}/v*).</p> <code>None</code> <code>service_type</code> <code>ServiceType | None</code> <p>The type of service (Api, Mcp, Agent). If not provided, defaults to Api.</p> <code>None</code> <code>load_spec</code> <code>bool</code> <p>Whether to load the opsmlspec.yaml file if it exists in the service card directory. This is useful when you have additional metadata in the opsmlspec.yaml file that you want to include in the service card. Defaults to False.</p> <code>False</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def __init__(\n    self,\n    space: str,\n    name: str,\n    cards: List[Card],\n    version: Optional[str] = None,\n    service_type: Optional[ServiceType] = None,\n    load_spec: bool = False,\n) -&gt; None:\n    \"\"\"Initialize the service card\n\n    Args:\n        space (str):\n            The space of the service card\n        name (str):\n            The name of the service card\n        cards (List[Card]):\n            The cards in the service card\n        version (str | None):\n            The version of the service card. If not provided, the latest version\n            for a given space and name will be used (e.g. {space}/{name}/v*).\n        service_type (ServiceType | None):\n            The type of service (Api, Mcp, Agent). If not provided, defaults to Api.\n        load_spec (bool):\n            Whether to load the opsmlspec.yaml file if it exists in the service card directory.\n            This is useful when you have additional metadata in the opsmlspec.yaml file that you want\n            to include in the service card. Defaults to False.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.download_artifacts","title":"<code>download_artifacts(path=None)</code>","text":"<p>Download artifacts associated with each card in the service card. This method will always overwrite existing artifacts.</p> <p>If the path is not provided, the artifacts will be saved to a directory.</p> <pre><code>service/\n|-- {name}-{version}/\n    |-- alias1/\n    |-- alias2/\n    |-- alias3/\n`-- ...\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Top-level Path to download the artifacts to. If not provided, the artifacts will be saved to a directory using the ServiceCard name.</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def download_artifacts(self, path: Optional[Path] = None) -&gt; None:\n    \"\"\"Download artifacts associated with each card in the service card. This method\n    will always overwrite existing artifacts.\n\n    If the path is not provided, the artifacts will be saved to a directory.\n\n    ```\n    service/\n    |-- {name}-{version}/\n        |-- alias1/\n        |-- alias2/\n        |-- alias3/\n    `-- ...\n    ```\n\n    Args:\n        path (Path):\n            Top-level Path to download the artifacts to. If not provided, the artifacts will be saved\n            to a directory using the ServiceCard name.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.from_path","title":"<code>from_path(path=None, load_kwargs=None)</code>  <code>staticmethod</code>","text":"<p>Loads a service card and its associated cards from a filesystem path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to load the service card from. Defaults to \"service\".</p> <code>None</code> <code>load_kwargs</code> <code>Dict[str, Dict[str, Any]]</code> <p>Optional kwargs for loading cards. Expected format: {     \"card_alias\": {         \"interface\": interface_object,         \"load_kwargs\": DataLoadKwargs | ModelLoadKwargs     } }</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ServiceCard</code> <code>ServiceCard</code> <p>The loaded service card with all cards instantiated.</p> <p>Raises:</p> Type Description <code>PyError</code> <p>If service card JSON cannot be read</p> <code>PyError</code> <p>If cards cannot be loaded</p> <code>PyError</code> <p>If invalid kwargs are provided</p> Example <pre><code># Load with custom kwargs for model loading\nload_kwargs = {\n    \"model_card\": {\n        \"load_kwargs\": ModelLoadKwargs(load_onnx=True)\n    }\n}\nservice = ServiceCard.from_path(load_kwargs=load_kwargs)\n</code></pre> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>@staticmethod\ndef from_path(\n    path: Optional[Path] = None,\n    load_kwargs: Optional[Dict[str, Dict[str, Any]]] = None,\n) -&gt; \"ServiceCard\":\n    \"\"\"Loads a service card and its associated cards from a filesystem path.\n\n    Args:\n        path (Path):\n            Path to load the service card from. Defaults to \"service\".\n        load_kwargs (Dict[str, Dict[str, Any]]):\n            Optional kwargs for loading cards. Expected format:\n            {\n                \"card_alias\": {\n                    \"interface\": interface_object,\n                    \"load_kwargs\": DataLoadKwargs | ModelLoadKwargs\n                }\n            }\n\n    Returns:\n        ServiceCard: The loaded service card with all cards instantiated.\n\n    Raises:\n        PyError: If service card JSON cannot be read\n        PyError: If cards cannot be loaded\n        PyError: If invalid kwargs are provided\n\n    Example:\n        ```python\n        # Load with custom kwargs for model loading\n        load_kwargs = {\n            \"model_card\": {\n                \"load_kwargs\": ModelLoadKwargs(load_onnx=True)\n            }\n        }\n        service = ServiceCard.from_path(load_kwargs=load_kwargs)\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.load","title":"<code>load(load_kwargs=None)</code>","text":"<p>Call the load method on each Card that requires additional loading. This applies to ModelCards and DataCards. PromptCards and ExperimentCards do not require additional loading and are loaded automatically when loading the ServiceCard from the registry.</p> <p>Parameters:</p> Name Type Description Default <code>load_kwargs</code> <code>Dict[str, ModelLoadKwargs | DataLoadKwargs]</code> <p>Optional kwargs for loading cards. Expected format: {     \"card_alias\":  DataLoadKwargs | ModelLoadKwargs }</p> <code>None</code> Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def load(\n    self,\n    load_kwargs: Optional[Dict[str, ModelLoadKwargs | DataLoadKwargs]] = None,\n) -&gt; None:\n    \"\"\"Call the load method on each Card that requires additional loading.\n    This applies to ModelCards and DataCards. PromptCards and ExperimentCards\n    do not require additional loading and are loaded automatically when loading\n    the ServiceCard from the registry.\n\n    Args:\n        load_kwargs (Dict[str, ModelLoadKwargs | DataLoadKwargs]):\n            Optional kwargs for loading cards. Expected format:\n            {\n                \"card_alias\":  DataLoadKwargs | ModelLoadKwargs\n            }\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.model_validate_json","title":"<code>model_validate_json(json_string)</code>","text":"<p>Load service card from json string</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The json string to validate</p> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def model_validate_json(self, json_string: str) -&gt; \"ServiceCard\":\n    \"\"\"Load service card from json string\n\n    Args:\n        json_string (str):\n            The json string to validate\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.ServiceCard.save","title":"<code>save(path)</code>","text":"<p>Save the service card to a directory</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to save the service card.</p> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def save(self, path: Path) -&gt; None:\n    \"\"\"Save the service card to a directory\n\n    Args:\n        path (Path):\n            Path to save the service card.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/cards/#opsml.card._card.download_service","title":"<code>download_service(write_dir, space=None, name=None, version=None, uid=None)</code>","text":"<p>Download a service from the registry.</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Space associated with the service.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the service.</p> <code>None</code> <code>version</code> <code>str</code> <p>Version number of the service.</p> <code>None</code> <code>uid</code> <code>str</code> <p>Unique identifier for the service.</p> <code>None</code> <code>write_dir</code> <code>str</code> <p>Directory to write the downloaded service to.</p> required Source code in <code>python/opsml/card/_card.pyi</code> <pre><code>def download_service(\n    write_dir: Path,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    uid: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Download a service from the registry.\n\n    Args:\n        space (str):\n            Space associated with the service.\n        name (str):\n            Name of the service.\n        version (str):\n            Version number of the service.\n        uid (str):\n            Unique identifier for the service.\n        write_dir (str):\n            Directory to write the downloaded service to.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/","title":"Data","text":""},{"location":"docs/api/data/#opsml.data._data.ArrowData","title":"<code>ArrowData</code>","text":"<p>               Bases: <code>DataInterface</code></p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class ArrowData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n             data (pa.Table | None):\n                PyArrow Table\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves pyarrow table to parquet via write_table\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n            row_group_size (int | None):\n                Maximum number of rows in each written row group. If None, the row group size will be the minimum of the\n                Table size and 1024 * 1024. Default is None.\n            version ({'1.0', '2.4', '2.6'}):\n                Determine which Parquet logical types are available for use. Default is '2.6'.\n            use_dictionary (bool | list):\n                Specify if dictionary encoding should be used in general or only for some columns. Default is True.\n            compression (str | dict):\n                Specify the compression codec, either on a general basis or per-column.\n                Valid values: {'NONE', 'SNAPPY', 'GZIP', 'BROTLI', 'LZ4', 'ZSTD'}. Default is 'snappy'.\n            write_statistics (bool | list):\n                Specify if statistics should be written in general or only for some columns. Default is True.\n            use_deprecated_int96_timestamps (bool | None):\n                Write timestamps to INT96 Parquet format. Default is None.\n            coerce_timestamps (str | None):\n                Cast timestamps to a particular resolution. Valid values: {None, 'ms', 'us'}. Default is None.\n            allow_truncated_timestamps (bool):\n                Allow loss of data when coercing timestamps to a particular resolution. Default is False.\n            data_page_size (int | None):\n                Set a target threshold for the approximate encoded size of data pages within a column chunk (in bytes).\n                Default is None.\n            flavor ({'spark'} | None):\n                Sanitize schema or set other compatibility options to work with various target systems. Default is None.\n            filesystem (FileSystem | None):\n                Filesystem object to use when reading the parquet file. Default is None.\n            compression_level (int | dict | None):\n                Specify the compression level for a codec, either on a general basis or per-column. Default is None.\n            use_byte_stream_split (bool | list):\n                Specify if the byte_stream_split encoding should be used in general or only for some columns. Default is False.\n            column_encoding (str | dict | None):\n                Specify the encoding scheme on a per column basis. Default is None.\n            data_page_version ({'1.0', '2.0'}):\n                The serialized Parquet data page format version to write. Default is '1.0'.\n            use_compliant_nested_type (bool):\n                Whether to write compliant Parquet nested type (lists). Default is True.\n            encryption_properties (FileEncryptionProperties | None):\n                File encryption properties for Parquet Modular Encryption. Default is None.\n            write_batch_size (int | None):\n                Number of values to write to a page at a time. Default is None.\n            dictionary_pagesize_limit (int | None):\n                Specify the dictionary page size limit per row group. Default is None.\n            store_schema (bool):\n                By default, the Arrow schema is serialized and stored in the Parquet file metadata. Default is True.\n            write_page_index (bool):\n                Whether to write a page index in general for all columns. Default is False.\n            write_page_checksum (bool):\n                Whether to write page checksums in general for all columns. Default is False.\n            sorting_columns (Sequence[SortingColumn] | None):\n                Specify the sort order of the data being written. Default is None.\n            store_decimal_as_integer (bool):\n                Allow decimals with 1 &lt;= precision &lt;= 18 to be stored as integers. Default is False.\n            **kwargs:\n                Additional options for ParquetWriter.\n\n        Additional Information:\n            https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_table.html\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data from a file\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable load kwargs:\n            columns (list | None):\n                If not None, only these columns will be read from the file. A column name may be a prefix of a nested field,\n                e.g. 'a' will select 'a.b', 'a.c', and 'a.d.e'. If empty, no columns will be read. Default is None.\n            use_threads (bool):\n                Perform multi-threaded column reads. Default is True.\n            schema (Schema | None):\n                Optionally provide the Schema for the parquet dataset, in which case it will not be inferred from the source.\n                Default is None.\n            use_pandas_metadata (bool):\n                If True and file has custom pandas schema metadata, ensure that index columns are also loaded. Default is False.\n            read_dictionary (list | None):\n                List of names or column paths (for nested types) to read directly as DictionaryArray.\n                Only supported for BYTE_ARRAY storage. Default is None.\n            memory_map (bool):\n                If the source is a file path, use a memory map to read file, which can improve performance in some environments.\n                Default is False.\n            buffer_size (int):\n                If positive, perform read buffering when deserializing individual column chunks.\n                Otherwise IO calls are unbuffered. Default is 0.\n            partitioning (pyarrow.dataset.Partitioning | str | list of str):\n                The partitioning scheme for a partitioned dataset. Default is 'hive'.\n            filesystem (FileSystem | None):\n                If nothing passed, will be inferred based on path. Default is None.\n            filters (pyarrow.compute.Expression | list[tuple] | list[list[tuple]] | None):\n                Rows which do not match the filter predicate will be removed from scanned data. Default is None.\n            use_legacy_dataset (bool | None):\n                Deprecated and has no effect from PyArrow version 15.0.0. Default is None.\n            ignore_prefixes (list | None):\n                Files matching any of these prefixes will be ignored by the discovery process. Default is ['.', '_'].\n            pre_buffer (bool):\n                Coalesce and issue file reads in parallel to improve performance on high-latency filesystems (e.g. S3).\n                Default is True.\n            coerce_int96_timestamp_unit (str | None):\n                Cast timestamps that are stored in INT96 format to a particular resolution (e.g. 'ms'). Default is None.\n            decryption_properties (FileDecryptionProperties | None):\n                File-level decryption properties. Default is None.\n            thrift_string_size_limit (int | None):\n                If not None, override the maximum total string size allocated when decoding Thrift structures. Default is None.\n            thrift_container_size_limit (int | None):\n                If not None, override the maximum total size of containers allocated when decoding Thrift structures.\n                Default is None.\n            page_checksum_verification (bool):\n                If True, verify the checksum for each page read from the file. Default is False.\n\n        Additional Information:\n            https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.ArrowData.__init__","title":"<code>__init__(data=None, data_splits=None, dependent_vars=None, sql_logic=None, data_profile=None)</code>","text":"<p>Define a data interface</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Table | None</code> <p>PyArrow Table</p> <code>None</code> <pre><code>dependent_vars (DependentVars | List[str] | List[int] | None):\n    List of dependent variables to associate with data\ndata_splits (DataSplits | List[DataSplit]):\n    Optional list of `DataSplit`\nsql_logic (SqlLogic | None):\n    Sql logic used to generate data represented as a dictionary.\ndata_profile (DataProfile | None):\n    Data profile\n</code></pre> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    data: Optional[Any] = None,\n    data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n    dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n    sql_logic: Optional[SqlLogic] = None,\n    data_profile: Optional[DataProfile] = None,\n) -&gt; None:\n    \"\"\"Define a data interface\n\n    Args:\n         data (pa.Table | None):\n            PyArrow Table\n        dependent_vars (DependentVars | List[str] | List[int] | None):\n            List of dependent variables to associate with data\n        data_splits (DataSplits | List[DataSplit]):\n            Optional list of `DataSplit`\n        sql_logic (SqlLogic | None):\n            Sql logic used to generate data represented as a dictionary.\n        data_profile (DataProfile | None):\n            Data profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.ArrowData.load","title":"<code>load(path, metadata, load_kwargs=None)</code>","text":"<p>Load the data from a file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to load the data from.</p> required <code>metadata</code> <code>DataInterfaceSaveMetadata</code> <p>Metadata associated with the data</p> required <code>load_kwargs</code> <code>DataLoadKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Acceptable load kwargs <p>columns (list | None):     If not None, only these columns will be read from the file. A column name may be a prefix of a nested field,     e.g. 'a' will select 'a.b', 'a.c', and 'a.d.e'. If empty, no columns will be read. Default is None. use_threads (bool):     Perform multi-threaded column reads. Default is True. schema (Schema | None):     Optionally provide the Schema for the parquet dataset, in which case it will not be inferred from the source.     Default is None. use_pandas_metadata (bool):     If True and file has custom pandas schema metadata, ensure that index columns are also loaded. Default is False. read_dictionary (list | None):     List of names or column paths (for nested types) to read directly as DictionaryArray.     Only supported for BYTE_ARRAY storage. Default is None. memory_map (bool):     If the source is a file path, use a memory map to read file, which can improve performance in some environments.     Default is False. buffer_size (int):     If positive, perform read buffering when deserializing individual column chunks.     Otherwise IO calls are unbuffered. Default is 0. partitioning (pyarrow.dataset.Partitioning | str | list of str):     The partitioning scheme for a partitioned dataset. Default is 'hive'. filesystem (FileSystem | None):     If nothing passed, will be inferred based on path. Default is None. filters (pyarrow.compute.Expression | list[tuple] | list[list[tuple]] | None):     Rows which do not match the filter predicate will be removed from scanned data. Default is None. use_legacy_dataset (bool | None):     Deprecated and has no effect from PyArrow version 15.0.0. Default is None. ignore_prefixes (list | None):     Files matching any of these prefixes will be ignored by the discovery process. Default is ['.', '_']. pre_buffer (bool):     Coalesce and issue file reads in parallel to improve performance on high-latency filesystems (e.g. S3).     Default is True. coerce_int96_timestamp_unit (str | None):     Cast timestamps that are stored in INT96 format to a particular resolution (e.g. 'ms'). Default is None. decryption_properties (FileDecryptionProperties | None):     File-level decryption properties. Default is None. thrift_string_size_limit (int | None):     If not None, override the maximum total string size allocated when decoding Thrift structures. Default is None. thrift_container_size_limit (int | None):     If not None, override the maximum total size of containers allocated when decoding Thrift structures.     Default is None. page_checksum_verification (bool):     If True, verify the checksum for each page read from the file. Default is False.</p> Additional Information <p>https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def load(\n    self,\n    path: Path,\n    metadata: DataInterfaceSaveMetadata,\n    load_kwargs: Optional[DataLoadKwargs] = None,\n) -&gt; None:\n    \"\"\"Load the data from a file\n\n    Args:\n        path (Path):\n            Base path to load the data from.\n        metadata (DataInterfaceSaveMetadata):\n            Metadata associated with the data\n        load_kwargs (DataLoadKwargs):\n            Additional kwargs to pass in.\n\n    Acceptable load kwargs:\n        columns (list | None):\n            If not None, only these columns will be read from the file. A column name may be a prefix of a nested field,\n            e.g. 'a' will select 'a.b', 'a.c', and 'a.d.e'. If empty, no columns will be read. Default is None.\n        use_threads (bool):\n            Perform multi-threaded column reads. Default is True.\n        schema (Schema | None):\n            Optionally provide the Schema for the parquet dataset, in which case it will not be inferred from the source.\n            Default is None.\n        use_pandas_metadata (bool):\n            If True and file has custom pandas schema metadata, ensure that index columns are also loaded. Default is False.\n        read_dictionary (list | None):\n            List of names or column paths (for nested types) to read directly as DictionaryArray.\n            Only supported for BYTE_ARRAY storage. Default is None.\n        memory_map (bool):\n            If the source is a file path, use a memory map to read file, which can improve performance in some environments.\n            Default is False.\n        buffer_size (int):\n            If positive, perform read buffering when deserializing individual column chunks.\n            Otherwise IO calls are unbuffered. Default is 0.\n        partitioning (pyarrow.dataset.Partitioning | str | list of str):\n            The partitioning scheme for a partitioned dataset. Default is 'hive'.\n        filesystem (FileSystem | None):\n            If nothing passed, will be inferred based on path. Default is None.\n        filters (pyarrow.compute.Expression | list[tuple] | list[list[tuple]] | None):\n            Rows which do not match the filter predicate will be removed from scanned data. Default is None.\n        use_legacy_dataset (bool | None):\n            Deprecated and has no effect from PyArrow version 15.0.0. Default is None.\n        ignore_prefixes (list | None):\n            Files matching any of these prefixes will be ignored by the discovery process. Default is ['.', '_'].\n        pre_buffer (bool):\n            Coalesce and issue file reads in parallel to improve performance on high-latency filesystems (e.g. S3).\n            Default is True.\n        coerce_int96_timestamp_unit (str | None):\n            Cast timestamps that are stored in INT96 format to a particular resolution (e.g. 'ms'). Default is None.\n        decryption_properties (FileDecryptionProperties | None):\n            File-level decryption properties. Default is None.\n        thrift_string_size_limit (int | None):\n            If not None, override the maximum total string size allocated when decoding Thrift structures. Default is None.\n        thrift_container_size_limit (int | None):\n            If not None, override the maximum total size of containers allocated when decoding Thrift structures.\n            Default is None.\n        page_checksum_verification (bool):\n            If True, verify the checksum for each page read from the file. Default is False.\n\n    Additional Information:\n        https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.ArrowData.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Saves pyarrow table to parquet via write_table</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to save the data to.</p> required <code>save_kwargs</code> <code>DataSaveKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Acceptable save kwargs <p>row_group_size (int | None):     Maximum number of rows in each written row group. If None, the row group size will be the minimum of the     Table size and 1024 * 1024. Default is None. version ({'1.0', '2.4', '2.6'}):     Determine which Parquet logical types are available for use. Default is '2.6'. use_dictionary (bool | list):     Specify if dictionary encoding should be used in general or only for some columns. Default is True. compression (str | dict):     Specify the compression codec, either on a general basis or per-column.     Valid values: {'NONE', 'SNAPPY', 'GZIP', 'BROTLI', 'LZ4', 'ZSTD'}. Default is 'snappy'. write_statistics (bool | list):     Specify if statistics should be written in general or only for some columns. Default is True. use_deprecated_int96_timestamps (bool | None):     Write timestamps to INT96 Parquet format. Default is None. coerce_timestamps (str | None):     Cast timestamps to a particular resolution. Valid values: {None, 'ms', 'us'}. Default is None. allow_truncated_timestamps (bool):     Allow loss of data when coercing timestamps to a particular resolution. Default is False. data_page_size (int | None):     Set a target threshold for the approximate encoded size of data pages within a column chunk (in bytes).     Default is None. flavor ({'spark'} | None):     Sanitize schema or set other compatibility options to work with various target systems. Default is None. filesystem (FileSystem | None):     Filesystem object to use when reading the parquet file. Default is None. compression_level (int | dict | None):     Specify the compression level for a codec, either on a general basis or per-column. Default is None. use_byte_stream_split (bool | list):     Specify if the byte_stream_split encoding should be used in general or only for some columns. Default is False. column_encoding (str | dict | None):     Specify the encoding scheme on a per column basis. Default is None. data_page_version ({'1.0', '2.0'}):     The serialized Parquet data page format version to write. Default is '1.0'. use_compliant_nested_type (bool):     Whether to write compliant Parquet nested type (lists). Default is True. encryption_properties (FileEncryptionProperties | None):     File encryption properties for Parquet Modular Encryption. Default is None. write_batch_size (int | None):     Number of values to write to a page at a time. Default is None. dictionary_pagesize_limit (int | None):     Specify the dictionary page size limit per row group. Default is None. store_schema (bool):     By default, the Arrow schema is serialized and stored in the Parquet file metadata. Default is True. write_page_index (bool):     Whether to write a page index in general for all columns. Default is False. write_page_checksum (bool):     Whether to write page checksums in general for all columns. Default is False. sorting_columns (Sequence[SortingColumn] | None):     Specify the sort order of the data being written. Default is None. store_decimal_as_integer (bool):     Allow decimals with 1 &lt;= precision &lt;= 18 to be stored as integers. Default is False. **kwargs:     Additional options for ParquetWriter.</p> Additional Information <p>https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_table.html</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def save(self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None) -&gt; DataInterfaceMetadata:\n    \"\"\"Saves pyarrow table to parquet via write_table\n\n    Args:\n        path (Path):\n            Base path to save the data to.\n        save_kwargs (DataSaveKwargs):\n            Additional kwargs to pass in.\n\n    Acceptable save kwargs:\n        row_group_size (int | None):\n            Maximum number of rows in each written row group. If None, the row group size will be the minimum of the\n            Table size and 1024 * 1024. Default is None.\n        version ({'1.0', '2.4', '2.6'}):\n            Determine which Parquet logical types are available for use. Default is '2.6'.\n        use_dictionary (bool | list):\n            Specify if dictionary encoding should be used in general or only for some columns. Default is True.\n        compression (str | dict):\n            Specify the compression codec, either on a general basis or per-column.\n            Valid values: {'NONE', 'SNAPPY', 'GZIP', 'BROTLI', 'LZ4', 'ZSTD'}. Default is 'snappy'.\n        write_statistics (bool | list):\n            Specify if statistics should be written in general or only for some columns. Default is True.\n        use_deprecated_int96_timestamps (bool | None):\n            Write timestamps to INT96 Parquet format. Default is None.\n        coerce_timestamps (str | None):\n            Cast timestamps to a particular resolution. Valid values: {None, 'ms', 'us'}. Default is None.\n        allow_truncated_timestamps (bool):\n            Allow loss of data when coercing timestamps to a particular resolution. Default is False.\n        data_page_size (int | None):\n            Set a target threshold for the approximate encoded size of data pages within a column chunk (in bytes).\n            Default is None.\n        flavor ({'spark'} | None):\n            Sanitize schema or set other compatibility options to work with various target systems. Default is None.\n        filesystem (FileSystem | None):\n            Filesystem object to use when reading the parquet file. Default is None.\n        compression_level (int | dict | None):\n            Specify the compression level for a codec, either on a general basis or per-column. Default is None.\n        use_byte_stream_split (bool | list):\n            Specify if the byte_stream_split encoding should be used in general or only for some columns. Default is False.\n        column_encoding (str | dict | None):\n            Specify the encoding scheme on a per column basis. Default is None.\n        data_page_version ({'1.0', '2.0'}):\n            The serialized Parquet data page format version to write. Default is '1.0'.\n        use_compliant_nested_type (bool):\n            Whether to write compliant Parquet nested type (lists). Default is True.\n        encryption_properties (FileEncryptionProperties | None):\n            File encryption properties for Parquet Modular Encryption. Default is None.\n        write_batch_size (int | None):\n            Number of values to write to a page at a time. Default is None.\n        dictionary_pagesize_limit (int | None):\n            Specify the dictionary page size limit per row group. Default is None.\n        store_schema (bool):\n            By default, the Arrow schema is serialized and stored in the Parquet file metadata. Default is True.\n        write_page_index (bool):\n            Whether to write a page index in general for all columns. Default is False.\n        write_page_checksum (bool):\n            Whether to write page checksums in general for all columns. Default is False.\n        sorting_columns (Sequence[SortingColumn] | None):\n            Specify the sort order of the data being written. Default is None.\n        store_decimal_as_integer (bool):\n            Allow decimals with 1 &lt;= precision &lt;= 18 to be stored as integers. Default is False.\n        **kwargs:\n            Additional options for ParquetWriter.\n\n    Additional Information:\n        https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_table.html\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.ColumnSplit","title":"<code>ColumnSplit</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class ColumnSplit:\n    column_name: str\n    column_value: ColValType\n    column_type: ColType\n    inequality: Inequality\n\n    def __init__(\n        self,\n        column_name: str,\n        column_value: Union[str, float, int],\n        column_type: ColType = ColType.Builtin,\n        inequality: Optional[Union[str, Inequality]] = None,\n    ) -&gt; None:\n        \"\"\"Define a column split\n\n        Args:\n            column_name:\n                The name of the column\n            column_value:\n                The value of the column. Can be a string, float, or int. If\n                timestamp, convert to isoformat (str) and specify timestamp coltype\n            column_type:\n                The type of the column. Defaults to ColType.Builtin. If providing ColtType.Timestamp, the\n                column_value should be a float\n            inequality:\n                The inequality of the column\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.ColumnSplit.__init__","title":"<code>__init__(column_name, column_value, column_type=ColType.Builtin, inequality=None)</code>","text":"<p>Define a column split</p> <p>Parameters:</p> Name Type Description Default <code>column_name</code> <code>str</code> <p>The name of the column</p> required <code>column_value</code> <code>Union[str, float, int]</code> <p>The value of the column. Can be a string, float, or int. If timestamp, convert to isoformat (str) and specify timestamp coltype</p> required <code>column_type</code> <code>ColType</code> <p>The type of the column. Defaults to ColType.Builtin. If providing ColtType.Timestamp, the column_value should be a float</p> <code>Builtin</code> <code>inequality</code> <code>Optional[Union[str, Inequality]]</code> <p>The inequality of the column</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    column_name: str,\n    column_value: Union[str, float, int],\n    column_type: ColType = ColType.Builtin,\n    inequality: Optional[Union[str, Inequality]] = None,\n) -&gt; None:\n    \"\"\"Define a column split\n\n    Args:\n        column_name:\n            The name of the column\n        column_value:\n            The value of the column. Can be a string, float, or int. If\n            timestamp, convert to isoformat (str) and specify timestamp coltype\n        column_type:\n            The type of the column. Defaults to ColType.Builtin. If providing ColtType.Timestamp, the\n            column_value should be a float\n        inequality:\n            The inequality of the column\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterface","title":"<code>DataInterface</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class DataInterface:\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (Any):\n                Data. Can be a pyarrow table, pandas dataframe, polars dataframe\n                or numpy array\n            dependent_vars (DependentVars):\n                List of dependent variables to associate with data\n            data_splits (DataSplits):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic):\n                SqlLogic class used to generate data.\n            data_profile (DataProfile):\n                Data profile\n        \"\"\"\n\n    @property\n    def data(self) -&gt; Optional[Any]:\n        \"\"\"Returns the data\"\"\"\n\n    @data.setter\n    def data(self, data: Any) -&gt; None:\n        \"\"\"Sets the data\"\"\"\n\n    @property\n    def data_splits(self) -&gt; DataSplits:\n        \"\"\"Returns the data splits.\"\"\"\n\n    @data_splits.setter\n    def data_splits(self, data_splits: Union[DataSplits, List[DataSplit]]) -&gt; None:\n        \"\"\"Sets the data splits\"\"\"\n\n    @property\n    def dependent_vars(self) -&gt; DependentVars:\n        \"\"\"Returns the dependent variables.\"\"\"\n\n    @dependent_vars.setter\n    def dependent_vars(\n        self,\n        dependent_vars: Union[DependentVars, List[str], List[int]],\n    ) -&gt; None:\n        \"\"\"Sets the dependent variables\"\"\"\n\n    @property\n    def schema(self) -&gt; FeatureSchema:\n        \"\"\"Returns the feature map.\"\"\"\n\n    @schema.setter\n    def schema(self, schema: FeatureSchema) -&gt; None:\n        \"\"\"Sets the feature map\"\"\"\n\n    @property\n    def sql_logic(self) -&gt; SqlLogic:\n        \"\"\"Returns the sql logic.\"\"\"\n\n    @property\n    def data_type(self) -&gt; DataType:\n        \"\"\"Return the data type.\"\"\"\n\n    def add_sql_logic(\n        self,\n        name: str,\n        query: Optional[str] = None,\n        filepath: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Add sql logic to the data interface\n\n        Args:\n            name:\n                The name of the sql logic\n            query:\n                The optional query to use\n            filepath:\n                The optional filepath to open the query from\n        \"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: Optional[DataSaveKwargs] = None,\n    ) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves all data interface component to the given path. This used as part of saving a\n        DataCard\n\n        Methods called in save:\n            - save_sql: Saves all sql logic to files(s)\n            - create_schema: Creates a FeatureSchema from the associated data\n            - save_data: Saves the data to a file\n\n        Args:\n            path (Path):\n                The path to save the data interface components to.\n            save_kwargs (DataSaveKwargs):\n                The save kwargs to use.\n\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data from a file\n\n        Args:\n            path (Path):\n                Base path to load the data from\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n        \"\"\"\n\n    def split_data(self) -&gt; Dict[str, Data]:\n        \"\"\"Split the data\n\n        Returns:\n            A dictionary of data splits\n        \"\"\"\n\n    def create_data_profile(\n        self,\n        bin_size: Optional[int] = 20,\n        compute_correlations: Optional[bool] = False,\n    ) -&gt; DataProfile:\n        \"\"\"Create a data profile\n\n\n        Args:\n            bin_size (int):\n                The bin size for the data profile\n            compute_correlations (bool):\n                Whether to compute correlations\n        \"\"\"\n\n    @property\n    def data_profile(self) -&gt; Optional[DataProfile]:\n        \"\"\"Return the data profile\n\n        Returns:\n            The data profile\n        \"\"\"\n\n    @data_profile.setter\n    def data_profile(self, data_profile: Optional[DataProfile]) -&gt; None:\n        \"\"\"Set the data profile\n\n        Args:\n            data_profile (DataProfile | None):\n                The data profile to set\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.data","title":"<code>data</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the data</p>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.data_profile","title":"<code>data_profile</code>  <code>property</code> <code>writable</code>","text":"<p>Return the data profile</p> <p>Returns:</p> Type Description <code>Optional[DataProfile]</code> <p>The data profile</p>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.data_splits","title":"<code>data_splits</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the data splits.</p>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.data_type","title":"<code>data_type</code>  <code>property</code>","text":"<p>Return the data type.</p>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.dependent_vars","title":"<code>dependent_vars</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the dependent variables.</p>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.schema","title":"<code>schema</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the feature map.</p>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.sql_logic","title":"<code>sql_logic</code>  <code>property</code>","text":"<p>Returns the sql logic.</p>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.__init__","title":"<code>__init__(data=None, data_splits=None, dependent_vars=None, sql_logic=None, data_profile=None)</code>","text":"<p>Define a data interface</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data. Can be a pyarrow table, pandas dataframe, polars dataframe or numpy array</p> <code>None</code> <code>dependent_vars</code> <code>DependentVars</code> <p>List of dependent variables to associate with data</p> <code>None</code> <code>data_splits</code> <code>DataSplits</code> <p>Optional list of <code>DataSplit</code></p> <code>None</code> <code>sql_logic</code> <code>SqlLogic</code> <p>SqlLogic class used to generate data.</p> <code>None</code> <code>data_profile</code> <code>DataProfile</code> <p>Data profile</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    data: Optional[Any] = None,\n    data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n    dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n    sql_logic: Optional[SqlLogic] = None,\n    data_profile: Optional[DataProfile] = None,\n) -&gt; None:\n    \"\"\"Define a data interface\n\n    Args:\n        data (Any):\n            Data. Can be a pyarrow table, pandas dataframe, polars dataframe\n            or numpy array\n        dependent_vars (DependentVars):\n            List of dependent variables to associate with data\n        data_splits (DataSplits):\n            Optional list of `DataSplit`\n        sql_logic (SqlLogic):\n            SqlLogic class used to generate data.\n        data_profile (DataProfile):\n            Data profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.add_sql_logic","title":"<code>add_sql_logic(name, query=None, filepath=None)</code>","text":"<p>Add sql logic to the data interface</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the sql logic</p> required <code>query</code> <code>Optional[str]</code> <p>The optional query to use</p> <code>None</code> <code>filepath</code> <code>Optional[str]</code> <p>The optional filepath to open the query from</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def add_sql_logic(\n    self,\n    name: str,\n    query: Optional[str] = None,\n    filepath: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Add sql logic to the data interface\n\n    Args:\n        name:\n            The name of the sql logic\n        query:\n            The optional query to use\n        filepath:\n            The optional filepath to open the query from\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.create_data_profile","title":"<code>create_data_profile(bin_size=20, compute_correlations=False)</code>","text":"<p>Create a data profile</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>int</code> <p>The bin size for the data profile</p> <code>20</code> <code>compute_correlations</code> <code>bool</code> <p>Whether to compute correlations</p> <code>False</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def create_data_profile(\n    self,\n    bin_size: Optional[int] = 20,\n    compute_correlations: Optional[bool] = False,\n) -&gt; DataProfile:\n    \"\"\"Create a data profile\n\n\n    Args:\n        bin_size (int):\n            The bin size for the data profile\n        compute_correlations (bool):\n            Whether to compute correlations\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.load","title":"<code>load(path, metadata, load_kwargs=None)</code>","text":"<p>Load the data from a file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to load the data from</p> required <code>metadata</code> <code>DataInterfaceSaveMetadata</code> <p>Metadata associated with the data</p> required <code>load_kwargs</code> <code>DataLoadKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def load(\n    self,\n    path: Path,\n    metadata: DataInterfaceSaveMetadata,\n    load_kwargs: Optional[DataLoadKwargs] = None,\n) -&gt; None:\n    \"\"\"Load the data from a file\n\n    Args:\n        path (Path):\n            Base path to load the data from\n        metadata (DataInterfaceSaveMetadata):\n            Metadata associated with the data\n        load_kwargs (DataLoadKwargs):\n            Additional kwargs to pass in.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Saves all data interface component to the given path. This used as part of saving a DataCard</p> Methods called in save <ul> <li>save_sql: Saves all sql logic to files(s)</li> <li>create_schema: Creates a FeatureSchema from the associated data</li> <li>save_data: Saves the data to a file</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to save the data interface components to.</p> required <code>save_kwargs</code> <code>DataSaveKwargs</code> <p>The save kwargs to use.</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def save(\n    self,\n    path: Path,\n    save_kwargs: Optional[DataSaveKwargs] = None,\n) -&gt; DataInterfaceMetadata:\n    \"\"\"Saves all data interface component to the given path. This used as part of saving a\n    DataCard\n\n    Methods called in save:\n        - save_sql: Saves all sql logic to files(s)\n        - create_schema: Creates a FeatureSchema from the associated data\n        - save_data: Saves the data to a file\n\n    Args:\n        path (Path):\n            The path to save the data interface components to.\n        save_kwargs (DataSaveKwargs):\n            The save kwargs to use.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterface.split_data","title":"<code>split_data()</code>","text":"<p>Split the data</p> <p>Returns:</p> Type Description <code>Dict[str, Data]</code> <p>A dictionary of data splits</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def split_data(self) -&gt; Dict[str, Data]:\n    \"\"\"Split the data\n\n    Returns:\n        A dictionary of data splits\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterfaceMetadata","title":"<code>DataInterfaceMetadata</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class DataInterfaceMetadata:\n    save_metadata: DataInterfaceSaveMetadata\n    schema: FeatureSchema\n    extra_metadata: dict[str, str]\n    sql_logic: SqlLogic  # pylint: disable=used-before-assignment\n    interface_type: DataInterfaceType\n    data_splits: DataSplits\n    dependent_vars: DependentVars\n    data_type: DataType\n\n    def __init__(\n        self,\n        save_metadata: DataInterfaceSaveMetadata,\n        schema: FeatureSchema,\n        extra_metadata: dict[str, str],\n        sql_logic: SqlLogic,\n        interface_type: DataInterfaceType,\n        data_splits: DataSplits,\n        dependent_vars: DependentVars,\n        data_type: DataType,\n    ) -&gt; None:\n        \"\"\"Instantiate DataInterfaceMetadata object\n\n        Args:\n            save_metadata:\n                The save metadata\n            schema:\n                The schema\n            extra_metadata:\n                Extra metadata\n            sql_logic:\n                Sql logic\n            interface_type:\n                The interface type\n            data_splits:\n                The data splits\n            dependent_vars:\n                Dependent variables\n            data_type:\n                The data type\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the model interface metadata\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model interface metadata to json\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"DataInterfaceMetadata\":\n        \"\"\"Validate the model interface metadata json\"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterfaceMetadata.__init__","title":"<code>__init__(save_metadata, schema, extra_metadata, sql_logic, interface_type, data_splits, dependent_vars, data_type)</code>","text":"<p>Instantiate DataInterfaceMetadata object</p> <p>Parameters:</p> Name Type Description Default <code>save_metadata</code> <code>DataInterfaceSaveMetadata</code> <p>The save metadata</p> required <code>schema</code> <code>FeatureSchema</code> <p>The schema</p> required <code>extra_metadata</code> <code>dict[str, str]</code> <p>Extra metadata</p> required <code>sql_logic</code> <code>SqlLogic</code> <p>Sql logic</p> required <code>interface_type</code> <code>DataInterfaceType</code> <p>The interface type</p> required <code>data_splits</code> <code>DataSplits</code> <p>The data splits</p> required <code>dependent_vars</code> <code>DependentVars</code> <p>Dependent variables</p> required <code>data_type</code> <code>DataType</code> <p>The data type</p> required Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    save_metadata: DataInterfaceSaveMetadata,\n    schema: FeatureSchema,\n    extra_metadata: dict[str, str],\n    sql_logic: SqlLogic,\n    interface_type: DataInterfaceType,\n    data_splits: DataSplits,\n    dependent_vars: DependentVars,\n    data_type: DataType,\n) -&gt; None:\n    \"\"\"Instantiate DataInterfaceMetadata object\n\n    Args:\n        save_metadata:\n            The save metadata\n        schema:\n            The schema\n        extra_metadata:\n            Extra metadata\n        sql_logic:\n            Sql logic\n        interface_type:\n            The interface type\n        data_splits:\n            The data splits\n        dependent_vars:\n            Dependent variables\n        data_type:\n            The data type\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterfaceMetadata.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the model interface metadata</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the model interface metadata\"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterfaceMetadata.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the model interface metadata to json</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the model interface metadata to json\"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterfaceMetadata.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Validate the model interface metadata json</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"DataInterfaceMetadata\":\n    \"\"\"Validate the model interface metadata json\"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterfaceSaveMetadata","title":"<code>DataInterfaceSaveMetadata</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class DataInterfaceSaveMetadata:\n    data_uri: Path\n    data_profile_uri: Optional[Path]\n    sql_uri: Optional[Path]\n    extra: Optional[ExtraMetadata]\n    save_kwargs: DataSaveKwargs\n\n    def __init__(\n        self,\n        data_uri: Path,\n        data_profile_uri: Optional[Path] = None,\n        sql_uri: Optional[Path] = None,\n        extra: Optional[ExtraMetadata] = None,\n        save_kwargs: Optional[DataSaveKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Define interface save metadata\n\n        Args:\n            data_uri:\n                The data uri\n            data_profile_uri:\n                The data profile uri\n            sql_uri:\n                The sql uri\n            extra:\n                Extra metadata\n            save_kwargs:\n                Save kwargs\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataInterfaceSaveMetadata.__init__","title":"<code>__init__(data_uri, data_profile_uri=None, sql_uri=None, extra=None, save_kwargs=None)</code>","text":"<p>Define interface save metadata</p> <p>Parameters:</p> Name Type Description Default <code>data_uri</code> <code>Path</code> <p>The data uri</p> required <code>data_profile_uri</code> <code>Optional[Path]</code> <p>The data profile uri</p> <code>None</code> <code>sql_uri</code> <code>Optional[Path]</code> <p>The sql uri</p> <code>None</code> <code>extra</code> <code>Optional[ExtraMetadata]</code> <p>Extra metadata</p> <code>None</code> <code>save_kwargs</code> <code>Optional[DataSaveKwargs]</code> <p>Save kwargs</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    data_uri: Path,\n    data_profile_uri: Optional[Path] = None,\n    sql_uri: Optional[Path] = None,\n    extra: Optional[ExtraMetadata] = None,\n    save_kwargs: Optional[DataSaveKwargs] = None,\n) -&gt; None:\n    \"\"\"Define interface save metadata\n\n    Args:\n        data_uri:\n            The data uri\n        data_profile_uri:\n            The data profile uri\n        sql_uri:\n            The sql uri\n        extra:\n            Extra metadata\n        save_kwargs:\n            Save kwargs\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataLoadKwargs","title":"<code>DataLoadKwargs</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class DataLoadKwargs:\n    data: Optional[Dict]\n\n    def __init__(\n        self,\n        data: Optional[Dict] = None,\n    ) -&gt; None:\n        \"\"\"Optional arguments to pass to load_model\n\n        Args:\n            data (Dict):\n                Optional data arguments to use when loading\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataLoadKwargs.__init__","title":"<code>__init__(data=None)</code>","text":"<p>Optional arguments to pass to load_model</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict</code> <p>Optional data arguments to use when loading</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    data: Optional[Dict] = None,\n) -&gt; None:\n    \"\"\"Optional arguments to pass to load_model\n\n    Args:\n        data (Dict):\n            Optional data arguments to use when loading\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSaveKwargs","title":"<code>DataSaveKwargs</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class DataSaveKwargs:\n    def __init__(\n        self,\n        data: Optional[Dict] = None,\n    ) -&gt; None:\n        \"\"\"Optional arguments to pass to save_model\n\n        Args:\n            data (Dict):\n                Optional data arguments to use when saving model to onnx format\n        \"\"\"\n\n    def __str__(self): ...\n    def model_dump_json(self) -&gt; str: ...\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"DataSaveKwargs\": ...\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSaveKwargs.__init__","title":"<code>__init__(data=None)</code>","text":"<p>Optional arguments to pass to save_model</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict</code> <p>Optional data arguments to use when saving model to onnx format</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    data: Optional[Dict] = None,\n) -&gt; None:\n    \"\"\"Optional arguments to pass to save_model\n\n    Args:\n        data (Dict):\n            Optional data arguments to use when saving model to onnx format\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSplit","title":"<code>DataSplit</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class DataSplit:\n    label: str\n    column_split: Optional[ColumnSplit]\n    start_stop_split: Optional[StartStopSplit]\n    indice_split: Optional[IndiceSplit]\n\n    def __init__(\n        self,\n        label: str,\n        column_split: Optional[ColumnSplit] = None,\n        start_stop_split: Optional[StartStopSplit] = None,\n        indice_split: Optional[IndiceSplit] = None,\n    ) -&gt; None:\n        \"\"\"Define a data split\n\n        Args:\n            label:\n                The label of the split\n            column_split:\n                The column split\n            start_stop_split:\n                The start stop split\n            indice_split:\n                The indice split\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSplit.__init__","title":"<code>__init__(label, column_split=None, start_stop_split=None, indice_split=None)</code>","text":"<p>Define a data split</p> <p>Parameters:</p> Name Type Description Default <code>label</code> <code>str</code> <p>The label of the split</p> required <code>column_split</code> <code>Optional[ColumnSplit]</code> <p>The column split</p> <code>None</code> <code>start_stop_split</code> <code>Optional[StartStopSplit]</code> <p>The start stop split</p> <code>None</code> <code>indice_split</code> <code>Optional[IndiceSplit]</code> <p>The indice split</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    label: str,\n    column_split: Optional[ColumnSplit] = None,\n    start_stop_split: Optional[StartStopSplit] = None,\n    indice_split: Optional[IndiceSplit] = None,\n) -&gt; None:\n    \"\"\"Define a data split\n\n    Args:\n        label:\n            The label of the split\n        column_split:\n            The column split\n        start_stop_split:\n            The start stop split\n        indice_split:\n            The indice split\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSplits","title":"<code>DataSplits</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class DataSplits:\n    def __init__(self, splits: List[DataSplit]) -&gt; None:\n        \"\"\"Define data splits\n\n        Args:\n            splits:\n                The data splits\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the data splits\"\"\"\n\n    @property\n    def splits(self) -&gt; List[DataSplit]:\n        \"\"\"Return the splits\"\"\"\n\n    @splits.setter\n    def splits(self, splits: List[DataSplit]) -&gt; None:\n        \"\"\"Set the splits\"\"\"\n\n    def split_data(\n        self,\n        data: Any,\n        data_type: DataType,\n        dependent_vars: DependentVars,\n    ) -&gt; Dict[str, Data]:\n        \"\"\"Split the data\n\n        Args:\n            data:\n                The data to split\n            data_type:\n                The data type\n            dependent_vars:\n                Dependent variables to associate with the data\n\n        Returns:\n            A dictionary of data splits\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSplits.splits","title":"<code>splits</code>  <code>property</code> <code>writable</code>","text":"<p>Return the splits</p>"},{"location":"docs/api/data/#opsml.data._data.DataSplits.__init__","title":"<code>__init__(splits)</code>","text":"<p>Define data splits</p> <p>Parameters:</p> Name Type Description Default <code>splits</code> <code>List[DataSplit]</code> <p>The data splits</p> required Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(self, splits: List[DataSplit]) -&gt; None:\n    \"\"\"Define data splits\n\n    Args:\n        splits:\n            The data splits\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSplits.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the data splits</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the data splits\"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSplits.split_data","title":"<code>split_data(data, data_type, dependent_vars)</code>","text":"<p>Split the data</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to split</p> required <code>data_type</code> <code>DataType</code> <p>The data type</p> required <code>dependent_vars</code> <code>DependentVars</code> <p>Dependent variables to associate with the data</p> required <p>Returns:</p> Type Description <code>Dict[str, Data]</code> <p>A dictionary of data splits</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def split_data(\n    self,\n    data: Any,\n    data_type: DataType,\n    dependent_vars: DependentVars,\n) -&gt; Dict[str, Data]:\n    \"\"\"Split the data\n\n    Args:\n        data:\n            The data to split\n        data_type:\n            The data type\n        dependent_vars:\n            Dependent variables to associate with the data\n\n    Returns:\n        A dictionary of data splits\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSplitter","title":"<code>DataSplitter</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class DataSplitter:\n    @staticmethod\n    def split_data(\n        split: DataSplit,\n        data: Any,\n        data_type: DataType,\n        dependent_vars: DependentVars,\n    ) -&gt; Data:\n        \"\"\"Create a split\n\n        Args:\n            split:\n                The data split to use to split the data\n            data:\n                The data to split\n            data_type:\n                The data type\n            dependent_vars:\n                Dependent variables to associate with the data\n\n        Returns:\n            A Data object\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DataSplitter.split_data","title":"<code>split_data(split, data, data_type, dependent_vars)</code>  <code>staticmethod</code>","text":"<p>Create a split</p> <p>Parameters:</p> Name Type Description Default <code>split</code> <code>DataSplit</code> <p>The data split to use to split the data</p> required <code>data</code> <code>Any</code> <p>The data to split</p> required <code>data_type</code> <code>DataType</code> <p>The data type</p> required <code>dependent_vars</code> <code>DependentVars</code> <p>Dependent variables to associate with the data</p> required <p>Returns:</p> Type Description <code>Data</code> <p>A Data object</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>@staticmethod\ndef split_data(\n    split: DataSplit,\n    data: Any,\n    data_type: DataType,\n    dependent_vars: DependentVars,\n) -&gt; Data:\n    \"\"\"Create a split\n\n    Args:\n        split:\n            The data split to use to split the data\n        data:\n            The data to split\n        data_type:\n            The data type\n        dependent_vars:\n            Dependent variables to associate with the data\n\n    Returns:\n        A Data object\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DependentVars","title":"<code>DependentVars</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class DependentVars:\n    def __init__(\n        self,\n        column_names: Optional[List[str]] = None,\n        column_indices: Optional[List[int]] = None,\n    ) -&gt; None:\n        \"\"\"Define dependent variables for the data interface. User\n        can specify either column names or column indices.\n\n        Args:\n            column_names:\n                The column names of the dependent variables\n            column_indices:\n                The column indices of the dependent variables\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the dependent variables\"\"\"\n\n    @property\n    def column_names(self) -&gt; List[str]:\n        \"\"\"Return the column names\"\"\"\n\n    @column_names.setter\n    def column_names(self, column_names: List[str]) -&gt; None:\n        \"\"\"Set the column names\"\"\"\n\n    @property\n    def column_indices(self) -&gt; List[int]:\n        \"\"\"Return the column indices\"\"\"\n\n    @column_indices.setter\n    def column_indices(self, column_indices: List[int]) -&gt; None:\n        \"\"\"Set the column indices\"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DependentVars.column_indices","title":"<code>column_indices</code>  <code>property</code> <code>writable</code>","text":"<p>Return the column indices</p>"},{"location":"docs/api/data/#opsml.data._data.DependentVars.column_names","title":"<code>column_names</code>  <code>property</code> <code>writable</code>","text":"<p>Return the column names</p>"},{"location":"docs/api/data/#opsml.data._data.DependentVars.__init__","title":"<code>__init__(column_names=None, column_indices=None)</code>","text":"<p>Define dependent variables for the data interface. User can specify either column names or column indices.</p> <p>Parameters:</p> Name Type Description Default <code>column_names</code> <code>Optional[List[str]]</code> <p>The column names of the dependent variables</p> <code>None</code> <code>column_indices</code> <code>Optional[List[int]]</code> <p>The column indices of the dependent variables</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    column_names: Optional[List[str]] = None,\n    column_indices: Optional[List[int]] = None,\n) -&gt; None:\n    \"\"\"Define dependent variables for the data interface. User\n    can specify either column names or column indices.\n\n    Args:\n        column_names:\n            The column names of the dependent variables\n        column_indices:\n            The column indices of the dependent variables\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.DependentVars.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the dependent variables</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the dependent variables\"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.IndiceSplit","title":"<code>IndiceSplit</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class IndiceSplit:\n    indices: List[int]\n\n    def __init__(self, indices: List[int]) -&gt; None:\n        \"\"\"Define an indice split\n\n        Args:\n            indices:\n                The indices of the split\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.IndiceSplit.__init__","title":"<code>__init__(indices)</code>","text":"<p>Define an indice split</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>List[int]</code> <p>The indices of the split</p> required Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(self, indices: List[int]) -&gt; None:\n    \"\"\"Define an indice split\n\n    Args:\n        indices:\n            The indices of the split\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.NumpyData","title":"<code>NumpyData</code>","text":"<p>               Bases: <code>DataInterface</code></p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class NumpyData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (np.NDArray | None):\n                Numpy array\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: Optional[DataSaveKwargs] = None,\n    ) -&gt; DataInterfaceMetadata:\n        \"\"\"Save data using numpy save format\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n\n            see: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n\n            allow_pickle (bool):\n                Allow saving object arrays using Python pickles.\n            fix_imports (bool):\n                The fix_imports flag is deprecated and has no effect\n\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data via numpy.load\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to use when loading\n\n        Acceptable load kwargs:\n\n            see: https://numpy.org/doc/stable/reference/generated/numpy.load.html\n\n            mmap_mode:\n                If not None, then memory-map the file, using the given mode\n            allow_pickle (bool):\n                Allow loading pickled object arrays stored in npy files\n            fix_imports (bool):\n                If fix_imports is True, pickle will try to map the old Python 2 names to the new names used in Python 3.\n            encoding (str):\n                What encoding to use when reading Python 2 strings. Only useful when py3k is True.\n            max_header_size (int):\n                The maximum size of the file header\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.NumpyData.__init__","title":"<code>__init__(data=None, data_splits=None, dependent_vars=None, sql_logic=None, data_profile=None)</code>","text":"<p>Define a data interface</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray | None</code> <p>Numpy array</p> <code>None</code> <code>dependent_vars</code> <code>DependentVars | List[str] | List[int] | None</code> <p>List of dependent variables to associate with data</p> <code>None</code> <code>data_splits</code> <code>DataSplits | List[DataSplit]</code> <p>Optional list of <code>DataSplit</code></p> <code>None</code> <code>sql_logic</code> <code>SqlLogic | None</code> <p>Sql logic used to generate data represented as a dictionary.</p> <code>None</code> <code>data_profile</code> <code>DataProfile | None</code> <p>Data profile</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    data: Optional[Any] = None,\n    data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n    dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n    sql_logic: Optional[SqlLogic] = None,\n    data_profile: Optional[DataProfile] = None,\n) -&gt; None:\n    \"\"\"Define a data interface\n\n    Args:\n        data (np.NDArray | None):\n            Numpy array\n        dependent_vars (DependentVars | List[str] | List[int] | None):\n            List of dependent variables to associate with data\n        data_splits (DataSplits | List[DataSplit]):\n            Optional list of `DataSplit`\n        sql_logic (SqlLogic | None):\n            Sql logic used to generate data represented as a dictionary.\n        data_profile (DataProfile | None):\n            Data profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.NumpyData.load","title":"<code>load(path, metadata, load_kwargs=None)</code>","text":"<p>Load the data via numpy.load</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to load the data from.</p> required <code>metadata</code> <code>DataInterfaceSaveMetadata</code> <p>Metadata associated with the data</p> required <code>load_kwargs</code> <code>DataLoadKwargs</code> <p>Additional kwargs to use when loading</p> <code>None</code> <p>Acceptable load kwargs:</p> <pre><code>see: https://numpy.org/doc/stable/reference/generated/numpy.load.html\n\nmmap_mode:\n    If not None, then memory-map the file, using the given mode\nallow_pickle (bool):\n    Allow loading pickled object arrays stored in npy files\nfix_imports (bool):\n    If fix_imports is True, pickle will try to map the old Python 2 names to the new names used in Python 3.\nencoding (str):\n    What encoding to use when reading Python 2 strings. Only useful when py3k is True.\nmax_header_size (int):\n    The maximum size of the file header\n</code></pre> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def load(\n    self,\n    path: Path,\n    metadata: DataInterfaceSaveMetadata,\n    load_kwargs: Optional[DataLoadKwargs] = None,\n) -&gt; None:\n    \"\"\"Load the data via numpy.load\n\n    Args:\n        path (Path):\n            Base path to load the data from.\n        metadata (DataInterfaceSaveMetadata):\n            Metadata associated with the data\n        load_kwargs (DataLoadKwargs):\n            Additional kwargs to use when loading\n\n    Acceptable load kwargs:\n\n        see: https://numpy.org/doc/stable/reference/generated/numpy.load.html\n\n        mmap_mode:\n            If not None, then memory-map the file, using the given mode\n        allow_pickle (bool):\n            Allow loading pickled object arrays stored in npy files\n        fix_imports (bool):\n            If fix_imports is True, pickle will try to map the old Python 2 names to the new names used in Python 3.\n        encoding (str):\n            What encoding to use when reading Python 2 strings. Only useful when py3k is True.\n        max_header_size (int):\n            The maximum size of the file header\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.NumpyData.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Save data using numpy save format</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to save the data to.</p> required <code>save_kwargs</code> <code>DataSaveKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> <p>Acceptable save kwargs:</p> <pre><code>see: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n\nallow_pickle (bool):\n    Allow saving object arrays using Python pickles.\nfix_imports (bool):\n    The fix_imports flag is deprecated and has no effect\n</code></pre> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def save(\n    self,\n    path: Path,\n    save_kwargs: Optional[DataSaveKwargs] = None,\n) -&gt; DataInterfaceMetadata:\n    \"\"\"Save data using numpy save format\n\n    Args:\n        path (Path):\n            Base path to save the data to.\n        save_kwargs (DataSaveKwargs):\n            Additional kwargs to pass in.\n\n    Acceptable save kwargs:\n\n        see: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n\n        allow_pickle (bool):\n            Allow saving object arrays using Python pickles.\n        fix_imports (bool):\n            The fix_imports flag is deprecated and has no effect\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.PandasData","title":"<code>PandasData</code>","text":"<p>               Bases: <code>DataInterface</code></p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class PandasData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (pd.DataFrame | None):\n                Pandas dataframe\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves pandas dataframe as parquet file via to_parquet\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n            engine ({'auto', 'pyarrow', 'fastparquet'}):\n                Parquet library to use. If 'auto', then the option io.parquet.engine is used.\n                The default io.parquet.engine behavior is to try 'pyarrow',\n                falling back to 'fastparquet' if 'pyarrow' is unavailable. Default is 'auto'.\n            compression (str | None):\n                Name of the compression to use. Use None for no compression.\n                Supported options: 'snappy', 'gzip', 'brotli', 'lz4', 'zstd'. Default is 'snappy'.\n            index (bool | None):\n                If True, include the dataframe's index(es) in the file output.\n                If False, they will not be written to the file. If None, similar to True the dataframe's index(es) will be saved.\n                However, instead of being saved as values, the RangeIndex will be stored as a range in the metadata so it doesn't\n                require much space and is faster.\n                Other indexes will be included as columns in the file output. Default is None.\n            partition_cols (list | None):\n                Column names by which to partition the dataset. Columns are partitioned in the order they are given.\n                Must be None if path is not a string. Default is None.\n            storage_options (dict | None):\n                Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc.\n                For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options.\n                For other URLs (e.g. starting with \u201cs3://\u201d, and \u201cgcs://\u201d) the key-value pairs are forwarded to fsspec.open.\n                Default is None.\n            **kwargs:\n                Any additional kwargs are passed to the engine\n\n        Additional Information:\n            https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the pandas dataframe from a parquet dataset via read_parquet\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable load kwargs:\n            engine ({'auto', 'pyarrow', 'fastparquet'}):\n                Parquet library to use. If 'auto', then the option io.parquet.engine is used.\n                The default io.parquet.engine behavior is to try 'pyarrow',\n                falling back to 'fastparquet' if 'pyarrow' is unavailable. Default is 'auto'.\n            columns (list | None):\n                If not None, only these columns will be read from the file. Default is None.\n            storage_options (dict | None):\n                Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc.\n                For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options.\n                For other URLs (e.g. starting with \u201cs3://\u201d, and \u201cgcs://\u201d) the key-value pairs are forwarded to fsspec.open.\n                Default is None.\n            use_nullable_dtypes (bool):\n                If True, use dtypes that use pd.NA as missing value indicator for the resulting DataFrame.\n                (only applicable for the pyarrow engine) As new dtypes are added that support pd.NA in the future,\n                the output with this option will change to use those dtypes.\n                Note: this is an experimental option, and behaviour (e.g. additional support dtypes) may change without notice.\n                Default is False. Deprecated since version 2.0.\n            dtype_backend ({'numpy_nullable', 'pyarrow'}):\n                Back-end data type applied to the resultant DataFrame (still experimental).\n                Behaviour is as follows:\n                    - \"numpy_nullable\": returns nullable-dtype-backed DataFrame (default).\n                    - \"pyarrow\": returns pyarrow-backed nullable ArrowDtype DataFrame. Default is 'numpy_nullable'.\n            filesystem (fsspec | pyarrow filesystem | None):\n                Filesystem object to use when reading the parquet file. Only implemented for engine=\"pyarrow\". Default is None.\n            filters (list[tuple] | list[list[tuple]] | None):\n                To filter out data.\n                Filter syntax:\n                    [[(column, op, val), \u2026],\u2026] where op is [==, =, &gt;, &gt;=, &lt;, &lt;=, !=, in, not in]\n                The innermost tuples are transposed into a set of filters applied through an AND operation.\n                The outer list combines these sets of filters through an OR operation. A single list of tuples can also be used,\n                meaning that no OR operation between set of filters is to be conducted.\n                Using this argument will NOT result in row-wise filtering of the final partitions unless engine=\"pyarrow\"\n                is also specified.\n                For other engines, filtering is only performed at the partition level, that is,\n                to prevent the loading of some row-groups and/or files. Default is None.\n            **kwargs:\n                Any additional kwargs are passed to the engine.\n\n        Additional Information:\n            https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.PandasData.__init__","title":"<code>__init__(data=None, data_splits=None, dependent_vars=None, sql_logic=None, data_profile=None)</code>","text":"<p>Define a data interface</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | None</code> <p>Pandas dataframe</p> <code>None</code> <code>dependent_vars</code> <code>DependentVars | List[str] | List[int] | None</code> <p>List of dependent variables to associate with data</p> <code>None</code> <code>data_splits</code> <code>DataSplits | List[DataSplit]</code> <p>Optional list of <code>DataSplit</code></p> <code>None</code> <code>sql_logic</code> <code>SqlLogic | None</code> <p>Sql logic used to generate data represented as a dictionary.</p> <code>None</code> <code>data_profile</code> <code>DataProfile | None</code> <p>Data profile</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    data: Optional[Any] = None,\n    data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n    dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n    sql_logic: Optional[SqlLogic] = None,\n    data_profile: Optional[DataProfile] = None,\n) -&gt; None:\n    \"\"\"Define a data interface\n\n    Args:\n        data (pd.DataFrame | None):\n            Pandas dataframe\n        dependent_vars (DependentVars | List[str] | List[int] | None):\n            List of dependent variables to associate with data\n        data_splits (DataSplits | List[DataSplit]):\n            Optional list of `DataSplit`\n        sql_logic (SqlLogic | None):\n            Sql logic used to generate data represented as a dictionary.\n        data_profile (DataProfile | None):\n            Data profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.PandasData.load","title":"<code>load(path, metadata, load_kwargs=None)</code>","text":"<p>Load the pandas dataframe from a parquet dataset via read_parquet</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to load the data from.</p> required <code>metadata</code> <code>DataInterfaceSaveMetadata</code> <p>Metadata associated with the data</p> required <code>load_kwargs</code> <code>DataLoadKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Acceptable load kwargs <p>engine ({'auto', 'pyarrow', 'fastparquet'}):     Parquet library to use. If 'auto', then the option io.parquet.engine is used.     The default io.parquet.engine behavior is to try 'pyarrow',     falling back to 'fastparquet' if 'pyarrow' is unavailable. Default is 'auto'. columns (list | None):     If not None, only these columns will be read from the file. Default is None. storage_options (dict | None):     Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc.     For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options.     For other URLs (e.g. starting with \u201cs3://\u201d, and \u201cgcs://\u201d) the key-value pairs are forwarded to fsspec.open.     Default is None. use_nullable_dtypes (bool):     If True, use dtypes that use pd.NA as missing value indicator for the resulting DataFrame.     (only applicable for the pyarrow engine) As new dtypes are added that support pd.NA in the future,     the output with this option will change to use those dtypes.     Note: this is an experimental option, and behaviour (e.g. additional support dtypes) may change without notice.     Default is False. Deprecated since version 2.0. dtype_backend ({'numpy_nullable', 'pyarrow'}):     Back-end data type applied to the resultant DataFrame (still experimental).     Behaviour is as follows:         - \"numpy_nullable\": returns nullable-dtype-backed DataFrame (default).         - \"pyarrow\": returns pyarrow-backed nullable ArrowDtype DataFrame. Default is 'numpy_nullable'. filesystem (fsspec | pyarrow filesystem | None):     Filesystem object to use when reading the parquet file. Only implemented for engine=\"pyarrow\". Default is None. filters (list[tuple] | list[list[tuple]] | None):     To filter out data.     Filter syntax:         [[(column, op, val), \u2026],\u2026] where op is [==, =, &gt;, &gt;=, &lt;, &lt;=, !=, in, not in]     The innermost tuples are transposed into a set of filters applied through an AND operation.     The outer list combines these sets of filters through an OR operation. A single list of tuples can also be used,     meaning that no OR operation between set of filters is to be conducted.     Using this argument will NOT result in row-wise filtering of the final partitions unless engine=\"pyarrow\"     is also specified.     For other engines, filtering is only performed at the partition level, that is,     to prevent the loading of some row-groups and/or files. Default is None. **kwargs:     Any additional kwargs are passed to the engine.</p> Additional Information <p>https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def load(\n    self,\n    path: Path,\n    metadata: DataInterfaceSaveMetadata,\n    load_kwargs: Optional[DataLoadKwargs] = None,\n) -&gt; None:\n    \"\"\"Load the pandas dataframe from a parquet dataset via read_parquet\n\n    Args:\n        path (Path):\n            Base path to load the data from.\n        metadata (DataInterfaceSaveMetadata):\n            Metadata associated with the data\n        load_kwargs (DataLoadKwargs):\n            Additional kwargs to pass in.\n\n    Acceptable load kwargs:\n        engine ({'auto', 'pyarrow', 'fastparquet'}):\n            Parquet library to use. If 'auto', then the option io.parquet.engine is used.\n            The default io.parquet.engine behavior is to try 'pyarrow',\n            falling back to 'fastparquet' if 'pyarrow' is unavailable. Default is 'auto'.\n        columns (list | None):\n            If not None, only these columns will be read from the file. Default is None.\n        storage_options (dict | None):\n            Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc.\n            For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options.\n            For other URLs (e.g. starting with \u201cs3://\u201d, and \u201cgcs://\u201d) the key-value pairs are forwarded to fsspec.open.\n            Default is None.\n        use_nullable_dtypes (bool):\n            If True, use dtypes that use pd.NA as missing value indicator for the resulting DataFrame.\n            (only applicable for the pyarrow engine) As new dtypes are added that support pd.NA in the future,\n            the output with this option will change to use those dtypes.\n            Note: this is an experimental option, and behaviour (e.g. additional support dtypes) may change without notice.\n            Default is False. Deprecated since version 2.0.\n        dtype_backend ({'numpy_nullable', 'pyarrow'}):\n            Back-end data type applied to the resultant DataFrame (still experimental).\n            Behaviour is as follows:\n                - \"numpy_nullable\": returns nullable-dtype-backed DataFrame (default).\n                - \"pyarrow\": returns pyarrow-backed nullable ArrowDtype DataFrame. Default is 'numpy_nullable'.\n        filesystem (fsspec | pyarrow filesystem | None):\n            Filesystem object to use when reading the parquet file. Only implemented for engine=\"pyarrow\". Default is None.\n        filters (list[tuple] | list[list[tuple]] | None):\n            To filter out data.\n            Filter syntax:\n                [[(column, op, val), \u2026],\u2026] where op is [==, =, &gt;, &gt;=, &lt;, &lt;=, !=, in, not in]\n            The innermost tuples are transposed into a set of filters applied through an AND operation.\n            The outer list combines these sets of filters through an OR operation. A single list of tuples can also be used,\n            meaning that no OR operation between set of filters is to be conducted.\n            Using this argument will NOT result in row-wise filtering of the final partitions unless engine=\"pyarrow\"\n            is also specified.\n            For other engines, filtering is only performed at the partition level, that is,\n            to prevent the loading of some row-groups and/or files. Default is None.\n        **kwargs:\n            Any additional kwargs are passed to the engine.\n\n    Additional Information:\n        https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.PandasData.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Saves pandas dataframe as parquet file via to_parquet</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to save the data to.</p> required <code>save_kwargs</code> <code>DataSaveKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Acceptable save kwargs <p>engine ({'auto', 'pyarrow', 'fastparquet'}):     Parquet library to use. If 'auto', then the option io.parquet.engine is used.     The default io.parquet.engine behavior is to try 'pyarrow',     falling back to 'fastparquet' if 'pyarrow' is unavailable. Default is 'auto'. compression (str | None):     Name of the compression to use. Use None for no compression.     Supported options: 'snappy', 'gzip', 'brotli', 'lz4', 'zstd'. Default is 'snappy'. index (bool | None):     If True, include the dataframe's index(es) in the file output.     If False, they will not be written to the file. If None, similar to True the dataframe's index(es) will be saved.     However, instead of being saved as values, the RangeIndex will be stored as a range in the metadata so it doesn't     require much space and is faster.     Other indexes will be included as columns in the file output. Default is None. partition_cols (list | None):     Column names by which to partition the dataset. Columns are partitioned in the order they are given.     Must be None if path is not a string. Default is None. storage_options (dict | None):     Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc.     For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options.     For other URLs (e.g. starting with \u201cs3://\u201d, and \u201cgcs://\u201d) the key-value pairs are forwarded to fsspec.open.     Default is None. **kwargs:     Any additional kwargs are passed to the engine</p> Additional Information <p>https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def save(self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None) -&gt; DataInterfaceMetadata:\n    \"\"\"Saves pandas dataframe as parquet file via to_parquet\n\n    Args:\n        path (Path):\n            Base path to save the data to.\n        save_kwargs (DataSaveKwargs):\n            Additional kwargs to pass in.\n\n    Acceptable save kwargs:\n        engine ({'auto', 'pyarrow', 'fastparquet'}):\n            Parquet library to use. If 'auto', then the option io.parquet.engine is used.\n            The default io.parquet.engine behavior is to try 'pyarrow',\n            falling back to 'fastparquet' if 'pyarrow' is unavailable. Default is 'auto'.\n        compression (str | None):\n            Name of the compression to use. Use None for no compression.\n            Supported options: 'snappy', 'gzip', 'brotli', 'lz4', 'zstd'. Default is 'snappy'.\n        index (bool | None):\n            If True, include the dataframe's index(es) in the file output.\n            If False, they will not be written to the file. If None, similar to True the dataframe's index(es) will be saved.\n            However, instead of being saved as values, the RangeIndex will be stored as a range in the metadata so it doesn't\n            require much space and is faster.\n            Other indexes will be included as columns in the file output. Default is None.\n        partition_cols (list | None):\n            Column names by which to partition the dataset. Columns are partitioned in the order they are given.\n            Must be None if path is not a string. Default is None.\n        storage_options (dict | None):\n            Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc.\n            For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options.\n            For other URLs (e.g. starting with \u201cs3://\u201d, and \u201cgcs://\u201d) the key-value pairs are forwarded to fsspec.open.\n            Default is None.\n        **kwargs:\n            Any additional kwargs are passed to the engine\n\n    Additional Information:\n        https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.PolarsData","title":"<code>PolarsData</code>","text":"<p>               Bases: <code>DataInterface</code></p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class PolarsData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (pl.DataFrame | None):\n                Pandas dataframe\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n\n        \"\"\"\n\n    def save(self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves polars dataframe to parquet dataset via write_parquet\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n            compression (ParquetCompression):\n                Compression codec to use for writing.\n            compression_level (int | None):\n                Compression level to use. Default is None.\n            statistics (bool | str | dict[str, bool]):\n                Whether to write statistics. Default is True.\n            row_group_size (int | None):\n                Number of rows per row group. Default is None.\n            data_page_size (int | None):\n                Size of data pages. Default is None.\n            use_pyarrow (bool):\n                Whether to use PyArrow for writing. Default is False.\n            pyarrow_options (dict[str, Any] | None):\n                Additional options for PyArrow. Default is None.\n            partition_by (str | Sequence[str] | None):\n                Columns to partition by. Default is None.\n            partition_chunk_size_bytes (int):\n                Size of partition chunks in bytes. Default is 4294967296.\n            storage_options (dict[str, Any] | None):\n                Additional storage options. Default is None.\n            credential_provider (CredentialProviderFunction | Literal['auto'] | None):\n                Credential provider function. Default is 'auto'.\n            retries (int):\n                Number of retries for writing. Default is 2.\n\n        See Also:\n            https://docs.pola.rs/api/python/dev/reference/api/polars.DataFrame.write_parquet.html\n\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data from a file\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable load kwargs:\n            columns (list[int] | list[str] | None):\n                Columns to load. Default is None.\n            n_rows (int | None):\n                Number of rows to load. Default is None.\n            row_index_name (str | None):\n                Name of the row index. Default is None.\n            row_index_offset (int):\n                Offset for the row index. Default is 0.\n            parallel (ParallelStrategy):\n                Parallel strategy to use. Default is 'auto'.\n            use_statistics (bool):\n                Whether to use statistics. Default is True.\n            hive_partitioning (bool | None):\n                Whether to use hive partitioning. Default is None.\n            glob (bool):\n                Whether to use glob pattern matching. Default is True.\n            schema (SchemaDict | None):\n                Schema to use. Default is None.\n            hive_schema (SchemaDict | None):\n                Hive schema to use. Default is None.\n            try_parse_hive_dates (bool):\n                Whether to try parsing hive dates. Default is True.\n            rechunk (bool):\n                Whether to rechunk the data. Default is False.\n            low_memory (bool):\n                Whether to use low memory mode. Default is False.\n            storage_options (dict[str, Any] | None):\n                Additional storage options. Default is None.\n            credential_provider (CredentialProviderFunction | Literal['auto'] | None):\n                Credential provider function. Default is 'auto'.\n            retries (int):\n                Number of retries for loading. Default is 2.\n            use_pyarrow (bool):\n                Whether to use PyArrow for loading. Default is False.\n            pyarrow_options (dict[str, Any] | None):\n                Additional options for PyArrow. Default is None.\n            memory_map (bool):\n                Whether to use memory mapping. Default is True.\n            include_file_paths (str | None):\n                File paths to include. Default is None.\n            allow_missing_columns (bool):\n                Whether to allow missing columns. Default is False.\n\n        See Also:\n            https://docs.pola.rs/api/python/dev/reference/api/polars.read_parquet.html\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.PolarsData.__init__","title":"<code>__init__(data=None, data_splits=None, dependent_vars=None, sql_logic=None, data_profile=None)</code>","text":"<p>Define a data interface</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | None</code> <p>Pandas dataframe</p> <code>None</code> <code>dependent_vars</code> <code>DependentVars | List[str] | List[int] | None</code> <p>List of dependent variables to associate with data</p> <code>None</code> <code>data_splits</code> <code>DataSplits | List[DataSplit]</code> <p>Optional list of <code>DataSplit</code></p> <code>None</code> <code>sql_logic</code> <code>SqlLogic | None</code> <p>Sql logic used to generate data represented as a dictionary.</p> <code>None</code> <code>data_profile</code> <code>DataProfile | None</code> <p>Data profile</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    data: Optional[Any] = None,\n    data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n    dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n    sql_logic: Optional[SqlLogic] = None,\n    data_profile: Optional[DataProfile] = None,\n) -&gt; None:\n    \"\"\"Define a data interface\n\n    Args:\n        data (pl.DataFrame | None):\n            Pandas dataframe\n        dependent_vars (DependentVars | List[str] | List[int] | None):\n            List of dependent variables to associate with data\n        data_splits (DataSplits | List[DataSplit]):\n            Optional list of `DataSplit`\n        sql_logic (SqlLogic | None):\n            Sql logic used to generate data represented as a dictionary.\n        data_profile (DataProfile | None):\n            Data profile\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.PolarsData.load","title":"<code>load(path, metadata, load_kwargs=None)</code>","text":"<p>Load the data from a file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to load the data from.</p> required <code>metadata</code> <code>DataInterfaceSaveMetadata</code> <p>Metadata associated with the data</p> required <code>load_kwargs</code> <code>DataLoadKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Acceptable load kwargs <p>columns (list[int] | list[str] | None):     Columns to load. Default is None. n_rows (int | None):     Number of rows to load. Default is None. row_index_name (str | None):     Name of the row index. Default is None. row_index_offset (int):     Offset for the row index. Default is 0. parallel (ParallelStrategy):     Parallel strategy to use. Default is 'auto'. use_statistics (bool):     Whether to use statistics. Default is True. hive_partitioning (bool | None):     Whether to use hive partitioning. Default is None. glob (bool):     Whether to use glob pattern matching. Default is True. schema (SchemaDict | None):     Schema to use. Default is None. hive_schema (SchemaDict | None):     Hive schema to use. Default is None. try_parse_hive_dates (bool):     Whether to try parsing hive dates. Default is True. rechunk (bool):     Whether to rechunk the data. Default is False. low_memory (bool):     Whether to use low memory mode. Default is False. storage_options (dict[str, Any] | None):     Additional storage options. Default is None. credential_provider (CredentialProviderFunction | Literal['auto'] | None):     Credential provider function. Default is 'auto'. retries (int):     Number of retries for loading. Default is 2. use_pyarrow (bool):     Whether to use PyArrow for loading. Default is False. pyarrow_options (dict[str, Any] | None):     Additional options for PyArrow. Default is None. memory_map (bool):     Whether to use memory mapping. Default is True. include_file_paths (str | None):     File paths to include. Default is None. allow_missing_columns (bool):     Whether to allow missing columns. Default is False.</p> See Also <p>https://docs.pola.rs/api/python/dev/reference/api/polars.read_parquet.html</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def load(\n    self,\n    path: Path,\n    metadata: DataInterfaceSaveMetadata,\n    load_kwargs: Optional[DataLoadKwargs] = None,\n) -&gt; None:\n    \"\"\"Load the data from a file\n\n    Args:\n        path (Path):\n            Base path to load the data from.\n        metadata (DataInterfaceSaveMetadata):\n            Metadata associated with the data\n        load_kwargs (DataLoadKwargs):\n            Additional kwargs to pass in.\n\n    Acceptable load kwargs:\n        columns (list[int] | list[str] | None):\n            Columns to load. Default is None.\n        n_rows (int | None):\n            Number of rows to load. Default is None.\n        row_index_name (str | None):\n            Name of the row index. Default is None.\n        row_index_offset (int):\n            Offset for the row index. Default is 0.\n        parallel (ParallelStrategy):\n            Parallel strategy to use. Default is 'auto'.\n        use_statistics (bool):\n            Whether to use statistics. Default is True.\n        hive_partitioning (bool | None):\n            Whether to use hive partitioning. Default is None.\n        glob (bool):\n            Whether to use glob pattern matching. Default is True.\n        schema (SchemaDict | None):\n            Schema to use. Default is None.\n        hive_schema (SchemaDict | None):\n            Hive schema to use. Default is None.\n        try_parse_hive_dates (bool):\n            Whether to try parsing hive dates. Default is True.\n        rechunk (bool):\n            Whether to rechunk the data. Default is False.\n        low_memory (bool):\n            Whether to use low memory mode. Default is False.\n        storage_options (dict[str, Any] | None):\n            Additional storage options. Default is None.\n        credential_provider (CredentialProviderFunction | Literal['auto'] | None):\n            Credential provider function. Default is 'auto'.\n        retries (int):\n            Number of retries for loading. Default is 2.\n        use_pyarrow (bool):\n            Whether to use PyArrow for loading. Default is False.\n        pyarrow_options (dict[str, Any] | None):\n            Additional options for PyArrow. Default is None.\n        memory_map (bool):\n            Whether to use memory mapping. Default is True.\n        include_file_paths (str | None):\n            File paths to include. Default is None.\n        allow_missing_columns (bool):\n            Whether to allow missing columns. Default is False.\n\n    See Also:\n        https://docs.pola.rs/api/python/dev/reference/api/polars.read_parquet.html\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.PolarsData.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Saves polars dataframe to parquet dataset via write_parquet</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to save the data to.</p> required <code>save_kwargs</code> <code>DataSaveKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Acceptable save kwargs <p>compression (ParquetCompression):     Compression codec to use for writing. compression_level (int | None):     Compression level to use. Default is None. statistics (bool | str | dict[str, bool]):     Whether to write statistics. Default is True. row_group_size (int | None):     Number of rows per row group. Default is None. data_page_size (int | None):     Size of data pages. Default is None. use_pyarrow (bool):     Whether to use PyArrow for writing. Default is False. pyarrow_options (dict[str, Any] | None):     Additional options for PyArrow. Default is None. partition_by (str | Sequence[str] | None):     Columns to partition by. Default is None. partition_chunk_size_bytes (int):     Size of partition chunks in bytes. Default is 4294967296. storage_options (dict[str, Any] | None):     Additional storage options. Default is None. credential_provider (CredentialProviderFunction | Literal['auto'] | None):     Credential provider function. Default is 'auto'. retries (int):     Number of retries for writing. Default is 2.</p> See Also <p>https://docs.pola.rs/api/python/dev/reference/api/polars.DataFrame.write_parquet.html</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def save(self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None) -&gt; DataInterfaceMetadata:\n    \"\"\"Saves polars dataframe to parquet dataset via write_parquet\n\n    Args:\n        path (Path):\n            Base path to save the data to.\n        save_kwargs (DataSaveKwargs):\n            Additional kwargs to pass in.\n\n    Acceptable save kwargs:\n        compression (ParquetCompression):\n            Compression codec to use for writing.\n        compression_level (int | None):\n            Compression level to use. Default is None.\n        statistics (bool | str | dict[str, bool]):\n            Whether to write statistics. Default is True.\n        row_group_size (int | None):\n            Number of rows per row group. Default is None.\n        data_page_size (int | None):\n            Size of data pages. Default is None.\n        use_pyarrow (bool):\n            Whether to use PyArrow for writing. Default is False.\n        pyarrow_options (dict[str, Any] | None):\n            Additional options for PyArrow. Default is None.\n        partition_by (str | Sequence[str] | None):\n            Columns to partition by. Default is None.\n        partition_chunk_size_bytes (int):\n            Size of partition chunks in bytes. Default is 4294967296.\n        storage_options (dict[str, Any] | None):\n            Additional storage options. Default is None.\n        credential_provider (CredentialProviderFunction | Literal['auto'] | None):\n            Credential provider function. Default is 'auto'.\n        retries (int):\n            Number of retries for writing. Default is 2.\n\n    See Also:\n        https://docs.pola.rs/api/python/dev/reference/api/polars.DataFrame.write_parquet.html\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.SqlData","title":"<code>SqlData</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class SqlData:\n    data_type: DataType\n\n    def __init__(\n        self,\n        sql_logic: SqlLogic,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a sql data interface\n\n        Args:\n            sql (SqlLogic):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: Optional[DataSaveKwargs] = None,\n    ) -&gt; DataInterfaceMetadata:\n        \"\"\"Save the sql logic to a file\n\n        Args:\n            path (Path):\n                The path to save the sql logic to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.SqlData.__init__","title":"<code>__init__(sql_logic, data_profile=None)</code>","text":"<p>Define a sql data interface</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>SqlLogic</code> <p>Sql logic used to generate data represented as a dictionary.</p> required <code>data_profile</code> <code>DataProfile | None</code> <p>Data profile</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    sql_logic: SqlLogic,\n    data_profile: Optional[DataProfile] = None,\n) -&gt; None:\n    \"\"\"Define a sql data interface\n\n    Args:\n        sql (SqlLogic):\n            Sql logic used to generate data represented as a dictionary.\n        data_profile (DataProfile | None):\n            Data profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.SqlData.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Save the sql logic to a file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to save the sql logic to.</p> required <code>save_kwargs</code> <code>DataSaveKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def save(\n    self,\n    path: Path,\n    save_kwargs: Optional[DataSaveKwargs] = None,\n) -&gt; DataInterfaceMetadata:\n    \"\"\"Save the sql logic to a file\n\n    Args:\n        path (Path):\n            The path to save the sql logic to.\n        save_kwargs (DataSaveKwargs):\n            Additional kwargs to pass in.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.SqlLogic","title":"<code>SqlLogic</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class SqlLogic:\n    def __init__(self, queries: Dict[str, str]) -&gt; None:\n        \"\"\"Define sql logic\n\n        Args:\n            queries:\n                Sql logic used to generate data represented as a dictionary.\n                Key is the name to assign to the sql logic and value is either a sql query\n                or a path to a .sql file.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the sql logic\"\"\"\n\n    def add_sql_logic(\n        self,\n        name: str,\n        query: Optional[str] = None,\n        filepath: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Add sql logic to existing queries\n\n        Args:\n            name:\n                The name to associate with the sql logic\n            query:\n                SQL query\n            filepath:\n                Filepath to SQL query\n\n        \"\"\"\n\n    @property\n    def queries(self) -&gt; Dict[str, str]:\n        \"\"\"Return the queries\"\"\"\n\n    @queries.setter\n    def queries(self, queries: Dict[str, str]) -&gt; None:\n        \"\"\"Set the queries\"\"\"\n\n    def __getitem__(self, key: str) -&gt; str:\n        \"\"\"Get the query by key\n\n        Args:\n            key:\n                The key to get the query by\n\n        Returns:\n            The query\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.SqlLogic.queries","title":"<code>queries</code>  <code>property</code> <code>writable</code>","text":"<p>Return the queries</p>"},{"location":"docs/api/data/#opsml.data._data.SqlLogic.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get the query by key</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the query by</p> required <p>Returns:</p> Type Description <code>str</code> <p>The query</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __getitem__(self, key: str) -&gt; str:\n    \"\"\"Get the query by key\n\n    Args:\n        key:\n            The key to get the query by\n\n    Returns:\n        The query\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.SqlLogic.__init__","title":"<code>__init__(queries)</code>","text":"<p>Define sql logic</p> <p>Parameters:</p> Name Type Description Default <code>queries</code> <code>Dict[str, str]</code> <p>Sql logic used to generate data represented as a dictionary. Key is the name to assign to the sql logic and value is either a sql query or a path to a .sql file.</p> required Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(self, queries: Dict[str, str]) -&gt; None:\n    \"\"\"Define sql logic\n\n    Args:\n        queries:\n            Sql logic used to generate data represented as a dictionary.\n            Key is the name to assign to the sql logic and value is either a sql query\n            or a path to a .sql file.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.SqlLogic.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the sql logic</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the sql logic\"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.SqlLogic.add_sql_logic","title":"<code>add_sql_logic(name, query=None, filepath=None)</code>","text":"<p>Add sql logic to existing queries</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to associate with the sql logic</p> required <code>query</code> <code>Optional[str]</code> <p>SQL query</p> <code>None</code> <code>filepath</code> <code>Optional[str]</code> <p>Filepath to SQL query</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def add_sql_logic(\n    self,\n    name: str,\n    query: Optional[str] = None,\n    filepath: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Add sql logic to existing queries\n\n    Args:\n        name:\n            The name to associate with the sql logic\n        query:\n            SQL query\n        filepath:\n            Filepath to SQL query\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.StartStopSplit","title":"<code>StartStopSplit</code>","text":"Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class StartStopSplit:\n    start: int\n    stop: int\n\n    def __init__(self, start: int, stop: int) -&gt; None:\n        \"\"\"Define a start stop split\n\n        Args:\n            start:\n                The start of the split\n            stop:\n                The stop of the split\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.StartStopSplit.__init__","title":"<code>__init__(start, stop)</code>","text":"<p>Define a start stop split</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>int</code> <p>The start of the split</p> required <code>stop</code> <code>int</code> <p>The stop of the split</p> required Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(self, start: int, stop: int) -&gt; None:\n    \"\"\"Define a start stop split\n\n    Args:\n        start:\n            The start of the split\n        stop:\n            The stop of the split\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.TorchData","title":"<code>TorchData</code>","text":"<p>               Bases: <code>DataInterface</code></p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>class TorchData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (torch.Tensor | None):\n                Torch tensor\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves torch tensor to a file\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n            pickle_module (Any):\n                Module used for pickling metadata and objects.\n            pickle_protocol (int):\n                Can be specified to override the default protocol.\n\n\n        Additional Information:\n           https://pytorch.org/docs/main/generated/torch.save.html\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the torch tensor from file\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable load kwargs:\n            map_location:\n                A function, torch.device, string or a dict specifying how to remap storage locations.\n            pickle_module:\n                Module used for unpickling metadata and objects (has to match the pickle_module used to serialize file).\n            weights_only:\n                Indicates whether unpickler should be restricted to loading only tensors, primitive types,\n                dictionaries and any types added via torch.serialization.add_safe_globals().\n            mmap:\n                Indicates whether the file should be mmaped rather than loading all the storages into memory.\n                Typically, tensor storages in the file will first be moved from disk to CPU memory,\n                after which they are moved to the location that they were tagged with when saving, or specified by map_location.\n                This second step is a no-op if the final location is CPU. When the mmap flag is set,\n                instead of copying the tensor storages from disk to CPU memory in the first step, f is mmaped.\n            pickle_load_args:\n                (Python 3 only) optional keyword arguments passed over to pickle_module.load() and pickle_module.Unpickler(),\n                e.g., errors=....\n\n\n        Additional Information:\n            https://pytorch.org/docs/stable/generated/torch.load.html\n        \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.TorchData.__init__","title":"<code>__init__(data=None, data_splits=None, dependent_vars=None, sql_logic=None, data_profile=None)</code>","text":"<p>Define a data interface</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Tensor | None</code> <p>Torch tensor</p> <code>None</code> <code>dependent_vars</code> <code>DependentVars | List[str] | List[int] | None</code> <p>List of dependent variables to associate with data</p> <code>None</code> <code>data_splits</code> <code>DataSplits | List[DataSplit]</code> <p>Optional list of <code>DataSplit</code></p> <code>None</code> <code>sql_logic</code> <code>SqlLogic | None</code> <p>Sql logic used to generate data represented as a dictionary.</p> <code>None</code> <code>data_profile</code> <code>DataProfile | None</code> <p>Data profile</p> <code>None</code> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def __init__(\n    self,\n    data: Optional[Any] = None,\n    data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n    dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n    sql_logic: Optional[SqlLogic] = None,\n    data_profile: Optional[DataProfile] = None,\n) -&gt; None:\n    \"\"\"Define a data interface\n\n    Args:\n        data (torch.Tensor | None):\n            Torch tensor\n        dependent_vars (DependentVars | List[str] | List[int] | None):\n            List of dependent variables to associate with data\n        data_splits (DataSplits | List[DataSplit]):\n            Optional list of `DataSplit`\n        sql_logic (SqlLogic | None):\n            Sql logic used to generate data represented as a dictionary.\n        data_profile (DataProfile | None):\n            Data profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.TorchData.load","title":"<code>load(path, metadata, load_kwargs=None)</code>","text":"<p>Load the torch tensor from file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to load the data from.</p> required <code>metadata</code> <code>DataInterfaceSaveMetadata</code> <p>Metadata associated with the data</p> required <code>load_kwargs</code> <code>DataLoadKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Acceptable load kwargs <p>map_location:     A function, torch.device, string or a dict specifying how to remap storage locations. pickle_module:     Module used for unpickling metadata and objects (has to match the pickle_module used to serialize file). weights_only:     Indicates whether unpickler should be restricted to loading only tensors, primitive types,     dictionaries and any types added via torch.serialization.add_safe_globals(). mmap:     Indicates whether the file should be mmaped rather than loading all the storages into memory.     Typically, tensor storages in the file will first be moved from disk to CPU memory,     after which they are moved to the location that they were tagged with when saving, or specified by map_location.     This second step is a no-op if the final location is CPU. When the mmap flag is set,     instead of copying the tensor storages from disk to CPU memory in the first step, f is mmaped. pickle_load_args:     (Python 3 only) optional keyword arguments passed over to pickle_module.load() and pickle_module.Unpickler(),     e.g., errors=....</p> Additional Information <p>https://pytorch.org/docs/stable/generated/torch.load.html</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def load(\n    self,\n    path: Path,\n    metadata: DataInterfaceSaveMetadata,\n    load_kwargs: Optional[DataLoadKwargs] = None,\n) -&gt; None:\n    \"\"\"Load the torch tensor from file\n\n    Args:\n        path (Path):\n            Base path to load the data from.\n        metadata (DataInterfaceSaveMetadata):\n            Metadata associated with the data\n        load_kwargs (DataLoadKwargs):\n            Additional kwargs to pass in.\n\n    Acceptable load kwargs:\n        map_location:\n            A function, torch.device, string or a dict specifying how to remap storage locations.\n        pickle_module:\n            Module used for unpickling metadata and objects (has to match the pickle_module used to serialize file).\n        weights_only:\n            Indicates whether unpickler should be restricted to loading only tensors, primitive types,\n            dictionaries and any types added via torch.serialization.add_safe_globals().\n        mmap:\n            Indicates whether the file should be mmaped rather than loading all the storages into memory.\n            Typically, tensor storages in the file will first be moved from disk to CPU memory,\n            after which they are moved to the location that they were tagged with when saving, or specified by map_location.\n            This second step is a no-op if the final location is CPU. When the mmap flag is set,\n            instead of copying the tensor storages from disk to CPU memory in the first step, f is mmaped.\n        pickle_load_args:\n            (Python 3 only) optional keyword arguments passed over to pickle_module.load() and pickle_module.Unpickler(),\n            e.g., errors=....\n\n\n    Additional Information:\n        https://pytorch.org/docs/stable/generated/torch.load.html\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.TorchData.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Saves torch tensor to a file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to save the data to.</p> required <code>save_kwargs</code> <code>DataSaveKwargs</code> <p>Additional kwargs to pass in.</p> <code>None</code> Acceptable save kwargs <p>pickle_module (Any):     Module used for pickling metadata and objects. pickle_protocol (int):     Can be specified to override the default protocol.</p> Additional Information <p>https://pytorch.org/docs/main/generated/torch.save.html</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def save(self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None) -&gt; DataInterfaceMetadata:\n    \"\"\"Saves torch tensor to a file\n\n    Args:\n        path (Path):\n            Base path to save the data to.\n        save_kwargs (DataSaveKwargs):\n            Additional kwargs to pass in.\n\n    Acceptable save kwargs:\n        pickle_module (Any):\n            Module used for pickling metadata and objects.\n        pickle_protocol (int):\n            Can be specified to override the default protocol.\n\n\n    Additional Information:\n       https://pytorch.org/docs/main/generated/torch.save.html\n    \"\"\"\n</code></pre>"},{"location":"docs/api/data/#opsml.data._data.generate_feature_schema","title":"<code>generate_feature_schema(data, data_type)</code>","text":"<p>Generate a feature schema</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to generate the feature schema from</p> required <code>data_type</code> <code>DataType</code> <p>The data type</p> required <p>Returns:</p> Type Description <code>FeatureSchema</code> <p>A feature map</p> Source code in <code>python/opsml/data/_data.pyi</code> <pre><code>def generate_feature_schema(data: Any, data_type: DataType) -&gt; FeatureSchema:\n    \"\"\"Generate a feature schema\n\n    Args:\n        data:\n            Data to generate the feature schema from\n        data_type:\n            The data type\n\n    Returns:\n        A feature map\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/","title":"Evaluate","text":""},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.BaseModel","title":"<code>BaseModel</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for pydantic BaseModel to ensure compatibility with context</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>class BaseModel(Protocol):\n    \"\"\"Protocol for pydantic BaseModel to ensure compatibility with context\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Dump the model as a dictionary\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model as a JSON string\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the model\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.BaseModel.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the model</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the model\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.BaseModel.model_dump","title":"<code>model_dump()</code>","text":"<p>Dump the model as a dictionary</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Dump the model as a dictionary\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.BaseModel.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the model as a JSON string</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the model as a JSON string\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.EvaluationConfig","title":"<code>EvaluationConfig</code>","text":"<p>Configuration options for LLM evaluation.</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>class EvaluationConfig:\n    \"\"\"Configuration options for LLM evaluation.\"\"\"\n\n    def __init__(\n        self,\n        embedder: Optional[Embedder] = None,\n        embedding_targets: Optional[List[str]] = None,\n        compute_similarity: bool = False,\n        cluster: bool = False,\n        compute_histograms: bool = False,\n    ):\n        \"\"\"\n        Initialize the EvaluationConfig with optional parameters.\n\n        Args:\n            embedder (Optional[Embedder]):\n                Optional Embedder instance to use for generating embeddings for similarity-based metrics.\n                If not provided, no embeddings will be generated.\n            embedding_targets (Optional[List[str]]):\n                Optional list of context keys to generate embeddings for. If not provided, embeddings will\n                be generated for all string fields in the record context.\n            compute_similarity (bool):\n                Whether to compute similarity between embeddings. Default is False.\n            cluster (bool):\n                Whether to perform clustering on the embeddings. Default is False.\n            compute_histograms (bool):\n                Whether to compute histograms for all calculated features (metrics, embeddings, similarities).\n                Default is False.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.EvaluationConfig.__init__","title":"<code>__init__(embedder=None, embedding_targets=None, compute_similarity=False, cluster=False, compute_histograms=False)</code>","text":"<p>Initialize the EvaluationConfig with optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>embedder</code> <code>Optional[Embedder]</code> <p>Optional Embedder instance to use for generating embeddings for similarity-based metrics. If not provided, no embeddings will be generated.</p> <code>None</code> <code>embedding_targets</code> <code>Optional[List[str]]</code> <p>Optional list of context keys to generate embeddings for. If not provided, embeddings will be generated for all string fields in the record context.</p> <code>None</code> <code>compute_similarity</code> <code>bool</code> <p>Whether to compute similarity between embeddings. Default is False.</p> <code>False</code> <code>cluster</code> <code>bool</code> <p>Whether to perform clustering on the embeddings. Default is False.</p> <code>False</code> <code>compute_histograms</code> <code>bool</code> <p>Whether to compute histograms for all calculated features (metrics, embeddings, similarities). Default is False.</p> <code>False</code> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def __init__(\n    self,\n    embedder: Optional[Embedder] = None,\n    embedding_targets: Optional[List[str]] = None,\n    compute_similarity: bool = False,\n    cluster: bool = False,\n    compute_histograms: bool = False,\n):\n    \"\"\"\n    Initialize the EvaluationConfig with optional parameters.\n\n    Args:\n        embedder (Optional[Embedder]):\n            Optional Embedder instance to use for generating embeddings for similarity-based metrics.\n            If not provided, no embeddings will be generated.\n        embedding_targets (Optional[List[str]]):\n            Optional list of context keys to generate embeddings for. If not provided, embeddings will\n            be generated for all string fields in the record context.\n        compute_similarity (bool):\n            Whether to compute similarity between embeddings. Default is False.\n        cluster (bool):\n            Whether to perform clustering on the embeddings. Default is False.\n        compute_histograms (bool):\n            Whether to compute histograms for all calculated features (metrics, embeddings, similarities).\n            Default is False.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalMetric","title":"<code>LLMEvalMetric</code>","text":"<p>Defines an LLM eval metric to use when evaluating LLMs</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>class LLMEvalMetric:\n    \"\"\"Defines an LLM eval metric to use when evaluating LLMs\"\"\"\n\n    def __init__(self, name: str, prompt: Prompt):\n        \"\"\"\n        Initialize an LLMEvalMetric to use for evaluating LLMs. This is\n        most commonly used in conjunction with `evaluate_llm` where LLM inputs\n        and responses can be evaluated against a variety of user-defined metrics.\n\n        Args:\n            name (str):\n                Name of the metric\n            prompt (Prompt):\n                Prompt to use for the metric. For example, a user may create\n                an accuracy analysis prompt or a query reformulation analysis prompt.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        String representation of the LLMEvalMetric\n        \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalMetric.__init__","title":"<code>__init__(name, prompt)</code>","text":"<p>Initialize an LLMEvalMetric to use for evaluating LLMs. This is most commonly used in conjunction with <code>evaluate_llm</code> where LLM inputs and responses can be evaluated against a variety of user-defined metrics.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the metric</p> required <code>prompt</code> <code>Prompt</code> <p>Prompt to use for the metric. For example, a user may create an accuracy analysis prompt or a query reformulation analysis prompt.</p> required Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def __init__(self, name: str, prompt: Prompt):\n    \"\"\"\n    Initialize an LLMEvalMetric to use for evaluating LLMs. This is\n    most commonly used in conjunction with `evaluate_llm` where LLM inputs\n    and responses can be evaluated against a variety of user-defined metrics.\n\n    Args:\n        name (str):\n            Name of the metric\n        prompt (Prompt):\n            Prompt to use for the metric. For example, a user may create\n            an accuracy analysis prompt or a query reformulation analysis prompt.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalMetric.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the LLMEvalMetric</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    String representation of the LLMEvalMetric\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalRecord","title":"<code>LLMEvalRecord</code>","text":"<p>LLM record containing context tied to a Large Language Model interaction that is used to evaluate LLM responses.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; record = LLMEvalRecord(\n        id=\"123\",\n        context={\n            \"input\": \"What is the capital of France?\",\n            \"response\": \"Paris is the capital of France.\"\n        },\n... )\n&gt;&gt;&gt; print(record.context[\"input\"])\n\"What is the capital of France?\"\n</code></pre> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>class LLMEvalRecord:\n    \"\"\"LLM record containing context tied to a Large Language Model interaction\n    that is used to evaluate LLM responses.\n\n\n    Examples:\n        &gt;&gt;&gt; record = LLMEvalRecord(\n                id=\"123\",\n                context={\n                    \"input\": \"What is the capital of France?\",\n                    \"response\": \"Paris is the capital of France.\"\n                },\n        ... )\n        &gt;&gt;&gt; print(record.context[\"input\"])\n        \"What is the capital of France?\"\n    \"\"\"\n\n    def __init__(\n        self,\n        context: Context,\n        id: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Creates a new LLM record to associate with an `LLMDriftProfile`.\n        The record is sent to the `Scouter` server via the `ScouterQueue` and is\n        then used to inject context into the evaluation prompts.\n\n        Args:\n            context:\n                Additional context information as a dictionary or a pydantic BaseModel. During evaluation,\n                this will be merged with the input and response data and passed to the assigned\n                evaluation prompts. So if you're evaluation prompts expect additional context via\n                bound variables (e.g., `${foo}`), you can pass that here as key value pairs.\n                {\"foo\": \"bar\"}\n            id:\n                Unique identifier for the record. If not provided, a new UUID will be generated.\n                This is helpful for when joining evaluation results back to the original request.\n\n        Raises:\n            TypeError: If context is not a dict or a pydantic BaseModel.\n\n        \"\"\"\n\n    @property\n    def context(self) -&gt; Dict[str, Any]:\n        \"\"\"Get the contextual information.\n\n        Returns:\n            The context data as a Python object (deserialized from JSON).\n        \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalRecord.context","title":"<code>context</code>  <code>property</code>","text":"<p>Get the contextual information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The context data as a Python object (deserialized from JSON).</p>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalRecord.__init__","title":"<code>__init__(context, id=None)</code>","text":"<p>Creates a new LLM record to associate with an <code>LLMDriftProfile</code>. The record is sent to the <code>Scouter</code> server via the <code>ScouterQueue</code> and is then used to inject context into the evaluation prompts.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>Additional context information as a dictionary or a pydantic BaseModel. During evaluation, this will be merged with the input and response data and passed to the assigned evaluation prompts. So if you're evaluation prompts expect additional context via bound variables (e.g., <code>${foo}</code>), you can pass that here as key value pairs.</p> required <code>id</code> <code>Optional[str]</code> <p>Unique identifier for the record. If not provided, a new UUID will be generated. This is helpful for when joining evaluation results back to the original request.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If context is not a dict or a pydantic BaseModel.</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def __init__(\n    self,\n    context: Context,\n    id: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Creates a new LLM record to associate with an `LLMDriftProfile`.\n    The record is sent to the `Scouter` server via the `ScouterQueue` and is\n    then used to inject context into the evaluation prompts.\n\n    Args:\n        context:\n            Additional context information as a dictionary or a pydantic BaseModel. During evaluation,\n            this will be merged with the input and response data and passed to the assigned\n            evaluation prompts. So if you're evaluation prompts expect additional context via\n            bound variables (e.g., `${foo}`), you can pass that here as key value pairs.\n            {\"foo\": \"bar\"}\n        id:\n            Unique identifier for the record. If not provided, a new UUID will be generated.\n            This is helpful for when joining evaluation results back to the original request.\n\n    Raises:\n        TypeError: If context is not a dict or a pydantic BaseModel.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalResults","title":"<code>LLMEvalResults</code>","text":"<p>Defines the results of an LLM eval metric</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>class LLMEvalResults:\n    \"\"\"Defines the results of an LLM eval metric\"\"\"\n\n    def __getitem__(self, key: str) -&gt; LLMEvalTaskResult:\n        \"\"\"Get the task results for a specific record ID. A RuntimeError will be raised if the record ID does not exist.\"\"\"\n\n    def __str__(self):\n        \"\"\"String representation of the LLMEvalResults\"\"\"\n\n    def to_dataframe(self, polars: bool = False) -&gt; Any:\n        \"\"\"\n        Convert the results to a Pandas or Polars DataFrame.\n\n        Args:\n            polars (bool):\n                Whether to return a Polars DataFrame. If False, a Pandas DataFrame will be returned.\n\n        Returns:\n            DataFrame:\n                A Pandas or Polars DataFrame containing the results.\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the results as a JSON string\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"LLMEvalResults\":\n        \"\"\"Validate and create an LLMEvalResults instance from a JSON string\n\n        Args:\n            json_string (str):\n                JSON string to validate and create the LLMEvalResults instance from.\n        \"\"\"\n\n    @property\n    def errored_tasks(self) -&gt; List[str]:\n        \"\"\"Get a list of record IDs that had errors during evaluation\"\"\"\n\n    @property\n    def histograms(self) -&gt; Optional[Dict[str, Histogram]]:\n        \"\"\"Get histograms for all calculated features (metrics, embeddings, similarities)\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalResults.errored_tasks","title":"<code>errored_tasks</code>  <code>property</code>","text":"<p>Get a list of record IDs that had errors during evaluation</p>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalResults.histograms","title":"<code>histograms</code>  <code>property</code>","text":"<p>Get histograms for all calculated features (metrics, embeddings, similarities)</p>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalResults.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get the task results for a specific record ID. A RuntimeError will be raised if the record ID does not exist.</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def __getitem__(self, key: str) -&gt; LLMEvalTaskResult:\n    \"\"\"Get the task results for a specific record ID. A RuntimeError will be raised if the record ID does not exist.\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalResults.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the LLMEvalResults</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def __str__(self):\n    \"\"\"String representation of the LLMEvalResults\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalResults.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the results as a JSON string</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the results as a JSON string\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalResults.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Validate and create an LLMEvalResults instance from a JSON string</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string to validate and create the LLMEvalResults instance from.</p> required Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"LLMEvalResults\":\n    \"\"\"Validate and create an LLMEvalResults instance from a JSON string\n\n    Args:\n        json_string (str):\n            JSON string to validate and create the LLMEvalResults instance from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalResults.to_dataframe","title":"<code>to_dataframe(polars=False)</code>","text":"<p>Convert the results to a Pandas or Polars DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>polars</code> <code>bool</code> <p>Whether to return a Polars DataFrame. If False, a Pandas DataFrame will be returned.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <code>Any</code> <p>A Pandas or Polars DataFrame containing the results.</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def to_dataframe(self, polars: bool = False) -&gt; Any:\n    \"\"\"\n    Convert the results to a Pandas or Polars DataFrame.\n\n    Args:\n        polars (bool):\n            Whether to return a Polars DataFrame. If False, a Pandas DataFrame will be returned.\n\n    Returns:\n        DataFrame:\n            A Pandas or Polars DataFrame containing the results.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalTaskResult","title":"<code>LLMEvalTaskResult</code>","text":"<p>Eval Result for a specific evaluation</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>class LLMEvalTaskResult:\n    \"\"\"Eval Result for a specific evaluation\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Get the record id associated with this result\"\"\"\n\n    @property\n    def metrics(self) -&gt; Dict[str, Score]:\n        \"\"\"Get the list of metrics\"\"\"\n\n    @property\n    def embedding(self) -&gt; Dict[str, List[float]]:\n        \"\"\"Get embeddings of embedding targets\"\"\"\n</code></pre>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalTaskResult.embedding","title":"<code>embedding</code>  <code>property</code>","text":"<p>Get embeddings of embedding targets</p>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalTaskResult.id","title":"<code>id</code>  <code>property</code>","text":"<p>Get the record id associated with this result</p>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.LLMEvalTaskResult.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>Get the list of metrics</p>"},{"location":"docs/api/evaluate/#opsml.evaluate._evaluate.evaluate_llm","title":"<code>evaluate_llm(records, metrics, config=None)</code>","text":"<p>Evaluate LLM responses using the provided evaluation metrics.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>List[LLMEvalRecord]</code> <p>List of LLM evaluation records to evaluate.</p> required <code>metrics</code> <code>List[LLMEvalMetric]</code> <p>List of LLMEvalMetric instances to use for evaluation.</p> required <code>config</code> <code>Optional[EvaluationConfig]</code> <p>Optional EvaluationConfig instance to configure evaluation options.</p> <code>None</code> <p>Returns:</p> Type Description <code>LLMEvalResults</code> <p>LLMEvalResults</p> Source code in <code>python/opsml/evaluate/_evaluate.pyi</code> <pre><code>def evaluate_llm(\n    records: List[LLMEvalRecord],\n    metrics: List[LLMEvalMetric],\n    config: Optional[EvaluationConfig] = None,\n) -&gt; LLMEvalResults:\n    \"\"\"\n    Evaluate LLM responses using the provided evaluation metrics.\n\n    Args:\n        records (List[LLMEvalRecord]):\n            List of LLM evaluation records to evaluate.\n        metrics (List[LLMEvalMetric]):\n            List of LLMEvalMetric instances to use for evaluation.\n        config (Optional[EvaluationConfig]):\n            Optional EvaluationConfig instance to configure evaluation options.\n\n    Returns:\n        LLMEvalResults\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/","title":"Experiment","text":""},{"location":"docs/api/experiment/#opsml.experiment._experiment.BaseModel","title":"<code>BaseModel</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for pydantic BaseModel to ensure compatibility with context</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>class BaseModel(Protocol):\n    \"\"\"Protocol for pydantic BaseModel to ensure compatibility with context\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Dump the model as a dictionary\"\"\"\n        ...\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model as a JSON string\"\"\"\n        ...\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the model\"\"\"\n        ...\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.BaseModel.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the model</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the model\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.BaseModel.model_dump","title":"<code>model_dump()</code>","text":"<p>Dump the model as a dictionary</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Dump the model as a dictionary\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.BaseModel.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the model as a JSON string</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the model as a JSON string\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.EvalMetrics","title":"<code>EvalMetrics</code>","text":"<p>Map of metrics used that can be used to evaluate a model. The metrics are also used when comparing a model with other models</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>class EvalMetrics:\n    \"\"\"\n    Map of metrics used that can be used to evaluate a model.\n    The metrics are also used when comparing a model with other models\n    \"\"\"\n\n    def __init__(self, metrics: Dict[str, float]) -&gt; None:\n        \"\"\"\n        Initialize EvalMetrics\n\n        Args:\n            metrics (Dict[str, float]):\n                Dictionary of metrics containing the name of the metric as the key and its value as the value.\n        \"\"\"\n\n    def __getitem__(self, key: str) -&gt; float:\n        \"\"\"Get the value of a metric by name. A RuntimeError will be raised if the metric does not exist.\"\"\"\n        ...\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.EvalMetrics.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get the value of a metric by name. A RuntimeError will be raised if the metric does not exist.</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def __getitem__(self, key: str) -&gt; float:\n    \"\"\"Get the value of a metric by name. A RuntimeError will be raised if the metric does not exist.\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.EvalMetrics.__init__","title":"<code>__init__(metrics)</code>","text":"<p>Initialize EvalMetrics</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>Dict[str, float]</code> <p>Dictionary of metrics containing the name of the metric as the key and its value as the value.</p> required Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def __init__(self, metrics: Dict[str, float]) -&gt; None:\n    \"\"\"\n    Initialize EvalMetrics\n\n    Args:\n        metrics (Dict[str, float]):\n            Dictionary of metrics containing the name of the metric as the key and its value as the value.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment","title":"<code>Experiment</code>","text":"Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>class Experiment:\n    def start_experiment(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        code_dir: Optional[Path] = None,\n        log_hardware: bool = False,\n        experiment_uid: Optional[str] = None,\n    ) -&gt; \"Experiment\":\n        \"\"\"\n        Start an Experiment\n\n        Args:\n            space (str | None):\n                space to associate with `ExperimentCard`\n            name (str | None):\n                Name to associate with `ExperimentCard`\n            code_dir (Path | None):\n                Directory to log code from\n            log_hardware (bool):\n                Whether to log hardware information or not\n            experiment_uid (str | None):\n                Experiment UID. If provided, the experiment will be loaded from the server.\n\n        Returns:\n            Experiment\n        \"\"\"\n\n    def __enter__(self) -&gt; \"Experiment\":\n        pass\n\n    def __exit__(self, exc_type, exc_value, traceback) -&gt; None:\n        pass\n\n    @property\n    def llm(self) -&gt; LLMEvaluator:\n        \"\"\"Access to LLM evaluation methods.\"\"\"\n\n    def log_metric(\n        self,\n        name: str,\n        value: float,\n        step: Optional[int] = None,\n        timestamp: Optional[int] = None,\n        created_at: Optional[datetime] = None,\n    ) -&gt; None:\n        \"\"\"\n        Log a metric\n\n        Args:\n            name (str):\n                Name of the metric\n            value (float):\n                Value of the metric\n            step (int | None):\n                Step of the metric\n            timestamp (int | None):\n                Timestamp of the metric\n            created_at (datetime | None):\n                Created at of the metric\n        \"\"\"\n\n    def log_metrics(self, metrics: list[Metric]) -&gt; None:\n        \"\"\"\n        Log multiple metrics\n\n        Args:\n            metrics (list[Metric]):\n                List of metrics to log\n        \"\"\"\n\n    def log_eval_metrics(self, metrics: \"EvalMetrics\") -&gt; None:\n        \"\"\"\n        Log evaluation metrics\n\n        Args:\n            metrics (EvalMetrics):\n                Evaluation metrics to log\n        \"\"\"\n\n    def log_parameter(\n        self,\n        name: str,\n        value: Union[int, float, str],\n    ) -&gt; None:\n        \"\"\"\n        Log a parameter\n\n        Args:\n            name (str):\n                Name of the parameter\n            value (int | float | str):\n                Value of the parameter\n        \"\"\"\n\n    def log_parameters(self, parameters: list[Parameter] | Dict[str, Union[int, float, str]]) -&gt; None:\n        \"\"\"\n        Log multiple parameters\n\n        Args:\n            parameters (list[Parameter] | Dict[str, Union[int, float, str]]):\n                Parameters to log\n        \"\"\"\n\n    def log_artifact(\n        self,\n        lpath: Path,\n        rpath: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"\n        Log an artifact\n\n        Args:\n            lpath (Path):\n                The local path where the artifact has been saved to\n            rpath (Optional[str]):\n                The path to associate with the artifact in the experiment artifact directory\n                {experiment_path}/artifacts. If not provided, defaults to\n                {experiment}/artifacts/{filename}\n        \"\"\"\n\n    def log_figure_from_path(\n        self,\n        lpath: Path,\n        rpath: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"\n        Log a figure\n\n        Args:\n            lpath (Path):\n                The local path where the figure has been saved to. Must be an image type\n                (e.g. jpeg, tiff, png, etc.)\n            rpath (Optional[str]):\n                The path to associate with the figure in the experiment artifact directory\n                {experiment_path}/artifacts/figures. If not provided, defaults to\n                {experiment}/artifacts/figures/{filename}\n\n        \"\"\"\n\n    def log_figure(self, name: str, figure: Any, kwargs: Optional[Dict[str, Any]] = None) -&gt; None:\n        \"\"\"\n        Log a figure. This method will log a matplotlib Figure object to the experiment artifacts.\n\n        Args:\n            name (str):\n                Name of the figure including its file extension\n            figure (Any):\n                Figure to log\n            kwargs (Optional[Dict[str, Any]]):\n                Additional keyword arguments\n        \"\"\"\n\n    def log_artifacts(\n        self,\n        paths: Path,\n    ) -&gt; None:\n        \"\"\"\n        Log multiple artifacts\n\n        Args:\n            paths (Path):\n                Paths to a directory containing artifacts.\n                All files in the directory will be logged.\n        \"\"\"\n\n    @property\n    def card(self) -&gt; \"ExperimentCard\":\n        \"\"\"\n        ExperimentCard associated with the Experiment\n        \"\"\"\n\n    def register_card(\n        self,\n        card: Union[DataCard, ModelCard, PromptCard],\n        version_type: VersionType = VersionType.Minor,\n        pre_tag: Optional[str] = None,\n        build_tag: Optional[str] = None,\n        save_kwargs: Optional[ModelSaveKwargs | DataSaveKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Register a Card as part of an experiment\n\n        Args:\n            card (DataCard | ModelCard):\n                Card to register. Can be a DataCard or a ModelCard\n            version_type (VersionType):\n                How to increment the version SemVer. Default is VersionType.Minor.\n            pre_tag (str):\n                Optional pre tag to associate with the version.\n            build_tag (str):\n                Optional build_tag to associate with the version.\n            save_kwargs (SaveKwargs):\n                Optional SaveKwargs to pass to the Card interface (If using DataCards\n                and ModelCards).\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.card","title":"<code>card</code>  <code>property</code>","text":"<p>ExperimentCard associated with the Experiment</p>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.llm","title":"<code>llm</code>  <code>property</code>","text":"<p>Access to LLM evaluation methods.</p>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.log_artifact","title":"<code>log_artifact(lpath, rpath=None)</code>","text":"<p>Log an artifact</p> <p>Parameters:</p> Name Type Description Default <code>lpath</code> <code>Path</code> <p>The local path where the artifact has been saved to</p> required <code>rpath</code> <code>Optional[str]</code> <p>The path to associate with the artifact in the experiment artifact directory {experiment_path}/artifacts. If not provided, defaults to {experiment}/artifacts/{filename}</p> <code>None</code> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def log_artifact(\n    self,\n    lpath: Path,\n    rpath: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Log an artifact\n\n    Args:\n        lpath (Path):\n            The local path where the artifact has been saved to\n        rpath (Optional[str]):\n            The path to associate with the artifact in the experiment artifact directory\n            {experiment_path}/artifacts. If not provided, defaults to\n            {experiment}/artifacts/{filename}\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.log_artifacts","title":"<code>log_artifacts(paths)</code>","text":"<p>Log multiple artifacts</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>Path</code> <p>Paths to a directory containing artifacts. All files in the directory will be logged.</p> required Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def log_artifacts(\n    self,\n    paths: Path,\n) -&gt; None:\n    \"\"\"\n    Log multiple artifacts\n\n    Args:\n        paths (Path):\n            Paths to a directory containing artifacts.\n            All files in the directory will be logged.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.log_eval_metrics","title":"<code>log_eval_metrics(metrics)</code>","text":"<p>Log evaluation metrics</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>EvalMetrics</code> <p>Evaluation metrics to log</p> required Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def log_eval_metrics(self, metrics: \"EvalMetrics\") -&gt; None:\n    \"\"\"\n    Log evaluation metrics\n\n    Args:\n        metrics (EvalMetrics):\n            Evaluation metrics to log\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.log_figure","title":"<code>log_figure(name, figure, kwargs=None)</code>","text":"<p>Log a figure. This method will log a matplotlib Figure object to the experiment artifacts.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the figure including its file extension</p> required <code>figure</code> <code>Any</code> <p>Figure to log</p> required <code>kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Additional keyword arguments</p> <code>None</code> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def log_figure(self, name: str, figure: Any, kwargs: Optional[Dict[str, Any]] = None) -&gt; None:\n    \"\"\"\n    Log a figure. This method will log a matplotlib Figure object to the experiment artifacts.\n\n    Args:\n        name (str):\n            Name of the figure including its file extension\n        figure (Any):\n            Figure to log\n        kwargs (Optional[Dict[str, Any]]):\n            Additional keyword arguments\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.log_figure_from_path","title":"<code>log_figure_from_path(lpath, rpath=None)</code>","text":"<p>Log a figure</p> <p>Parameters:</p> Name Type Description Default <code>lpath</code> <code>Path</code> <p>The local path where the figure has been saved to. Must be an image type (e.g. jpeg, tiff, png, etc.)</p> required <code>rpath</code> <code>Optional[str]</code> <p>The path to associate with the figure in the experiment artifact directory {experiment_path}/artifacts/figures. If not provided, defaults to {experiment}/artifacts/figures/{filename}</p> <code>None</code> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def log_figure_from_path(\n    self,\n    lpath: Path,\n    rpath: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Log a figure\n\n    Args:\n        lpath (Path):\n            The local path where the figure has been saved to. Must be an image type\n            (e.g. jpeg, tiff, png, etc.)\n        rpath (Optional[str]):\n            The path to associate with the figure in the experiment artifact directory\n            {experiment_path}/artifacts/figures. If not provided, defaults to\n            {experiment}/artifacts/figures/{filename}\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.log_metric","title":"<code>log_metric(name, value, step=None, timestamp=None, created_at=None)</code>","text":"<p>Log a metric</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the metric</p> required <code>value</code> <code>float</code> <p>Value of the metric</p> required <code>step</code> <code>int | None</code> <p>Step of the metric</p> <code>None</code> <code>timestamp</code> <code>int | None</code> <p>Timestamp of the metric</p> <code>None</code> <code>created_at</code> <code>datetime | None</code> <p>Created at of the metric</p> <code>None</code> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def log_metric(\n    self,\n    name: str,\n    value: float,\n    step: Optional[int] = None,\n    timestamp: Optional[int] = None,\n    created_at: Optional[datetime] = None,\n) -&gt; None:\n    \"\"\"\n    Log a metric\n\n    Args:\n        name (str):\n            Name of the metric\n        value (float):\n            Value of the metric\n        step (int | None):\n            Step of the metric\n        timestamp (int | None):\n            Timestamp of the metric\n        created_at (datetime | None):\n            Created at of the metric\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.log_metrics","title":"<code>log_metrics(metrics)</code>","text":"<p>Log multiple metrics</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>list[Metric]</code> <p>List of metrics to log</p> required Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def log_metrics(self, metrics: list[Metric]) -&gt; None:\n    \"\"\"\n    Log multiple metrics\n\n    Args:\n        metrics (list[Metric]):\n            List of metrics to log\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.log_parameter","title":"<code>log_parameter(name, value)</code>","text":"<p>Log a parameter</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the parameter</p> required <code>value</code> <code>int | float | str</code> <p>Value of the parameter</p> required Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def log_parameter(\n    self,\n    name: str,\n    value: Union[int, float, str],\n) -&gt; None:\n    \"\"\"\n    Log a parameter\n\n    Args:\n        name (str):\n            Name of the parameter\n        value (int | float | str):\n            Value of the parameter\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.log_parameters","title":"<code>log_parameters(parameters)</code>","text":"<p>Log multiple parameters</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <code>list[Parameter] | Dict[str, Union[int, float, str]]</code> <p>Parameters to log</p> required Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def log_parameters(self, parameters: list[Parameter] | Dict[str, Union[int, float, str]]) -&gt; None:\n    \"\"\"\n    Log multiple parameters\n\n    Args:\n        parameters (list[Parameter] | Dict[str, Union[int, float, str]]):\n            Parameters to log\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.register_card","title":"<code>register_card(card, version_type=VersionType.Minor, pre_tag=None, build_tag=None, save_kwargs=None)</code>","text":"<p>Register a Card as part of an experiment</p> <p>Parameters:</p> Name Type Description Default <code>card</code> <code>DataCard | ModelCard</code> <p>Card to register. Can be a DataCard or a ModelCard</p> required <code>version_type</code> <code>VersionType</code> <p>How to increment the version SemVer. Default is VersionType.Minor.</p> <code>Minor</code> <code>pre_tag</code> <code>str</code> <p>Optional pre tag to associate with the version.</p> <code>None</code> <code>build_tag</code> <code>str</code> <p>Optional build_tag to associate with the version.</p> <code>None</code> <code>save_kwargs</code> <code>SaveKwargs</code> <p>Optional SaveKwargs to pass to the Card interface (If using DataCards and ModelCards).</p> <code>None</code> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def register_card(\n    self,\n    card: Union[DataCard, ModelCard, PromptCard],\n    version_type: VersionType = VersionType.Minor,\n    pre_tag: Optional[str] = None,\n    build_tag: Optional[str] = None,\n    save_kwargs: Optional[ModelSaveKwargs | DataSaveKwargs] = None,\n) -&gt; None:\n    \"\"\"Register a Card as part of an experiment\n\n    Args:\n        card (DataCard | ModelCard):\n            Card to register. Can be a DataCard or a ModelCard\n        version_type (VersionType):\n            How to increment the version SemVer. Default is VersionType.Minor.\n        pre_tag (str):\n            Optional pre tag to associate with the version.\n        build_tag (str):\n            Optional build_tag to associate with the version.\n        save_kwargs (SaveKwargs):\n            Optional SaveKwargs to pass to the Card interface (If using DataCards\n            and ModelCards).\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Experiment.start_experiment","title":"<code>start_experiment(space=None, name=None, code_dir=None, log_hardware=False, experiment_uid=None)</code>","text":"<p>Start an Experiment</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str | None</code> <p>space to associate with <code>ExperimentCard</code></p> <code>None</code> <code>name</code> <code>str | None</code> <p>Name to associate with <code>ExperimentCard</code></p> <code>None</code> <code>code_dir</code> <code>Path | None</code> <p>Directory to log code from</p> <code>None</code> <code>log_hardware</code> <code>bool</code> <p>Whether to log hardware information or not</p> <code>False</code> <code>experiment_uid</code> <code>str | None</code> <p>Experiment UID. If provided, the experiment will be loaded from the server.</p> <code>None</code> <p>Returns:</p> Type Description <code>Experiment</code> <p>Experiment</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def start_experiment(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    code_dir: Optional[Path] = None,\n    log_hardware: bool = False,\n    experiment_uid: Optional[str] = None,\n) -&gt; \"Experiment\":\n    \"\"\"\n    Start an Experiment\n\n    Args:\n        space (str | None):\n            space to associate with `ExperimentCard`\n        name (str | None):\n            Name to associate with `ExperimentCard`\n        code_dir (Path | None):\n            Directory to log code from\n        log_hardware (bool):\n            Whether to log hardware information or not\n        experiment_uid (str | None):\n            Experiment UID. If provided, the experiment will be loaded from the server.\n\n    Returns:\n        Experiment\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.LLMEvaluator","title":"<code>LLMEvaluator</code>","text":"Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>class LLMEvaluator:\n    @staticmethod\n    def evaluate(\n        records: List[LLMEvalRecord],\n        metrics: List[LLMEvalMetric],\n        config: Optional[EvaluationConfig] = None,\n    ) -&gt; LLMEvalResults:\n        \"\"\"\n            Evaluate LLM responses using the provided evaluation metrics.\n\n        Args:\n            records (List[LLMEvalRecord]):\n                List of LLM evaluation records to evaluate.\n            metrics (List[LLMEvalMetric]):\n                List of LLMEvalMetric instances to use for evaluation.\n            config (Optional[EvaluationConfig]):\n                Optional EvaluationConfig instance to configure evaluation options.\n\n        Returns:\n            LLMEvalResults\n        \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.LLMEvaluator.evaluate","title":"<code>evaluate(records, metrics, config=None)</code>  <code>staticmethod</code>","text":"<pre><code>Evaluate LLM responses using the provided evaluation metrics.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>List[LLMEvalRecord]</code> <p>List of LLM evaluation records to evaluate.</p> required <code>metrics</code> <code>List[LLMEvalMetric]</code> <p>List of LLMEvalMetric instances to use for evaluation.</p> required <code>config</code> <code>Optional[EvaluationConfig]</code> <p>Optional EvaluationConfig instance to configure evaluation options.</p> <code>None</code> <p>Returns:</p> Type Description <code>LLMEvalResults</code> <p>LLMEvalResults</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>@staticmethod\ndef evaluate(\n    records: List[LLMEvalRecord],\n    metrics: List[LLMEvalMetric],\n    config: Optional[EvaluationConfig] = None,\n) -&gt; LLMEvalResults:\n    \"\"\"\n        Evaluate LLM responses using the provided evaluation metrics.\n\n    Args:\n        records (List[LLMEvalRecord]):\n            List of LLM evaluation records to evaluate.\n        metrics (List[LLMEvalMetric]):\n            List of LLMEvalMetric instances to use for evaluation.\n        config (Optional[EvaluationConfig]):\n            Optional EvaluationConfig instance to configure evaluation options.\n\n    Returns:\n        LLMEvalResults\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Metric","title":"<code>Metric</code>","text":"Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>class Metric:\n    def __init__(\n        self,\n        name: str,\n        value: float,\n        step: Optional[int] = None,\n        timestamp: Optional[int] = None,\n        created_at: Optional[datetime] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize a Metric\n\n        Args:\n            name (str):\n                Name of the metric\n            value (float):\n                Value of the metric\n            step (int | None):\n                Step of the metric\n            timestamp (int | None):\n                Timestamp of the metric\n            created_at (datetime | None):\n                Created at of the metric\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"\n        Name of the metric\n        \"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"\n        Value of the metric\n        \"\"\"\n\n    @property\n    def step(self) -&gt; Optional[int]:\n        \"\"\"\n        Step of the metric\n        \"\"\"\n\n    @property\n    def timestamp(self) -&gt; Optional[int]:\n        \"\"\"\n        Timestamp of the metric\n        \"\"\"\n\n    @property\n    def created_at(self) -&gt; Optional[datetime]:\n        \"\"\"\n        Created at of the metric\n        \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Metric.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Created at of the metric</p>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Metric.name","title":"<code>name</code>  <code>property</code>","text":"<p>Name of the metric</p>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Metric.step","title":"<code>step</code>  <code>property</code>","text":"<p>Step of the metric</p>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Metric.timestamp","title":"<code>timestamp</code>  <code>property</code>","text":"<p>Timestamp of the metric</p>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Metric.value","title":"<code>value</code>  <code>property</code>","text":"<p>Value of the metric</p>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Metric.__init__","title":"<code>__init__(name, value, step=None, timestamp=None, created_at=None)</code>","text":"<p>Initialize a Metric</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the metric</p> required <code>value</code> <code>float</code> <p>Value of the metric</p> required <code>step</code> <code>int | None</code> <p>Step of the metric</p> <code>None</code> <code>timestamp</code> <code>int | None</code> <p>Timestamp of the metric</p> <code>None</code> <code>created_at</code> <code>datetime | None</code> <p>Created at of the metric</p> <code>None</code> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    value: float,\n    step: Optional[int] = None,\n    timestamp: Optional[int] = None,\n    created_at: Optional[datetime] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize a Metric\n\n    Args:\n        name (str):\n            Name of the metric\n        value (float):\n            Value of the metric\n        step (int | None):\n            Step of the metric\n        timestamp (int | None):\n            Timestamp of the metric\n        created_at (datetime | None):\n            Created at of the metric\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Parameter","title":"<code>Parameter</code>","text":"Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>class Parameter:\n    def __init__(\n        self,\n        name: str,\n        value: Union[int, float, str],\n    ) -&gt; None:\n        \"\"\"\n        Initialize a Parameter\n\n        Args:\n            name (str):\n                Name of the parameter\n            value (int | float | str):\n                Value of the parameter\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"\n        Name of the parameter\n        \"\"\"\n\n    @property\n    def value(self) -&gt; Union[int, float, str]:\n        \"\"\"\n        Value of the parameter\n        \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Parameter.name","title":"<code>name</code>  <code>property</code>","text":"<p>Name of the parameter</p>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Parameter.value","title":"<code>value</code>  <code>property</code>","text":"<p>Value of the parameter</p>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.Parameter.__init__","title":"<code>__init__(name, value)</code>","text":"<p>Initialize a Parameter</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the parameter</p> required <code>value</code> <code>int | float | str</code> <p>Value of the parameter</p> required Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    value: Union[int, float, str],\n) -&gt; None:\n    \"\"\"\n    Initialize a Parameter\n\n    Args:\n        name (str):\n            Name of the parameter\n        value (int | float | str):\n            Value of the parameter\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.get_experiment_metrics","title":"<code>get_experiment_metrics(experiment_uid, names=None)</code>","text":"<p>Get metrics of an experiment</p> <p>Parameters:</p> Name Type Description Default <code>experiment_uid</code> <code>str</code> <p>UID of the experiment</p> required <code>names</code> <code>list[str] | None</code> <p>Names of the metrics to get. If None, all metrics will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <code>Metrics</code> <p>Metrics</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def get_experiment_metrics(\n    experiment_uid: str,\n    names: Optional[list[str]] = None,\n) -&gt; Metrics:\n    \"\"\"\n    Get metrics of an experiment\n\n    Args:\n        experiment_uid (str):\n            UID of the experiment\n        names (list[str] | None):\n            Names of the metrics to get. If None, all metrics will be returned.\n\n    Returns:\n        Metrics\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.get_experiment_parameters","title":"<code>get_experiment_parameters(experiment_uid, names=None)</code>","text":"<p>Get parameters of an experiment</p> <p>Parameters:</p> Name Type Description Default <code>experiment_uid</code> <code>str</code> <p>UID of the experiment</p> required <code>names</code> <code>list[str] | None</code> <p>Names of the parameters to get. If None, all parameters will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <code>Parameters</code> <p>Parameters</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def get_experiment_parameters(\n    experiment_uid: str,\n    names: Optional[list[str]] = None,\n) -&gt; Parameters:\n    \"\"\"\n    Get parameters of an experiment\n\n    Args:\n        experiment_uid (str):\n            UID of the experiment\n        names (list[str] | None):\n            Names of the parameters to get. If None, all parameters will be returned.\n\n    Returns:\n        Parameters\n    \"\"\"\n</code></pre>"},{"location":"docs/api/experiment/#opsml.experiment._experiment.start_experiment","title":"<code>start_experiment(space=None, name=None, code_dir=None, log_hardware=False, experiment_uid=None)</code>","text":"<p>Start an Experiment</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str | None</code> <p>space to associate with <code>ExperimentCard</code></p> <code>None</code> <code>name</code> <code>str | None</code> <p>Name to associate with <code>ExperimentCard</code></p> <code>None</code> <code>code_dir</code> <code>Path | None</code> <p>Directory to log code from</p> <code>None</code> <code>log_hardware</code> <code>bool</code> <p>Whether to log hardware information or not</p> <code>False</code> <code>experiment_uid</code> <code>str | None</code> <p>Experiment UID. If provided, the experiment will be loaded from the server.</p> <code>None</code> <p>Returns:</p> Type Description <code>Experiment</code> <p>Experiment</p> Source code in <code>python/opsml/experiment/_experiment.pyi</code> <pre><code>def start_experiment(\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    code_dir: Optional[Path] = None,\n    log_hardware: bool = False,\n    experiment_uid: Optional[str] = None,\n) -&gt; Experiment:\n    \"\"\"\n    Start an Experiment\n\n    Args:\n        space (str | None):\n            space to associate with `ExperimentCard`\n        name (str | None):\n            Name to associate with `ExperimentCard`\n        code_dir (Path | None):\n            Directory to log code from\n        log_hardware (bool):\n            Whether to log hardware information or not\n        experiment_uid (str | None):\n            Experiment UID. If provided, the experiment will be loaded from the server.\n\n    Returns:\n        Experiment\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/","title":"Logging","text":""},{"location":"docs/api/logging/#opsml.logging._logging.LoggingConfig","title":"<code>LoggingConfig</code>","text":"Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>class LoggingConfig:\n    show_threads: bool\n    log_level: LogLevel\n    write_level: WriteLevel\n    use_json: bool\n\n    def __init__(\n        self,\n        show_threads: bool = True,\n        log_level: LogLevel = LogLevel.Info,\n        write_level: WriteLevel = WriteLevel.Stdout,\n        use_json: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Logging configuration options.\n\n        Args:\n            show_threads:\n                Whether to include thread information in log messages.\n                Default is True.\n\n            log_level:\n                Log level for the logger.\n                Default is LogLevel.Info.\n\n            write_level:\n                Write level for the logger.\n                Default is WriteLevel.Stdout.\n\n            use_json:\n                Whether to write log messages in JSON format.\n                Default is False.\n        \"\"\"\n\n    @staticmethod\n    def json_default() -&gt; \"LoggingConfig\":\n        \"\"\"Gets a default JSON configuration.\n\n        show_threads: True\n        log_level: Env or LogLevel.Info\n        write_level: WriteLevel.Stdout\n        use_json: True\n\n        Returns:\n            LoggingConfig:\n                The default JSON configuration.\n        \"\"\"\n\n    @staticmethod\n    def default() -&gt; \"LoggingConfig\":\n        \"\"\"Gets a default configuration.\n\n        show_threads: True\n        log_level: Env or LogLevel.Info\n        write_level: WriteLevel.Stdout\n        use_json: False\n\n        Returns:\n            LoggingConfig:\n                The default JSON configuration.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.LoggingConfig.__init__","title":"<code>__init__(show_threads=True, log_level=LogLevel.Info, write_level=WriteLevel.Stdout, use_json=False)</code>","text":"<p>Logging configuration options.</p> <p>Parameters:</p> Name Type Description Default <code>show_threads</code> <code>bool</code> <p>Whether to include thread information in log messages. Default is True.</p> <code>True</code> <code>log_level</code> <code>LogLevel</code> <p>Log level for the logger. Default is LogLevel.Info.</p> <code>Info</code> <code>write_level</code> <code>WriteLevel</code> <p>Write level for the logger. Default is WriteLevel.Stdout.</p> <code>Stdout</code> <code>use_json</code> <code>bool</code> <p>Whether to write log messages in JSON format. Default is False.</p> <code>False</code> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>def __init__(\n    self,\n    show_threads: bool = True,\n    log_level: LogLevel = LogLevel.Info,\n    write_level: WriteLevel = WriteLevel.Stdout,\n    use_json: bool = False,\n) -&gt; None:\n    \"\"\"\n    Logging configuration options.\n\n    Args:\n        show_threads:\n            Whether to include thread information in log messages.\n            Default is True.\n\n        log_level:\n            Log level for the logger.\n            Default is LogLevel.Info.\n\n        write_level:\n            Write level for the logger.\n            Default is WriteLevel.Stdout.\n\n        use_json:\n            Whether to write log messages in JSON format.\n            Default is False.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.LoggingConfig.default","title":"<code>default()</code>  <code>staticmethod</code>","text":"<p>Gets a default configuration.</p> <p>show_threads: True log_level: Env or LogLevel.Info write_level: WriteLevel.Stdout use_json: False</p> <p>Returns:</p> Name Type Description <code>LoggingConfig</code> <code>LoggingConfig</code> <p>The default JSON configuration.</p> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>@staticmethod\ndef default() -&gt; \"LoggingConfig\":\n    \"\"\"Gets a default configuration.\n\n    show_threads: True\n    log_level: Env or LogLevel.Info\n    write_level: WriteLevel.Stdout\n    use_json: False\n\n    Returns:\n        LoggingConfig:\n            The default JSON configuration.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.LoggingConfig.json_default","title":"<code>json_default()</code>  <code>staticmethod</code>","text":"<p>Gets a default JSON configuration.</p> <p>show_threads: True log_level: Env or LogLevel.Info write_level: WriteLevel.Stdout use_json: True</p> <p>Returns:</p> Name Type Description <code>LoggingConfig</code> <code>LoggingConfig</code> <p>The default JSON configuration.</p> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>@staticmethod\ndef json_default() -&gt; \"LoggingConfig\":\n    \"\"\"Gets a default JSON configuration.\n\n    show_threads: True\n    log_level: Env or LogLevel.Info\n    write_level: WriteLevel.Stdout\n    use_json: True\n\n    Returns:\n        LoggingConfig:\n            The default JSON configuration.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.RustyLogger","title":"<code>RustyLogger</code>","text":"<p>The Rusty Logger class to use with your python and rust-backed projects.</p> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>class RustyLogger:\n    \"\"\"The Rusty Logger class to use with your python and rust-backed projects.\"\"\"\n\n    @staticmethod\n    def setup_logging(config: Optional[LoggingConfig] = None) -&gt; None:\n        \"\"\"Sets up the logger with the given configuration.\n\n        Args:\n            config (LoggingConfig):\n                The configuration to use for the logger.\n        \"\"\"\n\n    @staticmethod\n    def get_logger(config: Optional[LoggingConfig] = None) -&gt; \"RustyLogger\":\n        \"\"\"Gets the logger instance.\n\n        Args:\n            config (LoggingConfig):\n                The configuration to use for the logger.\n\n        Returns:\n            RustyLogger:\n                The logger instance.\n        \"\"\"\n\n    def debug(self, message: str, *args) -&gt; None:\n        \"\"\"Logs a debug message.\n\n        Args:\n            message (str):\n                The message to log.\n\n            *args:\n                Additional arguments to log.\n        \"\"\"\n\n    def info(self, message: str, *args) -&gt; None:\n        \"\"\"Logs an info message.\n\n        Args:\n            message (str):\n                The message to log.\n\n            *args:\n                Additional arguments to log.\n        \"\"\"\n\n    def warn(self, message: str, *args) -&gt; None:\n        \"\"\"Logs a warning message.\n\n        Args:\n            message (str):\n                The message to log.\n\n            *args:\n                Additional arguments to log.\n        \"\"\"\n\n    def error(self, message: str, *args) -&gt; None:\n        \"\"\"Logs an error message.\n\n        Args:\n            message (str):\n                The message to log.\n\n            *args:\n                Additional arguments to log.\n        \"\"\"\n\n    def trace(self, message: str, *args) -&gt; None:\n        \"\"\"Logs a trace message.\n\n        Args:\n            message (str):\n                The message to log.\n\n            *args:\n                Additional arguments to log.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.RustyLogger.debug","title":"<code>debug(message, *args)</code>","text":"<p>Logs a debug message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to log.</p> required <code>*args</code> <p>Additional arguments to log.</p> <code>()</code> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>def debug(self, message: str, *args) -&gt; None:\n    \"\"\"Logs a debug message.\n\n    Args:\n        message (str):\n            The message to log.\n\n        *args:\n            Additional arguments to log.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.RustyLogger.error","title":"<code>error(message, *args)</code>","text":"<p>Logs an error message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to log.</p> required <code>*args</code> <p>Additional arguments to log.</p> <code>()</code> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>def error(self, message: str, *args) -&gt; None:\n    \"\"\"Logs an error message.\n\n    Args:\n        message (str):\n            The message to log.\n\n        *args:\n            Additional arguments to log.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.RustyLogger.get_logger","title":"<code>get_logger(config=None)</code>  <code>staticmethod</code>","text":"<p>Gets the logger instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LoggingConfig</code> <p>The configuration to use for the logger.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RustyLogger</code> <code>RustyLogger</code> <p>The logger instance.</p> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>@staticmethod\ndef get_logger(config: Optional[LoggingConfig] = None) -&gt; \"RustyLogger\":\n    \"\"\"Gets the logger instance.\n\n    Args:\n        config (LoggingConfig):\n            The configuration to use for the logger.\n\n    Returns:\n        RustyLogger:\n            The logger instance.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.RustyLogger.info","title":"<code>info(message, *args)</code>","text":"<p>Logs an info message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to log.</p> required <code>*args</code> <p>Additional arguments to log.</p> <code>()</code> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>def info(self, message: str, *args) -&gt; None:\n    \"\"\"Logs an info message.\n\n    Args:\n        message (str):\n            The message to log.\n\n        *args:\n            Additional arguments to log.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.RustyLogger.setup_logging","title":"<code>setup_logging(config=None)</code>  <code>staticmethod</code>","text":"<p>Sets up the logger with the given configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LoggingConfig</code> <p>The configuration to use for the logger.</p> <code>None</code> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>@staticmethod\ndef setup_logging(config: Optional[LoggingConfig] = None) -&gt; None:\n    \"\"\"Sets up the logger with the given configuration.\n\n    Args:\n        config (LoggingConfig):\n            The configuration to use for the logger.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.RustyLogger.trace","title":"<code>trace(message, *args)</code>","text":"<p>Logs a trace message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to log.</p> required <code>*args</code> <p>Additional arguments to log.</p> <code>()</code> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>def trace(self, message: str, *args) -&gt; None:\n    \"\"\"Logs a trace message.\n\n    Args:\n        message (str):\n            The message to log.\n\n        *args:\n            Additional arguments to log.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/logging/#opsml.logging._logging.RustyLogger.warn","title":"<code>warn(message, *args)</code>","text":"<p>Logs a warning message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to log.</p> required <code>*args</code> <p>Additional arguments to log.</p> <code>()</code> Source code in <code>python/opsml/logging/_logging.pyi</code> <pre><code>def warn(self, message: str, *args) -&gt; None:\n    \"\"\"Logs a warning message.\n\n    Args:\n        message (str):\n            The message to log.\n\n        *args:\n            Additional arguments to log.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/mock/","title":"Mock","text":""},{"location":"docs/api/mock/#opsml.mock._mock.LLMTestServer","title":"<code>LLMTestServer</code>","text":"<p>Mock server for OpenAI API. This class is used to simulate the OpenAI API for testing purposes.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>class LLMTestServer:\n    \"\"\"\n    Mock server for OpenAI API.\n    This class is used to simulate the OpenAI API for testing purposes.\n    \"\"\"\n\n    def __init__(self): ...\n    def __enter__(self):\n        \"\"\"\n        Start the mock server.\n        \"\"\"\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        \"\"\"\n        Stop the mock server.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.LLMTestServer.__enter__","title":"<code>__enter__()</code>","text":"<p>Start the mock server.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def __enter__(self):\n    \"\"\"\n    Start the mock server.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.LLMTestServer.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Stop the mock server.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def __exit__(self, exc_type, exc_value, traceback):\n    \"\"\"\n    Stop the mock server.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.MockConfig","title":"<code>MockConfig</code>","text":"Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>class MockConfig:\n    def __init__(self, **kwargs) -&gt; None:\n        \"\"\"Mock configuration for the ScouterQueue\n\n        Args:\n            **kwargs: Arbitrary keyword arguments to set as attributes.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.MockConfig.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Mock configuration for the ScouterQueue</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments to set as attributes.</p> <code>{}</code> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def __init__(self, **kwargs) -&gt; None:\n    \"\"\"Mock configuration for the ScouterQueue\n\n    Args:\n        **kwargs: Arbitrary keyword arguments to set as attributes.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlServerContext","title":"<code>OpsmlServerContext</code>","text":"Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>class OpsmlServerContext:\n    def __init__(self) -&gt; None:\n        \"\"\"Instantiates the server context.\n        This is helpful when you are running tests in server mode to\n        aid in background cleanup of resources\n        \"\"\"\n\n    def __enter__(self) -&gt; \"OpsmlServerContext\":\n        \"\"\"Starts the server context.\"\"\"\n\n    def __exit__(self, exc_type, exc_value, traceback) -&gt; None:\n        \"\"\"Stops the server context.\"\"\"\n\n    @property\n    def server_uri(self) -&gt; str:\n        \"\"\"Returns the server URI.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlServerContext.server_uri","title":"<code>server_uri</code>  <code>property</code>","text":"<p>Returns the server URI.</p>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlServerContext.__enter__","title":"<code>__enter__()</code>","text":"<p>Starts the server context.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def __enter__(self) -&gt; \"OpsmlServerContext\":\n    \"\"\"Starts the server context.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlServerContext.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Stops the server context.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def __exit__(self, exc_type, exc_value, traceback) -&gt; None:\n    \"\"\"Stops the server context.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlServerContext.__init__","title":"<code>__init__()</code>","text":"<p>Instantiates the server context. This is helpful when you are running tests in server mode to aid in background cleanup of resources</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Instantiates the server context.\n    This is helpful when you are running tests in server mode to\n    aid in background cleanup of resources\n    \"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlTestServer","title":"<code>OpsmlTestServer</code>","text":"Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>class OpsmlTestServer:\n    def __init__(self, cleanup: bool = True, base_path: Optional[Path] = None) -&gt; None:\n        \"\"\"Instantiates the test server.\n\n        When the test server is used as a context manager, it will start the server\n        in a background thread and set the appropriate env vars so that the client\n        can connect to the server. The server will be stopped when the context manager\n        exits and the env vars will be reset.\n\n        Args:\n            cleanup (bool, optional):\n                Whether to cleanup the server after the test. Defaults to True.\n            base_path (Optional[Path], optional):\n                The base path for the server. Defaults to None. This is primarily\n                used for testing loading attributes from a pyproject.toml file.\n        \"\"\"\n\n    def start_server(self) -&gt; None:\n        \"\"\"Starts the test server.\"\"\"\n\n    def stop_server(self) -&gt; None:\n        \"\"\"Stops the test server.\"\"\"\n\n    def __enter__(self) -&gt; \"OpsmlTestServer\":\n        \"\"\"Starts the test server.\"\"\"\n\n    def __exit__(self, exc_type, exc_value, traceback) -&gt; None:\n        \"\"\"Stops the test server.\"\"\"\n\n    def set_env_vars_for_client(self) -&gt; None:\n        \"\"\"Sets the env vars for the client to connect to the server.\"\"\"\n\n    def remove_env_vars_for_client(self) -&gt; None:\n        \"\"\"Removes the env vars for the client to connect to the server.\"\"\"\n\n    @staticmethod\n    def cleanup() -&gt; None:\n        \"\"\"Cleans up the test server.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlTestServer.__enter__","title":"<code>__enter__()</code>","text":"<p>Starts the test server.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def __enter__(self) -&gt; \"OpsmlTestServer\":\n    \"\"\"Starts the test server.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlTestServer.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Stops the test server.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def __exit__(self, exc_type, exc_value, traceback) -&gt; None:\n    \"\"\"Stops the test server.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlTestServer.__init__","title":"<code>__init__(cleanup=True, base_path=None)</code>","text":"<p>Instantiates the test server.</p> <p>When the test server is used as a context manager, it will start the server in a background thread and set the appropriate env vars so that the client can connect to the server. The server will be stopped when the context manager exits and the env vars will be reset.</p> <p>Parameters:</p> Name Type Description Default <code>cleanup</code> <code>bool</code> <p>Whether to cleanup the server after the test. Defaults to True.</p> <code>True</code> <code>base_path</code> <code>Optional[Path]</code> <p>The base path for the server. Defaults to None. This is primarily used for testing loading attributes from a pyproject.toml file.</p> <code>None</code> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def __init__(self, cleanup: bool = True, base_path: Optional[Path] = None) -&gt; None:\n    \"\"\"Instantiates the test server.\n\n    When the test server is used as a context manager, it will start the server\n    in a background thread and set the appropriate env vars so that the client\n    can connect to the server. The server will be stopped when the context manager\n    exits and the env vars will be reset.\n\n    Args:\n        cleanup (bool, optional):\n            Whether to cleanup the server after the test. Defaults to True.\n        base_path (Optional[Path], optional):\n            The base path for the server. Defaults to None. This is primarily\n            used for testing loading attributes from a pyproject.toml file.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlTestServer.cleanup","title":"<code>cleanup()</code>  <code>staticmethod</code>","text":"<p>Cleans up the test server.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>@staticmethod\ndef cleanup() -&gt; None:\n    \"\"\"Cleans up the test server.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlTestServer.remove_env_vars_for_client","title":"<code>remove_env_vars_for_client()</code>","text":"<p>Removes the env vars for the client to connect to the server.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def remove_env_vars_for_client(self) -&gt; None:\n    \"\"\"Removes the env vars for the client to connect to the server.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlTestServer.set_env_vars_for_client","title":"<code>set_env_vars_for_client()</code>","text":"<p>Sets the env vars for the client to connect to the server.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def set_env_vars_for_client(self) -&gt; None:\n    \"\"\"Sets the env vars for the client to connect to the server.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlTestServer.start_server","title":"<code>start_server()</code>","text":"<p>Starts the test server.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def start_server(self) -&gt; None:\n    \"\"\"Starts the test server.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.OpsmlTestServer.stop_server","title":"<code>stop_server()</code>","text":"<p>Stops the test server.</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>def stop_server(self) -&gt; None:\n    \"\"\"Stops the test server.\"\"\"\n</code></pre>"},{"location":"docs/api/mock/#opsml.mock._mock.RegistryTestHelper","title":"<code>RegistryTestHelper</code>","text":"<p>Helper class for testing the registry</p> Source code in <code>python/opsml/mock/_mock.pyi</code> <pre><code>class RegistryTestHelper:\n    \"\"\"Helper class for testing the registry\"\"\"\n\n    def __init__(self) -&gt; None: ...\n    def setup(self) -&gt; None: ...\n    def cleanup(self) -&gt; None: ...\n</code></pre>"},{"location":"docs/api/model/","title":"Model","text":""},{"location":"docs/api/model/#opsml.model._model.CatBoostModel","title":"<code>CatBoostModel</code>","text":"<p>               Bases: <code>ModelInterface</code></p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class CatBoostModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving CatBoost models\n\n        Args:\n            model:\n                Model to associate with the interface. This model must be a CatBoost model.\n            preprocessor:\n                Preprocessor to associate with the model.\n            sample_data:\n                Sample data to use to make predictions.\n            task_type:\n                The type of task the model performs\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n        \"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.CatBoostModel.preprocessor","title":"<code>preprocessor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the preprocessor</p>"},{"location":"docs/api/model/#opsml.model._model.CatBoostModel.preprocessor_name","title":"<code>preprocessor_name</code>  <code>property</code>","text":"<p>Returns the preprocessor name</p>"},{"location":"docs/api/model/#opsml.model._model.CatBoostModel.__init__","title":"<code>__init__(model=None, preprocessor=None, sample_data=None, task_type=None, drift_profile=None)</code>","text":"<p>Interface for saving CatBoost models</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[Any]</code> <p>Model to associate with the interface. This model must be a CatBoost model.</p> <code>None</code> <code>preprocessor</code> <code>Optional[Any]</code> <p>Preprocessor to associate with the model.</p> <code>None</code> <code>sample_data</code> <code>Optional[Any]</code> <p>Sample data to use to make predictions.</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The type of task the model performs</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Interface for saving CatBoost models\n\n    Args:\n        model:\n            Model to associate with the interface. This model must be a CatBoost model.\n        preprocessor:\n            Preprocessor to associate with the model.\n        sample_data:\n            Sample data to use to make predictions.\n        task_type:\n            The type of task the model performs\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.DataProcessor","title":"<code>DataProcessor</code>","text":"<p>Generic class that holds uri information for data preprocessors and postprocessors</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class DataProcessor:\n    \"\"\"Generic class that holds uri information for data preprocessors and postprocessors\"\"\"\n\n    name: str\n    uri: Path\n    type: ProcessorType\n\n    def __init__(self, name: str, uri: Path) -&gt; None:\n        \"\"\"Define a data processor\n\n        Args:\n            name:\n                Name of the data processor\n            uri:\n                Path to the data processor\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.DataProcessor.__init__","title":"<code>__init__(name, uri)</code>","text":"<p>Define a data processor</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the data processor</p> required <code>uri</code> <code>Path</code> <p>Path to the data processor</p> required Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(self, name: str, uri: Path) -&gt; None:\n    \"\"\"Define a data processor\n\n    Args:\n        name:\n            Name of the data processor\n        uri:\n            Path to the data processor\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.Feature","title":"<code>Feature</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class Feature:\n    feature_type: str\n    shape: List[int]\n    extra_args: Dict[str, str]\n\n    def __init__(\n        self,\n        feature_type: str,\n        shape: List[int],\n        extra_args: Optional[Dict[str, str]] = None,\n    ) -&gt; None:\n        \"\"\"Define a feature\n\n        Args:\n            feature_type:\n                The type of the feature\n            shape:\n                The shape of the feature\n            extra_args:\n                Extra arguments to pass to the feature\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the Feature.\n\n        Returns:\n            String representation of the Feature.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.Feature.__init__","title":"<code>__init__(feature_type, shape, extra_args=None)</code>","text":"<p>Define a feature</p> <p>Parameters:</p> Name Type Description Default <code>feature_type</code> <code>str</code> <p>The type of the feature</p> required <code>shape</code> <code>List[int]</code> <p>The shape of the feature</p> required <code>extra_args</code> <code>Optional[Dict[str, str]]</code> <p>Extra arguments to pass to the feature</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    feature_type: str,\n    shape: List[int],\n    extra_args: Optional[Dict[str, str]] = None,\n) -&gt; None:\n    \"\"\"Define a feature\n\n    Args:\n        feature_type:\n            The type of the feature\n        shape:\n            The shape of the feature\n        extra_args:\n            Extra arguments to pass to the feature\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.Feature.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the Feature.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the Feature.</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the Feature.\n\n    Returns:\n        String representation of the Feature.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.FeatureSchema","title":"<code>FeatureSchema</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class FeatureSchema:\n    def __init__(self, items: Optional[dict[str, Feature]] = None) -&gt; None:\n        \"\"\"Define a feature map\n\n        Args:\n            features:\n                The features to use in the feature map\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the FeatureSchema.\"\"\"\n\n    def __getitem__(self, key: str) -&gt; Feature:\n        \"\"\"Returns the feature at the given key.\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.FeatureSchema.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Returns the feature at the given key.</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __getitem__(self, key: str) -&gt; Feature:\n    \"\"\"Returns the feature at the given key.\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.FeatureSchema.__init__","title":"<code>__init__(items=None)</code>","text":"<p>Define a feature map</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <p>The features to use in the feature map</p> required Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(self, items: Optional[dict[str, Feature]] = None) -&gt; None:\n    \"\"\"Define a feature map\n\n    Args:\n        features:\n            The features to use in the feature map\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.FeatureSchema.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the FeatureSchema.</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the FeatureSchema.\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.HuggingFaceModel","title":"<code>HuggingFaceModel</code>","text":"<p>               Bases: <code>ModelInterface</code></p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class HuggingFaceModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        tokenizer: Optional[Any] = None,\n        feature_extractor: Optional[Any] = None,\n        image_processor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        hf_task: Optional[HuggingFaceTask] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving HuggingFace models and pipelines\n\n        Args:\n            model:\n                Model to associate with interface. This can be a HuggingFace pipeline (inherits from Pipeline),\n                or a HuggingFace model (inherits from PreTrainedModel or TFPreTrainedModel).\n            tokenizer:\n                Tokenizer to associate with the model. This must be a HuggingFace tokenizer (PreTrainedTokenizerBase).\n                If using a pipeline that already has a tokenizer, this can be None.\n            feature_extractor:\n                Feature extractor to associate with the model. This must be a HuggingFace feature extractor\n                (PreTrainedFeatureExtractor). If using a pipeline that already has a feature extractor,\n                this can be None.\n            image_processor:\n                Image processor to associate with the model. This must be a HuggingFace image processor\n                (BaseImageProcessor). If using a pipeline that already has an image processor,\n                this can be None.\n            sample_data:\n                Sample data to use to convert to ONNX and make sample predictions. This data must be a\n                HuggingFace-supported type.\n            hf_task:\n                HuggingFace task to associate with the model. Defaults to Undefined.\n                Accepted tasks are as follows (taken from HuggingFace pipeline docs):\n                    - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n                    - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n                    - `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n                    - `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n                    - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n                    - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n                    - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n                    - `\"image-feature-extraction\"`: will return an [`ImageFeatureExtractionPipeline`].\n                    - `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n                    - `\"image-text-to-text\"`: will return a [`ImageTextToTextPipeline`].\n                    - `\"image-to-image\"`: will return a [`ImageToImagePipeline`].\n                    - `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n                    - `\"mask-generation\"`: will return a [`MaskGenerationPipeline`].\n                    - `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n                    - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n                    - `\"summarization\"`: will return a [`SummarizationPipeline`].\n                    - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n                    - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n                    - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n                    [`TextClassificationPipeline`].\n                    - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n                    - `\"text-to-audio\"` (alias `\"text-to-speech\"` available): will return a [`TextToAudioPipeline`]:.\n                    - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n                    - `\"translation\"`: will return a [`TranslationPipeline`].\n                    - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n                    - `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n                    - `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n                    - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n                    - `\"zero-shot-image-classification\"`: will return a [`ZeroShotImageClassificationPipeline`].\n                    - `\"zero-shot-audio-classification\"`: will return a [`ZeroShotAudioClassificationPipeline`].\n                    - `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`].\n            task_type:\n                The intended task type for the model. Note: This is the OpsML task type, not the HuggingFace task type.\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n        \"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: None | ModelSaveKwargs = None,\n    ) -&gt; ModelInterfaceMetadata:\n        \"\"\"Save the HuggingFaceModel interface\n\n        Args:\n            path (Path):\n                Base path to save artifacts\n            save_kwargs (ModelSaveKwargs):\n                Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n                that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n                the underlying library.\n\n                - model: Kwargs that will be passed to save_model. See save_model for more details.\n                - preprocessor: Kwargs that will be passed to save_preprocessor\n                - onnx: Kwargs that will be passed when saving the onnx model\n                    - For the HuggingFaceModel, this should be an instance of HuggingFaceOnnxArgs\n                - save_onnx: Whether to save the onnx model. Defaults to false.\n        \"\"\"\n\n    @property\n    def model(self) -&gt; Optional[Any]:\n        \"\"\"Returns as HuggingFace model (PreTrainedModel, TFPreTrainedModel).\n        Can be None if the model is a pipeline.\n        \"\"\"\n\n    @model.setter\n    def model(self, model: Any) -&gt; None:\n        \"\"\"Sets the model\n\n        Args:\n            model:\n                Model to associate with the interface. This must be a HuggingFace model (PreTrainedModel, TFPreTrainedModel).\n                If using a pipeline that already has a model, this can be None.\n        \"\"\"\n\n    @property\n    def tokenizer(self) -&gt; Optional[Any]:\n        \"\"\"Returns the tokenizer. Can be None if the model is a pipeline.\n        If present, will be of type PreTrainedTokenizerBase\n        \"\"\"\n\n    @tokenizer.setter\n    def tokenizer(self, tokenizer: Any) -&gt; None:\n        \"\"\"Sets the tokenizer\n\n        Args:\n            tokenizer:\n                Tokenizer to associate with the model. This must be a HuggingFace tokenizer (PreTrainedTokenizerBase).\n                If using a pipeline that already has a tokenizer, this can be None.\n        \"\"\"\n\n    @property\n    def image_processor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the image processor. Can be None if the model is a pipeline.\n        If present, will be of type BaseImageProcessor\n        \"\"\"\n\n    @image_processor.setter\n    def image_processor(self, image_processor: Any) -&gt; None:\n        \"\"\"Sets the image processor\n\n        Args:\n            image_processor:\n                Image processor to associate with the model. This must be a HuggingFace image processor\n                (BaseImageProcessor). If using a pipeline that already has an image processor,\n                this can be None.\n        \"\"\"\n\n    @property\n    def feature_extractor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the feature extractor. Can be None if the model is a pipeline.\n        If present, will be of type PreTrainedFeatureExtractor\n        \"\"\"\n\n    @feature_extractor.setter\n    def feature_extractor(self, feature_extractor: Any) -&gt; None:\n        \"\"\"Sets the feature extractor\n\n        Args:\n            feature_extractor:\n                Feature extractor to associate with the model. This must be a HuggingFace feature extractor\n                (PreTrainedFeatureExtractor). If using a pipeline that already has a feature extractor,\n                this can be None.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.HuggingFaceModel.feature_extractor","title":"<code>feature_extractor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the feature extractor. Can be None if the model is a pipeline. If present, will be of type PreTrainedFeatureExtractor</p>"},{"location":"docs/api/model/#opsml.model._model.HuggingFaceModel.image_processor","title":"<code>image_processor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the image processor. Can be None if the model is a pipeline. If present, will be of type BaseImageProcessor</p>"},{"location":"docs/api/model/#opsml.model._model.HuggingFaceModel.model","title":"<code>model</code>  <code>property</code> <code>writable</code>","text":"<p>Returns as HuggingFace model (PreTrainedModel, TFPreTrainedModel). Can be None if the model is a pipeline.</p>"},{"location":"docs/api/model/#opsml.model._model.HuggingFaceModel.tokenizer","title":"<code>tokenizer</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the tokenizer. Can be None if the model is a pipeline. If present, will be of type PreTrainedTokenizerBase</p>"},{"location":"docs/api/model/#opsml.model._model.HuggingFaceModel.__init__","title":"<code>__init__(model=None, tokenizer=None, feature_extractor=None, image_processor=None, sample_data=None, hf_task=None, task_type=None, drift_profile=None)</code>","text":"<p>Interface for saving HuggingFace models and pipelines</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[Any]</code> <p>Model to associate with interface. This can be a HuggingFace pipeline (inherits from Pipeline), or a HuggingFace model (inherits from PreTrainedModel or TFPreTrainedModel).</p> <code>None</code> <code>tokenizer</code> <code>Optional[Any]</code> <p>Tokenizer to associate with the model. This must be a HuggingFace tokenizer (PreTrainedTokenizerBase). If using a pipeline that already has a tokenizer, this can be None.</p> <code>None</code> <code>feature_extractor</code> <code>Optional[Any]</code> <p>Feature extractor to associate with the model. This must be a HuggingFace feature extractor (PreTrainedFeatureExtractor). If using a pipeline that already has a feature extractor, this can be None.</p> <code>None</code> <code>image_processor</code> <code>Optional[Any]</code> <p>Image processor to associate with the model. This must be a HuggingFace image processor (BaseImageProcessor). If using a pipeline that already has an image processor, this can be None.</p> <code>None</code> <code>sample_data</code> <code>Optional[Any]</code> <p>Sample data to use to convert to ONNX and make sample predictions. This data must be a HuggingFace-supported type.</p> <code>None</code> <code>hf_task</code> <code>Optional[HuggingFaceTask]</code> <p>HuggingFace task to associate with the model. Defaults to Undefined. Accepted tasks are as follows (taken from HuggingFace pipeline docs):     - <code>\"audio-classification\"</code>: will return a [<code>AudioClassificationPipeline</code>].     - <code>\"automatic-speech-recognition\"</code>: will return a [<code>AutomaticSpeechRecognitionPipeline</code>].     - <code>\"depth-estimation\"</code>: will return a [<code>DepthEstimationPipeline</code>].     - <code>\"document-question-answering\"</code>: will return a [<code>DocumentQuestionAnsweringPipeline</code>].     - <code>\"feature-extraction\"</code>: will return a [<code>FeatureExtractionPipeline</code>].     - <code>\"fill-mask\"</code>: will return a [<code>FillMaskPipeline</code>]:.     - <code>\"image-classification\"</code>: will return a [<code>ImageClassificationPipeline</code>].     - <code>\"image-feature-extraction\"</code>: will return an [<code>ImageFeatureExtractionPipeline</code>].     - <code>\"image-segmentation\"</code>: will return a [<code>ImageSegmentationPipeline</code>].     - <code>\"image-text-to-text\"</code>: will return a [<code>ImageTextToTextPipeline</code>].     - <code>\"image-to-image\"</code>: will return a [<code>ImageToImagePipeline</code>].     - <code>\"image-to-text\"</code>: will return a [<code>ImageToTextPipeline</code>].     - <code>\"mask-generation\"</code>: will return a [<code>MaskGenerationPipeline</code>].     - <code>\"object-detection\"</code>: will return a [<code>ObjectDetectionPipeline</code>].     - <code>\"question-answering\"</code>: will return a [<code>QuestionAnsweringPipeline</code>].     - <code>\"summarization\"</code>: will return a [<code>SummarizationPipeline</code>].     - <code>\"table-question-answering\"</code>: will return a [<code>TableQuestionAnsweringPipeline</code>].     - <code>\"text2text-generation\"</code>: will return a [<code>Text2TextGenerationPipeline</code>].     - <code>\"text-classification\"</code> (alias <code>\"sentiment-analysis\"</code> available): will return a     [<code>TextClassificationPipeline</code>].     - <code>\"text-generation\"</code>: will return a [<code>TextGenerationPipeline</code>]:.     - <code>\"text-to-audio\"</code> (alias <code>\"text-to-speech\"</code> available): will return a [<code>TextToAudioPipeline</code>]:.     - <code>\"token-classification\"</code> (alias <code>\"ner\"</code> available): will return a [<code>TokenClassificationPipeline</code>].     - <code>\"translation\"</code>: will return a [<code>TranslationPipeline</code>].     - <code>\"translation_xx_to_yy\"</code>: will return a [<code>TranslationPipeline</code>].     - <code>\"video-classification\"</code>: will return a [<code>VideoClassificationPipeline</code>].     - <code>\"visual-question-answering\"</code>: will return a [<code>VisualQuestionAnsweringPipeline</code>].     - <code>\"zero-shot-classification\"</code>: will return a [<code>ZeroShotClassificationPipeline</code>].     - <code>\"zero-shot-image-classification\"</code>: will return a [<code>ZeroShotImageClassificationPipeline</code>].     - <code>\"zero-shot-audio-classification\"</code>: will return a [<code>ZeroShotAudioClassificationPipeline</code>].     - <code>\"zero-shot-object-detection\"</code>: will return a [<code>ZeroShotObjectDetectionPipeline</code>].</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The intended task type for the model. Note: This is the OpsML task type, not the HuggingFace task type.</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model: Optional[Any] = None,\n    tokenizer: Optional[Any] = None,\n    feature_extractor: Optional[Any] = None,\n    image_processor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    hf_task: Optional[HuggingFaceTask] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Interface for saving HuggingFace models and pipelines\n\n    Args:\n        model:\n            Model to associate with interface. This can be a HuggingFace pipeline (inherits from Pipeline),\n            or a HuggingFace model (inherits from PreTrainedModel or TFPreTrainedModel).\n        tokenizer:\n            Tokenizer to associate with the model. This must be a HuggingFace tokenizer (PreTrainedTokenizerBase).\n            If using a pipeline that already has a tokenizer, this can be None.\n        feature_extractor:\n            Feature extractor to associate with the model. This must be a HuggingFace feature extractor\n            (PreTrainedFeatureExtractor). If using a pipeline that already has a feature extractor,\n            this can be None.\n        image_processor:\n            Image processor to associate with the model. This must be a HuggingFace image processor\n            (BaseImageProcessor). If using a pipeline that already has an image processor,\n            this can be None.\n        sample_data:\n            Sample data to use to convert to ONNX and make sample predictions. This data must be a\n            HuggingFace-supported type.\n        hf_task:\n            HuggingFace task to associate with the model. Defaults to Undefined.\n            Accepted tasks are as follows (taken from HuggingFace pipeline docs):\n                - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n                - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n                - `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n                - `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n                - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n                - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n                - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n                - `\"image-feature-extraction\"`: will return an [`ImageFeatureExtractionPipeline`].\n                - `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n                - `\"image-text-to-text\"`: will return a [`ImageTextToTextPipeline`].\n                - `\"image-to-image\"`: will return a [`ImageToImagePipeline`].\n                - `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n                - `\"mask-generation\"`: will return a [`MaskGenerationPipeline`].\n                - `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n                - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n                - `\"summarization\"`: will return a [`SummarizationPipeline`].\n                - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n                - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n                - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n                [`TextClassificationPipeline`].\n                - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n                - `\"text-to-audio\"` (alias `\"text-to-speech\"` available): will return a [`TextToAudioPipeline`]:.\n                - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n                - `\"translation\"`: will return a [`TranslationPipeline`].\n                - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n                - `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n                - `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n                - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n                - `\"zero-shot-image-classification\"`: will return a [`ZeroShotImageClassificationPipeline`].\n                - `\"zero-shot-audio-classification\"`: will return a [`ZeroShotAudioClassificationPipeline`].\n                - `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`].\n        task_type:\n            The intended task type for the model. Note: This is the OpsML task type, not the HuggingFace task type.\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.HuggingFaceModel.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Save the HuggingFaceModel interface</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to save artifacts</p> required <code>save_kwargs</code> <code>ModelSaveKwargs</code> <p>Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning that the kwargs will be passed to the underlying methods as is and are expected to be supported by the underlying library.</p> <ul> <li>model: Kwargs that will be passed to save_model. See save_model for more details.</li> <li>preprocessor: Kwargs that will be passed to save_preprocessor</li> <li>onnx: Kwargs that will be passed when saving the onnx model<ul> <li>For the HuggingFaceModel, this should be an instance of HuggingFaceOnnxArgs</li> </ul> </li> <li>save_onnx: Whether to save the onnx model. Defaults to false.</li> </ul> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def save(\n    self,\n    path: Path,\n    save_kwargs: None | ModelSaveKwargs = None,\n) -&gt; ModelInterfaceMetadata:\n    \"\"\"Save the HuggingFaceModel interface\n\n    Args:\n        path (Path):\n            Base path to save artifacts\n        save_kwargs (ModelSaveKwargs):\n            Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n            that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n            the underlying library.\n\n            - model: Kwargs that will be passed to save_model. See save_model for more details.\n            - preprocessor: Kwargs that will be passed to save_preprocessor\n            - onnx: Kwargs that will be passed when saving the onnx model\n                - For the HuggingFaceModel, this should be an instance of HuggingFaceOnnxArgs\n            - save_onnx: Whether to save the onnx model. Defaults to false.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.HuggingFaceOnnxArgs","title":"<code>HuggingFaceOnnxArgs</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class HuggingFaceOnnxArgs:\n    ort_type: HuggingFaceORTModel\n    provider: str\n    quantize: bool\n    export: bool\n    config: Optional[Any]\n    extra_kwargs: Optional[Dict[str, Any]]\n\n    def __init__(\n        self,\n        ort_type: HuggingFaceORTModel,\n        provider: str,\n        quantize: bool = False,\n        config: Optional[Any] = None,\n        extra_kwargs: Optional[Dict[str, Any]] = None,\n    ) -&gt; None:\n        \"\"\"Optional Args to use with a huggingface model\n\n        Args:\n            ort_type:\n                Optimum onnx class name\n            provider:\n                Onnx runtime provider to use\n            config:\n                Optional optimum config to use\n            quantize:\n                Whether to quantize the model\n            extra_kwargs:\n                Extra kwargs to pass to the onnx conversion (save_pretrained method for ort models)\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.HuggingFaceOnnxArgs.__init__","title":"<code>__init__(ort_type, provider, quantize=False, config=None, extra_kwargs=None)</code>","text":"<p>Optional Args to use with a huggingface model</p> <p>Parameters:</p> Name Type Description Default <code>ort_type</code> <code>HuggingFaceORTModel</code> <p>Optimum onnx class name</p> required <code>provider</code> <code>str</code> <p>Onnx runtime provider to use</p> required <code>config</code> <code>Optional[Any]</code> <p>Optional optimum config to use</p> <code>None</code> <code>quantize</code> <code>bool</code> <p>Whether to quantize the model</p> <code>False</code> <code>extra_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Extra kwargs to pass to the onnx conversion (save_pretrained method for ort models)</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    ort_type: HuggingFaceORTModel,\n    provider: str,\n    quantize: bool = False,\n    config: Optional[Any] = None,\n    extra_kwargs: Optional[Dict[str, Any]] = None,\n) -&gt; None:\n    \"\"\"Optional Args to use with a huggingface model\n\n    Args:\n        ort_type:\n            Optimum onnx class name\n        provider:\n            Onnx runtime provider to use\n        config:\n            Optional optimum config to use\n        quantize:\n            Whether to quantize the model\n        extra_kwargs:\n            Extra kwargs to pass to the onnx conversion (save_pretrained method for ort models)\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.LightGBMModel","title":"<code>LightGBMModel</code>","text":"<p>               Bases: <code>ModelInterface</code></p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class LightGBMModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Instantiate a LightGBMModel interface\n\n        Args:\n            model:\n                Model to associate with interface. This model must be a lightgbm booster.\n            preprocessor:\n                Preprocessor to associate with the model.\n            sample_data:\n                Sample data to use to make predictions\n            task_type:\n                The type of task the model performs\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n        \"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.LightGBMModel.preprocessor","title":"<code>preprocessor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the preprocessor</p>"},{"location":"docs/api/model/#opsml.model._model.LightGBMModel.preprocessor_name","title":"<code>preprocessor_name</code>  <code>property</code>","text":"<p>Returns the preprocessor name</p>"},{"location":"docs/api/model/#opsml.model._model.LightGBMModel.__init__","title":"<code>__init__(model=None, preprocessor=None, sample_data=None, task_type=None, drift_profile=None)</code>","text":"<p>Instantiate a LightGBMModel interface</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[Any]</code> <p>Model to associate with interface. This model must be a lightgbm booster.</p> <code>None</code> <code>preprocessor</code> <code>Optional[Any]</code> <p>Preprocessor to associate with the model.</p> <code>None</code> <code>sample_data</code> <code>Optional[Any]</code> <p>Sample data to use to make predictions</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The type of task the model performs</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Instantiate a LightGBMModel interface\n\n    Args:\n        model:\n            Model to associate with interface. This model must be a lightgbm booster.\n        preprocessor:\n            Preprocessor to associate with the model.\n        sample_data:\n            Sample data to use to make predictions\n        task_type:\n            The type of task the model performs\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.LightningModel","title":"<code>LightningModel</code>","text":"<p>               Bases: <code>ModelInterface</code></p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class LightningModel(ModelInterface):\n    def __init__(\n        self,\n        trainer: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving PyTorch Lightning models\n\n        Args:\n            trainer:\n                Pytorch lightning trainer to associate with interface.\n            preprocessor:\n                Preprocessor to associate with model.\n            sample_data:\n                Sample data to use to convert to ONNX and make sample predictions. This data must be a\n                pytorch-supported type. TorchData interface, torch tensor, torch dataset, Dict[str, torch.Tensor],\n                List[torch.Tensor], Tuple[torch.Tensor].\n            task_type:\n                The intended task type of the model.\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n        \"\"\"\n\n    @property\n    def trainer(self) -&gt; None:\n        \"\"\"Returns the trainer\"\"\"\n\n    @trainer.setter\n    def trainer(self, trainer: Any) -&gt; None:\n        \"\"\"Sets the trainer\"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: None | ModelSaveKwargs = None,\n    ) -&gt; ModelInterfaceMetadata:\n        \"\"\"Save the LightningModel interface. Lightning models are saved via checkpoints.\n\n        Args:\n            path (Path):\n                Base path to save artifacts\n            save_kwargs (ModelSaveKwargs):\n                Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n                that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n                the underlying library.\n\n                - model: Kwargs that will be passed to save_model. See save_model for more details.\n                - preprocessor: Kwargs that will be passed to save_preprocessor\n                - onnx: Library specific kwargs to pass to the onnx conversion. Independent of save_onnx.\n                - save_onnx: Whether to save the onnx model. Defaults to false.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.LightningModel.preprocessor","title":"<code>preprocessor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the preprocessor</p>"},{"location":"docs/api/model/#opsml.model._model.LightningModel.preprocessor_name","title":"<code>preprocessor_name</code>  <code>property</code>","text":"<p>Returns the preprocessor name</p>"},{"location":"docs/api/model/#opsml.model._model.LightningModel.trainer","title":"<code>trainer</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the trainer</p>"},{"location":"docs/api/model/#opsml.model._model.LightningModel.__init__","title":"<code>__init__(trainer=None, preprocessor=None, sample_data=None, task_type=None, drift_profile=None)</code>","text":"<p>Interface for saving PyTorch Lightning models</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Optional[Any]</code> <p>Pytorch lightning trainer to associate with interface.</p> <code>None</code> <code>preprocessor</code> <code>Optional[Any]</code> <p>Preprocessor to associate with model.</p> <code>None</code> <code>sample_data</code> <code>Optional[Any]</code> <p>Sample data to use to convert to ONNX and make sample predictions. This data must be a pytorch-supported type. TorchData interface, torch tensor, torch dataset, Dict[str, torch.Tensor], List[torch.Tensor], Tuple[torch.Tensor].</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The intended task type of the model.</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    trainer: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Interface for saving PyTorch Lightning models\n\n    Args:\n        trainer:\n            Pytorch lightning trainer to associate with interface.\n        preprocessor:\n            Preprocessor to associate with model.\n        sample_data:\n            Sample data to use to convert to ONNX and make sample predictions. This data must be a\n            pytorch-supported type. TorchData interface, torch tensor, torch dataset, Dict[str, torch.Tensor],\n            List[torch.Tensor], Tuple[torch.Tensor].\n        task_type:\n            The intended task type of the model.\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.LightningModel.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Save the LightningModel interface. Lightning models are saved via checkpoints.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to save artifacts</p> required <code>save_kwargs</code> <code>ModelSaveKwargs</code> <p>Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning that the kwargs will be passed to the underlying methods as is and are expected to be supported by the underlying library.</p> <ul> <li>model: Kwargs that will be passed to save_model. See save_model for more details.</li> <li>preprocessor: Kwargs that will be passed to save_preprocessor</li> <li>onnx: Library specific kwargs to pass to the onnx conversion. Independent of save_onnx.</li> <li>save_onnx: Whether to save the onnx model. Defaults to false.</li> </ul> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def save(\n    self,\n    path: Path,\n    save_kwargs: None | ModelSaveKwargs = None,\n) -&gt; ModelInterfaceMetadata:\n    \"\"\"Save the LightningModel interface. Lightning models are saved via checkpoints.\n\n    Args:\n        path (Path):\n            Base path to save artifacts\n        save_kwargs (ModelSaveKwargs):\n            Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n            that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n            the underlying library.\n\n            - model: Kwargs that will be passed to save_model. See save_model for more details.\n            - preprocessor: Kwargs that will be passed to save_preprocessor\n            - onnx: Library specific kwargs to pass to the onnx conversion. Independent of save_onnx.\n            - save_onnx: Whether to save the onnx model. Defaults to false.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface","title":"<code>ModelInterface</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class ModelInterface:\n    def __init__(\n        self,\n        model: Any = None,\n        sample_data: Any = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Base class for ModelInterface\n\n        Args:\n            model:\n                Model to associate with interface.\n            sample_data:\n                Sample data to use to make predictions\n            task_type:\n                The type of task the model performs\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n        \"\"\"\n\n    @property\n    def model(self) -&gt; None | Any:\n        \"\"\"Returns the model\"\"\"\n\n    @model.setter\n    def model(self, model: Any) -&gt; None:\n        \"\"\"Sets the model\"\"\"\n\n    @property\n    def sample_data(self) -&gt; None | Any:\n        \"\"\"Returns the sample data\"\"\"\n\n    @sample_data.setter\n    def sample_data(self, sample_data: Any) -&gt; None:\n        \"\"\"Sets the sample data\"\"\"\n\n    @property\n    def data_type(self) -&gt; DataType:\n        \"\"\"Returns the task type\"\"\"\n\n    @property\n    def task_type(self) -&gt; TaskType:\n        \"\"\"Returns the task type\"\"\"\n\n    @property\n    def schema(self) -&gt; FeatureSchema:\n        \"\"\"Returns the feature schema\"\"\"\n\n    @property\n    def model_type(self) -&gt; ModelType:\n        \"\"\"Returns the model type\"\"\"\n\n    @property\n    def interface_type(self) -&gt; ModelInterfaceType:\n        \"\"\"Returns the model type\"\"\"\n\n    @property\n    def drift_profile(\n        self,\n    ) -&gt; DriftProfileMap:\n        \"\"\"Returns the drift profile mapping\"\"\"\n\n    @property\n    def onnx_session(self) -&gt; None | OnnxSession:\n        \"\"\"Returns the onnx session if it exists\"\"\"\n\n    @onnx_session.setter\n    def onnx_session(self, session: None | OnnxSession) -&gt; None:\n        \"\"\"Sets the onnx session\n\n\n        Args:\n            session:\n                Onnx session\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        alias: str,\n        data: CustomMetric | List[CustomMetric],\n        config: CustomMetricDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; CustomDriftProfile: ...\n    @overload\n    def create_drift_profile(\n        self,\n        alias: str,\n        data: Any,\n        config: SpcDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftProfile: ...\n    @overload\n    def create_drift_profile(\n        self,\n        alias: str,\n        data: Any,\n        config: PsiDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; PsiDriftProfile: ...\n    @overload\n    def create_drift_profile(\n        self,\n        alias: str,\n        data: Any,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftProfile: ...\n    def create_drift_profile(  # type: ignore\n        self,\n        alias: str,\n        data: Any,\n        config: None | SpcDriftConfig | PsiDriftConfig | CustomMetricDriftConfig = None,\n        data_type: None | DataType = None,\n    ) -&gt; Any:\n        \"\"\"Create a drift profile and append it to the drift profile list\n\n        Args:\n            alias:\n                Alias to use for the drift profile\n            data:\n                Data to use to create the drift profile. Can be a pandas dataframe,\n                polars dataframe, pyarrow table or numpy array.\n            config:\n                Drift config to use. If None, defaults to SpcDriftConfig.\n            data_type:\n                Data type to use. If None, data_type will be inferred from the data.\n\n        Returns:\n            Drift profile SPcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: None | ModelSaveKwargs = None,\n    ) -&gt; ModelInterfaceMetadata:\n        \"\"\"Save the model interface\n\n        Args:\n            path (Path):\n                Path to save the model\n            save_kwargs (ModelSaveKwargs):\n                Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n                that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n                the underlying library.\n\n                - model: Kwargs that will be passed to save_model. See save_model for more details.\n                - preprocessor: Kwargs that will be passed to save_preprocessor\n                - onnx: Library specific kwargs to pass to the onnx conversion. Independent of save_onnx.\n                - save_onnx: Whether to save the onnx model. Defaults to false.\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: ModelInterfaceSaveMetadata,\n        load_kwargs: None | ModelLoadKwargs = None,\n    ) -&gt; None:\n        \"\"\"Load ModelInterface components\n\n        Args:\n            path (Path):\n                Path to load the model\n            metadata (ModelInterfaceSaveMetadata):\n                Metadata to use to load the model\n            load_kwargs (ModelLoadKwargs):\n                Optional load kwargs to pass to the different load methods\n        \"\"\"\n\n    @staticmethod\n    def from_metadata(metadata: ModelInterfaceMetadata) -&gt; \"ModelInterface\":\n        \"\"\"Create a ModelInterface from metadata\n\n        Args:\n            metadata:\n                Model interface metadata\n\n        Returns:\n            Model interface\n        \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.data_type","title":"<code>data_type</code>  <code>property</code>","text":"<p>Returns the task type</p>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.drift_profile","title":"<code>drift_profile</code>  <code>property</code>","text":"<p>Returns the drift profile mapping</p>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.interface_type","title":"<code>interface_type</code>  <code>property</code>","text":"<p>Returns the model type</p>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.model","title":"<code>model</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the model</p>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.model_type","title":"<code>model_type</code>  <code>property</code>","text":"<p>Returns the model type</p>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.onnx_session","title":"<code>onnx_session</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the onnx session if it exists</p>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.sample_data","title":"<code>sample_data</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the sample data</p>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.schema","title":"<code>schema</code>  <code>property</code>","text":"<p>Returns the feature schema</p>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.task_type","title":"<code>task_type</code>  <code>property</code>","text":"<p>Returns the task type</p>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.__init__","title":"<code>__init__(model=None, sample_data=None, task_type=None, drift_profile=None)</code>","text":"<p>Base class for ModelInterface</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Any</code> <p>Model to associate with interface.</p> <code>None</code> <code>sample_data</code> <code>Any</code> <p>Sample data to use to make predictions</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The type of task the model performs</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model: Any = None,\n    sample_data: Any = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Base class for ModelInterface\n\n    Args:\n        model:\n            Model to associate with interface.\n        sample_data:\n            Sample data to use to make predictions\n        task_type:\n            The type of task the model performs\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.create_drift_profile","title":"<code>create_drift_profile(alias, data, config=None, data_type=None)</code>","text":"<pre><code>create_drift_profile(\n    alias: str,\n    data: CustomMetric | List[CustomMetric],\n    config: CustomMetricDriftConfig,\n    data_type: Optional[DataType] = None,\n) -&gt; CustomDriftProfile\n</code></pre><pre><code>create_drift_profile(\n    alias: str,\n    data: Any,\n    config: SpcDriftConfig,\n    data_type: Optional[DataType] = None,\n) -&gt; SpcDriftProfile\n</code></pre><pre><code>create_drift_profile(\n    alias: str,\n    data: Any,\n    config: PsiDriftConfig,\n    data_type: Optional[DataType] = None,\n) -&gt; PsiDriftProfile\n</code></pre><pre><code>create_drift_profile(\n    alias: str,\n    data: Any,\n    data_type: Optional[DataType] = None,\n) -&gt; SpcDriftProfile\n</code></pre> <p>Create a drift profile and append it to the drift profile list</p> <p>Parameters:</p> Name Type Description Default <code>alias</code> <code>str</code> <p>Alias to use for the drift profile</p> required <code>data</code> <code>Any</code> <p>Data to use to create the drift profile. Can be a pandas dataframe, polars dataframe, pyarrow table or numpy array.</p> required <code>config</code> <code>None | SpcDriftConfig | PsiDriftConfig | CustomMetricDriftConfig</code> <p>Drift config to use. If None, defaults to SpcDriftConfig.</p> <code>None</code> <code>data_type</code> <code>None | DataType</code> <p>Data type to use. If None, data_type will be inferred from the data.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Drift profile SPcDriftProfile, PsiDriftProfile or CustomDriftProfile</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def create_drift_profile(  # type: ignore\n    self,\n    alias: str,\n    data: Any,\n    config: None | SpcDriftConfig | PsiDriftConfig | CustomMetricDriftConfig = None,\n    data_type: None | DataType = None,\n) -&gt; Any:\n    \"\"\"Create a drift profile and append it to the drift profile list\n\n    Args:\n        alias:\n            Alias to use for the drift profile\n        data:\n            Data to use to create the drift profile. Can be a pandas dataframe,\n            polars dataframe, pyarrow table or numpy array.\n        config:\n            Drift config to use. If None, defaults to SpcDriftConfig.\n        data_type:\n            Data type to use. If None, data_type will be inferred from the data.\n\n    Returns:\n        Drift profile SPcDriftProfile, PsiDriftProfile or CustomDriftProfile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.from_metadata","title":"<code>from_metadata(metadata)</code>  <code>staticmethod</code>","text":"<p>Create a ModelInterface from metadata</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>ModelInterfaceMetadata</code> <p>Model interface metadata</p> required <p>Returns:</p> Type Description <code>ModelInterface</code> <p>Model interface</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>@staticmethod\ndef from_metadata(metadata: ModelInterfaceMetadata) -&gt; \"ModelInterface\":\n    \"\"\"Create a ModelInterface from metadata\n\n    Args:\n        metadata:\n            Model interface metadata\n\n    Returns:\n        Model interface\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.load","title":"<code>load(path, metadata, load_kwargs=None)</code>","text":"<p>Load ModelInterface components</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to load the model</p> required <code>metadata</code> <code>ModelInterfaceSaveMetadata</code> <p>Metadata to use to load the model</p> required <code>load_kwargs</code> <code>ModelLoadKwargs</code> <p>Optional load kwargs to pass to the different load methods</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def load(\n    self,\n    path: Path,\n    metadata: ModelInterfaceSaveMetadata,\n    load_kwargs: None | ModelLoadKwargs = None,\n) -&gt; None:\n    \"\"\"Load ModelInterface components\n\n    Args:\n        path (Path):\n            Path to load the model\n        metadata (ModelInterfaceSaveMetadata):\n            Metadata to use to load the model\n        load_kwargs (ModelLoadKwargs):\n            Optional load kwargs to pass to the different load methods\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterface.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Save the model interface</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to save the model</p> required <code>save_kwargs</code> <code>ModelSaveKwargs</code> <p>Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning that the kwargs will be passed to the underlying methods as is and are expected to be supported by the underlying library.</p> <ul> <li>model: Kwargs that will be passed to save_model. See save_model for more details.</li> <li>preprocessor: Kwargs that will be passed to save_preprocessor</li> <li>onnx: Library specific kwargs to pass to the onnx conversion. Independent of save_onnx.</li> <li>save_onnx: Whether to save the onnx model. Defaults to false.</li> </ul> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def save(\n    self,\n    path: Path,\n    save_kwargs: None | ModelSaveKwargs = None,\n) -&gt; ModelInterfaceMetadata:\n    \"\"\"Save the model interface\n\n    Args:\n        path (Path):\n            Path to save the model\n        save_kwargs (ModelSaveKwargs):\n            Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n            that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n            the underlying library.\n\n            - model: Kwargs that will be passed to save_model. See save_model for more details.\n            - preprocessor: Kwargs that will be passed to save_preprocessor\n            - onnx: Library specific kwargs to pass to the onnx conversion. Independent of save_onnx.\n            - save_onnx: Whether to save the onnx model. Defaults to false.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterfaceMetadata","title":"<code>ModelInterfaceMetadata</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class ModelInterfaceMetadata:\n    task_type: TaskType\n    model_type: ModelType\n    data_type: DataType\n    onnx_session: Optional[OnnxSession]\n    schema: FeatureSchema\n    save_metadata: ModelInterfaceSaveMetadata\n    extra_metadata: dict[str, str]\n    version: str\n\n    def __init__(\n        self,\n        save_metadata: ModelInterfaceSaveMetadata,\n        task_type: TaskType = TaskType.Undefined,\n        model_type: ModelType = ModelType.Unknown,\n        data_type: DataType = DataType.NotProvided,\n        schema: FeatureSchema = FeatureSchema(),\n        onnx_session: Optional[OnnxSession] = None,\n        extra_metadata: dict[str, str] = {},  # type: ignore\n        version: str = \"undefined\",\n    ) -&gt; None:\n        \"\"\"Define a model interface\n\n        Args:\n            task_type:\n                Task type\n            model_type:\n                Model type\n            data_type:\n                Data type\n            onnx_session:\n                Onnx session\n            schema:\n                Feature schema\n            data_type:\n                Sample data type\n            save_metadata:\n                Save metadata\n            extra_metadata:\n                Extra metadata. Must be a dictionary of strings\n            version:\n                Package version of the model being used (sklearn.__version__, torch.__version__, etc)\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the model interface metadata\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model interface metadata to json\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"ModelInterfaceMetadata\":\n        \"\"\"Validate the model interface metadata json\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterfaceMetadata.__init__","title":"<code>__init__(save_metadata, task_type=TaskType.Undefined, model_type=ModelType.Unknown, data_type=DataType.NotProvided, schema=FeatureSchema(), onnx_session=None, extra_metadata={}, version='undefined')</code>","text":"<p>Define a model interface</p> <p>Parameters:</p> Name Type Description Default <code>task_type</code> <code>TaskType</code> <p>Task type</p> <code>Undefined</code> <code>model_type</code> <code>ModelType</code> <p>Model type</p> <code>Unknown</code> <code>data_type</code> <code>DataType</code> <p>Data type</p> <code>NotProvided</code> <code>onnx_session</code> <code>Optional[OnnxSession]</code> <p>Onnx session</p> <code>None</code> <code>schema</code> <code>FeatureSchema</code> <p>Feature schema</p> <code>FeatureSchema()</code> <code>data_type</code> <code>DataType</code> <p>Sample data type</p> <code>NotProvided</code> <code>save_metadata</code> <code>ModelInterfaceSaveMetadata</code> <p>Save metadata</p> required <code>extra_metadata</code> <code>dict[str, str]</code> <p>Extra metadata. Must be a dictionary of strings</p> <code>{}</code> <code>version</code> <code>str</code> <p>Package version of the model being used (sklearn.version, torch.version, etc)</p> <code>'undefined'</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    save_metadata: ModelInterfaceSaveMetadata,\n    task_type: TaskType = TaskType.Undefined,\n    model_type: ModelType = ModelType.Unknown,\n    data_type: DataType = DataType.NotProvided,\n    schema: FeatureSchema = FeatureSchema(),\n    onnx_session: Optional[OnnxSession] = None,\n    extra_metadata: dict[str, str] = {},  # type: ignore\n    version: str = \"undefined\",\n) -&gt; None:\n    \"\"\"Define a model interface\n\n    Args:\n        task_type:\n            Task type\n        model_type:\n            Model type\n        data_type:\n            Data type\n        onnx_session:\n            Onnx session\n        schema:\n            Feature schema\n        data_type:\n            Sample data type\n        save_metadata:\n            Save metadata\n        extra_metadata:\n            Extra metadata. Must be a dictionary of strings\n        version:\n            Package version of the model being used (sklearn.__version__, torch.__version__, etc)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterfaceMetadata.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the model interface metadata</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the model interface metadata\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterfaceMetadata.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the model interface metadata to json</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the model interface metadata to json\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterfaceMetadata.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Validate the model interface metadata json</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"ModelInterfaceMetadata\":\n    \"\"\"Validate the model interface metadata json\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterfaceSaveMetadata","title":"<code>ModelInterfaceSaveMetadata</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class ModelInterfaceSaveMetadata:\n    model_uri: Path\n    data_processor_map: Dict[str, DataProcessor]\n    sample_data_uri: Path\n    onnx_model_uri: Optional[Path]\n    drift_profile_uri_map: Optional[Dict[str, DriftProfileUri]]\n    extra: Optional[ExtraMetadata]\n    save_kwargs: Optional[ModelSaveKwargs]\n\n    def __init__(\n        self,\n        model_uri: Path,\n        data_processor_map: Optional[Dict[str, DataProcessor]] = {},  # type: ignore\n        sample_data_uri: Optional[Path] = None,\n        onnx_model_uri: Optional[Path] = None,\n        drift_profile_uri_map: Optional[Dict[str, DriftProfileUri]] = None,\n        extra: Optional[ExtraMetadata] = None,\n        save_kwargs: Optional[ModelSaveKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Define model interface save arguments\n\n        Args:\n            model_uri:\n                Path to the model\n            data_processor_map:\n                Dictionary of data processors\n            sample_data_uri:\n                Path to the sample data\n            onnx_model_uri:\n                Path to the onnx model\n            drift_profile_uri_map:\n                Dictionary of drift profiles\n            extra_metadata:\n                Extra metadata\n            save_kwargs:\n                Optional save args\n        \"\"\"\n\n    def __str__(self): ...\n    def model_dump_json(self) -&gt; str: ...\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelInterfaceSaveMetadata.__init__","title":"<code>__init__(model_uri, data_processor_map={}, sample_data_uri=None, onnx_model_uri=None, drift_profile_uri_map=None, extra=None, save_kwargs=None)</code>","text":"<p>Define model interface save arguments</p> <p>Parameters:</p> Name Type Description Default <code>model_uri</code> <code>Path</code> <p>Path to the model</p> required <code>data_processor_map</code> <code>Optional[Dict[str, DataProcessor]]</code> <p>Dictionary of data processors</p> <code>{}</code> <code>sample_data_uri</code> <code>Optional[Path]</code> <p>Path to the sample data</p> <code>None</code> <code>onnx_model_uri</code> <code>Optional[Path]</code> <p>Path to the onnx model</p> <code>None</code> <code>drift_profile_uri_map</code> <code>Optional[Dict[str, DriftProfileUri]]</code> <p>Dictionary of drift profiles</p> <code>None</code> <code>extra_metadata</code> <p>Extra metadata</p> required <code>save_kwargs</code> <code>Optional[ModelSaveKwargs]</code> <p>Optional save args</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model_uri: Path,\n    data_processor_map: Optional[Dict[str, DataProcessor]] = {},  # type: ignore\n    sample_data_uri: Optional[Path] = None,\n    onnx_model_uri: Optional[Path] = None,\n    drift_profile_uri_map: Optional[Dict[str, DriftProfileUri]] = None,\n    extra: Optional[ExtraMetadata] = None,\n    save_kwargs: Optional[ModelSaveKwargs] = None,\n) -&gt; None:\n    \"\"\"Define model interface save arguments\n\n    Args:\n        model_uri:\n            Path to the model\n        data_processor_map:\n            Dictionary of data processors\n        sample_data_uri:\n            Path to the sample data\n        onnx_model_uri:\n            Path to the onnx model\n        drift_profile_uri_map:\n            Dictionary of drift profiles\n        extra_metadata:\n            Extra metadata\n        save_kwargs:\n            Optional save args\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelLoadKwargs","title":"<code>ModelLoadKwargs</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class ModelLoadKwargs:\n    onnx: Optional[Dict]\n    model: Optional[Dict]\n    preprocessor: Optional[Dict]\n    load_onnx: bool\n\n    def __init__(\n        self,\n        onnx: Optional[Dict] = None,\n        model: Optional[Dict] = None,\n        preprocessor: Optional[Dict] = None,\n        load_onnx: bool = False,\n    ) -&gt; None:\n        \"\"\"Optional arguments to pass to load_model\n\n        Args:\n            onnx (Dict):\n                Optional onnx arguments to use when loading\n            model (Dict):\n                Optional model arguments to use when loading\n            preprocessor (Dict):\n                Optional preprocessor arguments to use when loading\n            load_onnx (bool):\n                Whether to load the onnx model. Defaults to false unless onnx args are\n                provided. If true, the onnx model will be loaded.\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelLoadKwargs.__init__","title":"<code>__init__(onnx=None, model=None, preprocessor=None, load_onnx=False)</code>","text":"<p>Optional arguments to pass to load_model</p> <p>Parameters:</p> Name Type Description Default <code>onnx</code> <code>Dict</code> <p>Optional onnx arguments to use when loading</p> <code>None</code> <code>model</code> <code>Dict</code> <p>Optional model arguments to use when loading</p> <code>None</code> <code>preprocessor</code> <code>Dict</code> <p>Optional preprocessor arguments to use when loading</p> <code>None</code> <code>load_onnx</code> <code>bool</code> <p>Whether to load the onnx model. Defaults to false unless onnx args are provided. If true, the onnx model will be loaded.</p> <code>False</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    onnx: Optional[Dict] = None,\n    model: Optional[Dict] = None,\n    preprocessor: Optional[Dict] = None,\n    load_onnx: bool = False,\n) -&gt; None:\n    \"\"\"Optional arguments to pass to load_model\n\n    Args:\n        onnx (Dict):\n            Optional onnx arguments to use when loading\n        model (Dict):\n            Optional model arguments to use when loading\n        preprocessor (Dict):\n            Optional preprocessor arguments to use when loading\n        load_onnx (bool):\n            Whether to load the onnx model. Defaults to false unless onnx args are\n            provided. If true, the onnx model will be loaded.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelSaveKwargs","title":"<code>ModelSaveKwargs</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class ModelSaveKwargs:\n    def __init__(\n        self,\n        onnx: Optional[Dict | HuggingFaceOnnxArgs] = None,\n        model: Optional[Dict] = None,\n        preprocessor: Optional[Dict] = None,\n        save_onnx: bool = False,\n        drift: Optional[DriftArgs] = None,\n    ) -&gt; None:\n        \"\"\"Optional arguments to pass to save_model\n\n        Args:\n            onnx (Dict or HuggingFaceOnnxArgs):\n                Optional onnx arguments to use when saving model to onnx format\n            model (Dict):\n                Optional model arguments to use when saving. This is a pass-through that will\n                be directly injected as kwargs to the underlying library's save method. For instance,\n                pytorch models are saved with `torch.save` so any kwargs that torch.save supports can be\n                used here.\n            preprocessor (Dict):\n                Optional preprocessor arguments to use when saving\n            save_onnx (bool):\n                Whether to save the onnx model. Defaults to false. This is independent of the\n                onnx argument since it's possible to convert a model to onnx without additional kwargs.\n                If onnx args are provided, this will be set to true.\n            drift (DriftArgs):\n                Optional drift args to use when saving and registering a model.\n        \"\"\"\n\n    def __str__(self): ...\n    def model_dump_json(self) -&gt; str: ...\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"ModelSaveKwargs\": ...\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.ModelSaveKwargs.__init__","title":"<code>__init__(onnx=None, model=None, preprocessor=None, save_onnx=False, drift=None)</code>","text":"<p>Optional arguments to pass to save_model</p> <p>Parameters:</p> Name Type Description Default <code>onnx</code> <code>Dict or HuggingFaceOnnxArgs</code> <p>Optional onnx arguments to use when saving model to onnx format</p> <code>None</code> <code>model</code> <code>Dict</code> <p>Optional model arguments to use when saving. This is a pass-through that will be directly injected as kwargs to the underlying library's save method. For instance, pytorch models are saved with <code>torch.save</code> so any kwargs that torch.save supports can be used here.</p> <code>None</code> <code>preprocessor</code> <code>Dict</code> <p>Optional preprocessor arguments to use when saving</p> <code>None</code> <code>save_onnx</code> <code>bool</code> <p>Whether to save the onnx model. Defaults to false. This is independent of the onnx argument since it's possible to convert a model to onnx without additional kwargs. If onnx args are provided, this will be set to true.</p> <code>False</code> <code>drift</code> <code>DriftArgs</code> <p>Optional drift args to use when saving and registering a model.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    onnx: Optional[Dict | HuggingFaceOnnxArgs] = None,\n    model: Optional[Dict] = None,\n    preprocessor: Optional[Dict] = None,\n    save_onnx: bool = False,\n    drift: Optional[DriftArgs] = None,\n) -&gt; None:\n    \"\"\"Optional arguments to pass to save_model\n\n    Args:\n        onnx (Dict or HuggingFaceOnnxArgs):\n            Optional onnx arguments to use when saving model to onnx format\n        model (Dict):\n            Optional model arguments to use when saving. This is a pass-through that will\n            be directly injected as kwargs to the underlying library's save method. For instance,\n            pytorch models are saved with `torch.save` so any kwargs that torch.save supports can be\n            used here.\n        preprocessor (Dict):\n            Optional preprocessor arguments to use when saving\n        save_onnx (bool):\n            Whether to save the onnx model. Defaults to false. This is independent of the\n            onnx argument since it's possible to convert a model to onnx without additional kwargs.\n            If onnx args are provided, this will be set to true.\n        drift (DriftArgs):\n            Optional drift args to use when saving and registering a model.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.OnnxModel","title":"<code>OnnxModel</code>","text":"<p>               Bases: <code>ModelInterface</code></p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class OnnxModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving an OnnxModel\n\n        Args:\n            model:\n                Onnx model to associate with the interface. This model must be an Onnx ModelProto\n            sample_data:\n                Sample data to use to make predictions\n            task_type:\n                The type of task the model performs\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n\n        Example:\n            ```python\n            from sklearn.datasets import load_iris  # type: ignore\n            from sklearn.model_selection import train_test_split  # type: ignore\n            from sklearn.ensemble import RandomForestClassifier  # type: ignore\n            from skl2onnx import to_onnx  # type: ignore\n            import onnxruntime as rt  # type: ignore\n\n            iris = load_iris()\n\n            X, y = iris.data, iris.target\n            X = X.astype(np.float32)\n            X_train, X_test, y_train, y_test = train_test_split(X, y)\n            clr = RandomForestClassifier()\n            clr.fit(X_train, y_train)\n\n            onx = to_onnx(clr, X[:1])\n\n            interface = OnnxModel(model=onx, sample_data=X_train)\n            ```\n        \"\"\"\n\n    @property\n    def session(self) -&gt; OnnxSession:\n        \"\"\"Returns the onnx session. This will error if the OnnxSession is not set\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.OnnxModel.session","title":"<code>session</code>  <code>property</code>","text":"<p>Returns the onnx session. This will error if the OnnxSession is not set</p>"},{"location":"docs/api/model/#opsml.model._model.OnnxModel.__init__","title":"<code>__init__(model=None, sample_data=None, task_type=None, drift_profile=None)</code>","text":"<p>Interface for saving an OnnxModel</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[Any]</code> <p>Onnx model to associate with the interface. This model must be an Onnx ModelProto</p> <code>None</code> <code>sample_data</code> <code>Optional[Any]</code> <p>Sample data to use to make predictions</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The type of task the model performs</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Example <pre><code>from sklearn.datasets import load_iris  # type: ignore\nfrom sklearn.model_selection import train_test_split  # type: ignore\nfrom sklearn.ensemble import RandomForestClassifier  # type: ignore\nfrom skl2onnx import to_onnx  # type: ignore\nimport onnxruntime as rt  # type: ignore\n\niris = load_iris()\n\nX, y = iris.data, iris.target\nX = X.astype(np.float32)\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nclr = RandomForestClassifier()\nclr.fit(X_train, y_train)\n\nonx = to_onnx(clr, X[:1])\n\ninterface = OnnxModel(model=onx, sample_data=X_train)\n</code></pre> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Interface for saving an OnnxModel\n\n    Args:\n        model:\n            Onnx model to associate with the interface. This model must be an Onnx ModelProto\n        sample_data:\n            Sample data to use to make predictions\n        task_type:\n            The type of task the model performs\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n\n    Example:\n        ```python\n        from sklearn.datasets import load_iris  # type: ignore\n        from sklearn.model_selection import train_test_split  # type: ignore\n        from sklearn.ensemble import RandomForestClassifier  # type: ignore\n        from skl2onnx import to_onnx  # type: ignore\n        import onnxruntime as rt  # type: ignore\n\n        iris = load_iris()\n\n        X, y = iris.data, iris.target\n        X = X.astype(np.float32)\n        X_train, X_test, y_train, y_test = train_test_split(X, y)\n        clr = RandomForestClassifier()\n        clr.fit(X_train, y_train)\n\n        onx = to_onnx(clr, X[:1])\n\n        interface = OnnxModel(model=onx, sample_data=X_train)\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.OnnxSchema","title":"<code>OnnxSchema</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class OnnxSchema:\n    def __init__(\n        self,\n        input_features: FeatureSchema,\n        output_features: FeatureSchema,\n        onnx_version: str,\n        feature_names: Optional[List[str]] = None,\n    ) -&gt; None:\n        \"\"\"Define an onnx schema\n\n        Args:\n            input_features (FeatureSchema):\n                The input features of the onnx schema\n            output_features (FeatureSchema):\n                The output features of the onnx schema\n            onnx_version (str):\n                The onnx version of the schema\n            feature_names (List[str] | None):\n                The feature names and order for onnx.\n\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the OnnxSchema.\n\n        Returns:\n            String representation of the OnnxSchema.\n        \"\"\"\n\n    @property\n    def input_features(self) -&gt; FeatureSchema:\n        \"\"\"Return the input features of the OnnxSchema.\"\"\"\n\n    @property\n    def output_features(self) -&gt; FeatureSchema:\n        \"\"\"Return the output features of the OnnxSchema.\"\"\"\n\n    @property\n    def onnx_version(self) -&gt; str:\n        \"\"\"Return the onnx version of the OnnxSchema.\"\"\"\n\n    @property\n    def feature_names(self) -&gt; List[str]:\n        \"\"\"Return the feature names and order for onnx.\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.OnnxSchema.feature_names","title":"<code>feature_names</code>  <code>property</code>","text":"<p>Return the feature names and order for onnx.</p>"},{"location":"docs/api/model/#opsml.model._model.OnnxSchema.input_features","title":"<code>input_features</code>  <code>property</code>","text":"<p>Return the input features of the OnnxSchema.</p>"},{"location":"docs/api/model/#opsml.model._model.OnnxSchema.onnx_version","title":"<code>onnx_version</code>  <code>property</code>","text":"<p>Return the onnx version of the OnnxSchema.</p>"},{"location":"docs/api/model/#opsml.model._model.OnnxSchema.output_features","title":"<code>output_features</code>  <code>property</code>","text":"<p>Return the output features of the OnnxSchema.</p>"},{"location":"docs/api/model/#opsml.model._model.OnnxSchema.__init__","title":"<code>__init__(input_features, output_features, onnx_version, feature_names=None)</code>","text":"<p>Define an onnx schema</p> <p>Parameters:</p> Name Type Description Default <code>input_features</code> <code>FeatureSchema</code> <p>The input features of the onnx schema</p> required <code>output_features</code> <code>FeatureSchema</code> <p>The output features of the onnx schema</p> required <code>onnx_version</code> <code>str</code> <p>The onnx version of the schema</p> required <code>feature_names</code> <code>List[str] | None</code> <p>The feature names and order for onnx.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    input_features: FeatureSchema,\n    output_features: FeatureSchema,\n    onnx_version: str,\n    feature_names: Optional[List[str]] = None,\n) -&gt; None:\n    \"\"\"Define an onnx schema\n\n    Args:\n        input_features (FeatureSchema):\n            The input features of the onnx schema\n        output_features (FeatureSchema):\n            The output features of the onnx schema\n        onnx_version (str):\n            The onnx version of the schema\n        feature_names (List[str] | None):\n            The feature names and order for onnx.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.OnnxSchema.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the OnnxSchema.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the OnnxSchema.</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the OnnxSchema.\n\n    Returns:\n        String representation of the OnnxSchema.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.OnnxSession","title":"<code>OnnxSession</code>","text":"Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class OnnxSession:\n    @property\n    def schema(self) -&gt; OnnxSchema:\n        \"\"\"Returns the onnx schema\"\"\"\n\n    @property\n    def session(self) -&gt; Any:\n        \"\"\"Returns the onnx session\"\"\"\n\n    @session.setter\n    def session(self, session: Any) -&gt; None:\n        \"\"\"Sets the onnx session\n\n        Args:\n            session:\n                Onnx session\n        \"\"\"\n\n    def run(\n        self,\n        input_feed: Dict[str, Any],\n        output_names: Optional[list[str]] = None,\n        run_options: Optional[Dict[str, Any]] = None,\n    ) -&gt; Any:\n        \"\"\"Run the onnx session\n\n        Args:\n            input_feed:\n                Dictionary of input data\n            output_names:\n                List of output names\n            run_options:\n                Optional run options\n\n        Returns:\n            Output data\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the onnx model to json\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"OnnxSession\":\n        \"\"\"Validate the onnx model json\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.OnnxSession.schema","title":"<code>schema</code>  <code>property</code>","text":"<p>Returns the onnx schema</p>"},{"location":"docs/api/model/#opsml.model._model.OnnxSession.session","title":"<code>session</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the onnx session</p>"},{"location":"docs/api/model/#opsml.model._model.OnnxSession.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the onnx model to json</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the onnx model to json\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.OnnxSession.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Validate the onnx model json</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"OnnxSession\":\n    \"\"\"Validate the onnx model json\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.OnnxSession.run","title":"<code>run(input_feed, output_names=None, run_options=None)</code>","text":"<p>Run the onnx session</p> <p>Parameters:</p> Name Type Description Default <code>input_feed</code> <code>Dict[str, Any]</code> <p>Dictionary of input data</p> required <code>output_names</code> <code>Optional[list[str]]</code> <p>List of output names</p> <code>None</code> <code>run_options</code> <code>Optional[Dict[str, Any]]</code> <p>Optional run options</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Output data</p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def run(\n    self,\n    input_feed: Dict[str, Any],\n    output_names: Optional[list[str]] = None,\n    run_options: Optional[Dict[str, Any]] = None,\n) -&gt; Any:\n    \"\"\"Run the onnx session\n\n    Args:\n        input_feed:\n            Dictionary of input data\n        output_names:\n            List of output names\n        run_options:\n            Optional run options\n\n    Returns:\n        Output data\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.SklearnModel","title":"<code>SklearnModel</code>","text":"<p>               Bases: <code>ModelInterface</code></p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class SklearnModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Instantiate an SklearnModel interface\n\n        Args:\n            model:\n                Model to associate with interface. This model must be from the\n                scikit-learn ecosystem\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n            sample_data:\n                Sample data to use to make predictions\n            task_type:\n                The type of task the model performs\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n        \"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.SklearnModel.preprocessor","title":"<code>preprocessor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the preprocessor</p>"},{"location":"docs/api/model/#opsml.model._model.SklearnModel.preprocessor_name","title":"<code>preprocessor_name</code>  <code>property</code>","text":"<p>Returns the preprocessor name</p>"},{"location":"docs/api/model/#opsml.model._model.SklearnModel.__init__","title":"<code>__init__(model=None, preprocessor=None, sample_data=None, task_type=None, drift_profile=None)</code>","text":"<p>Instantiate an SklearnModel interface</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[Any]</code> <p>Model to associate with interface. This model must be from the scikit-learn ecosystem</p> <code>None</code> <code>preprocessor</code> <code>Optional[Any]</code> <p>Preprocessor to associate with the model. This preprocessor must be from the scikit-learn ecosystem</p> <code>None</code> <code>sample_data</code> <code>Optional[Any]</code> <p>Sample data to use to make predictions</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The type of task the model performs</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Instantiate an SklearnModel interface\n\n    Args:\n        model:\n            Model to associate with interface. This model must be from the\n            scikit-learn ecosystem\n        preprocessor:\n            Preprocessor to associate with the model. This preprocessor must be from the\n            scikit-learn ecosystem\n        sample_data:\n            Sample data to use to make predictions\n        task_type:\n            The type of task the model performs\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.TensorFlowModel","title":"<code>TensorFlowModel</code>","text":"<p>               Bases: <code>ModelInterface</code></p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class TensorFlowModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving PyTorch models\n\n        Args:\n            model:\n                Model to associate with interface. This model must inherit from tensorflow.keras.Model\n            preprocessor:\n                Preprocessor to associate with model.\n            sample_data:\n                Sample data to use to convert to ONNX and make sample predictions. This data must be a\n                tensorflow-supported type. numpy array, tf.Tensor, torch dataset, Dict[str, tf.Tensor],\n                List[tf.Tensor], Tuple[tf.Tensor].\n            task_type:\n                The intended task type of the model.\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n        \"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.TensorFlowModel.preprocessor","title":"<code>preprocessor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the preprocessor</p>"},{"location":"docs/api/model/#opsml.model._model.TensorFlowModel.preprocessor_name","title":"<code>preprocessor_name</code>  <code>property</code>","text":"<p>Returns the preprocessor name</p>"},{"location":"docs/api/model/#opsml.model._model.TensorFlowModel.__init__","title":"<code>__init__(model=None, preprocessor=None, sample_data=None, task_type=None, drift_profile=None)</code>","text":"<p>Interface for saving PyTorch models</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[Any]</code> <p>Model to associate with interface. This model must inherit from tensorflow.keras.Model</p> <code>None</code> <code>preprocessor</code> <code>Optional[Any]</code> <p>Preprocessor to associate with model.</p> <code>None</code> <code>sample_data</code> <code>Optional[Any]</code> <p>Sample data to use to convert to ONNX and make sample predictions. This data must be a tensorflow-supported type. numpy array, tf.Tensor, torch dataset, Dict[str, tf.Tensor], List[tf.Tensor], Tuple[tf.Tensor].</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The intended task type of the model.</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Interface for saving PyTorch models\n\n    Args:\n        model:\n            Model to associate with interface. This model must inherit from tensorflow.keras.Model\n        preprocessor:\n            Preprocessor to associate with model.\n        sample_data:\n            Sample data to use to convert to ONNX and make sample predictions. This data must be a\n            tensorflow-supported type. numpy array, tf.Tensor, torch dataset, Dict[str, tf.Tensor],\n            List[tf.Tensor], Tuple[tf.Tensor].\n        task_type:\n            The intended task type of the model.\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.TorchModel","title":"<code>TorchModel</code>","text":"<p>               Bases: <code>ModelInterface</code></p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class TorchModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving PyTorch models\n\n        Args:\n            model:\n                Model to associate with interface. This model must inherit from torch.nn.Module.\n            preprocessor:\n                Preprocessor to associate with model.\n            sample_data:\n                Sample data to use to convert to ONNX and make sample predictions. This data must be a\n                pytorch-supported type. TorchData interface, torch tensor, torch dataset, Dict[str, torch.Tensor],\n                List[torch.Tensor], Tuple[torch.Tensor].\n            task_type:\n                The intended task type of the model.\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n        \"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: None | ModelSaveKwargs = None,\n    ) -&gt; ModelInterfaceMetadata:\n        \"\"\"Save the TorchModel interface. Torch models are saved\n        as state_dicts as is the standard for PyTorch.\n\n        Args:\n            path (Path):\n                Base path to save artifacts\n            save_kwargs (ModelSaveKwargs):\n                Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n                that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n                the underlying library.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.TorchModel.preprocessor","title":"<code>preprocessor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the preprocessor</p>"},{"location":"docs/api/model/#opsml.model._model.TorchModel.preprocessor_name","title":"<code>preprocessor_name</code>  <code>property</code>","text":"<p>Returns the preprocessor name</p>"},{"location":"docs/api/model/#opsml.model._model.TorchModel.__init__","title":"<code>__init__(model=None, preprocessor=None, sample_data=None, task_type=None, drift_profile=None)</code>","text":"<p>Interface for saving PyTorch models</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[Any]</code> <p>Model to associate with interface. This model must inherit from torch.nn.Module.</p> <code>None</code> <code>preprocessor</code> <code>Optional[Any]</code> <p>Preprocessor to associate with model.</p> <code>None</code> <code>sample_data</code> <code>Optional[Any]</code> <p>Sample data to use to convert to ONNX and make sample predictions. This data must be a pytorch-supported type. TorchData interface, torch tensor, torch dataset, Dict[str, torch.Tensor], List[torch.Tensor], Tuple[torch.Tensor].</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The intended task type of the model.</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Interface for saving PyTorch models\n\n    Args:\n        model:\n            Model to associate with interface. This model must inherit from torch.nn.Module.\n        preprocessor:\n            Preprocessor to associate with model.\n        sample_data:\n            Sample data to use to convert to ONNX and make sample predictions. This data must be a\n            pytorch-supported type. TorchData interface, torch tensor, torch dataset, Dict[str, torch.Tensor],\n            List[torch.Tensor], Tuple[torch.Tensor].\n        task_type:\n            The intended task type of the model.\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.TorchModel.save","title":"<code>save(path, save_kwargs=None)</code>","text":"<p>Save the TorchModel interface. Torch models are saved as state_dicts as is the standard for PyTorch.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Base path to save artifacts</p> required <code>save_kwargs</code> <code>ModelSaveKwargs</code> <p>Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning that the kwargs will be passed to the underlying methods as is and are expected to be supported by the underlying library.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def save(\n    self,\n    path: Path,\n    save_kwargs: None | ModelSaveKwargs = None,\n) -&gt; ModelInterfaceMetadata:\n    \"\"\"Save the TorchModel interface. Torch models are saved\n    as state_dicts as is the standard for PyTorch.\n\n    Args:\n        path (Path):\n            Base path to save artifacts\n        save_kwargs (ModelSaveKwargs):\n            Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n            that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n            the underlying library.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.XGBoostModel","title":"<code>XGBoostModel</code>","text":"<p>               Bases: <code>ModelInterface</code></p> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>class XGBoostModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving XGBoost Booster models\n\n        Args:\n            model:\n                Model to associate with interface. This model must be an xgboost booster.\n            preprocessor:\n                Preprocessor to associate with the model.\n            sample_data:\n                Sample data to use to make predictions.\n            task_type:\n                The type of task the model performs\n            drift_profile:\n                Drift profile(s) to associate with the model. Must be a dictionary of\n                alias and drift profile.\n        \"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/api/model/#opsml.model._model.XGBoostModel.preprocessor","title":"<code>preprocessor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the preprocessor</p>"},{"location":"docs/api/model/#opsml.model._model.XGBoostModel.preprocessor_name","title":"<code>preprocessor_name</code>  <code>property</code>","text":"<p>Returns the preprocessor name</p>"},{"location":"docs/api/model/#opsml.model._model.XGBoostModel.__init__","title":"<code>__init__(model=None, preprocessor=None, sample_data=None, task_type=None, drift_profile=None)</code>","text":"<p>Interface for saving XGBoost Booster models</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[Any]</code> <p>Model to associate with interface. This model must be an xgboost booster.</p> <code>None</code> <code>preprocessor</code> <code>Optional[Any]</code> <p>Preprocessor to associate with the model.</p> <code>None</code> <code>sample_data</code> <code>Optional[Any]</code> <p>Sample data to use to make predictions.</p> <code>None</code> <code>task_type</code> <code>Optional[TaskType]</code> <p>The type of task the model performs</p> <code>None</code> <code>drift_profile</code> <code>Optional[DriftProfileType]</code> <p>Drift profile(s) to associate with the model. Must be a dictionary of alias and drift profile.</p> <code>None</code> Source code in <code>python/opsml/model/_model.pyi</code> <pre><code>def __init__(\n    self,\n    model: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Interface for saving XGBoost Booster models\n\n    Args:\n        model:\n            Model to associate with interface. This model must be an xgboost booster.\n        preprocessor:\n            Preprocessor to associate with the model.\n        sample_data:\n            Sample data to use to make predictions.\n        task_type:\n            The type of task the model performs\n        drift_profile:\n            Drift profile(s) to associate with the model. Must be a dictionary of\n            alias and drift profile.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/","title":"Types","text":""},{"location":"docs/api/types/#opsml.types._types.CommonKwargs","title":"<code>CommonKwargs</code>","text":"Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>class CommonKwargs:\n    IsPipeline: \"CommonKwargs\"\n    ModelType: \"CommonKwargs\"\n    ModelClass: \"CommonKwargs\"\n    ModelArch: \"CommonKwargs\"\n    PreprocessorName: \"CommonKwargs\"\n    Preprocessor: \"CommonKwargs\"\n    TaskType: \"CommonKwargs\"\n    Model: \"CommonKwargs\"\n    Undefined: \"CommonKwargs\"\n    Backend: \"CommonKwargs\"\n    Pytorch: \"CommonKwargs\"\n    Tensorflow: \"CommonKwargs\"\n    SampleData: \"CommonKwargs\"\n    Onnx: \"CommonKwargs\"\n    LoadType: \"CommonKwargs\"\n    DataType: \"CommonKwargs\"\n    Tokenizer: \"CommonKwargs\"\n    TokenizerName: \"CommonKwargs\"\n    FeatureExtractor: \"CommonKwargs\"\n    FeatureExtractorName: \"CommonKwargs\"\n    Image: \"CommonKwargs\"\n    Text: \"CommonKwargs\"\n    VowpalArgs: \"CommonKwargs\"\n    BaseVersion: \"CommonKwargs\"\n    SampleDataInterfaceType: \"CommonKwargs\"\n\n    @staticmethod\n    def from_string(s: str) -&gt; Optional[\"CommonKwargs\"]:\n        \"\"\"Return the CommonKwargs enum from a string.\n\n        Args:\n            s:\n                The string representation of the CommonKwargs.\n\n        Returns:\n            The CommonKwargs enum.\n        \"\"\"\n\n    def as_string(self) -&gt; str:\n        \"\"\"Return the string representation of the CommonKwargs.\n\n        Returns:\n            String representation of the CommonKwargs.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.CommonKwargs.as_string","title":"<code>as_string()</code>","text":"<p>Return the string representation of the CommonKwargs.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the CommonKwargs.</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def as_string(self) -&gt; str:\n    \"\"\"Return the string representation of the CommonKwargs.\n\n    Returns:\n        String representation of the CommonKwargs.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.CommonKwargs.from_string","title":"<code>from_string(s)</code>  <code>staticmethod</code>","text":"<p>Return the CommonKwargs enum from a string.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>The string representation of the CommonKwargs.</p> required <p>Returns:</p> Type Description <code>Optional[CommonKwargs]</code> <p>The CommonKwargs enum.</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>@staticmethod\ndef from_string(s: str) -&gt; Optional[\"CommonKwargs\"]:\n    \"\"\"Return the CommonKwargs enum from a string.\n\n    Args:\n        s:\n            The string representation of the CommonKwargs.\n\n    Returns:\n        The CommonKwargs enum.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.DriftArgs","title":"<code>DriftArgs</code>","text":"Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>class DriftArgs:\n    def __init__(self, active: bool = True, deactivate_others: bool = False) -&gt; None:\n        \"\"\"Define a drift config\n\n        Args:\n            active (bool):\n                Whether to set the drift profile to active\n            deactivate_others (bool):\n                Whether to deactivate all other drift profiles of the same space and name\n        \"\"\"\n\n    @property\n    def active(self) -&gt; bool:\n        \"\"\"Return the active status of the drift profile.\"\"\"\n\n    @property\n    def deactivate_others(self) -&gt; bool:\n        \"\"\"Return the deactivate_others status of the drift profile.\"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.DriftArgs.active","title":"<code>active</code>  <code>property</code>","text":"<p>Return the active status of the drift profile.</p>"},{"location":"docs/api/types/#opsml.types._types.DriftArgs.deactivate_others","title":"<code>deactivate_others</code>  <code>property</code>","text":"<p>Return the deactivate_others status of the drift profile.</p>"},{"location":"docs/api/types/#opsml.types._types.DriftArgs.__init__","title":"<code>__init__(active=True, deactivate_others=False)</code>","text":"<p>Define a drift config</p> <p>Parameters:</p> Name Type Description Default <code>active</code> <code>bool</code> <p>Whether to set the drift profile to active</p> <code>True</code> <code>deactivate_others</code> <code>bool</code> <p>Whether to deactivate all other drift profiles of the same space and name</p> <code>False</code> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def __init__(self, active: bool = True, deactivate_others: bool = False) -&gt; None:\n    \"\"\"Define a drift config\n\n    Args:\n        active (bool):\n            Whether to set the drift profile to active\n        deactivate_others (bool):\n            Whether to deactivate all other drift profiles of the same space and name\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.DriftProfileMap","title":"<code>DriftProfileMap</code>","text":"Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>class DriftProfileMap:\n    def __init__(self) -&gt; None:\n        \"\"\"Creates an empty drift profile map\"\"\"\n\n    def add_profile(self, alias: str, profile: Any) -&gt; None:\n        \"\"\"Add a drift profile to the map\n\n        Args:\n            alias:\n                Alias to use for the drift profile\n            profile:\n                Drift profile to add\n        \"\"\"\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"Returns the drift profile at the given key\"\"\"\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Returns whether the drift profile map is empty\n\n        Returns:\n            True if the drift profile map is empty, False otherwise\n        \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.DriftProfileMap.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Returns the drift profile at the given key</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def __getitem__(self, key: str) -&gt; Any:\n    \"\"\"Returns the drift profile at the given key\"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.DriftProfileMap.__init__","title":"<code>__init__()</code>","text":"<p>Creates an empty drift profile map</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Creates an empty drift profile map\"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.DriftProfileMap.add_profile","title":"<code>add_profile(alias, profile)</code>","text":"<p>Add a drift profile to the map</p> <p>Parameters:</p> Name Type Description Default <code>alias</code> <code>str</code> <p>Alias to use for the drift profile</p> required <code>profile</code> <code>Any</code> <p>Drift profile to add</p> required Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def add_profile(self, alias: str, profile: Any) -&gt; None:\n    \"\"\"Add a drift profile to the map\n\n    Args:\n        alias:\n            Alias to use for the drift profile\n        profile:\n            Drift profile to add\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.DriftProfileMap.is_empty","title":"<code>is_empty()</code>","text":"<p>Returns whether the drift profile map is empty</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the drift profile map is empty, False otherwise</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Returns whether the drift profile map is empty\n\n    Returns:\n        True if the drift profile map is empty, False otherwise\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.DriftProfileUri","title":"<code>DriftProfileUri</code>","text":"Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>class DriftProfileUri:\n    root_dir: Path\n    uri: Path\n    drift_type: DriftType\n\n    def __init__(self, uri: Path, drift_type: DriftType) -&gt; None:\n        \"\"\"Define a drift profile\n\n        Args:\n            root_dir:\n                The root directory of the drift profile\n            uri:\n                The relative path to the drift profile\n            drift_type:\n                Drift profile type\n        \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.DriftProfileUri.__init__","title":"<code>__init__(uri, drift_type)</code>","text":"<p>Define a drift profile</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <p>The root directory of the drift profile</p> required <code>uri</code> <code>Path</code> <p>The relative path to the drift profile</p> required <code>drift_type</code> <code>DriftType</code> <p>Drift profile type</p> required Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def __init__(self, uri: Path, drift_type: DriftType) -&gt; None:\n    \"\"\"Define a drift profile\n\n    Args:\n        root_dir:\n            The root directory of the drift profile\n        uri:\n            The relative path to the drift profile\n        drift_type:\n            Drift profile type\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.SaveName","title":"<code>SaveName</code>","text":"Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>class SaveName:\n    Card: \"SaveName\"\n    Audit: \"SaveName\"\n    ModelMetadata: \"SaveName\"\n    Model: \"SaveName\"\n    Preprocessor: \"SaveName\"\n    OnnxModel: \"SaveName\"\n    SampleModelData: \"SaveName\"\n    DataProfile: \"SaveName\"\n    Data: \"SaveName\"\n    Profile: \"SaveName\"\n    Artifacts: \"SaveName\"\n    QuantizedModel: \"SaveName\"\n    Tokenizer: \"SaveName\"\n    FeatureExtractor: \"SaveName\"\n    Metadata: \"SaveName\"\n    Graphs: \"SaveName\"\n    OnnxConfig: \"SaveName\"\n    Dataset: \"SaveName\"\n    DriftProfile: \"SaveName\"\n\n    @staticmethod\n    def from_string(s: str) -&gt; Optional[\"SaveName\"]:\n        \"\"\"Return the SaveName enum from a string.\n\n        Args:\n            s:\n                The string representation of the SaveName.\n\n        Returns:\n            The SaveName enum.\n        \"\"\"\n\n    def as_string(self) -&gt; str:\n        \"\"\"Return the string representation of the SaveName.\n\n        Returns:\n            String representation of the SaveName.\n        \"\"\"\n\n    def __str__(self):\n        \"\"\"Return a string representation of the SaveName.\n\n        Returns:\n            String representation of the SaveName.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.SaveName.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the SaveName.</p> <p>Returns:</p> Type Description <p>String representation of the SaveName.</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def __str__(self):\n    \"\"\"Return a string representation of the SaveName.\n\n    Returns:\n        String representation of the SaveName.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.SaveName.as_string","title":"<code>as_string()</code>","text":"<p>Return the string representation of the SaveName.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the SaveName.</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def as_string(self) -&gt; str:\n    \"\"\"Return the string representation of the SaveName.\n\n    Returns:\n        String representation of the SaveName.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.SaveName.from_string","title":"<code>from_string(s)</code>  <code>staticmethod</code>","text":"<p>Return the SaveName enum from a string.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>The string representation of the SaveName.</p> required <p>Returns:</p> Type Description <code>Optional[SaveName]</code> <p>The SaveName enum.</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>@staticmethod\ndef from_string(s: str) -&gt; Optional[\"SaveName\"]:\n    \"\"\"Return the SaveName enum from a string.\n\n    Args:\n        s:\n            The string representation of the SaveName.\n\n    Returns:\n        The SaveName enum.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.SaverPath","title":"<code>SaverPath</code>","text":"Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>class SaverPath:\n    path: Path\n\n    def __init__(\n        self,\n        parent: Path,\n        child: Optional[Path],\n        filename: Optional[SaveName],\n        extension: Optional[Suffix],\n    ) -&gt; None:\n        \"\"\"Helper for creating paths for saving artifacts.\n\n        Args:\n            parent (Path):\n                The parent path.\n            child (Path | None):\n                The child path.\n            filename (SaveName | None):\n                The filename.\n            extension (Suffix | None):\n                The extension.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.SaverPath.__init__","title":"<code>__init__(parent, child, filename, extension)</code>","text":"<p>Helper for creating paths for saving artifacts.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>Path</code> <p>The parent path.</p> required <code>child</code> <code>Path | None</code> <p>The child path.</p> required <code>filename</code> <code>SaveName | None</code> <p>The filename.</p> required <code>extension</code> <code>Suffix | None</code> <p>The extension.</p> required Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def __init__(\n    self,\n    parent: Path,\n    child: Optional[Path],\n    filename: Optional[SaveName],\n    extension: Optional[Suffix],\n) -&gt; None:\n    \"\"\"Helper for creating paths for saving artifacts.\n\n    Args:\n        parent (Path):\n            The parent path.\n        child (Path | None):\n            The child path.\n        filename (SaveName | None):\n            The filename.\n        extension (Suffix | None):\n            The extension.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.Suffix","title":"<code>Suffix</code>","text":"Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>class Suffix:\n    Onnx: \"Suffix\"\n    Parquet: \"Suffix\"\n    Zarr: \"Suffix\"\n    Joblib: \"Suffix\"\n    Html: \"Suffix\"\n    Json: \"Suffix\"\n    Ckpt: \"Suffix\"\n    Pt: \"Suffix\"\n    Text: \"Suffix\"\n    Catboost: \"Suffix\"\n    Jsonl: \"Suffix\"\n    Empty: \"Suffix\"\n    Dmatrix: \"Suffix\"\n    Model: \"Suffix\"\n\n    @staticmethod\n    def from_string(s: str) -&gt; Optional[\"Suffix\"]:\n        \"\"\"Return the Suffix enum from a string.\n\n        Args:\n            s:\n                The string representation of the Suffix.\n\n        Returns:\n            The Suffix enum.\n        \"\"\"\n\n    def as_string(self) -&gt; str:\n        \"\"\"Return the string representation of the Suffix.\n\n        Returns:\n            String representation of the Suffix.\n        \"\"\"\n\n    def __str__(self):\n        \"\"\"Return a string representation of the Suffix.\n\n        Returns:\n            String representation of the Suffix.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.Suffix.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the Suffix.</p> <p>Returns:</p> Type Description <p>String representation of the Suffix.</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def __str__(self):\n    \"\"\"Return a string representation of the Suffix.\n\n    Returns:\n        String representation of the Suffix.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.Suffix.as_string","title":"<code>as_string()</code>","text":"<p>Return the string representation of the Suffix.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the Suffix.</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>def as_string(self) -&gt; str:\n    \"\"\"Return the string representation of the Suffix.\n\n    Returns:\n        String representation of the Suffix.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/types/#opsml.types._types.Suffix.from_string","title":"<code>from_string(s)</code>  <code>staticmethod</code>","text":"<p>Return the Suffix enum from a string.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>The string representation of the Suffix.</p> required <p>Returns:</p> Type Description <code>Optional[Suffix]</code> <p>The Suffix enum.</p> Source code in <code>python/opsml/types/_types.pyi</code> <pre><code>@staticmethod\ndef from_string(s: str) -&gt; Optional[\"Suffix\"]:\n    \"\"\"Return the Suffix enum from a string.\n\n    Args:\n        s:\n            The string representation of the Suffix.\n\n    Returns:\n        The Suffix enum.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/","title":"Overview","text":""},{"location":"docs/api/genai/genai/#opsml.genai._genai.Agent","title":"<code>Agent</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class Agent:\n    def __init__(\n        self,\n        provider: Provider | str,\n        system_instruction: Optional[str | List[str] | Message | List[Message]] = None,\n    ) -&gt; None:\n        \"\"\"Create an Agent object.\n\n        Args:\n            provider (Provider | str):\n                The provider to use for the agent. This can be a Provider enum or a string\n                representing the provider.\n            system_instruction (Optional[str | List[str] | Message | List[Message]]):\n                The system message to use for the agent. This can be a string, a list of strings,\n                a Message object, or a list of Message objects. If None, no system message will be used.\n                This is added to all tasks that the agent executes. If a given task contains it's own\n                system message, the agent's system message will be prepended to the task's system message.\n\n        Example:\n        ```python\n            agent = Agent(\n                provider=Provider.OpenAI,\n                system_instruction=\"You are a helpful assistant.\",\n            )\n        ```\n        \"\"\"\n\n    @property\n    def system_instruction(self) -&gt; List[Message]:\n        \"\"\"The system message to use for the agent. This is a list of Message objects.\"\"\"\n\n    def execute_task(\n        self,\n        task: Task,\n        output_type: Optional[Any] = None,\n        model: Optional[str] = None,\n    ) -&gt; AgentResponse:\n        \"\"\"Execute a task.\n\n        Args:\n            task (Task):\n                The task to execute.\n            output_type (Optional[Any]):\n                The output type to use for the task. This can either be a Pydantic `BaseModel` class\n                or a supported PotatoHead response type such as `Score`.\n            model (Optional[str]):\n                The model to use for the task. If not provided, defaults to the `model` provided within\n                the Task's prompt. If the Task's prompt does not have a model, an error will be raised.\n\n        Returns:\n            AgentResponse:\n                The response from the agent after executing the task.\n        \"\"\"\n\n    def execute_prompt(\n        self,\n        prompt: Prompt,\n        output_type: Optional[Any] = None,\n        model: Optional[str] = None,\n    ) -&gt; AgentResponse:\n        \"\"\"Execute a prompt.\n\n        Args:\n            prompt (Prompt):`\n                The prompt to execute.\n            output_type (Optional[Any]):\n                The output type to use for the task. This can either be a Pydantic `BaseModel` class\n                or a supported potato_head response type such as `Score`.\n            model (Optional[str]):\n                The model to use for the task. If not provided, defaults to the `model` provided within\n                the Prompt. If the Prompt does not have a model, an error will be raised.\n\n        Returns:\n            AgentResponse:\n                The response from the agent after executing the task.\n        \"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the agent. This is a random uuid7 that is generated when the agent is created.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Agent.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the agent. This is a random uuid7 that is generated when the agent is created.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Agent.system_instruction","title":"<code>system_instruction</code>  <code>property</code>","text":"<p>The system message to use for the agent. This is a list of Message objects.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Agent.__init__","title":"<code>__init__(provider, system_instruction=None)</code>","text":"<p>Create an Agent object.</p> <p>Parameters:</p> Name Type Description Default <code>provider</code> <code>Provider | str</code> <p>The provider to use for the agent. This can be a Provider enum or a string representing the provider.</p> required <code>system_instruction</code> <code>Optional[str | List[str] | Message | List[Message]]</code> <p>The system message to use for the agent. This can be a string, a list of strings, a Message object, or a list of Message objects. If None, no system message will be used. This is added to all tasks that the agent executes. If a given task contains it's own system message, the agent's system message will be prepended to the task's system message.</p> <code>None</code> <p>Example: <pre><code>    agent = Agent(\n        provider=Provider.OpenAI,\n        system_instruction=\"You are a helpful assistant.\",\n    )\n</code></pre></p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(\n    self,\n    provider: Provider | str,\n    system_instruction: Optional[str | List[str] | Message | List[Message]] = None,\n) -&gt; None:\n    \"\"\"Create an Agent object.\n\n    Args:\n        provider (Provider | str):\n            The provider to use for the agent. This can be a Provider enum or a string\n            representing the provider.\n        system_instruction (Optional[str | List[str] | Message | List[Message]]):\n            The system message to use for the agent. This can be a string, a list of strings,\n            a Message object, or a list of Message objects. If None, no system message will be used.\n            This is added to all tasks that the agent executes. If a given task contains it's own\n            system message, the agent's system message will be prepended to the task's system message.\n\n    Example:\n    ```python\n        agent = Agent(\n            provider=Provider.OpenAI,\n            system_instruction=\"You are a helpful assistant.\",\n        )\n    ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Agent.execute_prompt","title":"<code>execute_prompt(prompt, output_type=None, model=None)</code>","text":"<p>Execute a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>Prompt</code> <p>` The prompt to execute.</p> required <code>output_type</code> <code>Optional[Any]</code> <p>The output type to use for the task. This can either be a Pydantic <code>BaseModel</code> class or a supported potato_head response type such as <code>Score</code>.</p> <code>None</code> <code>model</code> <code>Optional[str]</code> <p>The model to use for the task. If not provided, defaults to the <code>model</code> provided within the Prompt. If the Prompt does not have a model, an error will be raised.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AgentResponse</code> <code>AgentResponse</code> <p>The response from the agent after executing the task.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def execute_prompt(\n    self,\n    prompt: Prompt,\n    output_type: Optional[Any] = None,\n    model: Optional[str] = None,\n) -&gt; AgentResponse:\n    \"\"\"Execute a prompt.\n\n    Args:\n        prompt (Prompt):`\n            The prompt to execute.\n        output_type (Optional[Any]):\n            The output type to use for the task. This can either be a Pydantic `BaseModel` class\n            or a supported potato_head response type such as `Score`.\n        model (Optional[str]):\n            The model to use for the task. If not provided, defaults to the `model` provided within\n            the Prompt. If the Prompt does not have a model, an error will be raised.\n\n    Returns:\n        AgentResponse:\n            The response from the agent after executing the task.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Agent.execute_task","title":"<code>execute_task(task, output_type=None, model=None)</code>","text":"<p>Execute a task.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>The task to execute.</p> required <code>output_type</code> <code>Optional[Any]</code> <p>The output type to use for the task. This can either be a Pydantic <code>BaseModel</code> class or a supported PotatoHead response type such as <code>Score</code>.</p> <code>None</code> <code>model</code> <code>Optional[str]</code> <p>The model to use for the task. If not provided, defaults to the <code>model</code> provided within the Task's prompt. If the Task's prompt does not have a model, an error will be raised.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AgentResponse</code> <code>AgentResponse</code> <p>The response from the agent after executing the task.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def execute_task(\n    self,\n    task: Task,\n    output_type: Optional[Any] = None,\n    model: Optional[str] = None,\n) -&gt; AgentResponse:\n    \"\"\"Execute a task.\n\n    Args:\n        task (Task):\n            The task to execute.\n        output_type (Optional[Any]):\n            The output type to use for the task. This can either be a Pydantic `BaseModel` class\n            or a supported PotatoHead response type such as `Score`.\n        model (Optional[str]):\n            The model to use for the task. If not provided, defaults to the `model` provided within\n            the Task's prompt. If the Task's prompt does not have a model, an error will be raised.\n\n    Returns:\n        AgentResponse:\n            The response from the agent after executing the task.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AgentResponse","title":"<code>AgentResponse</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class AgentResponse:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the agent response.\"\"\"\n\n    @property\n    def result(self) -&gt; Any:\n        \"\"\"The result of the agent response. This can be a Pydantic BaseModel class or\n        a supported potato_head response type such as `Score`. If neither is provided,\n        the response json will be returned as a dictionary.\n        \"\"\"\n\n    @property\n    def token_usage(self) -&gt; Usage:\n        \"\"\"Returns the token usage of the agent response if supported\"\"\"\n\n    @property\n    def log_probs(self) -&gt; List[\"ResponseLogProbs\"]:\n        \"\"\"Returns the log probabilities of the agent response if supported.\n        This is primarily used for debugging and analysis purposes.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AgentResponse.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the agent response.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AgentResponse.log_probs","title":"<code>log_probs</code>  <code>property</code>","text":"<p>Returns the log probabilities of the agent response if supported. This is primarily used for debugging and analysis purposes.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AgentResponse.result","title":"<code>result</code>  <code>property</code>","text":"<p>The result of the agent response. This can be a Pydantic BaseModel class or a supported potato_head response type such as <code>Score</code>. If neither is provided, the response json will be returned as a dictionary.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AgentResponse.token_usage","title":"<code>token_usage</code>  <code>property</code>","text":"<p>Returns the token usage of the agent response if supported</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AudioUrl","title":"<code>AudioUrl</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class AudioUrl:\n    def __init__(\n        self,\n        url: str,\n        kind: Literal[\"audio-url\"] = \"audio-url\",\n    ) -&gt; None:\n        \"\"\"Create an AudioUrl object.\n\n        Args:\n            url (str):\n                The URL of the audio.\n            kind (Literal[\"audio-url\"]):\n                The kind of the content.\n        \"\"\"\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"The URL of the audio.\"\"\"\n\n    @property\n    def kind(self) -&gt; str:\n        \"\"\"The kind of the content.\"\"\"\n\n    @property\n    def media_type(self) -&gt; str:\n        \"\"\"The media type of the audio URL.\"\"\"\n\n    @property\n    def format(self) -&gt; str:\n        \"\"\"The format of the audio URL.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AudioUrl.format","title":"<code>format</code>  <code>property</code>","text":"<p>The format of the audio URL.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AudioUrl.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>The kind of the content.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AudioUrl.media_type","title":"<code>media_type</code>  <code>property</code>","text":"<p>The media type of the audio URL.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AudioUrl.url","title":"<code>url</code>  <code>property</code>","text":"<p>The URL of the audio.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.AudioUrl.__init__","title":"<code>__init__(url, kind='audio-url')</code>","text":"<p>Create an AudioUrl object.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the audio.</p> required <code>kind</code> <code>Literal['audio-url']</code> <p>The kind of the content.</p> <code>'audio-url'</code> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(\n    self,\n    url: str,\n    kind: Literal[\"audio-url\"] = \"audio-url\",\n) -&gt; None:\n    \"\"\"Create an AudioUrl object.\n\n    Args:\n        url (str):\n            The URL of the audio.\n        kind (Literal[\"audio-url\"]):\n            The kind of the content.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.BinaryContent","title":"<code>BinaryContent</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class BinaryContent:\n    def __init__(\n        self,\n        data: bytes,\n        media_type: str,\n        kind: str = \"binary\",\n    ) -&gt; None:\n        \"\"\"Create a BinaryContent object.\n\n        Args:\n            data (bytes):\n                The binary data.\n            media_type (str):\n                The media type of the binary data.\n            kind (str):\n                The kind of the content\n        \"\"\"\n\n    @property\n    def media_type(self) -&gt; str:\n        \"\"\"The media type of the binary content.\"\"\"\n\n    @property\n    def format(self) -&gt; str:\n        \"\"\"The format of the binary content.\"\"\"\n\n    @property\n    def data(self) -&gt; bytes:\n        \"\"\"The binary data.\"\"\"\n\n    @property\n    def kind(self) -&gt; str:\n        \"\"\"The kind of the content.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.BinaryContent.data","title":"<code>data</code>  <code>property</code>","text":"<p>The binary data.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.BinaryContent.format","title":"<code>format</code>  <code>property</code>","text":"<p>The format of the binary content.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.BinaryContent.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>The kind of the content.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.BinaryContent.media_type","title":"<code>media_type</code>  <code>property</code>","text":"<p>The media type of the binary content.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.BinaryContent.__init__","title":"<code>__init__(data, media_type, kind='binary')</code>","text":"<p>Create a BinaryContent object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>The binary data.</p> required <code>media_type</code> <code>str</code> <p>The media type of the binary data.</p> required <code>kind</code> <code>str</code> <p>The kind of the content</p> <code>'binary'</code> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(\n    self,\n    data: bytes,\n    media_type: str,\n    kind: str = \"binary\",\n) -&gt; None:\n    \"\"\"Create a BinaryContent object.\n\n    Args:\n        data (bytes):\n            The binary data.\n        media_type (str):\n            The media type of the binary data.\n        kind (str):\n            The kind of the content\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ChatResponse","title":"<code>ChatResponse</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class ChatResponse:\n    def to_py(self) -&gt; Any:\n        \"\"\"Convert the ChatResponse to it's Python representation.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the ChatResponse.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ChatResponse.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the ChatResponse.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the ChatResponse.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ChatResponse.to_py","title":"<code>to_py()</code>","text":"<p>Convert the ChatResponse to it's Python representation.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def to_py(self) -&gt; Any:\n    \"\"\"Convert the ChatResponse to it's Python representation.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.CompletionTokenDetails","title":"<code>CompletionTokenDetails</code>","text":"<p>Details about the completion tokens used in a model response.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class CompletionTokenDetails:\n    \"\"\"Details about the completion tokens used in a model response.\"\"\"\n\n    @property\n    def accepted_prediction_tokens(self) -&gt; int:\n        \"\"\"The number of accepted prediction tokens used in the response.\"\"\"\n\n    @property\n    def audio_tokens(self) -&gt; int:\n        \"\"\"The number of audio tokens used in the response.\"\"\"\n\n    @property\n    def reasoning_tokens(self) -&gt; int:\n        \"\"\"The number of reasoning tokens used in the response.\"\"\"\n\n    @property\n    def rejected_prediction_tokens(self) -&gt; int:\n        \"\"\"The number of rejected prediction tokens used in the response.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.CompletionTokenDetails.accepted_prediction_tokens","title":"<code>accepted_prediction_tokens</code>  <code>property</code>","text":"<p>The number of accepted prediction tokens used in the response.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.CompletionTokenDetails.audio_tokens","title":"<code>audio_tokens</code>  <code>property</code>","text":"<p>The number of audio tokens used in the response.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.CompletionTokenDetails.reasoning_tokens","title":"<code>reasoning_tokens</code>  <code>property</code>","text":"<p>The number of reasoning tokens used in the response.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.CompletionTokenDetails.rejected_prediction_tokens","title":"<code>rejected_prediction_tokens</code>  <code>property</code>","text":"<p>The number of rejected prediction tokens used in the response.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.DocumentUrl","title":"<code>DocumentUrl</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class DocumentUrl:\n    def __init__(\n        self,\n        url: str,\n        kind: Literal[\"document-url\"] = \"document-url\",\n    ) -&gt; None:\n        \"\"\"Create a DocumentUrl object.\n\n        Args:\n            url (str):\n                The URL of the document.\n            kind (Literal[\"document-url\"]):\n                The kind of the content.\n        \"\"\"\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"The URL of the document.\"\"\"\n\n    @property\n    def kind(self) -&gt; str:\n        \"\"\"The kind of the content.\"\"\"\n\n    @property\n    def media_type(self) -&gt; str:\n        \"\"\"The media type of the document URL.\"\"\"\n\n    @property\n    def format(self) -&gt; str:\n        \"\"\"The format of the document URL.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.DocumentUrl.format","title":"<code>format</code>  <code>property</code>","text":"<p>The format of the document URL.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.DocumentUrl.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>The kind of the content.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.DocumentUrl.media_type","title":"<code>media_type</code>  <code>property</code>","text":"<p>The media type of the document URL.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.DocumentUrl.url","title":"<code>url</code>  <code>property</code>","text":"<p>The URL of the document.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.DocumentUrl.__init__","title":"<code>__init__(url, kind='document-url')</code>","text":"<p>Create a DocumentUrl object.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the document.</p> required <code>kind</code> <code>Literal['document-url']</code> <p>The kind of the content.</p> <code>'document-url'</code> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(\n    self,\n    url: str,\n    kind: Literal[\"document-url\"] = \"document-url\",\n) -&gt; None:\n    \"\"\"Create a DocumentUrl object.\n\n    Args:\n        url (str):\n            The URL of the document.\n        kind (Literal[\"document-url\"]):\n            The kind of the content.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.EventDetails","title":"<code>EventDetails</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class EventDetails:\n    @property\n    def prompt(self) -&gt; Optional[Prompt]:\n        \"\"\"The prompt used for the task.\"\"\"\n\n    @property\n    def response(self) -&gt; Optional[ChatResponse]:\n        \"\"\"The response from the agent after executing the task.\"\"\"\n\n    @property\n    def duration(self) -&gt; Optional[datetime.timedelta]:\n        \"\"\"The duration of the task execution.\"\"\"\n\n    @property\n    def start_time(self) -&gt; Optional[datetime.datetime]:\n        \"\"\"The start time of the task execution.\"\"\"\n\n    @property\n    def end_time(self) -&gt; Optional[datetime.datetime]:\n        \"\"\"The end time of the task execution.\"\"\"\n\n    @property\n    def error(self) -&gt; Optional[str]:\n        \"\"\"The error message if the task failed, otherwise None.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.EventDetails.duration","title":"<code>duration</code>  <code>property</code>","text":"<p>The duration of the task execution.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.EventDetails.end_time","title":"<code>end_time</code>  <code>property</code>","text":"<p>The end time of the task execution.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.EventDetails.error","title":"<code>error</code>  <code>property</code>","text":"<p>The error message if the task failed, otherwise None.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.EventDetails.prompt","title":"<code>prompt</code>  <code>property</code>","text":"<p>The prompt used for the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.EventDetails.response","title":"<code>response</code>  <code>property</code>","text":"<p>The response from the agent after executing the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.EventDetails.start_time","title":"<code>start_time</code>  <code>property</code>","text":"<p>The start time of the task execution.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ImageUrl","title":"<code>ImageUrl</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class ImageUrl:\n    def __init__(\n        self,\n        url: str,\n        kind: Literal[\"image-url\"] = \"image-url\",\n    ) -&gt; None:\n        \"\"\"Create an ImageUrl object.\n\n        Args:\n            url (str):\n                The URL of the image.\n            kind (Literal[\"image-url\"]):\n                The kind of the content.\n        \"\"\"\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"The URL of the image.\"\"\"\n\n    @property\n    def kind(self) -&gt; str:\n        \"\"\"The kind of the content.\"\"\"\n\n    @property\n    def media_type(self) -&gt; str:\n        \"\"\"The media type of the image URL.\"\"\"\n\n    @property\n    def format(self) -&gt; str:\n        \"\"\"The format of the image URL.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ImageUrl.format","title":"<code>format</code>  <code>property</code>","text":"<p>The format of the image URL.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ImageUrl.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>The kind of the content.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ImageUrl.media_type","title":"<code>media_type</code>  <code>property</code>","text":"<p>The media type of the image URL.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ImageUrl.url","title":"<code>url</code>  <code>property</code>","text":"<p>The URL of the image.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ImageUrl.__init__","title":"<code>__init__(url, kind='image-url')</code>","text":"<p>Create an ImageUrl object.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the image.</p> required <code>kind</code> <code>Literal['image-url']</code> <p>The kind of the content.</p> <code>'image-url'</code> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(\n    self,\n    url: str,\n    kind: Literal[\"image-url\"] = \"image-url\",\n) -&gt; None:\n    \"\"\"Create an ImageUrl object.\n\n    Args:\n        url (str):\n            The URL of the image.\n        kind (Literal[\"image-url\"]):\n            The kind of the content.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.LogProbs","title":"<code>LogProbs</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class LogProbs:\n    @property\n    def tokens(self) -&gt; List[ResponseLogProbs]:\n        \"\"\"The log probabilities of the tokens in the response.\n        This is primarily used for debugging and analysis purposes.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the log probabilities.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.LogProbs.tokens","title":"<code>tokens</code>  <code>property</code>","text":"<p>The log probabilities of the tokens in the response. This is primarily used for debugging and analysis purposes.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.LogProbs.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the log probabilities.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the log probabilities.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpConfig","title":"<code>McpConfig</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class McpConfig:\n    @property\n    def transport(self) -&gt; McpTransport:\n        \"\"\"The transport method used by the MCP server.\"\"\"\n\n    @property\n    def capabilities(self) -&gt; List[McpCapability]:\n        \"\"\"The capabilities of the MCP server.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpConfig.capabilities","title":"<code>capabilities</code>  <code>property</code>","text":"<p>The capabilities of the MCP server.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpConfig.transport","title":"<code>transport</code>  <code>property</code>","text":"<p>The transport method used by the MCP server.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServer","title":"<code>McpServer</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class McpServer:\n    @property\n    def name(self) -&gt; str:\n        \"\"\"The name of the MCP server.\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"The space of the MCP server.\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"The version of the MCP server.\"\"\"\n\n    @property\n    def environment(self) -&gt; str:\n        \"\"\"The environment of the MCP server.\"\"\"\n\n    @property\n    def endpoints(self) -&gt; List[str]:\n        \"\"\"The endpoints of the MCP server.\"\"\"\n\n    @property\n    def config(self) -&gt; McpConfig:\n        \"\"\"The configuration of the MCP server.\"\"\"\n\n    @property\n    def description(self) -&gt; Optional[str]:\n        \"\"\"The description of the MCP server.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the MCP server.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServer.config","title":"<code>config</code>  <code>property</code>","text":"<p>The configuration of the MCP server.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServer.description","title":"<code>description</code>  <code>property</code>","text":"<p>The description of the MCP server.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServer.endpoints","title":"<code>endpoints</code>  <code>property</code>","text":"<p>The endpoints of the MCP server.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServer.environment","title":"<code>environment</code>  <code>property</code>","text":"<p>The environment of the MCP server.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServer.name","title":"<code>name</code>  <code>property</code>","text":"<p>The name of the MCP server.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServer.space","title":"<code>space</code>  <code>property</code>","text":"<p>The space of the MCP server.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServer.version","title":"<code>version</code>  <code>property</code>","text":"<p>The version of the MCP server.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServer.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the MCP server.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the MCP server.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServers","title":"<code>McpServers</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class McpServers:\n    def __getitem__(self, index: int) -&gt; McpServer:\n        \"\"\"Get the MCP server at the specified index.\"\"\"\n\n    def __iter__(self):\n        \"\"\"Iterator for the MCP servers.\"\"\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"Get the number of MCP servers.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServers.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Get the MCP server at the specified index.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __getitem__(self, index: int) -&gt; McpServer:\n    \"\"\"Get the MCP server at the specified index.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServers.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterator for the MCP servers.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __iter__(self):\n    \"\"\"Iterator for the MCP servers.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.McpServers.__len__","title":"<code>__len__()</code>","text":"<p>Get the number of MCP servers.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Get the number of MCP servers.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Message","title":"<code>Message</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class Message:\n    def __init__(self, content: str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl) -&gt; None:\n        \"\"\"Create a Message object.\n\n        Args:\n            content (str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl):\n                The content of the message.\n        \"\"\"\n\n    @property\n    def content(self) -&gt; str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl:\n        \"\"\"The content of the message\"\"\"\n\n    def bind(self, name: str, value: str) -&gt; \"Message\":\n        \"\"\"Bind context to a specific variable in the prompt. This is an immutable operation meaning that it\n        will return a new Message object with the context bound.\n\n            Example with Prompt that contains two messages\n\n            ```python\n                prompt = Prompt(\n                    model=\"openai:gpt-4o\",\n                    message=[\n                        \"My prompt variable is ${variable}\",\n                        \"This is another message\",\n                    ],\n                    system_instruction=\"system_prompt\",\n                )\n                bounded_prompt = prompt.message[0].bind(\"variable\", \"hello world\").unwrap() # we bind \"hello world\" to \"variable\"\n            ```\n\n        Args:\n            name (str):\n                The name of the variable to bind.\n            value (str):\n                The value to bind the variable to.\n\n        Returns:\n            Message:\n                The message with the context bound.\n        \"\"\"\n\n    def bind_mut(self, name: str, value: str) -&gt; \"Message\":\n        \"\"\"Bind context to a specific variable in the prompt. This is a mutable operation meaning that it\n        will modify the current Message object.\n\n            Example with Prompt that contains two messages\n\n            ```python\n                prompt = Prompt(\n                    model=\"openai:gpt-4o\",\n                    message=[\n                        \"My prompt variable is ${variable}\",\n                        \"This is another message\",\n                    ],\n                    system_instruction=\"system_prompt\",\n                )\n                prompt.message[0].bind_mut(\"variable\", \"hello world\") # we bind \"hello world\" to \"variable\"\n            ```\n\n        Args:\n            name (str):\n                The name of the variable to bind.\n            value (str):\n                The value to bind the variable to.\n\n        Returns:\n            Message:\n                The message with the context bound.\n        \"\"\"\n\n    def unwrap(self) -&gt; Any:\n        \"\"\"Unwrap the message content.\n\n        Returns:\n            A serializable representation of the message content, which can be a string, list, or dict.\n        \"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Unwrap the message content and serialize it to a dictionary.\n\n        Returns:\n            Dict[str, Any]:\n                The message dictionary with keys \"content\" and \"role\".\n        \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Message.content","title":"<code>content</code>  <code>property</code>","text":"<p>The content of the message</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Message.__init__","title":"<code>__init__(content)</code>","text":"<p>Create a Message object.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl</code> <p>The content of the message.</p> required Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(self, content: str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl) -&gt; None:\n    \"\"\"Create a Message object.\n\n    Args:\n        content (str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl):\n            The content of the message.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Message.bind","title":"<code>bind(name, value)</code>","text":"<p>Bind context to a specific variable in the prompt. This is an immutable operation meaning that it will return a new Message object with the context bound.</p> <pre><code>Example with Prompt that contains two messages\n\n```python\n    prompt = Prompt(\n        model=\"openai:gpt-4o\",\n        message=[\n            \"My prompt variable is ${variable}\",\n            \"This is another message\",\n        ],\n        system_instruction=\"system_prompt\",\n    )\n    bounded_prompt = prompt.message[0].bind(\"variable\", \"hello world\").unwrap() # we bind \"hello world\" to \"variable\"\n```\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable to bind.</p> required <code>value</code> <code>str</code> <p>The value to bind the variable to.</p> required <p>Returns:</p> Name Type Description <code>Message</code> <code>Message</code> <p>The message with the context bound.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def bind(self, name: str, value: str) -&gt; \"Message\":\n    \"\"\"Bind context to a specific variable in the prompt. This is an immutable operation meaning that it\n    will return a new Message object with the context bound.\n\n        Example with Prompt that contains two messages\n\n        ```python\n            prompt = Prompt(\n                model=\"openai:gpt-4o\",\n                message=[\n                    \"My prompt variable is ${variable}\",\n                    \"This is another message\",\n                ],\n                system_instruction=\"system_prompt\",\n            )\n            bounded_prompt = prompt.message[0].bind(\"variable\", \"hello world\").unwrap() # we bind \"hello world\" to \"variable\"\n        ```\n\n    Args:\n        name (str):\n            The name of the variable to bind.\n        value (str):\n            The value to bind the variable to.\n\n    Returns:\n        Message:\n            The message with the context bound.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Message.bind_mut","title":"<code>bind_mut(name, value)</code>","text":"<p>Bind context to a specific variable in the prompt. This is a mutable operation meaning that it will modify the current Message object.</p> <pre><code>Example with Prompt that contains two messages\n\n```python\n    prompt = Prompt(\n        model=\"openai:gpt-4o\",\n        message=[\n            \"My prompt variable is ${variable}\",\n            \"This is another message\",\n        ],\n        system_instruction=\"system_prompt\",\n    )\n    prompt.message[0].bind_mut(\"variable\", \"hello world\") # we bind \"hello world\" to \"variable\"\n```\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable to bind.</p> required <code>value</code> <code>str</code> <p>The value to bind the variable to.</p> required <p>Returns:</p> Name Type Description <code>Message</code> <code>Message</code> <p>The message with the context bound.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def bind_mut(self, name: str, value: str) -&gt; \"Message\":\n    \"\"\"Bind context to a specific variable in the prompt. This is a mutable operation meaning that it\n    will modify the current Message object.\n\n        Example with Prompt that contains two messages\n\n        ```python\n            prompt = Prompt(\n                model=\"openai:gpt-4o\",\n                message=[\n                    \"My prompt variable is ${variable}\",\n                    \"This is another message\",\n                ],\n                system_instruction=\"system_prompt\",\n            )\n            prompt.message[0].bind_mut(\"variable\", \"hello world\") # we bind \"hello world\" to \"variable\"\n        ```\n\n    Args:\n        name (str):\n            The name of the variable to bind.\n        value (str):\n            The value to bind the variable to.\n\n    Returns:\n        Message:\n            The message with the context bound.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Message.model_dump","title":"<code>model_dump()</code>","text":"<p>Unwrap the message content and serialize it to a dictionary.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: The message dictionary with keys \"content\" and \"role\".</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Unwrap the message content and serialize it to a dictionary.\n\n    Returns:\n        Dict[str, Any]:\n            The message dictionary with keys \"content\" and \"role\".\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Message.unwrap","title":"<code>unwrap()</code>","text":"<p>Unwrap the message content.</p> <p>Returns:</p> Type Description <code>Any</code> <p>A serializable representation of the message content, which can be a string, list, or dict.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def unwrap(self) -&gt; Any:\n    \"\"\"Unwrap the message content.\n\n    Returns:\n        A serializable representation of the message content, which can be a string, list, or dict.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ModelSettings","title":"<code>ModelSettings</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class ModelSettings:\n    def __init__(self, settings: OpenAIChatSettings | GeminiSettings) -&gt; None:\n        \"\"\"ModelSettings for configuring the model.\n\n        Args:\n            settings (OpenAIChatSettings | GeminiSettings):\n                The settings to use for the model. Currently supports OpenAI and Gemini settings.\n        \"\"\"\n\n    @property\n    def settings(self) -&gt; OpenAIChatSettings | GeminiSettings:\n        \"\"\"The settings to use for the model.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"The JSON representation of the model settings.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ModelSettings.settings","title":"<code>settings</code>  <code>property</code>","text":"<p>The settings to use for the model.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ModelSettings.__init__","title":"<code>__init__(settings)</code>","text":"<p>ModelSettings for configuring the model.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>OpenAIChatSettings | GeminiSettings</code> <p>The settings to use for the model. Currently supports OpenAI and Gemini settings.</p> required Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(self, settings: OpenAIChatSettings | GeminiSettings) -&gt; None:\n    \"\"\"ModelSettings for configuring the model.\n\n    Args:\n        settings (OpenAIChatSettings | GeminiSettings):\n            The settings to use for the model. Currently supports OpenAI and Gemini settings.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ModelSettings.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>The JSON representation of the model settings.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"The JSON representation of the model settings.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt","title":"<code>Prompt</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class Prompt:\n    def __init__(\n        self,\n        message: (\n            str\n            | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl]\n            | Message\n            | List[Message]\n            | List[Dict[str, Any]]\n        ),\n        model: str,\n        provider: Provider | str,\n        system_instruction: Optional[str | List[str]] = None,\n        model_settings: Optional[ModelSettings | GeminiSettings | OpenAIChatSettings] = None,\n        response_format: Optional[Any] = None,\n    ) -&gt; None:\n        \"\"\"Prompt for interacting with an LLM API.\n\n        Args:\n            message (str | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl] | Message | List[Message]):\n                The prompt to use.\n            model (str):\n                The model to use for the prompt\n            provider (Provider | str):\n                The provider to use for the prompt.\n            system_instruction (Optional[str | List[str]]):\n                The system prompt to use in the prompt.\n            model_settings (None):\n                The model settings to use for the prompt.\n                Defaults to None which means no model settings will be used\n            response_format (Optional[BaseModel | Score]):\n                The response format to use for the prompt. This is used for Structured Outputs\n                (https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat).\n                Currently, response_format only support Pydantic BaseModel classes and the PotatoHead Score class.\n                The provided response_format will be parsed into a JSON schema.\n\n        \"\"\"\n\n    @property\n    def model(self) -&gt; str:\n        \"\"\"The model to use for the prompt.\"\"\"\n\n    @property\n    def provider(self) -&gt; str:\n        \"\"\"The provider to use for the prompt.\"\"\"\n\n    @property\n    def model_identifier(self) -&gt; Any:\n        \"\"\"Concatenation of provider and model, used for identifying the model in the prompt. This\n        is commonly used with pydantic_ai to identify the model to use for the agent.\n\n        Example:\n            ```python\n                prompt = Prompt(\n                    model=\"gpt-4o\",\n                    message=\"My prompt variable is ${variable}\",\n                    system_instruction=\"system_instruction\",\n                    provider=\"openai\",\n                )\n                agent = Agent(\n                    prompt.model_identifier, # \"openai:gpt-4o\"\n                    system_instructions=prompt.system_instruction[0].unwrap(),\n                )\n            ```\n        \"\"\"\n\n    @property\n    def model_settings(self) -&gt; ModelSettings:\n        \"\"\"The model settings to use for the prompt.\"\"\"\n\n    @property\n    def message(\n        self,\n    ) -&gt; List[Message]:\n        \"\"\"The user message to use in the prompt.\"\"\"\n\n    @property\n    def system_instruction(self) -&gt; List[Message]:\n        \"\"\"The system message to use in the prompt.\"\"\"\n\n    def save_prompt(self, path: Optional[Path] = None) -&gt; None:\n        \"\"\"Save the prompt to a file.\n\n        Args:\n            path (Optional[Path]):\n                The path to save the prompt to. If None, the prompt will be saved to\n                the current working directory.\n        \"\"\"\n\n    @staticmethod\n    def from_path(path: Path) -&gt; \"Prompt\":\n        \"\"\"Load a prompt from a file.\n\n        Args:\n            path (Path):\n                The path to the prompt file.\n\n        Returns:\n            Prompt:\n                The loaded prompt.\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"Prompt\":\n        \"\"\"Validate the model JSON.\n\n        Args:\n            json_string (str):\n                The JSON string to validate.\n        Returns:\n            Prompt:\n                The prompt object.\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model to a JSON string.\n\n        Returns:\n            str:\n                The JSON string.\n        \"\"\"\n\n    def bind(\n        self,\n        name: Optional[str] = None,\n        value: Optional[str | int | float | bool | list] = None,\n        **kwargs: Any,\n    ) -&gt; \"Prompt\":\n        \"\"\"Bind context to a specific variable in the prompt. This is an immutable operation meaning that it\n        will return a new Prompt object with the context bound. This will iterate over all user messages.\n\n        Args:\n            name (str):\n                The name of the variable to bind.\n            value (str | int | float | bool | list):\n                The value to bind the variable to. Must be a JSON serializable type.\n            **kwargs (Any):\n                Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.\n\n        Returns:\n            Prompt:\n                The prompt with the context bound.\n        \"\"\"\n\n    def bind_mut(\n        self,\n        name: Optional[str] = None,\n        value: Optional[str | int | float | bool | list] = None,\n        **kwargs: Any,\n    ) -&gt; \"Prompt\":\n        \"\"\"Bind context to a specific variable in the prompt. This is a mutable operation meaning that it\n        will modify the current Prompt object. This will iterate over all user messages.\n\n        Args:\n            name (str):\n                The name of the variable to bind.\n            value (str | int | float | bool | list):\n                The value to bind the variable to. Must be a JSON serializable type.\n            **kwargs (Any):\n                Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.\n\n        Returns:\n            Prompt:\n                The prompt with the context bound.\n        \"\"\"\n\n    @property\n    def response_json_schema(self) -&gt; Optional[str]:\n        \"\"\"The JSON schema for the response if provided.\"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.message","title":"<code>message</code>  <code>property</code>","text":"<p>The user message to use in the prompt.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.model","title":"<code>model</code>  <code>property</code>","text":"<p>The model to use for the prompt.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.model_identifier","title":"<code>model_identifier</code>  <code>property</code>","text":"<p>Concatenation of provider and model, used for identifying the model in the prompt. This is commonly used with pydantic_ai to identify the model to use for the agent.</p> Example <pre><code>    prompt = Prompt(\n        model=\"gpt-4o\",\n        message=\"My prompt variable is ${variable}\",\n        system_instruction=\"system_instruction\",\n        provider=\"openai\",\n    )\n    agent = Agent(\n        prompt.model_identifier, # \"openai:gpt-4o\"\n        system_instructions=prompt.system_instruction[0].unwrap(),\n    )\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.model_settings","title":"<code>model_settings</code>  <code>property</code>","text":"<p>The model settings to use for the prompt.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.provider","title":"<code>provider</code>  <code>property</code>","text":"<p>The provider to use for the prompt.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.response_json_schema","title":"<code>response_json_schema</code>  <code>property</code>","text":"<p>The JSON schema for the response if provided.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.system_instruction","title":"<code>system_instruction</code>  <code>property</code>","text":"<p>The system message to use in the prompt.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.__init__","title":"<code>__init__(message, model, provider, system_instruction=None, model_settings=None, response_format=None)</code>","text":"<p>Prompt for interacting with an LLM API.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl] | Message | List[Message]</code> <p>The prompt to use.</p> required <code>model</code> <code>str</code> <p>The model to use for the prompt</p> required <code>provider</code> <code>Provider | str</code> <p>The provider to use for the prompt.</p> required <code>system_instruction</code> <code>Optional[str | List[str]]</code> <p>The system prompt to use in the prompt.</p> <code>None</code> <code>model_settings</code> <code>None</code> <p>The model settings to use for the prompt. Defaults to None which means no model settings will be used</p> <code>None</code> <code>response_format</code> <code>Optional[BaseModel | Score]</code> <p>The response format to use for the prompt. This is used for Structured Outputs (https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat). Currently, response_format only support Pydantic BaseModel classes and the PotatoHead Score class. The provided response_format will be parsed into a JSON schema.</p> <code>None</code> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(\n    self,\n    message: (\n        str\n        | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl]\n        | Message\n        | List[Message]\n        | List[Dict[str, Any]]\n    ),\n    model: str,\n    provider: Provider | str,\n    system_instruction: Optional[str | List[str]] = None,\n    model_settings: Optional[ModelSettings | GeminiSettings | OpenAIChatSettings] = None,\n    response_format: Optional[Any] = None,\n) -&gt; None:\n    \"\"\"Prompt for interacting with an LLM API.\n\n    Args:\n        message (str | Sequence[str | ImageUrl | AudioUrl | BinaryContent | DocumentUrl] | Message | List[Message]):\n            The prompt to use.\n        model (str):\n            The model to use for the prompt\n        provider (Provider | str):\n            The provider to use for the prompt.\n        system_instruction (Optional[str | List[str]]):\n            The system prompt to use in the prompt.\n        model_settings (None):\n            The model settings to use for the prompt.\n            Defaults to None which means no model settings will be used\n        response_format (Optional[BaseModel | Score]):\n            The response format to use for the prompt. This is used for Structured Outputs\n            (https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat).\n            Currently, response_format only support Pydantic BaseModel classes and the PotatoHead Score class.\n            The provided response_format will be parsed into a JSON schema.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.bind","title":"<code>bind(name=None, value=None, **kwargs)</code>","text":"<p>Bind context to a specific variable in the prompt. This is an immutable operation meaning that it will return a new Prompt object with the context bound. This will iterate over all user messages.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable to bind.</p> <code>None</code> <code>value</code> <code>str | int | float | bool | list</code> <p>The value to bind the variable to. Must be a JSON serializable type.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Prompt</code> <code>Prompt</code> <p>The prompt with the context bound.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def bind(\n    self,\n    name: Optional[str] = None,\n    value: Optional[str | int | float | bool | list] = None,\n    **kwargs: Any,\n) -&gt; \"Prompt\":\n    \"\"\"Bind context to a specific variable in the prompt. This is an immutable operation meaning that it\n    will return a new Prompt object with the context bound. This will iterate over all user messages.\n\n    Args:\n        name (str):\n            The name of the variable to bind.\n        value (str | int | float | bool | list):\n            The value to bind the variable to. Must be a JSON serializable type.\n        **kwargs (Any):\n            Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.\n\n    Returns:\n        Prompt:\n            The prompt with the context bound.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.bind_mut","title":"<code>bind_mut(name=None, value=None, **kwargs)</code>","text":"<p>Bind context to a specific variable in the prompt. This is a mutable operation meaning that it will modify the current Prompt object. This will iterate over all user messages.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable to bind.</p> <code>None</code> <code>value</code> <code>str | int | float | bool | list</code> <p>The value to bind the variable to. Must be a JSON serializable type.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Prompt</code> <code>Prompt</code> <p>The prompt with the context bound.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def bind_mut(\n    self,\n    name: Optional[str] = None,\n    value: Optional[str | int | float | bool | list] = None,\n    **kwargs: Any,\n) -&gt; \"Prompt\":\n    \"\"\"Bind context to a specific variable in the prompt. This is a mutable operation meaning that it\n    will modify the current Prompt object. This will iterate over all user messages.\n\n    Args:\n        name (str):\n            The name of the variable to bind.\n        value (str | int | float | bool | list):\n            The value to bind the variable to. Must be a JSON serializable type.\n        **kwargs (Any):\n            Additional keyword arguments to bind to the prompt. This can be used to bind multiple variables at once.\n\n    Returns:\n        Prompt:\n            The prompt with the context bound.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.from_path","title":"<code>from_path(path)</code>  <code>staticmethod</code>","text":"<p>Load a prompt from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to the prompt file.</p> required <p>Returns:</p> Name Type Description <code>Prompt</code> <code>Prompt</code> <p>The loaded prompt.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>@staticmethod\ndef from_path(path: Path) -&gt; \"Prompt\":\n    \"\"\"Load a prompt from a file.\n\n    Args:\n        path (Path):\n            The path to the prompt file.\n\n    Returns:\n        Prompt:\n            The loaded prompt.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the model to a JSON string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The JSON string.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the model to a JSON string.\n\n    Returns:\n        str:\n            The JSON string.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Validate the model JSON.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The JSON string to validate.</p> required <p>Returns:     Prompt:         The prompt object.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"Prompt\":\n    \"\"\"Validate the model JSON.\n\n    Args:\n        json_string (str):\n            The JSON string to validate.\n    Returns:\n        Prompt:\n            The prompt object.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Prompt.save_prompt","title":"<code>save_prompt(path=None)</code>","text":"<p>Save the prompt to a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>The path to save the prompt to. If None, the prompt will be saved to the current working directory.</p> <code>None</code> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def save_prompt(self, path: Optional[Path] = None) -&gt; None:\n    \"\"\"Save the prompt to a file.\n\n    Args:\n        path (Optional[Path]):\n            The path to save the prompt to. If None, the prompt will be saved to\n            the current working directory.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PromptTokenDetails","title":"<code>PromptTokenDetails</code>","text":"<p>Details about the prompt tokens used in a request.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class PromptTokenDetails:\n    \"\"\"Details about the prompt tokens used in a request.\"\"\"\n\n    @property\n    def audio_tokens(self) -&gt; int:\n        \"\"\"The number of audio tokens used in the request.\"\"\"\n\n    @property\n    def cached_tokens(self) -&gt; int:\n        \"\"\"The number of cached tokens used in the request.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PromptTokenDetails.audio_tokens","title":"<code>audio_tokens</code>  <code>property</code>","text":"<p>The number of audio tokens used in the request.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PromptTokenDetails.cached_tokens","title":"<code>cached_tokens</code>  <code>property</code>","text":"<p>The number of cached tokens used in the request.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PyTask","title":"<code>PyTask</code>","text":"<p>Python-specific task interface for Task objects and results</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class PyTask:\n    \"\"\"Python-specific task interface for Task objects and results\"\"\"\n\n    @property\n    def prompt(self) -&gt; Prompt:\n        \"\"\"The prompt to use for the task.\"\"\"\n\n    @property\n    def dependencies(self) -&gt; List[str]:\n        \"\"\"The dependencies of the task.\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the task.\"\"\"\n\n    @property\n    def agent_id(self) -&gt; str:\n        \"\"\"The ID of the agent that will execute the task.\"\"\"\n\n    @property\n    def status(self) -&gt; TaskStatus:\n        \"\"\"The status of the task.\"\"\"\n\n    @property\n    def result(self) -&gt; Optional[AgentResponse]:\n        \"\"\"The result of the task if it has been executed, otherwise None.\"\"\"\n\n    def __str__(self) -&gt; str: ...\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PyTask.agent_id","title":"<code>agent_id</code>  <code>property</code>","text":"<p>The ID of the agent that will execute the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PyTask.dependencies","title":"<code>dependencies</code>  <code>property</code>","text":"<p>The dependencies of the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PyTask.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PyTask.prompt","title":"<code>prompt</code>  <code>property</code>","text":"<p>The prompt to use for the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PyTask.result","title":"<code>result</code>  <code>property</code>","text":"<p>The result of the task if it has been executed, otherwise None.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.PyTask.status","title":"<code>status</code>  <code>property</code>","text":"<p>The status of the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ResponseLogProbs","title":"<code>ResponseLogProbs</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class ResponseLogProbs:\n    @property\n    def token(self) -&gt; str:\n        \"\"\"The token for which the log probabilities are calculated.\"\"\"\n\n    @property\n    def logprob(self) -&gt; float:\n        \"\"\"The log probability of the token.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ResponseLogProbs.logprob","title":"<code>logprob</code>  <code>property</code>","text":"<p>The log probability of the token.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.ResponseLogProbs.token","title":"<code>token</code>  <code>property</code>","text":"<p>The token for which the log probabilities are calculated.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Score","title":"<code>Score</code>","text":"<p>A class representing a score with a score value and a reason. This is typically used as a response type for tasks/prompts that require scoring or evaluation of results.</p> <p>Example: <pre><code>    Prompt(\n        model=\"openai:gpt-4o\",\n        message=\"What is the score of this response?\",\n        system_instruction=\"system_prompt\",\n        response_format=Score,\n    )\n</code></pre></p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class Score:\n    \"\"\"A class representing a score with a score value and a reason. This is typically used\n    as a response type for tasks/prompts that require scoring or evaluation of results.\n\n    Example:\n    ```python\n        Prompt(\n            model=\"openai:gpt-4o\",\n            message=\"What is the score of this response?\",\n            system_instruction=\"system_prompt\",\n            response_format=Score,\n        )\n    ```\n    \"\"\"\n\n    @property\n    def score(self) -&gt; int:\n        \"\"\"The score value.\"\"\"\n\n    @property\n    def reason(self) -&gt; str:\n        \"\"\"The reason for the score.\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"Score\":\n        \"\"\"Validate the score JSON.\n\n        Args:\n            json_string (str):\n                The JSON string to validate.\n\n        Returns:\n            Score:\n                The score object.\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Score.reason","title":"<code>reason</code>  <code>property</code>","text":"<p>The reason for the score.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Score.score","title":"<code>score</code>  <code>property</code>","text":"<p>The score value.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Score.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Validate the score JSON.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The JSON string to validate.</p> required <p>Returns:</p> Name Type Description <code>Score</code> <code>Score</code> <p>The score object.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"Score\":\n    \"\"\"Validate the score JSON.\n\n    Args:\n        json_string (str):\n            The JSON string to validate.\n\n    Returns:\n        Score:\n            The score object.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Task","title":"<code>Task</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class Task:\n    def __init__(\n        self,\n        agent_id: str,\n        prompt: Prompt,\n        dependencies: List[str] = [],\n        id: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Create a Task object.\n\n        Args:\n            agent_id (str):\n                The ID of the agent that will execute the task.\n            prompt (Prompt):\n                The prompt to use for the task.\n            dependencies (List[str]):\n                The dependencies of the task.\n            id (Optional[str]):\n                The ID of the task. If None, a random uuid7 will be generated.\n        \"\"\"\n\n    @property\n    def prompt(self) -&gt; Prompt:\n        \"\"\"The prompt to use for the task.\"\"\"\n\n    @property\n    def dependencies(self) -&gt; List[str]:\n        \"\"\"The dependencies of the task.\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the task.\"\"\"\n\n    @property\n    def status(self) -&gt; TaskStatus:\n        \"\"\"The status of the task.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Task.dependencies","title":"<code>dependencies</code>  <code>property</code>","text":"<p>The dependencies of the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Task.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Task.prompt","title":"<code>prompt</code>  <code>property</code>","text":"<p>The prompt to use for the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Task.status","title":"<code>status</code>  <code>property</code>","text":"<p>The status of the task.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Task.__init__","title":"<code>__init__(agent_id, prompt, dependencies=[], id=None)</code>","text":"<p>Create a Task object.</p> <p>Parameters:</p> Name Type Description Default <code>agent_id</code> <code>str</code> <p>The ID of the agent that will execute the task.</p> required <code>prompt</code> <code>Prompt</code> <p>The prompt to use for the task.</p> required <code>dependencies</code> <code>List[str]</code> <p>The dependencies of the task.</p> <code>[]</code> <code>id</code> <code>Optional[str]</code> <p>The ID of the task. If None, a random uuid7 will be generated.</p> <code>None</code> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(\n    self,\n    agent_id: str,\n    prompt: Prompt,\n    dependencies: List[str] = [],\n    id: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Create a Task object.\n\n    Args:\n        agent_id (str):\n            The ID of the agent that will execute the task.\n        prompt (Prompt):\n            The prompt to use for the task.\n        dependencies (List[str]):\n            The dependencies of the task.\n        id (Optional[str]):\n            The ID of the task. If None, a random uuid7 will be generated.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskEvent","title":"<code>TaskEvent</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class TaskEvent:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The ID of the event\"\"\"\n\n    @property\n    def workflow_id(self) -&gt; str:\n        \"\"\"The ID of the workflow that the task is part of.\"\"\"\n\n    @property\n    def task_id(self) -&gt; str:\n        \"\"\"The ID of the task that the event is associated with.\"\"\"\n\n    @property\n    def status(self) -&gt; TaskStatus:\n        \"\"\"The status of the task at the time of the event.\"\"\"\n\n    @property\n    def timestamp(self) -&gt; datetime.datetime:\n        \"\"\"The timestamp of the event. This is the time when the event occurred.\"\"\"\n\n    @property\n    def updated_at(self) -&gt; datetime.datetime:\n        \"\"\"The timestamp of when the event was last updated. This is useful for tracking changes to the event.\"\"\"\n\n    @property\n    def details(self) -&gt; EventDetails:\n        \"\"\"Additional details about the event. This can include information such as error messages or other relevant data.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskEvent.details","title":"<code>details</code>  <code>property</code>","text":"<p>Additional details about the event. This can include information such as error messages or other relevant data.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskEvent.id","title":"<code>id</code>  <code>property</code>","text":"<p>The ID of the event</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskEvent.status","title":"<code>status</code>  <code>property</code>","text":"<p>The status of the task at the time of the event.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskEvent.task_id","title":"<code>task_id</code>  <code>property</code>","text":"<p>The ID of the task that the event is associated with.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskEvent.timestamp","title":"<code>timestamp</code>  <code>property</code>","text":"<p>The timestamp of the event. This is the time when the event occurred.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskEvent.updated_at","title":"<code>updated_at</code>  <code>property</code>","text":"<p>The timestamp of when the event was last updated. This is useful for tracking changes to the event.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskEvent.workflow_id","title":"<code>workflow_id</code>  <code>property</code>","text":"<p>The ID of the workflow that the task is part of.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskList","title":"<code>TaskList</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class TaskList:\n    def __init__(self) -&gt; None:\n        \"\"\"Create a TaskList object.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.TaskList.__init__","title":"<code>__init__()</code>","text":"<p>Create a TaskList object.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Create a TaskList object.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Usage","title":"<code>Usage</code>","text":"<p>Usage statistics for a model response.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class Usage:\n    \"\"\"Usage statistics for a model response.\"\"\"\n\n    @property\n    def completion_tokens(self) -&gt; int:\n        \"\"\"The number of completion tokens used in the response.\"\"\"\n\n    @property\n    def prompt_tokens(self) -&gt; int:\n        \"\"\"The number of prompt tokens used in the request.\"\"\"\n\n    @property\n    def total_tokens(self) -&gt; int:\n        \"\"\"The total number of tokens used in the request and response.\"\"\"\n\n    @property\n    def completion_tokens_details(self) -&gt; CompletionTokenDetails:\n        \"\"\"Details about the completion tokens used in the response.\"\"\"\n\n    @property\n    def prompt_tokens_details(self) -&gt; \"PromptTokenDetails\":\n        \"\"\"Details about the prompt tokens used in the request.\"\"\"\n\n    @property\n    def finish_reason(self) -&gt; str:\n        \"\"\"The reason why the model stopped generating tokens\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Usage.completion_tokens","title":"<code>completion_tokens</code>  <code>property</code>","text":"<p>The number of completion tokens used in the response.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Usage.completion_tokens_details","title":"<code>completion_tokens_details</code>  <code>property</code>","text":"<p>Details about the completion tokens used in the response.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Usage.finish_reason","title":"<code>finish_reason</code>  <code>property</code>","text":"<p>The reason why the model stopped generating tokens</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Usage.prompt_tokens","title":"<code>prompt_tokens</code>  <code>property</code>","text":"<p>The number of prompt tokens used in the request.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Usage.prompt_tokens_details","title":"<code>prompt_tokens_details</code>  <code>property</code>","text":"<p>Details about the prompt tokens used in the request.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Usage.total_tokens","title":"<code>total_tokens</code>  <code>property</code>","text":"<p>The total number of tokens used in the request and response.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow","title":"<code>Workflow</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class Workflow:\n    def __init__(self, name: str) -&gt; None:\n        \"\"\"Create a Workflow object.\n\n        Args:\n            name (str):\n                The name of the workflow.\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"The name of the workflow.\"\"\"\n\n    @property\n    def task_list(self) -&gt; TaskList:\n        \"\"\"The tasks in the workflow.\"\"\"\n\n    @property\n    def agents(self) -&gt; Dict[str, Agent]:\n        \"\"\"The agents in the workflow.\"\"\"\n\n    @property\n    def is_workflow(self) -&gt; bool:\n        \"\"\"Returns True if the workflow is a valid workflow, otherwise False.\n        This is used to determine if the workflow can be executed.\n        \"\"\"\n\n    def __workflow__(self) -&gt; str:\n        \"\"\"Returns a string representation of the workflow.\"\"\"\n\n    def add_task_output_types(self, task_output_types: Dict[str, Any]) -&gt; None:\n        \"\"\"Add output types for tasks in the workflow. This is primarily used for\n        when loading a workflow as python objects are not serializable.\n\n        Args:\n            task_output_types (Dict[str, Any]):\n                A dictionary mapping task IDs to their output types.\n                This can either be a Pydantic `BaseModel` class or a supported potato_head response type such as `Score`.\n        \"\"\"\n\n    def add_task(self, task: Task, output_type: Optional[Any]) -&gt; None:\n        \"\"\"Add a task to the workflow.\n\n        Args:\n            task (Task):\n                The task to add to the workflow.\n            output_type (Optional[Any]):\n                The output type to use for the task. This can either be a Pydantic `BaseModel` class\n                or a supported potato_head response type such as `Score`.\n        \"\"\"\n\n    def add_tasks(self, tasks: List[Task]) -&gt; None:\n        \"\"\"Add multiple tasks to the workflow.\n\n        Args:\n            tasks (List[Task]):\n                The tasks to add to the workflow.\n        \"\"\"\n\n    def add_agent(self, agent: Agent) -&gt; None:\n        \"\"\"Add an agent to the workflow.\n\n        Args:\n            agent (Agent):\n                The agent to add to the workflow.\n        \"\"\"\n\n    def is_complete(self) -&gt; bool:\n        \"\"\"Check if the workflow is complete.\n\n        Returns:\n            bool:\n                True if the workflow is complete, False otherwise.\n        \"\"\"\n\n    def pending_count(self) -&gt; int:\n        \"\"\"Get the number of pending tasks in the workflow.\n\n        Returns:\n            int:\n                The number of pending tasks in the workflow.\n        \"\"\"\n\n    def execution_plan(self) -&gt; Dict[str, List[str]]:\n        \"\"\"Get the execution plan for the workflow.\n\n        Returns:\n            Dict[str, List[str]]:\n                A dictionary where the keys are task IDs and the values are lists of task IDs\n                that the task depends on.\n        \"\"\"\n\n    def run(\n        self,\n        global_context: Optional[Dict[str, Any]] = None,\n    ) -&gt; \"WorkflowResult\":\n        \"\"\"Run the workflow. This will execute all tasks in the workflow and return when all tasks are complete.\n\n        Args:\n            global_context (Optional[Dict[str, Any]]):\n                A dictionary of global context to bind to the workflow.\n                All tasks in the workflow will have this context bound to them.\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the workflow to a JSON string.\n\n        Returns:\n            str:\n                The JSON string.\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str, output_types: Optional[Dict[str, Any]]) -&gt; \"Workflow\":\n        \"\"\"Load a workflow from a JSON string.\n\n        Args:\n            json_string (str):\n                The JSON string to validate.\n            output_types (Optional[Dict[str, Any]]):\n                A dictionary mapping task IDs to their output types.\n                This can either be a Pydantic `BaseModel` class or a supported potato_head response type such as `Score`.\n\n        Returns:\n            Workflow:\n                The workflow object.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.agents","title":"<code>agents</code>  <code>property</code>","text":"<p>The agents in the workflow.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.is_workflow","title":"<code>is_workflow</code>  <code>property</code>","text":"<p>Returns True if the workflow is a valid workflow, otherwise False. This is used to determine if the workflow can be executed.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.name","title":"<code>name</code>  <code>property</code>","text":"<p>The name of the workflow.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.task_list","title":"<code>task_list</code>  <code>property</code>","text":"<p>The tasks in the workflow.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.__init__","title":"<code>__init__(name)</code>","text":"<p>Create a Workflow object.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the workflow.</p> required Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __init__(self, name: str) -&gt; None:\n    \"\"\"Create a Workflow object.\n\n    Args:\n        name (str):\n            The name of the workflow.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.__workflow__","title":"<code>__workflow__()</code>","text":"<p>Returns a string representation of the workflow.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def __workflow__(self) -&gt; str:\n    \"\"\"Returns a string representation of the workflow.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.add_agent","title":"<code>add_agent(agent)</code>","text":"<p>Add an agent to the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>Agent</code> <p>The agent to add to the workflow.</p> required Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def add_agent(self, agent: Agent) -&gt; None:\n    \"\"\"Add an agent to the workflow.\n\n    Args:\n        agent (Agent):\n            The agent to add to the workflow.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.add_task","title":"<code>add_task(task, output_type)</code>","text":"<p>Add a task to the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>The task to add to the workflow.</p> required <code>output_type</code> <code>Optional[Any]</code> <p>The output type to use for the task. This can either be a Pydantic <code>BaseModel</code> class or a supported potato_head response type such as <code>Score</code>.</p> required Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def add_task(self, task: Task, output_type: Optional[Any]) -&gt; None:\n    \"\"\"Add a task to the workflow.\n\n    Args:\n        task (Task):\n            The task to add to the workflow.\n        output_type (Optional[Any]):\n            The output type to use for the task. This can either be a Pydantic `BaseModel` class\n            or a supported potato_head response type such as `Score`.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.add_task_output_types","title":"<code>add_task_output_types(task_output_types)</code>","text":"<p>Add output types for tasks in the workflow. This is primarily used for when loading a workflow as python objects are not serializable.</p> <p>Parameters:</p> Name Type Description Default <code>task_output_types</code> <code>Dict[str, Any]</code> <p>A dictionary mapping task IDs to their output types. This can either be a Pydantic <code>BaseModel</code> class or a supported potato_head response type such as <code>Score</code>.</p> required Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def add_task_output_types(self, task_output_types: Dict[str, Any]) -&gt; None:\n    \"\"\"Add output types for tasks in the workflow. This is primarily used for\n    when loading a workflow as python objects are not serializable.\n\n    Args:\n        task_output_types (Dict[str, Any]):\n            A dictionary mapping task IDs to their output types.\n            This can either be a Pydantic `BaseModel` class or a supported potato_head response type such as `Score`.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.add_tasks","title":"<code>add_tasks(tasks)</code>","text":"<p>Add multiple tasks to the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[Task]</code> <p>The tasks to add to the workflow.</p> required Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def add_tasks(self, tasks: List[Task]) -&gt; None:\n    \"\"\"Add multiple tasks to the workflow.\n\n    Args:\n        tasks (List[Task]):\n            The tasks to add to the workflow.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.execution_plan","title":"<code>execution_plan()</code>","text":"<p>Get the execution plan for the workflow.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dict[str, List[str]]: A dictionary where the keys are task IDs and the values are lists of task IDs that the task depends on.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def execution_plan(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Get the execution plan for the workflow.\n\n    Returns:\n        Dict[str, List[str]]:\n            A dictionary where the keys are task IDs and the values are lists of task IDs\n            that the task depends on.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.is_complete","title":"<code>is_complete()</code>","text":"<p>Check if the workflow is complete.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the workflow is complete, False otherwise.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def is_complete(self) -&gt; bool:\n    \"\"\"Check if the workflow is complete.\n\n    Returns:\n        bool:\n            True if the workflow is complete, False otherwise.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the workflow to a JSON string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The JSON string.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the workflow to a JSON string.\n\n    Returns:\n        str:\n            The JSON string.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.model_validate_json","title":"<code>model_validate_json(json_string, output_types)</code>  <code>staticmethod</code>","text":"<p>Load a workflow from a JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>The JSON string to validate.</p> required <code>output_types</code> <code>Optional[Dict[str, Any]]</code> <p>A dictionary mapping task IDs to their output types. This can either be a Pydantic <code>BaseModel</code> class or a supported potato_head response type such as <code>Score</code>.</p> required <p>Returns:</p> Name Type Description <code>Workflow</code> <code>Workflow</code> <p>The workflow object.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str, output_types: Optional[Dict[str, Any]]) -&gt; \"Workflow\":\n    \"\"\"Load a workflow from a JSON string.\n\n    Args:\n        json_string (str):\n            The JSON string to validate.\n        output_types (Optional[Dict[str, Any]]):\n            A dictionary mapping task IDs to their output types.\n            This can either be a Pydantic `BaseModel` class or a supported potato_head response type such as `Score`.\n\n    Returns:\n        Workflow:\n            The workflow object.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.pending_count","title":"<code>pending_count()</code>","text":"<p>Get the number of pending tasks in the workflow.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of pending tasks in the workflow.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def pending_count(self) -&gt; int:\n    \"\"\"Get the number of pending tasks in the workflow.\n\n    Returns:\n        int:\n            The number of pending tasks in the workflow.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.Workflow.run","title":"<code>run(global_context=None)</code>","text":"<p>Run the workflow. This will execute all tasks in the workflow and return when all tasks are complete.</p> <p>Parameters:</p> Name Type Description Default <code>global_context</code> <code>Optional[Dict[str, Any]]</code> <p>A dictionary of global context to bind to the workflow. All tasks in the workflow will have this context bound to them.</p> <code>None</code> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def run(\n    self,\n    global_context: Optional[Dict[str, Any]] = None,\n) -&gt; \"WorkflowResult\":\n    \"\"\"Run the workflow. This will execute all tasks in the workflow and return when all tasks are complete.\n\n    Args:\n        global_context (Optional[Dict[str, Any]]):\n            A dictionary of global context to bind to the workflow.\n            All tasks in the workflow will have this context bound to them.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.WorkflowResult","title":"<code>WorkflowResult</code>","text":"Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>class WorkflowResult:\n    @property\n    def tasks(self) -&gt; Dict[str, PyTask]:\n        \"\"\"The tasks in the workflow result.\"\"\"\n\n    @property\n    def events(self) -&gt; List[TaskEvent]:\n        \"\"\"The events that occurred during the workflow execution. This is a list of dictionaries\n        where each dictionary contains information about the event such as the task ID, status, and timestamp.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.WorkflowResult.events","title":"<code>events</code>  <code>property</code>","text":"<p>The events that occurred during the workflow execution. This is a list of dictionaries where each dictionary contains information about the event such as the task ID, status, and timestamp.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.WorkflowResult.tasks","title":"<code>tasks</code>  <code>property</code>","text":"<p>The tasks in the workflow result.</p>"},{"location":"docs/api/genai/genai/#opsml.genai._genai.list_mcp_servers","title":"<code>list_mcp_servers(space=None, name=None, tags=None)</code>","text":"<p>List all available MCP servers.</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>Optional[str]</code> <p>The space to filter the MCP servers by.</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>The name to filter the MCP servers by.</p> <code>None</code> <code>tags</code> <code>Optional[List[str]]</code> <p>The tags to filter the MCP servers by.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>McpServers</code> <code>McpServers</code> <p>A list of MCP servers.</p> Source code in <code>python/opsml/genai/_genai.pyi</code> <pre><code>def list_mcp_servers(\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    tags: Optional[List[str]] = None,\n) -&gt; McpServers:\n    \"\"\"List all available MCP servers.\n\n    Args:\n        space (Optional[str]):\n            The space to filter the MCP servers by.\n        name (Optional[str]):\n            The name to filter the MCP servers by.\n        tags (Optional[List[str]]):\n            The tags to filter the MCP servers by.\n\n    Returns:\n        McpServers:\n            A list of MCP servers.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/","title":"Google","text":""},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.GeminiSettings","title":"<code>GeminiSettings</code>","text":"Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class GeminiSettings:\n    def __init__(\n        self,\n        labels: Optional[dict[str, str]] = None,\n        tool_config: Optional[ToolConfig] = None,\n        generation_config: Optional[GenerationConfig] = None,\n        safety_settings: Optional[list[SafetySetting]] = None,\n        model_armor_config: Optional[ModelArmorConfig] = None,\n        extra_body: Optional[dict] = None,\n    ) -&gt; None:\n        \"\"\"Settings to pass to the Gemini API when creating a request\n\n        Reference:\n            https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/generateContent\n\n        Args:\n            labels (Optional[dict[str, str]]):\n                An optional dictionary of labels for the settings.\n            tool_config (Optional[ToolConfig]):\n                Configuration for tools like function calling and retrieval.\n            generation_config (Optional[GenerationConfig]):\n                Configuration for content generation parameters.\n            safety_settings (Optional[list[SafetySetting]]):\n                List of safety settings to apply.\n            model_armor_config (Optional[ModelArmorConfig]):\n                Configuration for model armor templates.\n            extra_body (Optional[dict]):\n                Additional configuration as a dictionary.\n        \"\"\"\n\n    @property\n    def labels(self) -&gt; Optional[dict[str, str]]: ...\n    @property\n    def tool_config(self) -&gt; Optional[ToolConfig]: ...\n    @property\n    def generation_config(self) -&gt; Optional[GenerationConfig]: ...\n    @property\n    def safety_settings(self) -&gt; Optional[list[SafetySetting]]: ...\n    @property\n    def model_armor_config(self) -&gt; Optional[ModelArmorConfig]: ...\n    @property\n    def extra_body(self) -&gt; Optional[dict]: ...\n    def __str__(self) -&gt; str: ...\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.GeminiSettings.__init__","title":"<code>__init__(labels=None, tool_config=None, generation_config=None, safety_settings=None, model_armor_config=None, extra_body=None)</code>","text":"<p>Settings to pass to the Gemini API when creating a request</p> Reference <p>https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/generateContent</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Optional[dict[str, str]]</code> <p>An optional dictionary of labels for the settings.</p> <code>None</code> <code>tool_config</code> <code>Optional[ToolConfig]</code> <p>Configuration for tools like function calling and retrieval.</p> <code>None</code> <code>generation_config</code> <code>Optional[GenerationConfig]</code> <p>Configuration for content generation parameters.</p> <code>None</code> <code>safety_settings</code> <code>Optional[list[SafetySetting]]</code> <p>List of safety settings to apply.</p> <code>None</code> <code>model_armor_config</code> <code>Optional[ModelArmorConfig]</code> <p>Configuration for model armor templates.</p> <code>None</code> <code>extra_body</code> <code>Optional[dict]</code> <p>Additional configuration as a dictionary.</p> <code>None</code> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>def __init__(\n    self,\n    labels: Optional[dict[str, str]] = None,\n    tool_config: Optional[ToolConfig] = None,\n    generation_config: Optional[GenerationConfig] = None,\n    safety_settings: Optional[list[SafetySetting]] = None,\n    model_armor_config: Optional[ModelArmorConfig] = None,\n    extra_body: Optional[dict] = None,\n) -&gt; None:\n    \"\"\"Settings to pass to the Gemini API when creating a request\n\n    Reference:\n        https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/generateContent\n\n    Args:\n        labels (Optional[dict[str, str]]):\n            An optional dictionary of labels for the settings.\n        tool_config (Optional[ToolConfig]):\n            Configuration for tools like function calling and retrieval.\n        generation_config (Optional[GenerationConfig]):\n            Configuration for content generation parameters.\n        safety_settings (Optional[list[SafetySetting]]):\n            List of safety settings to apply.\n        model_armor_config (Optional[ModelArmorConfig]):\n            Configuration for model armor templates.\n        extra_body (Optional[dict]):\n            Additional configuration as a dictionary.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.GenerationConfig","title":"<code>GenerationConfig</code>","text":"<p>Configuration for content generation with comprehensive parameter control.</p> <p>This class provides fine-grained control over the generation process including sampling parameters, output format, modalities, and various specialized features.</p> <p>Examples:</p> <p>Basic usage with temperature control:</p> <pre><code>GenerationConfig(temperature=0.7, max_output_tokens=1000)\n</code></pre> <p>Multi-modal configuration: <pre><code>config = GenerationConfig(\n    response_modalities=[Modality.TEXT, Modality.AUDIO],\n    speech_config=SpeechConfig(language_code=\"en-US\")\n)\n</code></pre></p> <p>Advanced sampling with penalties: <pre><code>config = GenerationConfig(\n    temperature=0.8,\n    top_p=0.9,\n    top_k=40,\n    presence_penalty=0.1,\n    frequency_penalty=0.2\n)\n</code></pre></p> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class GenerationConfig:\n    \"\"\"Configuration for content generation with comprehensive parameter control.\n\n    This class provides fine-grained control over the generation process including\n    sampling parameters, output format, modalities, and various specialized features.\n\n    Examples:\n        Basic usage with temperature control:\n\n        ```python\n        GenerationConfig(temperature=0.7, max_output_tokens=1000)\n        ```\n\n        Multi-modal configuration:\n        ```python\n        config = GenerationConfig(\n            response_modalities=[Modality.TEXT, Modality.AUDIO],\n            speech_config=SpeechConfig(language_code=\"en-US\")\n        )\n        ```\n\n        Advanced sampling with penalties:\n        ```python\n        config = GenerationConfig(\n            temperature=0.8,\n            top_p=0.9,\n            top_k=40,\n            presence_penalty=0.1,\n            frequency_penalty=0.2\n        )\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        stop_sequences: Optional[List[str]] = None,\n        response_mime_type: Optional[str] = None,\n        response_modalities: Optional[List[Modality]] = None,\n        thinking_config: Optional[ThinkingConfig] = None,\n        temperature: Optional[float] = None,\n        top_p: Optional[float] = None,\n        top_k: Optional[int] = None,\n        candidate_count: Optional[int] = None,\n        max_output_tokens: Optional[int] = None,\n        response_logprobs: Optional[bool] = None,\n        logprobs: Optional[int] = None,\n        presence_penalty: Optional[float] = None,\n        frequency_penalty: Optional[float] = None,\n        seed: Optional[int] = None,\n        audio_timestamp: Optional[bool] = None,\n        media_resolution: Optional[MediaResolution] = None,\n        speech_config: Optional[SpeechConfig] = None,\n        enable_affective_dialog: Optional[bool] = None,\n    ) -&gt; None:\n        \"\"\"Initialize GenerationConfig with optional parameters.\n\n        Args:\n            stop_sequences (Optional[List[str]]):\n                List of strings that will stop generation when encountered\n            response_mime_type (Optional[str]):\n                MIME type for the response format\n            response_modalities (Optional[List[Modality]]):\n                List of modalities to include in the response\n            thinking_config (Optional[ThinkingConfig]):\n                Configuration for reasoning/thinking capabilities\n            temperature (Optional[float]):\n                Controls randomness in generation (0.0-1.0)\n            top_p (Optional[float]):\n                Nucleus sampling parameter (0.0-1.0)\n            top_k (Optional[int]):\n                Top-k sampling parameter\n            candidate_count (Optional[int]):\n                Number of response candidates to generate\n            max_output_tokens (Optional[int]):\n                Maximum number of tokens to generate\n            response_logprobs (Optional[bool]):\n                Whether to return log probabilities\n            logprobs (Optional[int]):\n                Number of log probabilities to return per token\n            presence_penalty (Optional[float]):\n                Penalty for token presence (-2.0 to 2.0)\n            frequency_penalty (Optional[float]):\n                Penalty for token frequency (-2.0 to 2.0)\n            seed (Optional[int]):\n                Random seed for deterministic generation\n            audio_timestamp (Optional[bool]):\n                Whether to include timestamps in audio responses\n            media_resolution (Optional[MediaResolution]):\n                Resolution setting for media content\n            speech_config (Optional[SpeechConfig]):\n                Configuration for speech synthesis\n            enable_affective_dialog (Optional[bool]):\n                Whether to enable emotional dialog features\n        \"\"\"\n\n    def __str__(self) -&gt; str: ...\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.GenerationConfig.__init__","title":"<code>__init__(stop_sequences=None, response_mime_type=None, response_modalities=None, thinking_config=None, temperature=None, top_p=None, top_k=None, candidate_count=None, max_output_tokens=None, response_logprobs=None, logprobs=None, presence_penalty=None, frequency_penalty=None, seed=None, audio_timestamp=None, media_resolution=None, speech_config=None, enable_affective_dialog=None)</code>","text":"<p>Initialize GenerationConfig with optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>stop_sequences</code> <code>Optional[List[str]]</code> <p>List of strings that will stop generation when encountered</p> <code>None</code> <code>response_mime_type</code> <code>Optional[str]</code> <p>MIME type for the response format</p> <code>None</code> <code>response_modalities</code> <code>Optional[List[Modality]]</code> <p>List of modalities to include in the response</p> <code>None</code> <code>thinking_config</code> <code>Optional[ThinkingConfig]</code> <p>Configuration for reasoning/thinking capabilities</p> <code>None</code> <code>temperature</code> <code>Optional[float]</code> <p>Controls randomness in generation (0.0-1.0)</p> <code>None</code> <code>top_p</code> <code>Optional[float]</code> <p>Nucleus sampling parameter (0.0-1.0)</p> <code>None</code> <code>top_k</code> <code>Optional[int]</code> <p>Top-k sampling parameter</p> <code>None</code> <code>candidate_count</code> <code>Optional[int]</code> <p>Number of response candidates to generate</p> <code>None</code> <code>max_output_tokens</code> <code>Optional[int]</code> <p>Maximum number of tokens to generate</p> <code>None</code> <code>response_logprobs</code> <code>Optional[bool]</code> <p>Whether to return log probabilities</p> <code>None</code> <code>logprobs</code> <code>Optional[int]</code> <p>Number of log probabilities to return per token</p> <code>None</code> <code>presence_penalty</code> <code>Optional[float]</code> <p>Penalty for token presence (-2.0 to 2.0)</p> <code>None</code> <code>frequency_penalty</code> <code>Optional[float]</code> <p>Penalty for token frequency (-2.0 to 2.0)</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>Random seed for deterministic generation</p> <code>None</code> <code>audio_timestamp</code> <code>Optional[bool]</code> <p>Whether to include timestamps in audio responses</p> <code>None</code> <code>media_resolution</code> <code>Optional[MediaResolution]</code> <p>Resolution setting for media content</p> <code>None</code> <code>speech_config</code> <code>Optional[SpeechConfig]</code> <p>Configuration for speech synthesis</p> <code>None</code> <code>enable_affective_dialog</code> <code>Optional[bool]</code> <p>Whether to enable emotional dialog features</p> <code>None</code> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>def __init__(\n    self,\n    stop_sequences: Optional[List[str]] = None,\n    response_mime_type: Optional[str] = None,\n    response_modalities: Optional[List[Modality]] = None,\n    thinking_config: Optional[ThinkingConfig] = None,\n    temperature: Optional[float] = None,\n    top_p: Optional[float] = None,\n    top_k: Optional[int] = None,\n    candidate_count: Optional[int] = None,\n    max_output_tokens: Optional[int] = None,\n    response_logprobs: Optional[bool] = None,\n    logprobs: Optional[int] = None,\n    presence_penalty: Optional[float] = None,\n    frequency_penalty: Optional[float] = None,\n    seed: Optional[int] = None,\n    audio_timestamp: Optional[bool] = None,\n    media_resolution: Optional[MediaResolution] = None,\n    speech_config: Optional[SpeechConfig] = None,\n    enable_affective_dialog: Optional[bool] = None,\n) -&gt; None:\n    \"\"\"Initialize GenerationConfig with optional parameters.\n\n    Args:\n        stop_sequences (Optional[List[str]]):\n            List of strings that will stop generation when encountered\n        response_mime_type (Optional[str]):\n            MIME type for the response format\n        response_modalities (Optional[List[Modality]]):\n            List of modalities to include in the response\n        thinking_config (Optional[ThinkingConfig]):\n            Configuration for reasoning/thinking capabilities\n        temperature (Optional[float]):\n            Controls randomness in generation (0.0-1.0)\n        top_p (Optional[float]):\n            Nucleus sampling parameter (0.0-1.0)\n        top_k (Optional[int]):\n            Top-k sampling parameter\n        candidate_count (Optional[int]):\n            Number of response candidates to generate\n        max_output_tokens (Optional[int]):\n            Maximum number of tokens to generate\n        response_logprobs (Optional[bool]):\n            Whether to return log probabilities\n        logprobs (Optional[int]):\n            Number of log probabilities to return per token\n        presence_penalty (Optional[float]):\n            Penalty for token presence (-2.0 to 2.0)\n        frequency_penalty (Optional[float]):\n            Penalty for token frequency (-2.0 to 2.0)\n        seed (Optional[int]):\n            Random seed for deterministic generation\n        audio_timestamp (Optional[bool]):\n            Whether to include timestamps in audio responses\n        media_resolution (Optional[MediaResolution]):\n            Resolution setting for media content\n        speech_config (Optional[SpeechConfig]):\n            Configuration for speech synthesis\n        enable_affective_dialog (Optional[bool]):\n            Whether to enable emotional dialog features\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.LatLng","title":"<code>LatLng</code>","text":"Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class LatLng:\n    @property\n    def latitude(self) -&gt; float: ...\n    @property\n    def longitude(self) -&gt; float: ...\n    def __init__(self, latitude: float, longitude: float) -&gt; None:\n        \"\"\"Initialize LatLng with latitude and longitude.\n\n        Args:\n            latitude (float):\n                The latitude value.\n            longitude (float):\n                The longitude value.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.LatLng.__init__","title":"<code>__init__(latitude, longitude)</code>","text":"<p>Initialize LatLng with latitude and longitude.</p> <p>Parameters:</p> Name Type Description Default <code>latitude</code> <code>float</code> <p>The latitude value.</p> required <code>longitude</code> <code>float</code> <p>The longitude value.</p> required Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>def __init__(self, latitude: float, longitude: float) -&gt; None:\n    \"\"\"Initialize LatLng with latitude and longitude.\n\n    Args:\n        latitude (float):\n            The latitude value.\n        longitude (float):\n            The longitude value.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.MediaResolution","title":"<code>MediaResolution</code>","text":"<p>Media resolution settings for content generation.</p> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class MediaResolution:\n    \"\"\"Media resolution settings for content generation.\"\"\"\n\n    MediaResolutionUnspecified: \"MediaResolution\"\n    MediaResolutionLow: \"MediaResolution\"\n    MediaResolutionMedium: \"MediaResolution\"\n    MediaResolutionHigh: \"MediaResolution\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.Modality","title":"<code>Modality</code>","text":"<p>Represents different modalities for content generation.</p> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class Modality:\n    \"\"\"Represents different modalities for content generation.\"\"\"\n\n    ModalityUnspecified: \"Modality\"\n    Text: \"Modality\"\n    Image: \"Modality\"\n    Audio: \"Modality\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.ModelArmorConfig","title":"<code>ModelArmorConfig</code>","text":"Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class ModelArmorConfig:\n    def __init__(\n        self,\n        prompt_template_name: Optional[str],\n        response_template_name: Optional[str],\n    ) -&gt; None:\n        \"\"\"\n        Args:\n            prompt_template_name (Optional[str]):\n                The name of the prompt template to use.\n            response_template_name (Optional[str]):\n                The name of the response template to use.\n        \"\"\"\n\n    @property\n    def prompt_template_name(self) -&gt; Optional[str]: ...\n    @property\n    def response_template_name(self) -&gt; Optional[str]: ...\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.ModelArmorConfig.__init__","title":"<code>__init__(prompt_template_name, response_template_name)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>prompt_template_name</code> <code>Optional[str]</code> <p>The name of the prompt template to use.</p> required <code>response_template_name</code> <code>Optional[str]</code> <p>The name of the response template to use.</p> required Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>def __init__(\n    self,\n    prompt_template_name: Optional[str],\n    response_template_name: Optional[str],\n) -&gt; None:\n    \"\"\"\n    Args:\n        prompt_template_name (Optional[str]):\n            The name of the prompt template to use.\n        response_template_name (Optional[str]):\n            The name of the response template to use.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.PrebuiltVoiceConfig","title":"<code>PrebuiltVoiceConfig</code>","text":"<p>Configuration for prebuilt voice models.</p> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class PrebuiltVoiceConfig:\n    \"\"\"Configuration for prebuilt voice models.\"\"\"\n\n    def __init__(\n        self,\n        voice_name: str,\n    ) -&gt; None: ...\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.RetrievalConfig","title":"<code>RetrievalConfig</code>","text":"Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class RetrievalConfig:\n    @property\n    def lat_lng(self) -&gt; LatLng: ...\n    @property\n    def language_code(self) -&gt; str: ...\n    def __init__(self, lat_lng: LatLng, language_code: str) -&gt; None:\n        \"\"\"Initialize RetrievalConfig with latitude/longitude and language code.\n\n        Args:\n            lat_lng (LatLng):\n                The latitude and longitude configuration.\n            language_code (str):\n                The language code for the retrieval.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.RetrievalConfig.__init__","title":"<code>__init__(lat_lng, language_code)</code>","text":"<p>Initialize RetrievalConfig with latitude/longitude and language code.</p> <p>Parameters:</p> Name Type Description Default <code>lat_lng</code> <code>LatLng</code> <p>The latitude and longitude configuration.</p> required <code>language_code</code> <code>str</code> <p>The language code for the retrieval.</p> required Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>def __init__(self, lat_lng: LatLng, language_code: str) -&gt; None:\n    \"\"\"Initialize RetrievalConfig with latitude/longitude and language code.\n\n    Args:\n        lat_lng (LatLng):\n            The latitude and longitude configuration.\n        language_code (str):\n            The language code for the retrieval.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.SafetySetting","title":"<code>SafetySetting</code>","text":"Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class SafetySetting:\n    category: HarmCategory\n    threshold: HarmBlockThreshold\n    method: Optional[HarmBlockMethod]\n\n    def __init__(\n        self,\n        category: HarmCategory,\n        threshold: HarmBlockThreshold,\n        method: Optional[HarmBlockMethod] = None,\n    ) -&gt; None:\n        \"\"\"Initialize SafetySetting with required and optional parameters.\n\n        Args:\n            category (HarmCategory):\n                The category of harm to protect against.\n            threshold (HarmBlockThreshold):\n                The threshold for blocking content.\n            method (Optional[HarmBlockMethod]):\n                The method used for blocking (if any).\n        \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.SafetySetting.__init__","title":"<code>__init__(category, threshold, method=None)</code>","text":"<p>Initialize SafetySetting with required and optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>HarmCategory</code> <p>The category of harm to protect against.</p> required <code>threshold</code> <code>HarmBlockThreshold</code> <p>The threshold for blocking content.</p> required <code>method</code> <code>Optional[HarmBlockMethod]</code> <p>The method used for blocking (if any).</p> <code>None</code> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>def __init__(\n    self,\n    category: HarmCategory,\n    threshold: HarmBlockThreshold,\n    method: Optional[HarmBlockMethod] = None,\n) -&gt; None:\n    \"\"\"Initialize SafetySetting with required and optional parameters.\n\n    Args:\n        category (HarmCategory):\n            The category of harm to protect against.\n        threshold (HarmBlockThreshold):\n            The threshold for blocking content.\n        method (Optional[HarmBlockMethod]):\n            The method used for blocking (if any).\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.SpeechConfig","title":"<code>SpeechConfig</code>","text":"<p>Configuration for speech generation.</p> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class SpeechConfig:\n    \"\"\"Configuration for speech generation.\"\"\"\n\n    def __init__(\n        self,\n        voice_config: Optional[\"VoiceConfig\"] = None,\n        language_code: Optional[str] = None,\n    ) -&gt; None: ...\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.ThinkingConfig","title":"<code>ThinkingConfig</code>","text":"<p>Configuration for thinking/reasoning capabilities.</p> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class ThinkingConfig:\n    \"\"\"Configuration for thinking/reasoning capabilities.\"\"\"\n\n    def __init__(\n        self,\n        include_thoughts: Optional[bool] = None,\n        thinking_budget: Optional[int] = None,\n    ) -&gt; None: ...\n</code></pre>"},{"location":"docs/api/genai/google/google/#opsml.genai.google._google.VoiceConfig","title":"<code>VoiceConfig</code>","text":"<p>Configuration for voice generation.</p> Source code in <code>python/opsml/genai/google/_google.pyi</code> <pre><code>class VoiceConfig:\n    \"\"\"Configuration for voice generation.\"\"\"\n\n    def __init__(self, voice_config: VoiceConfigMode) -&gt; None: ...\n</code></pre>"},{"location":"docs/api/genai/openai/openai/","title":"OpenAI","text":""},{"location":"docs/api/genai/openai/openai/#opsml.genai.openai._openai.OpenAIChatSettings","title":"<code>OpenAIChatSettings</code>","text":"<p>OpenAI chat completion settings configuration.</p> <p>This class provides configuration options for OpenAI chat completions, including model parameters, tool usage, and request options.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; settings = OpenAIChatSettings(\n...     temperature=0.7,\n...     max_completion_tokens=1000,\n...     stream=True\n... )\n&gt;&gt;&gt; settings.temperature = 0.5\n</code></pre> Source code in <code>python/opsml/genai/openai/_openai.pyi</code> <pre><code>class OpenAIChatSettings:\n    \"\"\"OpenAI chat completion settings configuration.\n\n    This class provides configuration options for OpenAI chat completions,\n    including model parameters, tool usage, and request options.\n\n    Examples:\n        &gt;&gt;&gt; settings = OpenAIChatSettings(\n        ...     temperature=0.7,\n        ...     max_completion_tokens=1000,\n        ...     stream=True\n        ... )\n        &gt;&gt;&gt; settings.temperature = 0.5\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        max_completion_tokens: Optional[int] = None,\n        temperature: Optional[float] = None,\n        top_p: Optional[float] = None,\n        top_k: Optional[int] = None,\n        frequency_penalty: Optional[float] = None,\n        timeout: Optional[float] = None,\n        parallel_tool_calls: Optional[bool] = None,\n        seed: Optional[int] = None,\n        logit_bias: Optional[Dict[str, int]] = None,\n        stop_sequences: Optional[List[str]] = None,\n        logprobs: Optional[bool] = None,\n        audio: Optional[AudioParam] = None,\n        metadata: Optional[Dict[str, str]] = None,\n        modalities: Optional[List[str]] = None,\n        n: Optional[int] = None,\n        prediction: Optional[Prediction] = None,\n        presence_penalty: Optional[float] = None,\n        prompt_cache_key: Optional[str] = None,\n        reasoning_effort: Optional[str] = None,\n        safety_identifier: Optional[str] = None,\n        service_tier: Optional[str] = None,\n        store: Optional[bool] = None,\n        stream: Optional[bool] = None,\n        stream_options: Optional[StreamOptions] = None,\n        tool_choice: Optional[ToolChoice] = None,\n        tools: Optional[List[Tool]] = None,\n        top_logprobs: Optional[int] = None,\n        verbosity: Optional[str] = None,\n        extra_body: Optional[Any] = None,\n    ) -&gt; None:\n        \"\"\"Initialize OpenAI chat settings.\n\n        Args:\n            max_completion_tokens (Optional[int]):\n                Maximum number of tokens to generate\n            temperature (Optional[float]):\n                Sampling temperature (0.0 to 2.0)\n            top_p (Optional[float]):\n                Nucleus sampling parameter\n            top_k (Optional[int]):\n                Top-k sampling parameter\n            frequency_penalty (Optional[float]):\n                Frequency penalty (-2.0 to 2.0)\n            timeout (Optional[float]):\n                Request timeout in seconds\n            parallel_tool_calls (Optional[bool]):\n                Whether to enable parallel tool calls\n            seed (Optional[int]):\n                Random seed for deterministic outputs\n            logit_bias (Optional[Dict[str, int]]):\n                Token bias modifications\n            stop_sequences (Optional[List[str]]):\n                Sequences where generation should stop\n            logprobs (Optional[bool]):\n                Whether to return log probabilities\n            audio (Optional[AudioParam]):\n                Audio generation parameters\n            metadata (Optional[Dict[str, str]]):\n                Additional metadata for the request\n            modalities (Optional[List[str]]):\n                List of modalities to use\n            n (Optional[int]):\n                Number of completions to generate\n            prediction (Optional[Prediction]):\n                Prediction configuration\n            presence_penalty (Optional[float]):\n                Presence penalty (-2.0 to 2.0)\n            prompt_cache_key (Optional[str]):\n                Key for prompt caching\n            reasoning_effort (Optional[str]):\n                Reasoning effort level\n            safety_identifier (Optional[str]):\n                Safety configuration identifier\n            service_tier (Optional[str]):\n                Service tier to use\n            store (Optional[bool]):\n                Whether to store the conversation\n            stream (Optional[bool]):\n                Whether to stream the response\n            stream_options (Optional[StreamOptions]):\n                Streaming configuration options\n            tool_choice (Optional[ToolChoice]):\n                Tool choice configuration\n            tools (Optional[List[Tool]]):\n                Available tools for the model\n            top_logprobs (Optional[int]):\n                Number of top log probabilities to return\n            verbosity (Optional[str]):\n                Verbosity level for the response\n            extra_body (Optional[Any]):\n                Additional request body parameters\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of the settings.\"\"\"\n</code></pre>"},{"location":"docs/api/genai/openai/openai/#opsml.genai.openai._openai.OpenAIChatSettings.__init__","title":"<code>__init__(*, max_completion_tokens=None, temperature=None, top_p=None, top_k=None, frequency_penalty=None, timeout=None, parallel_tool_calls=None, seed=None, logit_bias=None, stop_sequences=None, logprobs=None, audio=None, metadata=None, modalities=None, n=None, prediction=None, presence_penalty=None, prompt_cache_key=None, reasoning_effort=None, safety_identifier=None, service_tier=None, store=None, stream=None, stream_options=None, tool_choice=None, tools=None, top_logprobs=None, verbosity=None, extra_body=None)</code>","text":"<p>Initialize OpenAI chat settings.</p> <p>Parameters:</p> Name Type Description Default <code>max_completion_tokens</code> <code>Optional[int]</code> <p>Maximum number of tokens to generate</p> <code>None</code> <code>temperature</code> <code>Optional[float]</code> <p>Sampling temperature (0.0 to 2.0)</p> <code>None</code> <code>top_p</code> <code>Optional[float]</code> <p>Nucleus sampling parameter</p> <code>None</code> <code>top_k</code> <code>Optional[int]</code> <p>Top-k sampling parameter</p> <code>None</code> <code>frequency_penalty</code> <code>Optional[float]</code> <p>Frequency penalty (-2.0 to 2.0)</p> <code>None</code> <code>timeout</code> <code>Optional[float]</code> <p>Request timeout in seconds</p> <code>None</code> <code>parallel_tool_calls</code> <code>Optional[bool]</code> <p>Whether to enable parallel tool calls</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>Random seed for deterministic outputs</p> <code>None</code> <code>logit_bias</code> <code>Optional[Dict[str, int]]</code> <p>Token bias modifications</p> <code>None</code> <code>stop_sequences</code> <code>Optional[List[str]]</code> <p>Sequences where generation should stop</p> <code>None</code> <code>logprobs</code> <code>Optional[bool]</code> <p>Whether to return log probabilities</p> <code>None</code> <code>audio</code> <code>Optional[AudioParam]</code> <p>Audio generation parameters</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[str, str]]</code> <p>Additional metadata for the request</p> <code>None</code> <code>modalities</code> <code>Optional[List[str]]</code> <p>List of modalities to use</p> <code>None</code> <code>n</code> <code>Optional[int]</code> <p>Number of completions to generate</p> <code>None</code> <code>prediction</code> <code>Optional[Prediction]</code> <p>Prediction configuration</p> <code>None</code> <code>presence_penalty</code> <code>Optional[float]</code> <p>Presence penalty (-2.0 to 2.0)</p> <code>None</code> <code>prompt_cache_key</code> <code>Optional[str]</code> <p>Key for prompt caching</p> <code>None</code> <code>reasoning_effort</code> <code>Optional[str]</code> <p>Reasoning effort level</p> <code>None</code> <code>safety_identifier</code> <code>Optional[str]</code> <p>Safety configuration identifier</p> <code>None</code> <code>service_tier</code> <code>Optional[str]</code> <p>Service tier to use</p> <code>None</code> <code>store</code> <code>Optional[bool]</code> <p>Whether to store the conversation</p> <code>None</code> <code>stream</code> <code>Optional[bool]</code> <p>Whether to stream the response</p> <code>None</code> <code>stream_options</code> <code>Optional[StreamOptions]</code> <p>Streaming configuration options</p> <code>None</code> <code>tool_choice</code> <code>Optional[ToolChoice]</code> <p>Tool choice configuration</p> <code>None</code> <code>tools</code> <code>Optional[List[Tool]]</code> <p>Available tools for the model</p> <code>None</code> <code>top_logprobs</code> <code>Optional[int]</code> <p>Number of top log probabilities to return</p> <code>None</code> <code>verbosity</code> <code>Optional[str]</code> <p>Verbosity level for the response</p> <code>None</code> <code>extra_body</code> <code>Optional[Any]</code> <p>Additional request body parameters</p> <code>None</code> Source code in <code>python/opsml/genai/openai/_openai.pyi</code> <pre><code>def __init__(\n    self,\n    *,\n    max_completion_tokens: Optional[int] = None,\n    temperature: Optional[float] = None,\n    top_p: Optional[float] = None,\n    top_k: Optional[int] = None,\n    frequency_penalty: Optional[float] = None,\n    timeout: Optional[float] = None,\n    parallel_tool_calls: Optional[bool] = None,\n    seed: Optional[int] = None,\n    logit_bias: Optional[Dict[str, int]] = None,\n    stop_sequences: Optional[List[str]] = None,\n    logprobs: Optional[bool] = None,\n    audio: Optional[AudioParam] = None,\n    metadata: Optional[Dict[str, str]] = None,\n    modalities: Optional[List[str]] = None,\n    n: Optional[int] = None,\n    prediction: Optional[Prediction] = None,\n    presence_penalty: Optional[float] = None,\n    prompt_cache_key: Optional[str] = None,\n    reasoning_effort: Optional[str] = None,\n    safety_identifier: Optional[str] = None,\n    service_tier: Optional[str] = None,\n    store: Optional[bool] = None,\n    stream: Optional[bool] = None,\n    stream_options: Optional[StreamOptions] = None,\n    tool_choice: Optional[ToolChoice] = None,\n    tools: Optional[List[Tool]] = None,\n    top_logprobs: Optional[int] = None,\n    verbosity: Optional[str] = None,\n    extra_body: Optional[Any] = None,\n) -&gt; None:\n    \"\"\"Initialize OpenAI chat settings.\n\n    Args:\n        max_completion_tokens (Optional[int]):\n            Maximum number of tokens to generate\n        temperature (Optional[float]):\n            Sampling temperature (0.0 to 2.0)\n        top_p (Optional[float]):\n            Nucleus sampling parameter\n        top_k (Optional[int]):\n            Top-k sampling parameter\n        frequency_penalty (Optional[float]):\n            Frequency penalty (-2.0 to 2.0)\n        timeout (Optional[float]):\n            Request timeout in seconds\n        parallel_tool_calls (Optional[bool]):\n            Whether to enable parallel tool calls\n        seed (Optional[int]):\n            Random seed for deterministic outputs\n        logit_bias (Optional[Dict[str, int]]):\n            Token bias modifications\n        stop_sequences (Optional[List[str]]):\n            Sequences where generation should stop\n        logprobs (Optional[bool]):\n            Whether to return log probabilities\n        audio (Optional[AudioParam]):\n            Audio generation parameters\n        metadata (Optional[Dict[str, str]]):\n            Additional metadata for the request\n        modalities (Optional[List[str]]):\n            List of modalities to use\n        n (Optional[int]):\n            Number of completions to generate\n        prediction (Optional[Prediction]):\n            Prediction configuration\n        presence_penalty (Optional[float]):\n            Presence penalty (-2.0 to 2.0)\n        prompt_cache_key (Optional[str]):\n            Key for prompt caching\n        reasoning_effort (Optional[str]):\n            Reasoning effort level\n        safety_identifier (Optional[str]):\n            Safety configuration identifier\n        service_tier (Optional[str]):\n            Service tier to use\n        store (Optional[bool]):\n            Whether to store the conversation\n        stream (Optional[bool]):\n            Whether to stream the response\n        stream_options (Optional[StreamOptions]):\n            Streaming configuration options\n        tool_choice (Optional[ToolChoice]):\n            Tool choice configuration\n        tools (Optional[List[Tool]]):\n            Available tools for the model\n        top_logprobs (Optional[int]):\n            Number of top log probabilities to return\n        verbosity (Optional[str]):\n            Verbosity level for the response\n        extra_body (Optional[Any]):\n            Additional request body parameters\n    \"\"\"\n</code></pre>"},{"location":"docs/api/genai/openai/openai/#opsml.genai.openai._openai.OpenAIChatSettings.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of the settings.</p> Source code in <code>python/opsml/genai/openai/_openai.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of the settings.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/","title":"Alert","text":""},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.AlertDispatchType","title":"<code>AlertDispatchType</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class AlertDispatchType:\n    Slack: \"AlertDispatchType\"\n    OpsGenie: \"AlertDispatchType\"\n    Console: \"AlertDispatchType\"\n\n    @staticmethod\n    def to_string() -&gt; str:\n        \"\"\"Return the string representation of the alert dispatch type\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.AlertDispatchType.to_string","title":"<code>to_string()</code>  <code>staticmethod</code>","text":"<p>Return the string representation of the alert dispatch type</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>@staticmethod\ndef to_string() -&gt; str:\n    \"\"\"Return the string representation of the alert dispatch type\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.AlertThreshold","title":"<code>AlertThreshold</code>","text":"<p>Enum representing different alert conditions for monitoring metrics.</p> <p>Attributes:</p> Name Type Description <code>Below</code> <code>AlertThreshold</code> <p>Indicates that an alert should be triggered when the metric is below a threshold.</p> <code>Above</code> <code>AlertThreshold</code> <p>Indicates that an alert should be triggered when the metric is above a threshold.</p> <code>Outside</code> <code>AlertThreshold</code> <p>Indicates that an alert should be triggered when the metric is outside a specified range.</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class AlertThreshold:\n    \"\"\"\n    Enum representing different alert conditions for monitoring metrics.\n\n    Attributes:\n        Below: Indicates that an alert should be triggered when the metric is below a threshold.\n        Above: Indicates that an alert should be triggered when the metric is above a threshold.\n        Outside: Indicates that an alert should be triggered when the metric is outside a specified range.\n    \"\"\"\n\n    Below: \"AlertThreshold\"\n    Above: \"AlertThreshold\"\n    Outside: \"AlertThreshold\"\n\n    @staticmethod\n    def from_value(value: str) -&gt; \"AlertThreshold\":\n        \"\"\"\n        Creates an AlertThreshold enum member from a string value.\n\n        Args:\n            value (str): The string representation of the alert condition.\n\n        Returns:\n            AlertThreshold: The corresponding AlertThreshold enum member.\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.AlertThreshold.from_value","title":"<code>from_value(value)</code>  <code>staticmethod</code>","text":"<p>Creates an AlertThreshold enum member from a string value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The string representation of the alert condition.</p> required <p>Returns:</p> Name Type Description <code>AlertThreshold</code> <code>AlertThreshold</code> <p>The corresponding AlertThreshold enum member.</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>@staticmethod\ndef from_value(value: str) -&gt; \"AlertThreshold\":\n    \"\"\"\n    Creates an AlertThreshold enum member from a string value.\n\n    Args:\n        value (str): The string representation of the alert condition.\n\n    Returns:\n        AlertThreshold: The corresponding AlertThreshold enum member.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.ConsoleDispatchConfig","title":"<code>ConsoleDispatchConfig</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class ConsoleDispatchConfig:\n    def __init__(self):\n        \"\"\"Initialize alert config\"\"\"\n\n    @property\n    def enabled(self) -&gt; bool:\n        \"\"\"Return the alert dispatch type\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.ConsoleDispatchConfig.enabled","title":"<code>enabled</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.ConsoleDispatchConfig.__init__","title":"<code>__init__()</code>","text":"<p>Initialize alert config</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self):\n    \"\"\"Initialize alert config\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertCondition","title":"<code>CustomMetricAlertCondition</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class CustomMetricAlertCondition:\n    def __init__(\n        self,\n        alert_threshold: AlertThreshold,\n        alert_threshold_value: Optional[float],\n    ):\n        \"\"\"Initialize a CustomMetricAlertCondition instance.\n        Args:\n            alert_threshold (AlertThreshold): The condition that determines when an alert\n                should be triggered. This could be comparisons like 'greater than',\n                'less than', 'equal to', etc.\n            alert_threshold_value (Optional[float], optional): A numerical boundary used in\n                conjunction with the alert_threshold. This can be None for certain\n                types of comparisons that don't require a fixed boundary.\n        Example:\n            alert_threshold = CustomMetricAlertCondition(AlertCondition.BELOW, 2.0)\n        \"\"\"\n\n    @property\n    def alert_threshold(self) -&gt; AlertThreshold:\n        \"\"\"Return the alert_threshold\"\"\"\n\n    @alert_threshold.setter\n    def alert_threshold(self, alert_threshold: AlertThreshold) -&gt; None:\n        \"\"\"Set the alert_threshold\"\"\"\n\n    @property\n    def alert_threshold_value(self) -&gt; float:\n        \"\"\"Return the alert_threshold_value\"\"\"\n\n    @alert_threshold_value.setter\n    def alert_threshold_value(self, alert_threshold_value: float) -&gt; None:\n        \"\"\"Set the alert_threshold_value\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertCondition.alert_threshold","title":"<code>alert_threshold</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert_threshold</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertCondition.alert_threshold_value","title":"<code>alert_threshold_value</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert_threshold_value</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertCondition.__init__","title":"<code>__init__(alert_threshold, alert_threshold_value)</code>","text":"<p>Initialize a CustomMetricAlertCondition instance. Args:     alert_threshold (AlertThreshold): The condition that determines when an alert         should be triggered. This could be comparisons like 'greater than',         'less than', 'equal to', etc.     alert_threshold_value (Optional[float], optional): A numerical boundary used in         conjunction with the alert_threshold. This can be None for certain         types of comparisons that don't require a fixed boundary. Example:     alert_threshold = CustomMetricAlertCondition(AlertCondition.BELOW, 2.0)</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    alert_threshold: AlertThreshold,\n    alert_threshold_value: Optional[float],\n):\n    \"\"\"Initialize a CustomMetricAlertCondition instance.\n    Args:\n        alert_threshold (AlertThreshold): The condition that determines when an alert\n            should be triggered. This could be comparisons like 'greater than',\n            'less than', 'equal to', etc.\n        alert_threshold_value (Optional[float], optional): A numerical boundary used in\n            conjunction with the alert_threshold. This can be None for certain\n            types of comparisons that don't require a fixed boundary.\n    Example:\n        alert_threshold = CustomMetricAlertCondition(AlertCondition.BELOW, 2.0)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertConfig","title":"<code>CustomMetricAlertConfig</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class CustomMetricAlertConfig:\n    def __init__(\n        self,\n        dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n        schedule: Optional[str | CommonCrons] = None,\n    ):\n        \"\"\"Initialize alert config\n\n        Args:\n            dispatch_config:\n                Alert dispatch config. Defaults to console\n            schedule:\n                Schedule to run monitor. Defaults to daily at midnight\n\n        \"\"\"\n\n    @property\n    def dispatch_type(self) -&gt; AlertDispatchType:\n        \"\"\"Return the alert dispatch type\"\"\"\n\n    @property\n    def dispatch_config(self) -&gt; DispatchConfigType:\n        \"\"\"Return the dispatch config\"\"\"\n\n    @property\n    def schedule(self) -&gt; str:\n        \"\"\"Return the schedule\"\"\"\n\n    @schedule.setter\n    def schedule(self, schedule: str) -&gt; None:\n        \"\"\"Set the schedule\"\"\"\n\n    @property\n    def alert_conditions(self) -&gt; dict[str, CustomMetricAlertCondition]:\n        \"\"\"Return the alert_condition that were set during metric definition\"\"\"\n\n    @alert_conditions.setter\n    def alert_conditions(self, alert_conditions: dict[str, CustomMetricAlertCondition]) -&gt; None:\n        \"\"\"Update the alert_condition that were set during metric definition\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertConfig.alert_conditions","title":"<code>alert_conditions</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert_condition that were set during metric definition</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertConfig.dispatch_config","title":"<code>dispatch_config</code>  <code>property</code>","text":"<p>Return the dispatch config</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertConfig.dispatch_type","title":"<code>dispatch_type</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertConfig.schedule","title":"<code>schedule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the schedule</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.CustomMetricAlertConfig.__init__","title":"<code>__init__(dispatch_config=None, schedule=None)</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>dispatch_config</code> <code>Optional[SlackDispatchConfig | OpsGenieDispatchConfig]</code> <p>Alert dispatch config. Defaults to console</p> <code>None</code> <code>schedule</code> <code>Optional[str | CommonCrons]</code> <p>Schedule to run monitor. Defaults to daily at midnight</p> <code>None</code> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n    schedule: Optional[str | CommonCrons] = None,\n):\n    \"\"\"Initialize alert config\n\n    Args:\n        dispatch_config:\n            Alert dispatch config. Defaults to console\n        schedule:\n            Schedule to run monitor. Defaults to daily at midnight\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.LLMAlertConfig","title":"<code>LLMAlertConfig</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class LLMAlertConfig:\n    def __init__(\n        self,\n        dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n        schedule: Optional[str | CommonCrons] = None,\n    ):\n        \"\"\"Initialize alert config\n\n        Args:\n            dispatch_config:\n                Alert dispatch config. Defaults to console\n            schedule:\n                Schedule to run monitor. Defaults to daily at midnight\n\n        \"\"\"\n\n    @property\n    def dispatch_type(self) -&gt; AlertDispatchType:\n        \"\"\"Return the alert dispatch type\"\"\"\n\n    @property\n    def dispatch_config(self) -&gt; DispatchConfigType:\n        \"\"\"Return the dispatch config\"\"\"\n\n    @property\n    def schedule(self) -&gt; str:\n        \"\"\"Return the schedule\"\"\"\n\n    @schedule.setter\n    def schedule(self, schedule: str) -&gt; None:\n        \"\"\"Set the schedule\"\"\"\n\n    @property\n    def alert_conditions(self) -&gt; Optional[Dict[str, LLMMetricAlertCondition]]:\n        \"\"\"Return the alert conditions\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.LLMAlertConfig.alert_conditions","title":"<code>alert_conditions</code>  <code>property</code>","text":"<p>Return the alert conditions</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.LLMAlertConfig.dispatch_config","title":"<code>dispatch_config</code>  <code>property</code>","text":"<p>Return the dispatch config</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.LLMAlertConfig.dispatch_type","title":"<code>dispatch_type</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.LLMAlertConfig.schedule","title":"<code>schedule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the schedule</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.LLMAlertConfig.__init__","title":"<code>__init__(dispatch_config=None, schedule=None)</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>dispatch_config</code> <code>Optional[SlackDispatchConfig | OpsGenieDispatchConfig]</code> <p>Alert dispatch config. Defaults to console</p> <code>None</code> <code>schedule</code> <code>Optional[str | CommonCrons]</code> <p>Schedule to run monitor. Defaults to daily at midnight</p> <code>None</code> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n    schedule: Optional[str | CommonCrons] = None,\n):\n    \"\"\"Initialize alert config\n\n    Args:\n        dispatch_config:\n            Alert dispatch config. Defaults to console\n        schedule:\n            Schedule to run monitor. Defaults to daily at midnight\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.LLMMetricAlertCondition","title":"<code>LLMMetricAlertCondition</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class LLMMetricAlertCondition:\n    def __init__(\n        self,\n        alert_threshold: AlertThreshold,\n        alert_threshold_value: Optional[float],\n    ):\n        \"\"\"Initialize a LLMMetricAlertCondition instance.\n        Args:\n            alert_threshold (AlertThreshold):\n                The condition that determines when an alert should be triggered.\n                Must be one of the AlertThreshold enum members like Below, Above, or Outside.\n            alert_threshold_value (Optional[float], optional):\n                A numerical boundary used in conjunction with the alert_threshold.\n                This can be None for certain types of comparisons that don't require a fixed boundary.\n        Example:\n            alert_threshold = LLMMetricAlertCondition(AlertCondition.BELOW, 2.0)\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of LLMMetricAlertCondition.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.LLMMetricAlertCondition.__init__","title":"<code>__init__(alert_threshold, alert_threshold_value)</code>","text":"<p>Initialize a LLMMetricAlertCondition instance. Args:     alert_threshold (AlertThreshold):         The condition that determines when an alert should be triggered.         Must be one of the AlertThreshold enum members like Below, Above, or Outside.     alert_threshold_value (Optional[float], optional):         A numerical boundary used in conjunction with the alert_threshold.         This can be None for certain types of comparisons that don't require a fixed boundary. Example:     alert_threshold = LLMMetricAlertCondition(AlertCondition.BELOW, 2.0)</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    alert_threshold: AlertThreshold,\n    alert_threshold_value: Optional[float],\n):\n    \"\"\"Initialize a LLMMetricAlertCondition instance.\n    Args:\n        alert_threshold (AlertThreshold):\n            The condition that determines when an alert should be triggered.\n            Must be one of the AlertThreshold enum members like Below, Above, or Outside.\n        alert_threshold_value (Optional[float], optional):\n            A numerical boundary used in conjunction with the alert_threshold.\n            This can be None for certain types of comparisons that don't require a fixed boundary.\n    Example:\n        alert_threshold = LLMMetricAlertCondition(AlertCondition.BELOW, 2.0)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.LLMMetricAlertCondition.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of LLMMetricAlertCondition.</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of LLMMetricAlertCondition.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.OpsGenieDispatchConfig","title":"<code>OpsGenieDispatchConfig</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class OpsGenieDispatchConfig:\n    def __init__(self, team: str):\n        \"\"\"Initialize alert config\n\n        Args:\n            team:\n                Opsegenie team to be notified in the event of drift\n        \"\"\"\n\n    @property\n    def team(self) -&gt; str:\n        \"\"\"Return the opesgenie team name\"\"\"\n\n    @team.setter\n    def team(self, team: str) -&gt; None:\n        \"\"\"Set the opesgenie team name\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.OpsGenieDispatchConfig.team","title":"<code>team</code>  <code>property</code> <code>writable</code>","text":"<p>Return the opesgenie team name</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.OpsGenieDispatchConfig.__init__","title":"<code>__init__(team)</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>team</code> <code>str</code> <p>Opsegenie team to be notified in the event of drift</p> required Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, team: str):\n    \"\"\"Initialize alert config\n\n    Args:\n        team:\n            Opsegenie team to be notified in the event of drift\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiAlertConfig","title":"<code>PsiAlertConfig</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class PsiAlertConfig:\n    def __init__(\n        self,\n        dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n        schedule: Optional[str | CommonCrons] = None,\n        features_to_monitor: List[str] = [],\n        threshold: Optional[PsiThresholdType] = PsiChiSquareThreshold(),\n    ):\n        \"\"\"Initialize alert config\n\n        Args:\n            dispatch_config:\n                Alert dispatch configuration to use. Defaults to an internal \"Console\" type where\n                the alerts will be logged to the console\n            schedule:\n                Schedule to run monitor. Defaults to daily at midnight\n            features_to_monitor:\n                List of features to monitor. Defaults to empty list, which means all features\n            threshold:\n                Configuration that helps determine how to calculate PSI critical values.\n                Defaults to PsiChiSquareThreshold, which uses the chi-square distribution.\n        \"\"\"\n\n    @property\n    def dispatch_type(self) -&gt; AlertDispatchType:\n        \"\"\"Return the alert dispatch type\"\"\"\n\n    @property\n    def dispatch_config(self) -&gt; DispatchConfigType:\n        \"\"\"Return the dispatch config\"\"\"\n\n    @property\n    def threshold(self) -&gt; PsiThresholdType:\n        \"\"\"Return the threshold config\"\"\"\n\n    @property\n    def schedule(self) -&gt; str:\n        \"\"\"Return the schedule\"\"\"\n\n    @schedule.setter\n    def schedule(self, schedule: str) -&gt; None:\n        \"\"\"Set the schedule\"\"\"\n\n    @property\n    def features_to_monitor(self) -&gt; List[str]:\n        \"\"\"Return the features to monitor\"\"\"\n\n    @features_to_monitor.setter\n    def features_to_monitor(self, features_to_monitor: List[str]) -&gt; None:\n        \"\"\"Set the features to monitor\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiAlertConfig.dispatch_config","title":"<code>dispatch_config</code>  <code>property</code>","text":"<p>Return the dispatch config</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiAlertConfig.dispatch_type","title":"<code>dispatch_type</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiAlertConfig.features_to_monitor","title":"<code>features_to_monitor</code>  <code>property</code> <code>writable</code>","text":"<p>Return the features to monitor</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiAlertConfig.schedule","title":"<code>schedule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the schedule</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiAlertConfig.threshold","title":"<code>threshold</code>  <code>property</code>","text":"<p>Return the threshold config</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiAlertConfig.__init__","title":"<code>__init__(dispatch_config=None, schedule=None, features_to_monitor=[], threshold=PsiChiSquareThreshold())</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>dispatch_config</code> <code>Optional[SlackDispatchConfig | OpsGenieDispatchConfig]</code> <p>Alert dispatch configuration to use. Defaults to an internal \"Console\" type where the alerts will be logged to the console</p> <code>None</code> <code>schedule</code> <code>Optional[str | CommonCrons]</code> <p>Schedule to run monitor. Defaults to daily at midnight</p> <code>None</code> <code>features_to_monitor</code> <code>List[str]</code> <p>List of features to monitor. Defaults to empty list, which means all features</p> <code>[]</code> <code>threshold</code> <code>Optional[PsiThresholdType]</code> <p>Configuration that helps determine how to calculate PSI critical values. Defaults to PsiChiSquareThreshold, which uses the chi-square distribution.</p> <code>PsiChiSquareThreshold()</code> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n    schedule: Optional[str | CommonCrons] = None,\n    features_to_monitor: List[str] = [],\n    threshold: Optional[PsiThresholdType] = PsiChiSquareThreshold(),\n):\n    \"\"\"Initialize alert config\n\n    Args:\n        dispatch_config:\n            Alert dispatch configuration to use. Defaults to an internal \"Console\" type where\n            the alerts will be logged to the console\n        schedule:\n            Schedule to run monitor. Defaults to daily at midnight\n        features_to_monitor:\n            List of features to monitor. Defaults to empty list, which means all features\n        threshold:\n            Configuration that helps determine how to calculate PSI critical values.\n            Defaults to PsiChiSquareThreshold, which uses the chi-square distribution.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiChiSquareThreshold","title":"<code>PsiChiSquareThreshold</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class PsiChiSquareThreshold:\n    def __init__(self, alpha: float = 0.05):\n        \"\"\"Initialize PSI threshold using chi-square approximation.\n\n        Uses the asymptotic chi-square distribution of PSI.\n\n        The chi-square method is generally more statistically rigorous than\n        normal approximation, especially for smaller sample sizes.\n\n        Args:\n            alpha: Significance level (0.0 to 1.0, exclusive). Common values:\n                   0.05 (95% confidence), 0.01 (99% confidence)\n\n        Raises:\n            ValueError: If alpha not in range (0.0, 1.0)\n        \"\"\"\n\n    @property\n    def alpha(self) -&gt; float:\n        \"\"\"Statistical significance level for drift detection.\"\"\"\n\n    @alpha.setter\n    def alpha(self, alpha: float) -&gt; None:\n        \"\"\"Set significance level (must be between 0.0 and 1.0, exclusive).\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiChiSquareThreshold.alpha","title":"<code>alpha</code>  <code>property</code> <code>writable</code>","text":"<p>Statistical significance level for drift detection.</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiChiSquareThreshold.__init__","title":"<code>__init__(alpha=0.05)</code>","text":"<p>Initialize PSI threshold using chi-square approximation.</p> <p>Uses the asymptotic chi-square distribution of PSI.</p> <p>The chi-square method is generally more statistically rigorous than normal approximation, especially for smaller sample sizes.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level (0.0 to 1.0, exclusive). Common values:    0.05 (95% confidence), 0.01 (99% confidence)</p> <code>0.05</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If alpha not in range (0.0, 1.0)</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, alpha: float = 0.05):\n    \"\"\"Initialize PSI threshold using chi-square approximation.\n\n    Uses the asymptotic chi-square distribution of PSI.\n\n    The chi-square method is generally more statistically rigorous than\n    normal approximation, especially for smaller sample sizes.\n\n    Args:\n        alpha: Significance level (0.0 to 1.0, exclusive). Common values:\n               0.05 (95% confidence), 0.01 (99% confidence)\n\n    Raises:\n        ValueError: If alpha not in range (0.0, 1.0)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiFixedThreshold","title":"<code>PsiFixedThreshold</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class PsiFixedThreshold:\n    def __init__(self, threshold: float = 0.25):\n        \"\"\"Initialize PSI threshold using a fixed value.\n\n        Uses a predetermined PSI threshold value, similar to traditional\n        \"rule of thumb\" approaches (e.g., 0.10 for moderate drift, 0.25\n        for significant drift).\n\n        Args:\n            threshold: Fixed PSI threshold value (must be positive).\n                      Common industry values: 0.10, 0.25\n\n        Raises:\n            ValueError: If threshold is not positive\n        \"\"\"\n\n    @property\n    def threshold(self) -&gt; float:\n        \"\"\"Fixed PSI threshold value for drift detection.\"\"\"\n\n    @threshold.setter\n    def threshold(self, threshold: float) -&gt; None:\n        \"\"\"Set threshold value (must be positive).\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiFixedThreshold.threshold","title":"<code>threshold</code>  <code>property</code> <code>writable</code>","text":"<p>Fixed PSI threshold value for drift detection.</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiFixedThreshold.__init__","title":"<code>__init__(threshold=0.25)</code>","text":"<p>Initialize PSI threshold using a fixed value.</p> <p>Uses a predetermined PSI threshold value, similar to traditional \"rule of thumb\" approaches (e.g., 0.10 for moderate drift, 0.25 for significant drift).</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>Fixed PSI threshold value (must be positive).       Common industry values: 0.10, 0.25</p> <code>0.25</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If threshold is not positive</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, threshold: float = 0.25):\n    \"\"\"Initialize PSI threshold using a fixed value.\n\n    Uses a predetermined PSI threshold value, similar to traditional\n    \"rule of thumb\" approaches (e.g., 0.10 for moderate drift, 0.25\n    for significant drift).\n\n    Args:\n        threshold: Fixed PSI threshold value (must be positive).\n                  Common industry values: 0.10, 0.25\n\n    Raises:\n        ValueError: If threshold is not positive\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiNormalThreshold","title":"<code>PsiNormalThreshold</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class PsiNormalThreshold:\n    def __init__(self, alpha: float = 0.05):\n        \"\"\"Initialize PSI threshold using normal approximation.\n\n        Uses the asymptotic normal distribution of PSI to calculate critical values\n        for population drift detection.\n\n        Args:\n            alpha: Significance level (0.0 to 1.0, exclusive). Common values:\n                   0.05 (95% confidence), 0.01 (99% confidence)\n\n        Raises:\n            ValueError: If alpha not in range (0.0, 1.0)\n        \"\"\"\n\n    @property\n    def alpha(self) -&gt; float:\n        \"\"\"Statistical significance level for drift detection.\"\"\"\n\n    @alpha.setter\n    def alpha(self, alpha: float) -&gt; None:\n        \"\"\"Set significance level (must be between 0.0 and 1.0, exclusive).\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiNormalThreshold.alpha","title":"<code>alpha</code>  <code>property</code> <code>writable</code>","text":"<p>Statistical significance level for drift detection.</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.PsiNormalThreshold.__init__","title":"<code>__init__(alpha=0.05)</code>","text":"<p>Initialize PSI threshold using normal approximation.</p> <p>Uses the asymptotic normal distribution of PSI to calculate critical values for population drift detection.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Significance level (0.0 to 1.0, exclusive). Common values:    0.05 (95% confidence), 0.01 (99% confidence)</p> <code>0.05</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If alpha not in range (0.0, 1.0)</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, alpha: float = 0.05):\n    \"\"\"Initialize PSI threshold using normal approximation.\n\n    Uses the asymptotic normal distribution of PSI to calculate critical values\n    for population drift detection.\n\n    Args:\n        alpha: Significance level (0.0 to 1.0, exclusive). Common values:\n               0.05 (95% confidence), 0.01 (99% confidence)\n\n    Raises:\n        ValueError: If alpha not in range (0.0, 1.0)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SlackDispatchConfig","title":"<code>SlackDispatchConfig</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class SlackDispatchConfig:\n    def __init__(self, channel: str):\n        \"\"\"Initialize alert config\n\n        Args:\n            channel:\n                Slack channel name for where alerts will be reported\n        \"\"\"\n\n    @property\n    def channel(self) -&gt; str:\n        \"\"\"Return the slack channel name\"\"\"\n\n    @channel.setter\n    def channel(self, channel: str) -&gt; None:\n        \"\"\"Set the slack channel name for where alerts will be reported\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SlackDispatchConfig.channel","title":"<code>channel</code>  <code>property</code> <code>writable</code>","text":"<p>Return the slack channel name</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SlackDispatchConfig.__init__","title":"<code>__init__(channel)</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>str</code> <p>Slack channel name for where alerts will be reported</p> required Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, channel: str):\n    \"\"\"Initialize alert config\n\n    Args:\n        channel:\n            Slack channel name for where alerts will be reported\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlert","title":"<code>SpcAlert</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class SpcAlert:\n    def __init__(self, kind: SpcAlertType, zone: AlertZone):\n        \"\"\"Initialize alert\"\"\"\n\n    @property\n    def kind(self) -&gt; SpcAlertType:\n        \"\"\"Alert kind\"\"\"\n\n    @property\n    def zone(self) -&gt; AlertZone:\n        \"\"\"Zone associated with alert\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the alert.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlert.kind","title":"<code>kind</code>  <code>property</code>","text":"<p>Alert kind</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlert.zone","title":"<code>zone</code>  <code>property</code>","text":"<p>Zone associated with alert</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlert.__init__","title":"<code>__init__(kind, zone)</code>","text":"<p>Initialize alert</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(self, kind: SpcAlertType, zone: AlertZone):\n    \"\"\"Initialize alert\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlert.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the alert.</p> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the alert.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertConfig","title":"<code>SpcAlertConfig</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class SpcAlertConfig:\n    def __init__(\n        self,\n        rule: SpcAlertRule = SpcAlertRule(),\n        dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n        schedule: Optional[str | CommonCrons] = None,\n        features_to_monitor: List[str] = [],\n    ):\n        \"\"\"Initialize alert config\n\n        Args:\n            rule:\n                Alert rule to use. Defaults to Standard\n            dispatch_config:\n                Alert dispatch config. Defaults to console\n            schedule:\n                Schedule to run monitor. Defaults to daily at midnight\n            features_to_monitor:\n                List of features to monitor. Defaults to empty list, which means all features\n\n        \"\"\"\n\n    @property\n    def dispatch_type(self) -&gt; AlertDispatchType:\n        \"\"\"Return the alert dispatch type\"\"\"\n\n    @property\n    def dispatch_config(self) -&gt; DispatchConfigType:\n        \"\"\"Return the dispatch config\"\"\"\n\n    @property\n    def rule(self) -&gt; SpcAlertRule:\n        \"\"\"Return the alert rule\"\"\"\n\n    @rule.setter\n    def rule(self, rule: SpcAlertRule) -&gt; None:\n        \"\"\"Set the alert rule\"\"\"\n\n    @property\n    def schedule(self) -&gt; str:\n        \"\"\"Return the schedule\"\"\"\n\n    @schedule.setter\n    def schedule(self, schedule: str) -&gt; None:\n        \"\"\"Set the schedule\"\"\"\n\n    @property\n    def features_to_monitor(self) -&gt; List[str]:\n        \"\"\"Return the features to monitor\"\"\"\n\n    @features_to_monitor.setter\n    def features_to_monitor(self, features_to_monitor: List[str]) -&gt; None:\n        \"\"\"Set the features to monitor\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertConfig.dispatch_config","title":"<code>dispatch_config</code>  <code>property</code>","text":"<p>Return the dispatch config</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertConfig.dispatch_type","title":"<code>dispatch_type</code>  <code>property</code>","text":"<p>Return the alert dispatch type</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertConfig.features_to_monitor","title":"<code>features_to_monitor</code>  <code>property</code> <code>writable</code>","text":"<p>Return the features to monitor</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertConfig.rule","title":"<code>rule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert rule</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertConfig.schedule","title":"<code>schedule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the schedule</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertConfig.__init__","title":"<code>__init__(rule=SpcAlertRule(), dispatch_config=None, schedule=None, features_to_monitor=[])</code>","text":"<p>Initialize alert config</p> <p>Parameters:</p> Name Type Description Default <code>rule</code> <code>SpcAlertRule</code> <p>Alert rule to use. Defaults to Standard</p> <code>SpcAlertRule()</code> <code>dispatch_config</code> <code>Optional[SlackDispatchConfig | OpsGenieDispatchConfig]</code> <p>Alert dispatch config. Defaults to console</p> <code>None</code> <code>schedule</code> <code>Optional[str | CommonCrons]</code> <p>Schedule to run monitor. Defaults to daily at midnight</p> <code>None</code> <code>features_to_monitor</code> <code>List[str]</code> <p>List of features to monitor. Defaults to empty list, which means all features</p> <code>[]</code> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    rule: SpcAlertRule = SpcAlertRule(),\n    dispatch_config: Optional[SlackDispatchConfig | OpsGenieDispatchConfig] = None,\n    schedule: Optional[str | CommonCrons] = None,\n    features_to_monitor: List[str] = [],\n):\n    \"\"\"Initialize alert config\n\n    Args:\n        rule:\n            Alert rule to use. Defaults to Standard\n        dispatch_config:\n            Alert dispatch config. Defaults to console\n        schedule:\n            Schedule to run monitor. Defaults to daily at midnight\n        features_to_monitor:\n            List of features to monitor. Defaults to empty list, which means all features\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertRule","title":"<code>SpcAlertRule</code>","text":"Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>class SpcAlertRule:\n    def __init__(\n        self,\n        rule: str = \"8 16 4 8 2 4 1 1\",\n        zones_to_monitor: List[AlertZone] = [\n            AlertZone.Zone1,\n            AlertZone.Zone2,\n            AlertZone.Zone3,\n            AlertZone.Zone4,\n        ],\n    ) -&gt; None:\n        \"\"\"Initialize alert rule\n\n        Args:\n            rule:\n                Rule to use for alerting. Eight digit integer string.\n                Defaults to '8 16 4 8 2 4 1 1'\n            zones_to_monitor:\n                List of zones to monitor. Defaults to all zones.\n        \"\"\"\n\n    @property\n    def rule(self) -&gt; str:\n        \"\"\"Return the alert rule\"\"\"\n\n    @rule.setter\n    def rule(self, rule: str) -&gt; None:\n        \"\"\"Set the alert rule\"\"\"\n\n    @property\n    def zones_to_monitor(self) -&gt; List[AlertZone]:\n        \"\"\"Return the zones to monitor\"\"\"\n\n    @zones_to_monitor.setter\n    def zones_to_monitor(self, zones_to_monitor: List[AlertZone]) -&gt; None:\n        \"\"\"Set the zones to monitor\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertRule.rule","title":"<code>rule</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert rule</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertRule.zones_to_monitor","title":"<code>zones_to_monitor</code>  <code>property</code> <code>writable</code>","text":"<p>Return the zones to monitor</p>"},{"location":"docs/api/scouter/alert/#opsml.scouter.alert._alert.SpcAlertRule.__init__","title":"<code>__init__(rule='8 16 4 8 2 4 1 1', zones_to_monitor=[AlertZone.Zone1, AlertZone.Zone2, AlertZone.Zone3, AlertZone.Zone4])</code>","text":"<p>Initialize alert rule</p> <p>Parameters:</p> Name Type Description Default <code>rule</code> <code>str</code> <p>Rule to use for alerting. Eight digit integer string. Defaults to '8 16 4 8 2 4 1 1'</p> <code>'8 16 4 8 2 4 1 1'</code> <code>zones_to_monitor</code> <code>List[AlertZone]</code> <p>List of zones to monitor. Defaults to all zones.</p> <code>[Zone1, Zone2, Zone3, Zone4]</code> Source code in <code>python/opsml/scouter/alert/_alert.pyi</code> <pre><code>def __init__(\n    self,\n    rule: str = \"8 16 4 8 2 4 1 1\",\n    zones_to_monitor: List[AlertZone] = [\n        AlertZone.Zone1,\n        AlertZone.Zone2,\n        AlertZone.Zone3,\n        AlertZone.Zone4,\n    ],\n) -&gt; None:\n    \"\"\"Initialize alert rule\n\n    Args:\n        rule:\n            Rule to use for alerting. Eight digit integer string.\n            Defaults to '8 16 4 8 2 4 1 1'\n        zones_to_monitor:\n            List of zones to monitor. Defaults to all zones.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/","title":"Client","text":""},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.DriftAlertRequest","title":"<code>DriftAlertRequest</code>","text":"Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>class DriftAlertRequest:\n    def __init__(\n        self,\n        name: str,\n        space: str,\n        version: str,\n        active: bool = False,\n        limit_datetime: Optional[datetime.datetime] = None,\n        limit: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Initialize drift alert request\n\n        Args:\n            name:\n                Name\n            space:\n                Space\n            version:\n                Version\n            active:\n                Whether to get active alerts only\n            limit_datetime:\n                Limit datetime for alerts\n            limit:\n                Limit for number of alerts to return\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.DriftAlertRequest.__init__","title":"<code>__init__(name, space, version, active=False, limit_datetime=None, limit=None)</code>","text":"<p>Initialize drift alert request</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name</p> required <code>space</code> <code>str</code> <p>Space</p> required <code>version</code> <code>str</code> <p>Version</p> required <code>active</code> <code>bool</code> <p>Whether to get active alerts only</p> <code>False</code> <code>limit_datetime</code> <code>Optional[datetime]</code> <p>Limit datetime for alerts</p> <code>None</code> <code>limit</code> <code>Optional[int]</code> <p>Limit for number of alerts to return</p> <code>None</code> Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    space: str,\n    version: str,\n    active: bool = False,\n    limit_datetime: Optional[datetime.datetime] = None,\n    limit: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Initialize drift alert request\n\n    Args:\n        name:\n            Name\n        space:\n            Space\n        version:\n            Version\n        active:\n            Whether to get active alerts only\n        limit_datetime:\n            Limit datetime for alerts\n        limit:\n            Limit for number of alerts to return\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.DriftRequest","title":"<code>DriftRequest</code>","text":"Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>class DriftRequest:\n    def __init__(\n        self,\n        name: str,\n        space: str,\n        version: str,\n        time_interval: TimeInterval,\n        max_data_points: int,\n        drift_type: DriftType,\n    ) -&gt; None:\n        \"\"\"Initialize drift request\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            time_interval:\n                Time window for drift request\n            max_data_points:\n                Maximum data points to return\n            drift_type:\n                Drift type for request\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.DriftRequest.__init__","title":"<code>__init__(name, space, version, time_interval, max_data_points, drift_type)</code>","text":"<p>Initialize drift request</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Model name</p> required <code>space</code> <code>str</code> <p>Model space</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>time_interval</code> <code>TimeInterval</code> <p>Time window for drift request</p> required <code>max_data_points</code> <code>int</code> <p>Maximum data points to return</p> required <code>drift_type</code> <code>DriftType</code> <p>Drift type for request</p> required Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    space: str,\n    version: str,\n    time_interval: TimeInterval,\n    max_data_points: int,\n    drift_type: DriftType,\n) -&gt; None:\n    \"\"\"Initialize drift request\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        time_interval:\n            Time window for drift request\n        max_data_points:\n            Maximum data points to return\n        drift_type:\n            Drift type for request\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.GetProfileRequest","title":"<code>GetProfileRequest</code>","text":"Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>class GetProfileRequest:\n    def __init__(self, name: str, space: str, version: str, drift_type: DriftType) -&gt; None:\n        \"\"\"Initialize get profile request\n\n        Args:\n            name:\n                Profile name\n            space:\n                Profile space\n            version:\n                Profile version\n            drift_type:\n                Profile drift type. A (repo/name/version can be associated with more than one drift type)\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.GetProfileRequest.__init__","title":"<code>__init__(name, space, version, drift_type)</code>","text":"<p>Initialize get profile request</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Profile name</p> required <code>space</code> <code>str</code> <p>Profile space</p> required <code>version</code> <code>str</code> <p>Profile version</p> required <code>drift_type</code> <code>DriftType</code> <p>Profile drift type. A (repo/name/version can be associated with more than one drift type)</p> required Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def __init__(self, name: str, space: str, version: str, drift_type: DriftType) -&gt; None:\n    \"\"\"Initialize get profile request\n\n    Args:\n        name:\n            Profile name\n        space:\n            Profile space\n        version:\n            Profile version\n        drift_type:\n            Profile drift type. A (repo/name/version can be associated with more than one drift type)\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.HTTPConfig","title":"<code>HTTPConfig</code>","text":"Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>class HTTPConfig:\n    server_uri: str\n    username: str\n    password: str\n    auth_token: str\n\n    def __init__(\n        self,\n        server_uri: Optional[str] = None,\n        username: Optional[str] = None,\n        password: Optional[str] = None,\n        auth_token: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"HTTP configuration to use with the HTTPProducer.\n\n        Args:\n            server_uri:\n                URL of the HTTP server to publish messages to.\n                If not provided, the value of the HTTP_server_uri environment variable is used.\n\n            username:\n                Username for basic authentication.\n\n            password:\n                Password for basic authentication.\n\n            auth_token:\n                Authorization token to use for authentication.\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.HTTPConfig.__init__","title":"<code>__init__(server_uri=None, username=None, password=None, auth_token=None)</code>","text":"<p>HTTP configuration to use with the HTTPProducer.</p> <p>Parameters:</p> Name Type Description Default <code>server_uri</code> <code>Optional[str]</code> <p>URL of the HTTP server to publish messages to. If not provided, the value of the HTTP_server_uri environment variable is used.</p> <code>None</code> <code>username</code> <code>Optional[str]</code> <p>Username for basic authentication.</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>Password for basic authentication.</p> <code>None</code> <code>auth_token</code> <code>Optional[str]</code> <p>Authorization token to use for authentication.</p> <code>None</code> Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def __init__(\n    self,\n    server_uri: Optional[str] = None,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    auth_token: Optional[str] = None,\n) -&gt; None:\n    \"\"\"HTTP configuration to use with the HTTPProducer.\n\n    Args:\n        server_uri:\n            URL of the HTTP server to publish messages to.\n            If not provided, the value of the HTTP_server_uri environment variable is used.\n\n        username:\n            Username for basic authentication.\n\n        password:\n            Password for basic authentication.\n\n        auth_token:\n            Authorization token to use for authentication.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.ProfileStatusRequest","title":"<code>ProfileStatusRequest</code>","text":"Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>class ProfileStatusRequest:\n    def __init__(self, name: str, space: str, version: str, drift_type: DriftType, active: bool) -&gt; None:\n        \"\"\"Initialize profile status request\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            drift_type:\n                Profile drift type. A (repo/name/version can be associated with more than one drift type)\n            active:\n                Whether to set the profile as active or inactive\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.ProfileStatusRequest.__init__","title":"<code>__init__(name, space, version, drift_type, active)</code>","text":"<p>Initialize profile status request</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Model name</p> required <code>space</code> <code>str</code> <p>Model space</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>drift_type</code> <code>DriftType</code> <p>Profile drift type. A (repo/name/version can be associated with more than one drift type)</p> required <code>active</code> <code>bool</code> <p>Whether to set the profile as active or inactive</p> required Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def __init__(self, name: str, space: str, version: str, drift_type: DriftType, active: bool) -&gt; None:\n    \"\"\"Initialize profile status request\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        drift_type:\n            Profile drift type. A (repo/name/version can be associated with more than one drift type)\n        active:\n            Whether to set the profile as active or inactive\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.ScouterClient","title":"<code>ScouterClient</code>","text":"<p>Helper client for interacting with Scouter Server</p> Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>class ScouterClient:\n    \"\"\"Helper client for interacting with Scouter Server\"\"\"\n\n    def __init__(self, config: Optional[HTTPConfig] = None) -&gt; None:\n        \"\"\"Initialize ScouterClient\n\n        Args:\n            config:\n                HTTP configuration for interacting with the server.\n        \"\"\"\n\n    def get_binned_drift(self, drift_request: DriftRequest) -&gt; Any:\n        \"\"\"Get drift map from server\n\n        Args:\n            drift_request:\n                DriftRequest object\n\n        Returns:\n            Drift map of type BinnedMetrics | BinnedPsiFeatureMetrics | BinnedSpcFeatureMetrics\n        \"\"\"\n\n    def register_profile(self, profile: Any, set_active: bool = False) -&gt; bool:\n        \"\"\"Registers a drift profile with the server\n\n        Args:\n            profile:\n                Drift profile\n            set_active:\n                Whether to set the profile as active or inactive\n\n        Returns:\n            boolean\n        \"\"\"\n\n    def update_profile_status(self, request: ProfileStatusRequest) -&gt; bool:\n        \"\"\"Update profile status\n\n        Args:\n            request:\n                ProfileStatusRequest\n\n        Returns:\n            boolean\n        \"\"\"\n\n    def get_alerts(self, request: DriftAlertRequest) -&gt; List[Alert]:\n        \"\"\"Get alerts\n\n        Args:\n            request:\n                DriftAlertRequest\n\n        Returns:\n            List[Alert]\n        \"\"\"\n\n    def download_profile(self, request: GetProfileRequest, path: Optional[Path]) -&gt; str:\n        \"\"\"Download profile\n\n        Args:\n            request:\n                GetProfileRequest\n            path:\n                Path to save profile\n\n        Returns:\n            Path to downloaded profile\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.ScouterClient.__init__","title":"<code>__init__(config=None)</code>","text":"<p>Initialize ScouterClient</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Optional[HTTPConfig]</code> <p>HTTP configuration for interacting with the server.</p> <code>None</code> Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def __init__(self, config: Optional[HTTPConfig] = None) -&gt; None:\n    \"\"\"Initialize ScouterClient\n\n    Args:\n        config:\n            HTTP configuration for interacting with the server.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.ScouterClient.download_profile","title":"<code>download_profile(request, path)</code>","text":"<p>Download profile</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>GetProfileRequest</code> <p>GetProfileRequest</p> required <code>path</code> <code>Optional[Path]</code> <p>Path to save profile</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to downloaded profile</p> Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def download_profile(self, request: GetProfileRequest, path: Optional[Path]) -&gt; str:\n    \"\"\"Download profile\n\n    Args:\n        request:\n            GetProfileRequest\n        path:\n            Path to save profile\n\n    Returns:\n        Path to downloaded profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.ScouterClient.get_alerts","title":"<code>get_alerts(request)</code>","text":"<p>Get alerts</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>DriftAlertRequest</code> <p>DriftAlertRequest</p> required <p>Returns:</p> Type Description <code>List[Alert]</code> <p>List[Alert]</p> Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def get_alerts(self, request: DriftAlertRequest) -&gt; List[Alert]:\n    \"\"\"Get alerts\n\n    Args:\n        request:\n            DriftAlertRequest\n\n    Returns:\n        List[Alert]\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.ScouterClient.get_binned_drift","title":"<code>get_binned_drift(drift_request)</code>","text":"<p>Get drift map from server</p> <p>Parameters:</p> Name Type Description Default <code>drift_request</code> <code>DriftRequest</code> <p>DriftRequest object</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Drift map of type BinnedMetrics | BinnedPsiFeatureMetrics | BinnedSpcFeatureMetrics</p> Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def get_binned_drift(self, drift_request: DriftRequest) -&gt; Any:\n    \"\"\"Get drift map from server\n\n    Args:\n        drift_request:\n            DriftRequest object\n\n    Returns:\n        Drift map of type BinnedMetrics | BinnedPsiFeatureMetrics | BinnedSpcFeatureMetrics\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.ScouterClient.register_profile","title":"<code>register_profile(profile, set_active=False)</code>","text":"<p>Registers a drift profile with the server</p> <p>Parameters:</p> Name Type Description Default <code>profile</code> <code>Any</code> <p>Drift profile</p> required <code>set_active</code> <code>bool</code> <p>Whether to set the profile as active or inactive</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>boolean</p> Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def register_profile(self, profile: Any, set_active: bool = False) -&gt; bool:\n    \"\"\"Registers a drift profile with the server\n\n    Args:\n        profile:\n            Drift profile\n        set_active:\n            Whether to set the profile as active or inactive\n\n    Returns:\n        boolean\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/client/#opsml.scouter.client._client.ScouterClient.update_profile_status","title":"<code>update_profile_status(request)</code>","text":"<p>Update profile status</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>ProfileStatusRequest</code> <p>ProfileStatusRequest</p> required <p>Returns:</p> Type Description <code>bool</code> <p>boolean</p> Source code in <code>python/opsml/scouter/client/_client.pyi</code> <pre><code>def update_profile_status(self, request: ProfileStatusRequest) -&gt; bool:\n    \"\"\"Update profile status\n\n    Args:\n        request:\n            ProfileStatusRequest\n\n    Returns:\n        boolean\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/","title":"Drift","text":""},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Bin","title":"<code>Bin</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class Bin:\n    @property\n    def id(self) -&gt; int:\n        \"\"\"Return the bin id.\"\"\"\n\n    @property\n    def lower_limit(self) -&gt; float:\n        \"\"\"Return the lower limit of the bin.\"\"\"\n\n    @property\n    def upper_limit(self) -&gt; Optional[float]:\n        \"\"\"Return the upper limit of the bin.\"\"\"\n\n    @property\n    def proportion(self) -&gt; float:\n        \"\"\"Return the proportion of data found in the bin.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Bin.id","title":"<code>id</code>  <code>property</code>","text":"<p>Return the bin id.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Bin.lower_limit","title":"<code>lower_limit</code>  <code>property</code>","text":"<p>Return the lower limit of the bin.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Bin.proportion","title":"<code>proportion</code>  <code>property</code>","text":"<p>Return the proportion of data found in the bin.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Bin.upper_limit","title":"<code>upper_limit</code>  <code>property</code>","text":"<p>Return the upper limit of the bin.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile","title":"<code>CustomDriftProfile</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class CustomDriftProfile:\n    def __init__(\n        self,\n        config: CustomMetricDriftConfig,\n        metrics: list[CustomMetric],\n    ):\n        \"\"\"Initialize a CustomDriftProfile instance.\n\n        Args:\n            config (CustomMetricDriftConfig):\n                The configuration for custom metric drift detection.\n            metrics (list[CustomMetric]):\n                A list of CustomMetric objects representing the metrics to be monitored.\n\n        Example:\n            config = CustomMetricDriftConfig(...)\n            metrics = [CustomMetric(\"accuracy\", 0.95), CustomMetric(\"f1_score\", 0.88)]\n            profile = CustomDriftProfile(config, metrics, \"1.0.0\")\n        \"\"\"\n\n    @property\n    def config(self) -&gt; CustomMetricDriftConfig:\n        \"\"\"Return the drift config\"\"\"\n\n    @property\n    def metrics(self) -&gt; dict[str, float]:\n        \"\"\"Return custom metrics and their corresponding values\"\"\"\n\n    @property\n    def scouter_version(self) -&gt; str:\n        \"\"\"Return scouter version used to create DriftProfile\"\"\"\n\n    @property\n    def custom_metrics(self) -&gt; list[CustomMetric]:\n        \"\"\"Return custom metric objects that were used to create the drift profile\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Sting representation of DriftProfile\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of drift profile\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Return dictionary representation of drift profile\"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift profile to json file\n\n        Args:\n            path:\n                Optional path to save the drift profile. If None, outputs to `custom_drift_profile.json`\n\n        Returns:\n            Path to the saved json file\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"CustomDriftProfile\":\n        \"\"\"Load drift profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the drift profile\n\n        \"\"\"\n\n    @staticmethod\n    def model_validate(data: Dict[str, Any]) -&gt; \"CustomDriftProfile\":\n        \"\"\"Load drift profile from dictionary\n\n        Args:\n            data:\n                DriftProfile dictionary\n        \"\"\"\n\n    @staticmethod\n    def from_file(path: Path) -&gt; \"CustomDriftProfile\":\n        \"\"\"Load drift profile from file\n\n        Args:\n            path: Path to the file\n        \"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[CustomMetricAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            space (Optional[str]):\n                Model space\n            name (Optional[str]):\n                Model name\n            version (Optional[str]):\n                Model version\n            alert_config (Optional[CustomMetricAlertConfig]):\n                Custom metric alert configuration\n\n        Returns:\n            None\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.config","title":"<code>config</code>  <code>property</code>","text":"<p>Return the drift config</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.custom_metrics","title":"<code>custom_metrics</code>  <code>property</code>","text":"<p>Return custom metric objects that were used to create the drift profile</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>Return custom metrics and their corresponding values</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.scouter_version","title":"<code>scouter_version</code>  <code>property</code>","text":"<p>Return scouter version used to create DriftProfile</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.__init__","title":"<code>__init__(config, metrics)</code>","text":"<p>Initialize a CustomDriftProfile instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>CustomMetricDriftConfig</code> <p>The configuration for custom metric drift detection.</p> required <code>metrics</code> <code>list[CustomMetric]</code> <p>A list of CustomMetric objects representing the metrics to be monitored.</p> required Example <p>config = CustomMetricDriftConfig(...) metrics = [CustomMetric(\"accuracy\", 0.95), CustomMetric(\"f1_score\", 0.88)] profile = CustomDriftProfile(config, metrics, \"1.0.0\")</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    config: CustomMetricDriftConfig,\n    metrics: list[CustomMetric],\n):\n    \"\"\"Initialize a CustomDriftProfile instance.\n\n    Args:\n        config (CustomMetricDriftConfig):\n            The configuration for custom metric drift detection.\n        metrics (list[CustomMetric]):\n            A list of CustomMetric objects representing the metrics to be monitored.\n\n    Example:\n        config = CustomMetricDriftConfig(...)\n        metrics = [CustomMetric(\"accuracy\", 0.95), CustomMetric(\"f1_score\", 0.88)]\n        profile = CustomDriftProfile(config, metrics, \"1.0.0\")\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.__str__","title":"<code>__str__()</code>","text":"<p>Sting representation of DriftProfile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.from_file","title":"<code>from_file(path)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the file</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef from_file(path: Path) -&gt; \"CustomDriftProfile\":\n    \"\"\"Load drift profile from file\n\n    Args:\n        path: Path to the file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of drift profile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Return dictionary representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of drift profile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.model_validate","title":"<code>model_validate(data)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from dictionary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>DriftProfile dictionary</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate(data: Dict[str, Any]) -&gt; \"CustomDriftProfile\":\n    \"\"\"Load drift profile from dictionary\n\n    Args:\n        data:\n            DriftProfile dictionary\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift profile</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"CustomDriftProfile\":\n    \"\"\"Load drift profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the drift profile\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift profile. If None, outputs to <code>custom_drift_profile.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift profile to json file\n\n    Args:\n        path:\n            Optional path to save the drift profile. If None, outputs to `custom_drift_profile.json`\n\n    Returns:\n        Path to the saved json file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomDriftProfile.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>alert_config</code> <code>Optional[CustomMetricAlertConfig]</code> <p>Custom metric alert configuration</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[CustomMetricAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        space (Optional[str]):\n            Model space\n        name (Optional[str]):\n            Model name\n        version (Optional[str]):\n            Model version\n        alert_config (Optional[CustomMetricAlertConfig]):\n            Custom metric alert configuration\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetric","title":"<code>CustomMetric</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class CustomMetric:\n    def __init__(\n        self,\n        name: str,\n        value: float,\n        alert_threshold: AlertThreshold,\n        alert_threshold_value: Optional[float] = None,\n    ):\n        \"\"\"\n        Initialize a custom metric for alerting.\n\n        This class represents a custom metric that uses comparison-based alerting. It applies\n        an alert condition to a single metric value.\n\n        Args:\n            name (str): The name of the metric being monitored. This should be a\n                descriptive identifier for the metric.\n            value (float): The current value of the metric.\n            alert_threshold (AlertThreshold):\n                The condition used to determine when an alert should be triggered.\n            alert_threshold_value (Optional[float]):\n                The threshold or boundary value used in conjunction with the alert_threshold.\n                If supplied, this value will be added or subtracted from the provided metric value to\n                determine if an alert should be triggered.\n\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the metric name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set the metric name\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the metric value\"\"\"\n\n    @value.setter\n    def value(self, value: float) -&gt; None:\n        \"\"\"Set the metric value\"\"\"\n\n    @property\n    def alert_condition(self) -&gt; CustomMetricAlertCondition:\n        \"\"\"Return the alert_condition\"\"\"\n\n    @alert_condition.setter\n    def alert_condition(self, alert_condition: CustomMetricAlertCondition) -&gt; None:\n        \"\"\"Set the alert_condition\"\"\"\n\n    @property\n    def alert_threshold(self) -&gt; AlertThreshold:\n        \"\"\"Return the alert_threshold\"\"\"\n\n    @property\n    def alert_threshold_value(self) -&gt; Optional[float]:\n        \"\"\"Return the alert_threshold_value\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetric.alert_condition","title":"<code>alert_condition</code>  <code>property</code> <code>writable</code>","text":"<p>Return the alert_condition</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetric.alert_threshold","title":"<code>alert_threshold</code>  <code>property</code>","text":"<p>Return the alert_threshold</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetric.alert_threshold_value","title":"<code>alert_threshold_value</code>  <code>property</code>","text":"<p>Return the alert_threshold_value</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetric.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Return the metric name</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetric.value","title":"<code>value</code>  <code>property</code> <code>writable</code>","text":"<p>Return the metric value</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetric.__init__","title":"<code>__init__(name, value, alert_threshold, alert_threshold_value=None)</code>","text":"<p>Initialize a custom metric for alerting.</p> <p>This class represents a custom metric that uses comparison-based alerting. It applies an alert condition to a single metric value.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric being monitored. This should be a descriptive identifier for the metric.</p> required <code>value</code> <code>float</code> <p>The current value of the metric.</p> required <code>alert_threshold</code> <code>AlertThreshold</code> <p>The condition used to determine when an alert should be triggered.</p> required <code>alert_threshold_value</code> <code>Optional[float]</code> <p>The threshold or boundary value used in conjunction with the alert_threshold. If supplied, this value will be added or subtracted from the provided metric value to determine if an alert should be triggered.</p> <code>None</code> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    value: float,\n    alert_threshold: AlertThreshold,\n    alert_threshold_value: Optional[float] = None,\n):\n    \"\"\"\n    Initialize a custom metric for alerting.\n\n    This class represents a custom metric that uses comparison-based alerting. It applies\n    an alert condition to a single metric value.\n\n    Args:\n        name (str): The name of the metric being monitored. This should be a\n            descriptive identifier for the metric.\n        value (float): The current value of the metric.\n        alert_threshold (AlertThreshold):\n            The condition used to determine when an alert should be triggered.\n        alert_threshold_value (Optional[float]):\n            The threshold or boundary value used in conjunction with the alert_threshold.\n            If supplied, this value will be added or subtracted from the provided metric value to\n            determine if an alert should be triggered.\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetric.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig","title":"<code>CustomMetricDriftConfig</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class CustomMetricDriftConfig:\n    def __init__(\n        self,\n        space: str = \"__missing__\",\n        name: str = \"__missing__\",\n        version: str = \"0.1.0\",\n        sample_size: int = 25,\n        alert_config: CustomMetricAlertConfig = CustomMetricAlertConfig(),\n    ):\n        \"\"\"Initialize drift config\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version. Defaults to 0.1.0\n            sample_size:\n                Sample size\n            alert_config:\n                Custom metric alert configuration\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Model space\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set model space\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Model Name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set model name\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Model version\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set model version\"\"\"\n\n    @property\n    def drift_type(self) -&gt; DriftType:\n        \"\"\"Drift type\"\"\"\n\n    @property\n    def alert_config(self) -&gt; CustomMetricAlertConfig:\n        \"\"\"get alert_config\"\"\"\n\n    @alert_config.setter\n    def alert_config(self, alert_config: CustomMetricAlertConfig) -&gt; None:\n        \"\"\"Set alert_config\"\"\"\n\n    @staticmethod\n    def load_from_json_file(path: Path) -&gt; \"CustomMetricDriftConfig\":\n        \"\"\"Load config from json file\n        Args:\n            path:\n                Path to json file to load config from.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the config.\"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[CustomMetricAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            alert_config:\n                Custom metric alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.alert_config","title":"<code>alert_config</code>  <code>property</code> <code>writable</code>","text":"<p>get alert_config</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.drift_type","title":"<code>drift_type</code>  <code>property</code>","text":"<p>Drift type</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Model Name</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Model space</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Model version</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.__init__","title":"<code>__init__(space='__missing__', name='__missing__', version='0.1.0', sample_size=25, alert_config=CustomMetricAlertConfig())</code>","text":"<p>Initialize drift config Args:     space:         Model space     name:         Model name     version:         Model version. Defaults to 0.1.0     sample_size:         Sample size     alert_config:         Custom metric alert configuration</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    space: str = \"__missing__\",\n    name: str = \"__missing__\",\n    version: str = \"0.1.0\",\n    sample_size: int = 25,\n    alert_config: CustomMetricAlertConfig = CustomMetricAlertConfig(),\n):\n    \"\"\"Initialize drift config\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version. Defaults to 0.1.0\n        sample_size:\n            Sample size\n        alert_config:\n            Custom metric alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.load_from_json_file","title":"<code>load_from_json_file(path)</code>  <code>staticmethod</code>","text":"<p>Load config from json file Args:     path:         Path to json file to load config from.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef load_from_json_file(path: Path) -&gt; \"CustomMetricDriftConfig\":\n    \"\"\"Load config from json file\n    Args:\n        path:\n            Path to json file to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the config.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.CustomMetricDriftConfig.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args Args:     space:         Model space     name:         Model name     version:         Model version     alert_config:         Custom metric alert configuration</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[CustomMetricAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        alert_config:\n            Custom metric alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Drifter","title":"<code>Drifter</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class Drifter:\n    def __init__(self) -&gt; None:\n        \"\"\"Instantiate Rust Drifter class that is\n        used to create monitoring profiles and compute drifts.\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        data: Any,\n        config: SpcDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftProfile:\n        \"\"\"Create a SPC (Statistical process control) drift profile from the provided data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n            config:\n                SpcDriftConfig\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftProfile\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        data: Any,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftProfile:\n        \"\"\"Create a SPC (Statistical process control) drift profile from the provided data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n            config:\n                SpcDriftConfig\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftProfile\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        data: Any,\n        config: PsiDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; PsiDriftProfile:\n        \"\"\"Create a PSI (population stability index) drift profile from the provided data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n            config:\n                PsiDriftConfig\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            PsiDriftProfile\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        data: Union[CustomMetric, List[CustomMetric]],\n        config: CustomMetricDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; CustomDriftProfile:\n        \"\"\"Create a custom drift profile from data.\n\n        Args:\n            data:\n                CustomMetric or list of CustomMetric.\n            config:\n                CustomMetricDriftConfig\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            CustomDriftProfile\n        \"\"\"\n\n    def create_drift_profile(  # type: ignore\n        self,\n        data: Any,\n        config: Optional[Union[SpcDriftConfig, PsiDriftConfig, CustomMetricDriftConfig]] = None,\n        data_type: Optional[DataType] = None,\n    ) -&gt; Union[SpcDriftProfile, PsiDriftProfile, CustomDriftProfile]:\n        \"\"\"Create a drift profile from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe, pandas dataframe or a list of CustomMetric if creating\n                a custom metric profile.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n            config:\n                Drift config that will be used for monitoring\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    def create_llm_drift_profile(\n        self,\n        config: LLMDriftConfig,\n        metrics: List[LLMDriftMetric],\n        workflow: Optional[Workflow] = None,\n    ) -&gt; LLMDriftProfile:\n        \"\"\"Initialize a LLMDriftProfile for LLM evaluation and drift detection.\n\n        LLM evaluations are run asynchronously on the scouter server.\n\n        Logic flow:\n            1. If only metrics are provided, a workflow will be created automatically\n               from the metrics. In this case a prompt is required for each metric.\n            2. If a workflow is provided, it will be parsed and validated for compatibility:\n               - A list of metrics to evaluate workflow output must be provided\n               - Metric names must correspond to the final task names in the workflow\n\n        Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n        Args:\n            config (LLMDriftConfig):\n                The configuration for the LLM drift profile containing space, name,\n                version, and alert settings.\n            metrics (list[LLMDriftMetric]):\n                A list of LLMDriftMetric objects representing the metrics to be monitored.\n                Each metric defines evaluation criteria and alert thresholds.\n            workflow (Optional[Workflow]):\n                Optional custom workflow for advanced evaluation scenarios. If provided,\n                the workflow will be validated to ensure proper parameter and response\n                type configuration.\n\n        Returns:\n            LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n        Raises:\n            ProfileError: If workflow validation fails, metrics are empty when no\n                workflow is provided, or if workflow tasks don't match metric names.\n\n        Examples:\n            Basic usage with metrics only:\n\n            &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n            &gt;&gt;&gt; metrics = [\n            ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n            ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n            ... ]\n            &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics)\n\n            Advanced usage with custom workflow:\n\n            &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n            &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n            &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics, workflow)\n\n        Note:\n            - When using custom workflows, ensure final tasks have Score response types\n            - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n            - All metric names must match corresponding workflow task names\n        \"\"\"\n\n    @overload\n    def compute_drift(\n        self,\n        data: Any,\n        drift_profile: SpcDriftProfile,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftMap:\n        \"\"\"Create a drift map from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n            drift_profile:\n                Drift profile to use to compute drift map\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftMap\n        \"\"\"\n\n    @overload\n    def compute_drift(\n        self,\n        data: Any,\n        drift_profile: PsiDriftProfile,\n        data_type: Optional[DataType] = None,\n    ) -&gt; PsiDriftMap:\n        \"\"\"Create a drift map from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n            drift_profile:\n                Drift profile to use to compute drift map\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            PsiDriftMap\n        \"\"\"\n\n    @overload\n    def compute_drift(\n        self,\n        data: Union[LLMRecord, List[LLMRecord]],\n        drift_profile: LLMDriftProfile,\n        data_type: Optional[DataType] = None,\n    ) -&gt; LLMDriftMap:\n        \"\"\"Create a drift map from data.\n\n        Args:\n            data:\n\n            drift_profile:\n                Drift profile to use to compute drift map\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            LLMDriftMap\n        \"\"\"\n\n    def compute_drift(  # type: ignore\n        self,\n        data: Any,\n        drift_profile: Union[SpcDriftProfile, PsiDriftProfile, LLMDriftProfile],\n        data_type: Optional[DataType] = None,\n    ) -&gt; Union[SpcDriftMap, PsiDriftMap, LLMDriftMap]:\n        \"\"\"Create a drift map from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or a pandas dataframe.\n            drift_profile:\n                Drift profile to use to compute drift map\n            data_type:\n                Optional data type. Inferred from data if not provided.\n\n        Returns:\n            SpcDriftMap, PsiDriftMap or LLMDriftMap\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Drifter.__init__","title":"<code>__init__()</code>","text":"<p>Instantiate Rust Drifter class that is used to create monitoring profiles and compute drifts.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Instantiate Rust Drifter class that is\n    used to create monitoring profiles and compute drifts.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Drifter.compute_drift","title":"<code>compute_drift(data, drift_profile, data_type=None)</code>","text":"<pre><code>compute_drift(\n    data: Any,\n    drift_profile: SpcDriftProfile,\n    data_type: Optional[DataType] = None,\n) -&gt; SpcDriftMap\n</code></pre><pre><code>compute_drift(\n    data: Any,\n    drift_profile: PsiDriftProfile,\n    data_type: Optional[DataType] = None,\n) -&gt; PsiDriftMap\n</code></pre><pre><code>compute_drift(\n    data: Union[LLMRecord, List[LLMRecord]],\n    drift_profile: LLMDriftProfile,\n    data_type: Optional[DataType] = None,\n) -&gt; LLMDriftMap\n</code></pre> <p>Create a drift map from data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to create a data profile from. Data can be a numpy array, a polars dataframe or a pandas dataframe.</p> required <code>drift_profile</code> <code>Union[SpcDriftProfile, PsiDriftProfile, LLMDriftProfile]</code> <p>Drift profile to use to compute drift map</p> required <code>data_type</code> <code>Optional[DataType]</code> <p>Optional data type. Inferred from data if not provided.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[SpcDriftMap, PsiDriftMap, LLMDriftMap]</code> <p>SpcDriftMap, PsiDriftMap or LLMDriftMap</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def compute_drift(  # type: ignore\n    self,\n    data: Any,\n    drift_profile: Union[SpcDriftProfile, PsiDriftProfile, LLMDriftProfile],\n    data_type: Optional[DataType] = None,\n) -&gt; Union[SpcDriftMap, PsiDriftMap, LLMDriftMap]:\n    \"\"\"Create a drift map from data.\n\n    Args:\n        data:\n            Data to create a data profile from. Data can be a numpy array,\n            a polars dataframe or a pandas dataframe.\n        drift_profile:\n            Drift profile to use to compute drift map\n        data_type:\n            Optional data type. Inferred from data if not provided.\n\n    Returns:\n        SpcDriftMap, PsiDriftMap or LLMDriftMap\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Drifter.create_drift_profile","title":"<code>create_drift_profile(data, config=None, data_type=None)</code>","text":"<pre><code>create_drift_profile(\n    data: Any,\n    config: SpcDriftConfig,\n    data_type: Optional[DataType] = None,\n) -&gt; SpcDriftProfile\n</code></pre><pre><code>create_drift_profile(\n    data: Any, data_type: Optional[DataType] = None\n) -&gt; SpcDriftProfile\n</code></pre><pre><code>create_drift_profile(\n    data: Any,\n    config: PsiDriftConfig,\n    data_type: Optional[DataType] = None,\n) -&gt; PsiDriftProfile\n</code></pre><pre><code>create_drift_profile(\n    data: Union[CustomMetric, List[CustomMetric]],\n    config: CustomMetricDriftConfig,\n    data_type: Optional[DataType] = None,\n) -&gt; CustomDriftProfile\n</code></pre> <p>Create a drift profile from data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to create a data profile from. Data can be a numpy array, a polars dataframe, pandas dataframe or a list of CustomMetric if creating a custom metric profile.</p> <p>Data is expected to not contain any missing values, NaNs or infinities</p> required <code>config</code> <code>Optional[Union[SpcDriftConfig, PsiDriftConfig, CustomMetricDriftConfig]]</code> <p>Drift config that will be used for monitoring</p> <code>None</code> <code>data_type</code> <code>Optional[DataType]</code> <p>Optional data type. Inferred from data if not provided.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[SpcDriftProfile, PsiDriftProfile, CustomDriftProfile]</code> <p>SpcDriftProfile, PsiDriftProfile or CustomDriftProfile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def create_drift_profile(  # type: ignore\n    self,\n    data: Any,\n    config: Optional[Union[SpcDriftConfig, PsiDriftConfig, CustomMetricDriftConfig]] = None,\n    data_type: Optional[DataType] = None,\n) -&gt; Union[SpcDriftProfile, PsiDriftProfile, CustomDriftProfile]:\n    \"\"\"Create a drift profile from data.\n\n    Args:\n        data:\n            Data to create a data profile from. Data can be a numpy array,\n            a polars dataframe, pandas dataframe or a list of CustomMetric if creating\n            a custom metric profile.\n\n            **Data is expected to not contain any missing values, NaNs or infinities**\n\n        config:\n            Drift config that will be used for monitoring\n        data_type:\n            Optional data type. Inferred from data if not provided.\n\n    Returns:\n        SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Drifter.create_llm_drift_profile","title":"<code>create_llm_drift_profile(config, metrics, workflow=None)</code>","text":"<p>Initialize a LLMDriftProfile for LLM evaluation and drift detection.</p> <p>LLM evaluations are run asynchronously on the scouter server.</p> Logic flow <ol> <li>If only metrics are provided, a workflow will be created automatically    from the metrics. In this case a prompt is required for each metric.</li> <li>If a workflow is provided, it will be parsed and validated for compatibility:</li> <li>A list of metrics to evaluate workflow output must be provided</li> <li>Metric names must correspond to the final task names in the workflow</li> </ol> <p>Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LLMDriftConfig</code> <p>The configuration for the LLM drift profile containing space, name, version, and alert settings.</p> required <code>metrics</code> <code>list[LLMDriftMetric]</code> <p>A list of LLMDriftMetric objects representing the metrics to be monitored. Each metric defines evaluation criteria and alert thresholds.</p> required <code>workflow</code> <code>Optional[Workflow]</code> <p>Optional custom workflow for advanced evaluation scenarios. If provided, the workflow will be validated to ensure proper parameter and response type configuration.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>LLMDriftProfile</code> <code>LLMDriftProfile</code> <p>Configured profile ready for LLM drift monitoring.</p> <p>Raises:</p> Type Description <code>ProfileError</code> <p>If workflow validation fails, metrics are empty when no workflow is provided, or if workflow tasks don't match metric names.</p> <p>Examples:</p> <p>Basic usage with metrics only:</p> <pre><code>&gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n&gt;&gt;&gt; metrics = [\n...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n... ]\n&gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics)\n</code></pre> <p>Advanced usage with custom workflow:</p> <pre><code>&gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n&gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n&gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics, workflow)\n</code></pre> Note <ul> <li>When using custom workflows, ensure final tasks have Score response types</li> <li>Initial workflow tasks must include \"input\" and/or \"response\" parameters</li> <li>All metric names must match corresponding workflow task names</li> </ul> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def create_llm_drift_profile(\n    self,\n    config: LLMDriftConfig,\n    metrics: List[LLMDriftMetric],\n    workflow: Optional[Workflow] = None,\n) -&gt; LLMDriftProfile:\n    \"\"\"Initialize a LLMDriftProfile for LLM evaluation and drift detection.\n\n    LLM evaluations are run asynchronously on the scouter server.\n\n    Logic flow:\n        1. If only metrics are provided, a workflow will be created automatically\n           from the metrics. In this case a prompt is required for each metric.\n        2. If a workflow is provided, it will be parsed and validated for compatibility:\n           - A list of metrics to evaluate workflow output must be provided\n           - Metric names must correspond to the final task names in the workflow\n\n    Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n    Args:\n        config (LLMDriftConfig):\n            The configuration for the LLM drift profile containing space, name,\n            version, and alert settings.\n        metrics (list[LLMDriftMetric]):\n            A list of LLMDriftMetric objects representing the metrics to be monitored.\n            Each metric defines evaluation criteria and alert thresholds.\n        workflow (Optional[Workflow]):\n            Optional custom workflow for advanced evaluation scenarios. If provided,\n            the workflow will be validated to ensure proper parameter and response\n            type configuration.\n\n    Returns:\n        LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n    Raises:\n        ProfileError: If workflow validation fails, metrics are empty when no\n            workflow is provided, or if workflow tasks don't match metric names.\n\n    Examples:\n        Basic usage with metrics only:\n\n        &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n        &gt;&gt;&gt; metrics = [\n        ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n        ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n        ... ]\n        &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics)\n\n        Advanced usage with custom workflow:\n\n        &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n        &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n        &gt;&gt;&gt; profile = Drifter().create_llm_drift_profile(config, metrics, workflow)\n\n    Note:\n        - When using custom workflows, ensure final tasks have Score response types\n        - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n        - All metric names must match corresponding workflow task names\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.FeatureDrift","title":"<code>FeatureDrift</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class FeatureDrift:\n    @property\n    def samples(self) -&gt; List[float]:\n        \"\"\"Return list of samples\"\"\"\n\n    @property\n    def drift(self) -&gt; List[float]:\n        \"\"\"Return list of drift values\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of feature drift\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.FeatureDrift.drift","title":"<code>drift</code>  <code>property</code>","text":"<p>Return list of drift values</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.FeatureDrift.samples","title":"<code>samples</code>  <code>property</code>","text":"<p>Return list of samples</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.FeatureDrift.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of feature drift</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of feature drift\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.FeatureMap","title":"<code>FeatureMap</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class FeatureMap:\n    @property\n    def features(self) -&gt; Dict[str, Dict[str, int]]:\n        \"\"\"Return the feature map.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the feature map.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.FeatureMap.features","title":"<code>features</code>  <code>property</code>","text":"<p>Return the feature map.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.FeatureMap.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the feature map.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the feature map.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig","title":"<code>LLMDriftConfig</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class LLMDriftConfig:\n    def __init__(\n        self,\n        space: str = \"__missing__\",\n        name: str = \"__missing__\",\n        version: str = \"0.1.0\",\n        sample_rate: int = 5,\n        alert_config: LLMAlertConfig = LLMAlertConfig(),\n    ):\n        \"\"\"Initialize drift config\n        Args:\n            space:\n                Space to associate with the config\n            name:\n                Name to associate with the config\n            version:\n                Version to associate with the config. Defaults to 0.1.0\n            sample_rate:\n                Sample rate for LLM drift detection. Defaults to 5.\n            alert_config:\n                Custom metric alert configuration\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Model space\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set model space\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Model Name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set model name\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Model version\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set model version\"\"\"\n\n    @property\n    def drift_type(self) -&gt; DriftType:\n        \"\"\"Drift type\"\"\"\n\n    @property\n    def alert_config(self) -&gt; LLMAlertConfig:\n        \"\"\"get alert_config\"\"\"\n\n    @alert_config.setter\n    def alert_config(self, alert_config: LLMAlertConfig) -&gt; None:\n        \"\"\"Set alert_config\"\"\"\n\n    @staticmethod\n    def load_from_json_file(path: Path) -&gt; \"LLMDriftConfig\":\n        \"\"\"Load config from json file\n        Args:\n            path:\n                Path to json file to load config from.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the config.\"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[LLMAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n        Args:\n            space:\n                Space to associate with the config\n            name:\n                Name to associate with the config\n            version:\n                Version to associate with the config\n            alert_config:\n                LLM alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.alert_config","title":"<code>alert_config</code>  <code>property</code> <code>writable</code>","text":"<p>get alert_config</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.drift_type","title":"<code>drift_type</code>  <code>property</code>","text":"<p>Drift type</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Model Name</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Model space</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Model version</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.__init__","title":"<code>__init__(space='__missing__', name='__missing__', version='0.1.0', sample_rate=5, alert_config=LLMAlertConfig())</code>","text":"<p>Initialize drift config Args:     space:         Space to associate with the config     name:         Name to associate with the config     version:         Version to associate with the config. Defaults to 0.1.0     sample_rate:         Sample rate for LLM drift detection. Defaults to 5.     alert_config:         Custom metric alert configuration</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    space: str = \"__missing__\",\n    name: str = \"__missing__\",\n    version: str = \"0.1.0\",\n    sample_rate: int = 5,\n    alert_config: LLMAlertConfig = LLMAlertConfig(),\n):\n    \"\"\"Initialize drift config\n    Args:\n        space:\n            Space to associate with the config\n        name:\n            Name to associate with the config\n        version:\n            Version to associate with the config. Defaults to 0.1.0\n        sample_rate:\n            Sample rate for LLM drift detection. Defaults to 5.\n        alert_config:\n            Custom metric alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.load_from_json_file","title":"<code>load_from_json_file(path)</code>  <code>staticmethod</code>","text":"<p>Load config from json file Args:     path:         Path to json file to load config from.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef load_from_json_file(path: Path) -&gt; \"LLMDriftConfig\":\n    \"\"\"Load config from json file\n    Args:\n        path:\n            Path to json file to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the config.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftConfig.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args Args:     space:         Space to associate with the config     name:         Name to associate with the config     version:         Version to associate with the config     alert_config:         LLM alert configuration</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[LLMAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n    Args:\n        space:\n            Space to associate with the config\n        name:\n            Name to associate with the config\n        version:\n            Version to associate with the config\n        alert_config:\n            LLM alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftMap","title":"<code>LLMDriftMap</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class LLMDriftMap:\n    @property\n    def records(self) -&gt; List[LLMMetricRecord]:\n        \"\"\"Return the list of LLM records.\"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftMap.records","title":"<code>records</code>  <code>property</code>","text":"<p>Return the list of LLM records.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftMetric","title":"<code>LLMDriftMetric</code>","text":"<p>Metric for monitoring LLM performance.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class LLMDriftMetric:\n    \"\"\"Metric for monitoring LLM performance.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        value: float,\n        alert_threshold: AlertThreshold,\n        alert_threshold_value: Optional[float] = None,\n        prompt: Optional[Prompt] = None,\n    ):\n        \"\"\"\n        Initialize a metric for monitoring LLM performance.\n\n        Args:\n            name (str):\n                The name of the metric being monitored. This should be a\n                descriptive identifier for the metric.\n            value (float):\n                The current value of the metric.\n            alert_threshold (AlertThreshold):\n                The condition used to determine when an alert should be triggered.\n            alert_threshold_value (Optional[float]):\n                The threshold or boundary value used in conjunction with the alert_threshold.\n                If supplied, this value will be added or subtracted from the provided metric value to\n                determine if an alert should be triggered.\n            prompt (Optional[Prompt]):\n                Optional prompt associated with the metric. This can be used to provide context or\n                additional information about the metric being monitored. If creating an LLM drift profile\n                from a pre-defined workflow, this can be none.\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the metric name\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the metric value\"\"\"\n\n    @property\n    def prompt(self) -&gt; Optional[Prompt]:\n        \"\"\"Return the prompt associated with the metric\"\"\"\n\n    @property\n    def alert_threshold(self) -&gt; AlertThreshold:\n        \"\"\"Return the alert_threshold\"\"\"\n\n    @property\n    def alert_threshold_value(self) -&gt; Optional[float]:\n        \"\"\"Return the alert_threshold_value\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftMetric.alert_threshold","title":"<code>alert_threshold</code>  <code>property</code>","text":"<p>Return the alert_threshold</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftMetric.alert_threshold_value","title":"<code>alert_threshold_value</code>  <code>property</code>","text":"<p>Return the alert_threshold_value</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftMetric.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the metric name</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftMetric.prompt","title":"<code>prompt</code>  <code>property</code>","text":"<p>Return the prompt associated with the metric</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftMetric.value","title":"<code>value</code>  <code>property</code>","text":"<p>Return the metric value</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftMetric.__init__","title":"<code>__init__(name, value, alert_threshold, alert_threshold_value=None, prompt=None)</code>","text":"<p>Initialize a metric for monitoring LLM performance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric being monitored. This should be a descriptive identifier for the metric.</p> required <code>value</code> <code>float</code> <p>The current value of the metric.</p> required <code>alert_threshold</code> <code>AlertThreshold</code> <p>The condition used to determine when an alert should be triggered.</p> required <code>alert_threshold_value</code> <code>Optional[float]</code> <p>The threshold or boundary value used in conjunction with the alert_threshold. If supplied, this value will be added or subtracted from the provided metric value to determine if an alert should be triggered.</p> <code>None</code> <code>prompt</code> <code>Optional[Prompt]</code> <p>Optional prompt associated with the metric. This can be used to provide context or additional information about the metric being monitored. If creating an LLM drift profile from a pre-defined workflow, this can be none.</p> <code>None</code> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    name: str,\n    value: float,\n    alert_threshold: AlertThreshold,\n    alert_threshold_value: Optional[float] = None,\n    prompt: Optional[Prompt] = None,\n):\n    \"\"\"\n    Initialize a metric for monitoring LLM performance.\n\n    Args:\n        name (str):\n            The name of the metric being monitored. This should be a\n            descriptive identifier for the metric.\n        value (float):\n            The current value of the metric.\n        alert_threshold (AlertThreshold):\n            The condition used to determine when an alert should be triggered.\n        alert_threshold_value (Optional[float]):\n            The threshold or boundary value used in conjunction with the alert_threshold.\n            If supplied, this value will be added or subtracted from the provided metric value to\n            determine if an alert should be triggered.\n        prompt (Optional[Prompt]):\n            Optional prompt associated with the metric. This can be used to provide context or\n            additional information about the metric being monitored. If creating an LLM drift profile\n            from a pre-defined workflow, this can be none.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile","title":"<code>LLMDriftProfile</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class LLMDriftProfile:\n    def __init__(\n        self,\n        config: LLMDriftConfig,\n        metrics: list[LLMDriftMetric],\n        workflow: Optional[Workflow] = None,\n    ):\n        \"\"\"Initialize a LLMDriftProfile for LLM evaluation and drift detection.\n\n        LLM evaluations are run asynchronously on the scouter server.\n\n        Logic flow:\n            1. If only metrics are provided, a workflow will be created automatically\n               from the metrics. In this case a prompt is required for each metric.\n            2. If a workflow is provided, it will be parsed and validated for compatibility:\n               - A list of metrics to evaluate workflow output must be provided\n               - Metric names must correspond to the final task names in the workflow\n\n        Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n        Args:\n            config (LLMDriftConfig):\n                The configuration for the LLM drift profile containing space, name,\n                version, and alert settings.\n            metrics (list[LLMDriftMetric]):\n                A list of LLMDriftMetric objects representing the metrics to be monitored.\n                Each metric defines evaluation criteria and alert thresholds.\n            workflow (Optional[Workflow]):\n                Optional custom workflow for advanced evaluation scenarios. If provided,\n                the workflow will be validated to ensure proper parameter and response\n                type configuration.\n\n        Returns:\n            LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n        Raises:\n            ProfileError: If workflow validation fails, metrics are empty when no\n                workflow is provided, or if workflow tasks don't match metric names.\n\n        Examples:\n            Basic usage with metrics only:\n\n            &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n            &gt;&gt;&gt; metrics = [\n            ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n            ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n            ... ]\n            &gt;&gt;&gt; profile = LLMDriftProfile(config, metrics)\n\n            Advanced usage with custom workflow:\n\n            &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n            &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n            &gt;&gt;&gt; profile = LLMDriftProfile(config, metrics, workflow)\n\n        Note:\n            - When using custom workflows, ensure final tasks have Score response types\n            - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n            - All metric names must match corresponding workflow task names\n        \"\"\"\n\n    @property\n    def config(self) -&gt; LLMDriftConfig:\n        \"\"\"Return the drift config\"\"\"\n\n    @property\n    def metrics(self) -&gt; List[LLMDriftMetric]:\n        \"\"\"Return LLM metrics and their corresponding values\"\"\"\n\n    @property\n    def scouter_version(self) -&gt; str:\n        \"\"\"Return scouter version used to create DriftProfile\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of LLMDriftProfile\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of drift profile\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Return dictionary representation of drift profile\"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift profile to json file\n\n        Args:\n            path: Optional path to save the json file. If not provided, a default path will be used.\n\n        Returns:\n            Path to the saved json file.\n        \"\"\"\n\n    @staticmethod\n    def model_validate(data: Dict[str, Any]) -&gt; \"LLMDriftProfile\":\n        \"\"\"Load drift profile from dictionary\n\n        Args:\n            data:\n                DriftProfile dictionary\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"LLMDriftProfile\":\n        \"\"\"Load drift profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the drift profile\n        \"\"\"\n\n    @staticmethod\n    def from_file(path: Path) -&gt; \"LLMDriftProfile\":\n        \"\"\"Load drift profile from file\n\n        Args:\n            path: Path to the json file\n\n        Returns:\n            LLMDriftProfile\n        \"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        sample_size: Optional[int] = None,\n        alert_config: Optional[LLMAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            sample_size:\n                Sample size\n            alert_config:\n                Alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.config","title":"<code>config</code>  <code>property</code>","text":"<p>Return the drift config</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>Return LLM metrics and their corresponding values</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.scouter_version","title":"<code>scouter_version</code>  <code>property</code>","text":"<p>Return scouter version used to create DriftProfile</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.__init__","title":"<code>__init__(config, metrics, workflow=None)</code>","text":"<p>Initialize a LLMDriftProfile for LLM evaluation and drift detection.</p> <p>LLM evaluations are run asynchronously on the scouter server.</p> Logic flow <ol> <li>If only metrics are provided, a workflow will be created automatically    from the metrics. In this case a prompt is required for each metric.</li> <li>If a workflow is provided, it will be parsed and validated for compatibility:</li> <li>A list of metrics to evaluate workflow output must be provided</li> <li>Metric names must correspond to the final task names in the workflow</li> </ol> <p>Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LLMDriftConfig</code> <p>The configuration for the LLM drift profile containing space, name, version, and alert settings.</p> required <code>metrics</code> <code>list[LLMDriftMetric]</code> <p>A list of LLMDriftMetric objects representing the metrics to be monitored. Each metric defines evaluation criteria and alert thresholds.</p> required <code>workflow</code> <code>Optional[Workflow]</code> <p>Optional custom workflow for advanced evaluation scenarios. If provided, the workflow will be validated to ensure proper parameter and response type configuration.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>LLMDriftProfile</code> <p>Configured profile ready for LLM drift monitoring.</p> <p>Raises:</p> Type Description <code>ProfileError</code> <p>If workflow validation fails, metrics are empty when no workflow is provided, or if workflow tasks don't match metric names.</p> <p>Examples:</p> <p>Basic usage with metrics only:</p> <pre><code>&gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n&gt;&gt;&gt; metrics = [\n...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n... ]\n&gt;&gt;&gt; profile = LLMDriftProfile(config, metrics)\n</code></pre> <p>Advanced usage with custom workflow:</p> <pre><code>&gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n&gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n&gt;&gt;&gt; profile = LLMDriftProfile(config, metrics, workflow)\n</code></pre> Note <ul> <li>When using custom workflows, ensure final tasks have Score response types</li> <li>Initial workflow tasks must include \"input\" and/or \"response\" parameters</li> <li>All metric names must match corresponding workflow task names</li> </ul> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    config: LLMDriftConfig,\n    metrics: list[LLMDriftMetric],\n    workflow: Optional[Workflow] = None,\n):\n    \"\"\"Initialize a LLMDriftProfile for LLM evaluation and drift detection.\n\n    LLM evaluations are run asynchronously on the scouter server.\n\n    Logic flow:\n        1. If only metrics are provided, a workflow will be created automatically\n           from the metrics. In this case a prompt is required for each metric.\n        2. If a workflow is provided, it will be parsed and validated for compatibility:\n           - A list of metrics to evaluate workflow output must be provided\n           - Metric names must correspond to the final task names in the workflow\n\n    Baseline metrics and thresholds will be extracted from the LLMDriftMetric objects.\n\n    Args:\n        config (LLMDriftConfig):\n            The configuration for the LLM drift profile containing space, name,\n            version, and alert settings.\n        metrics (list[LLMDriftMetric]):\n            A list of LLMDriftMetric objects representing the metrics to be monitored.\n            Each metric defines evaluation criteria and alert thresholds.\n        workflow (Optional[Workflow]):\n            Optional custom workflow for advanced evaluation scenarios. If provided,\n            the workflow will be validated to ensure proper parameter and response\n            type configuration.\n\n    Returns:\n        LLMDriftProfile: Configured profile ready for LLM drift monitoring.\n\n    Raises:\n        ProfileError: If workflow validation fails, metrics are empty when no\n            workflow is provided, or if workflow tasks don't match metric names.\n\n    Examples:\n        Basic usage with metrics only:\n\n        &gt;&gt;&gt; config = LLMDriftConfig(\"my_space\", \"my_model\", \"1.0\")\n        &gt;&gt;&gt; metrics = [\n        ...     LLMDriftMetric(\"accuracy\", 0.95, AlertThreshold.Above, 0.1, prompt),\n        ...     LLMDriftMetric(\"relevance\", 0.85, AlertThreshold.Below, 0.2, prompt2)\n        ... ]\n        &gt;&gt;&gt; profile = LLMDriftProfile(config, metrics)\n\n        Advanced usage with custom workflow:\n\n        &gt;&gt;&gt; workflow = create_custom_workflow()  # Your custom workflow\n        &gt;&gt;&gt; metrics = [LLMDriftMetric(\"final_task\", 0.9, AlertThreshold.Above)]\n        &gt;&gt;&gt; profile = LLMDriftProfile(config, metrics, workflow)\n\n    Note:\n        - When using custom workflows, ensure final tasks have Score response types\n        - Initial workflow tasks must include \"input\" and/or \"response\" parameters\n        - All metric names must match corresponding workflow task names\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.__str__","title":"<code>__str__()</code>","text":"<p>String representation of LLMDriftProfile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of LLMDriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.from_file","title":"<code>from_file(path)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the json file</p> required <p>Returns:</p> Type Description <code>LLMDriftProfile</code> <p>LLMDriftProfile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef from_file(path: Path) -&gt; \"LLMDriftProfile\":\n    \"\"\"Load drift profile from file\n\n    Args:\n        path: Path to the json file\n\n    Returns:\n        LLMDriftProfile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of drift profile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Return dictionary representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of drift profile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.model_validate","title":"<code>model_validate(data)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from dictionary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>DriftProfile dictionary</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate(data: Dict[str, Any]) -&gt; \"LLMDriftProfile\":\n    \"\"\"Load drift profile from dictionary\n\n    Args:\n        data:\n            DriftProfile dictionary\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift profile</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"LLMDriftProfile\":\n    \"\"\"Load drift profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the drift profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the json file. If not provided, a default path will be used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift profile to json file\n\n    Args:\n        path: Optional path to save the json file. If not provided, a default path will be used.\n\n    Returns:\n        Path to the saved json file.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMDriftProfile.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, sample_size=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>sample_size</code> <code>Optional[int]</code> <p>Sample size</p> <code>None</code> <code>alert_config</code> <code>Optional[LLMAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    alert_config: Optional[LLMAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        sample_size:\n            Sample size\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMMetricRecord","title":"<code>LLMMetricRecord</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class LLMMetricRecord:\n    @property\n    def record_uid(self) -&gt; str:\n        \"\"\"Return the record id\"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime:\n        \"\"\"Return the timestamp when the record was created\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space associated with the record\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name associated with the record\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version associated with the record\"\"\"\n\n    @property\n    def metric(self) -&gt; str:\n        \"\"\"Return the name of the metric associated with the record\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the value of the metric associated with the record\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMMetricRecord.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Return the timestamp when the record was created</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMMetricRecord.metric","title":"<code>metric</code>  <code>property</code>","text":"<p>Return the name of the metric associated with the record</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMMetricRecord.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the name associated with the record</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMMetricRecord.record_uid","title":"<code>record_uid</code>  <code>property</code>","text":"<p>Return the record id</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMMetricRecord.space","title":"<code>space</code>  <code>property</code>","text":"<p>Return the space associated with the record</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMMetricRecord.value","title":"<code>value</code>  <code>property</code>","text":"<p>Return the value of the metric associated with the record</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMMetricRecord.version","title":"<code>version</code>  <code>property</code>","text":"<p>Return the version associated with the record</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.LLMMetricRecord.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Prompt","title":"<code>Prompt</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Potato Head Prompt Protocol</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class Prompt(Protocol):\n    \"\"\"Potato Head Prompt Protocol\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig","title":"<code>PsiDriftConfig</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class PsiDriftConfig:\n    def __init__(\n        self,\n        space: str = \"__missing__\",\n        name: str = \"__missing__\",\n        version: str = \"0.1.0\",\n        alert_config: PsiAlertConfig = PsiAlertConfig(),\n        config_path: Optional[Path] = None,\n        categorical_features: Optional[list[str]] = None,\n    ):\n        \"\"\"Initialize monitor config\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version. Defaults to 0.1.0\n            alert_config:\n                Alert configuration\n            config_path:\n                Optional path to load config from.\n            categorical_features:\n                List of features to treat as categorical for PSI calculation.\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Model Name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set model name\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Model space\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set model space\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Model version\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set model version\"\"\"\n\n    @property\n    def feature_map(self) -&gt; Optional[FeatureMap]:\n        \"\"\"Feature map\"\"\"\n\n    @property\n    def alert_config(self) -&gt; PsiAlertConfig:\n        \"\"\"Alert configuration\"\"\"\n\n    @alert_config.setter\n    def alert_config(self, alert_config: PsiAlertConfig) -&gt; None:\n        \"\"\"Set alert configuration\"\"\"\n\n    @property\n    def drift_type(self) -&gt; DriftType:\n        \"\"\"Drift type\"\"\"\n\n    @property\n    def categorical_features(self) -&gt; list[str]:\n        \"\"\"list of categorical features\"\"\"\n\n    @categorical_features.setter\n    def categorical_features(self, categorical_features: list[str]) -&gt; None:\n        \"\"\"Set list of categorical features\"\"\"\n\n    @staticmethod\n    def load_from_json_file(path: Path) -&gt; \"PsiDriftConfig\":\n        \"\"\"Load config from json file\n\n        Args:\n            path:\n                Path to json file to load config from.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the config.\"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[PsiAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            alert_config:\n                Alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.alert_config","title":"<code>alert_config</code>  <code>property</code> <code>writable</code>","text":"<p>Alert configuration</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.categorical_features","title":"<code>categorical_features</code>  <code>property</code> <code>writable</code>","text":"<p>list of categorical features</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.drift_type","title":"<code>drift_type</code>  <code>property</code>","text":"<p>Drift type</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.feature_map","title":"<code>feature_map</code>  <code>property</code>","text":"<p>Feature map</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Model Name</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Model space</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Model version</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.__init__","title":"<code>__init__(space='__missing__', name='__missing__', version='0.1.0', alert_config=PsiAlertConfig(), config_path=None, categorical_features=None)</code>","text":"<p>Initialize monitor config</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> <code>'__missing__'</code> <code>name</code> <code>str</code> <p>Model name</p> <code>'__missing__'</code> <code>version</code> <code>str</code> <p>Model version. Defaults to 0.1.0</p> <code>'0.1.0'</code> <code>alert_config</code> <code>PsiAlertConfig</code> <p>Alert configuration</p> <code>PsiAlertConfig()</code> <code>config_path</code> <code>Optional[Path]</code> <p>Optional path to load config from.</p> <code>None</code> <code>categorical_features</code> <code>Optional[list[str]]</code> <p>List of features to treat as categorical for PSI calculation.</p> <code>None</code> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    space: str = \"__missing__\",\n    name: str = \"__missing__\",\n    version: str = \"0.1.0\",\n    alert_config: PsiAlertConfig = PsiAlertConfig(),\n    config_path: Optional[Path] = None,\n    categorical_features: Optional[list[str]] = None,\n):\n    \"\"\"Initialize monitor config\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version. Defaults to 0.1.0\n        alert_config:\n            Alert configuration\n        config_path:\n            Optional path to load config from.\n        categorical_features:\n            List of features to treat as categorical for PSI calculation.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.load_from_json_file","title":"<code>load_from_json_file(path)</code>  <code>staticmethod</code>","text":"<p>Load config from json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to json file to load config from.</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef load_from_json_file(path: Path) -&gt; \"PsiDriftConfig\":\n    \"\"\"Load config from json file\n\n    Args:\n        path:\n            Path to json file to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the config.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftConfig.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>alert_config</code> <code>Optional[PsiAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[PsiAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftMap","title":"<code>PsiDriftMap</code>","text":"<p>Drift map of features</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class PsiDriftMap:\n    \"\"\"Drift map of features\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Space to associate with drift map\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"name to associate with drift map\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Version to associate with drift map\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, float]:\n        \"\"\"Returns dictionary of features and their reported drift, if any\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of data drift\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of data drift\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"PsiDriftMap\":\n        \"\"\"Load drift map from json file.\n\n        Args:\n            json_string:\n                JSON string representation of the drift map\n        \"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift map to json file\n\n        Args:\n            path:\n                Optional path to save the drift map. If None, outputs to `psi_drift_map.json`\n\n        Returns:\n            Path to the saved json file\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftMap.features","title":"<code>features</code>  <code>property</code>","text":"<p>Returns dictionary of features and their reported drift, if any</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftMap.name","title":"<code>name</code>  <code>property</code>","text":"<p>name to associate with drift map</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftMap.space","title":"<code>space</code>  <code>property</code>","text":"<p>Space to associate with drift map</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftMap.version","title":"<code>version</code>  <code>property</code>","text":"<p>Version to associate with drift map</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftMap.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of data drift</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of data drift\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftMap.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of data drift</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of data drift\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftMap.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift map from json file.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift map</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"PsiDriftMap\":\n    \"\"\"Load drift map from json file.\n\n    Args:\n        json_string:\n            JSON string representation of the drift map\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftMap.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift map to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift map. If None, outputs to <code>psi_drift_map.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift map to json file\n\n    Args:\n        path:\n            Optional path to save the drift map. If None, outputs to `psi_drift_map.json`\n\n    Returns:\n        Path to the saved json file\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile","title":"<code>PsiDriftProfile</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class PsiDriftProfile:\n    @property\n    def scouter_version(self) -&gt; str:\n        \"\"\"Return scouter version used to create DriftProfile\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, PsiFeatureDriftProfile]:\n        \"\"\"Return the list of features.\"\"\"\n\n    @property\n    def config(self) -&gt; PsiDriftConfig:\n        \"\"\"Return the monitor config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of drift profile\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Return dictionary representation of drift profile\"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift profile to json file\n\n        Args:\n            path:\n                Optional path to save the drift profile. If None, outputs to `psi_drift_profile.json`\n\n        Returns:\n            Path to the saved json file\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"PsiDriftProfile\":\n        \"\"\"Load drift profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the drift profile\n\n        \"\"\"\n\n    @staticmethod\n    def from_file(path: Path) -&gt; \"PsiDriftProfile\":\n        \"\"\"Load drift profile from file\n\n        Args:\n            path: Path to the file\n        \"\"\"\n\n    @staticmethod\n    def model_validate(data: Dict[str, Any]) -&gt; \"PsiDriftProfile\":\n        \"\"\"Load drift profile from dictionary\n\n        Args:\n            data:\n                DriftProfile dictionary\n        \"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        alert_config: Optional[PsiAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            alert_config:\n                Alert configuration\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.config","title":"<code>config</code>  <code>property</code>","text":"<p>Return the monitor config.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.features","title":"<code>features</code>  <code>property</code>","text":"<p>Return the list of features.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.scouter_version","title":"<code>scouter_version</code>  <code>property</code>","text":"<p>Return scouter version used to create DriftProfile</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.__str__","title":"<code>__str__()</code>","text":"<p>Sting representation of DriftProfile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.from_file","title":"<code>from_file(path)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the file</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef from_file(path: Path) -&gt; \"PsiDriftProfile\":\n    \"\"\"Load drift profile from file\n\n    Args:\n        path: Path to the file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of drift profile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Return dictionary representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of drift profile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.model_validate","title":"<code>model_validate(data)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from dictionary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>DriftProfile dictionary</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate(data: Dict[str, Any]) -&gt; \"PsiDriftProfile\":\n    \"\"\"Load drift profile from dictionary\n\n    Args:\n        data:\n            DriftProfile dictionary\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift profile</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"PsiDriftProfile\":\n    \"\"\"Load drift profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the drift profile\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift profile. If None, outputs to <code>psi_drift_profile.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift profile to json file\n\n    Args:\n        path:\n            Optional path to save the drift profile. If None, outputs to `psi_drift_profile.json`\n\n    Returns:\n        Path to the saved json file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiDriftProfile.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>alert_config</code> <code>Optional[PsiAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    alert_config: Optional[PsiAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiFeatureDriftProfile","title":"<code>PsiFeatureDriftProfile</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class PsiFeatureDriftProfile:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Return the feature name\"\"\"\n\n    @property\n    def bins(self) -&gt; List[Bin]:\n        \"\"\"Return the bins\"\"\"\n\n    @property\n    def timestamp(self) -&gt; str:\n        \"\"\"Return the timestamp.\"\"\"\n\n    @property\n    def bin_type(self) -&gt; BinType:\n        \"\"\"Return the timestamp.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiFeatureDriftProfile.bin_type","title":"<code>bin_type</code>  <code>property</code>","text":"<p>Return the timestamp.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiFeatureDriftProfile.bins","title":"<code>bins</code>  <code>property</code>","text":"<p>Return the bins</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiFeatureDriftProfile.id","title":"<code>id</code>  <code>property</code>","text":"<p>Return the feature name</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.PsiFeatureDriftProfile.timestamp","title":"<code>timestamp</code>  <code>property</code>","text":"<p>Return the timestamp.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig","title":"<code>SpcDriftConfig</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class SpcDriftConfig:\n    def __init__(\n        self,\n        space: str = \"__missing__\",\n        name: str = \"__missing__\",\n        version: str = \"0.1.0\",\n        sample_size: int = 25,\n        alert_config: SpcAlertConfig = SpcAlertConfig(),\n        config_path: Optional[Path] = None,\n    ):\n        \"\"\"Initialize monitor config\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version. Defaults to 0.1.0\n            sample_size:\n                Sample size\n            alert_config:\n                Alert configuration\n            config_path:\n                Optional path to load config from.\n        \"\"\"\n\n    @property\n    def sample_size(self) -&gt; int:\n        \"\"\"Return the sample size.\"\"\"\n\n    @sample_size.setter\n    def sample_size(self, sample_size: int) -&gt; None:\n        \"\"\"Set the sample size.\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Model Name\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set model name\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Model space\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set model space\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Model version\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set model version\"\"\"\n\n    @property\n    def feature_map(self) -&gt; Optional[FeatureMap]:\n        \"\"\"Feature map\"\"\"\n\n    @property\n    def alert_config(self) -&gt; SpcAlertConfig:\n        \"\"\"Alert configuration\"\"\"\n\n    @alert_config.setter\n    def alert_config(self, alert_config: SpcAlertConfig) -&gt; None:\n        \"\"\"Set alert configuration\"\"\"\n\n    @property\n    def drift_type(self) -&gt; DriftType:\n        \"\"\"Drift type\"\"\"\n\n    @staticmethod\n    def load_from_json_file(path: Path) -&gt; \"SpcDriftConfig\":\n        \"\"\"Load config from json file\n\n        Args:\n            path:\n                Path to json file to load config from.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the config.\"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        sample_size: Optional[int] = None,\n        alert_config: Optional[SpcAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            sample_size:\n                Sample size\n            alert_config:\n                Alert configuration\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.alert_config","title":"<code>alert_config</code>  <code>property</code> <code>writable</code>","text":"<p>Alert configuration</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.drift_type","title":"<code>drift_type</code>  <code>property</code>","text":"<p>Drift type</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.feature_map","title":"<code>feature_map</code>  <code>property</code>","text":"<p>Feature map</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Model Name</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.sample_size","title":"<code>sample_size</code>  <code>property</code> <code>writable</code>","text":"<p>Return the sample size.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.space","title":"<code>space</code>  <code>property</code> <code>writable</code>","text":"<p>Model space</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.version","title":"<code>version</code>  <code>property</code> <code>writable</code>","text":"<p>Model version</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.__init__","title":"<code>__init__(space='__missing__', name='__missing__', version='0.1.0', sample_size=25, alert_config=SpcAlertConfig(), config_path=None)</code>","text":"<p>Initialize monitor config</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> <code>'__missing__'</code> <code>name</code> <code>str</code> <p>Model name</p> <code>'__missing__'</code> <code>version</code> <code>str</code> <p>Model version. Defaults to 0.1.0</p> <code>'0.1.0'</code> <code>sample_size</code> <code>int</code> <p>Sample size</p> <code>25</code> <code>alert_config</code> <code>SpcAlertConfig</code> <p>Alert configuration</p> <code>SpcAlertConfig()</code> <code>config_path</code> <code>Optional[Path]</code> <p>Optional path to load config from.</p> <code>None</code> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __init__(\n    self,\n    space: str = \"__missing__\",\n    name: str = \"__missing__\",\n    version: str = \"0.1.0\",\n    sample_size: int = 25,\n    alert_config: SpcAlertConfig = SpcAlertConfig(),\n    config_path: Optional[Path] = None,\n):\n    \"\"\"Initialize monitor config\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version. Defaults to 0.1.0\n        sample_size:\n            Sample size\n        alert_config:\n            Alert configuration\n        config_path:\n            Optional path to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the config.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.load_from_json_file","title":"<code>load_from_json_file(path)</code>  <code>staticmethod</code>","text":"<p>Load config from json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to json file to load config from.</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef load_from_json_file(path: Path) -&gt; \"SpcDriftConfig\":\n    \"\"\"Load config from json file\n\n    Args:\n        path:\n            Path to json file to load config from.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the config.</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the config.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftConfig.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, sample_size=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>sample_size</code> <code>Optional[int]</code> <p>Sample size</p> <code>None</code> <code>alert_config</code> <code>Optional[SpcAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    alert_config: Optional[SpcAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        sample_size:\n            Sample size\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap","title":"<code>SpcDriftMap</code>","text":"<p>Drift map of features</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class SpcDriftMap:\n    \"\"\"Drift map of features\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Space to associate with drift map\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"name to associate with drift map\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Version to associate with drift map\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, SpcFeatureDrift]:\n        \"\"\"Returns dictionary of features and their data profiles\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of data drift\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of data drift\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"SpcDriftMap\":\n        \"\"\"Load drift map from json file.\n\n        Args:\n            json_string:\n                JSON string representation of the drift map\n        \"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift map to json file\n\n        Args:\n            path:\n                Optional path to save the drift map. If None, outputs to `spc_drift_map.json`\n\n        Returns:\n            Path to the saved json file\n\n        \"\"\"\n\n    def to_numpy(self) -&gt; Any:\n        \"\"\"Return drift map as a tuple of sample_array, drift_array and list of features\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap.features","title":"<code>features</code>  <code>property</code>","text":"<p>Returns dictionary of features and their data profiles</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap.name","title":"<code>name</code>  <code>property</code>","text":"<p>name to associate with drift map</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap.space","title":"<code>space</code>  <code>property</code>","text":"<p>Space to associate with drift map</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap.version","title":"<code>version</code>  <code>property</code>","text":"<p>Version to associate with drift map</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of data drift</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of data drift\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of data drift</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of data drift\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift map from json file.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift map</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"SpcDriftMap\":\n    \"\"\"Load drift map from json file.\n\n    Args:\n        json_string:\n            JSON string representation of the drift map\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift map to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift map. If None, outputs to <code>spc_drift_map.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift map to json file\n\n    Args:\n        path:\n            Optional path to save the drift map. If None, outputs to `spc_drift_map.json`\n\n    Returns:\n        Path to the saved json file\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftMap.to_numpy","title":"<code>to_numpy()</code>","text":"<p>Return drift map as a tuple of sample_array, drift_array and list of features</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def to_numpy(self) -&gt; Any:\n    \"\"\"Return drift map as a tuple of sample_array, drift_array and list of features\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile","title":"<code>SpcDriftProfile</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class SpcDriftProfile:\n    @property\n    def scouter_version(self) -&gt; str:\n        \"\"\"Return scouter version used to create DriftProfile\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, SpcFeatureDriftProfile]:\n        \"\"\"Return the list of features.\"\"\"\n\n    @property\n    def config(self) -&gt; SpcDriftConfig:\n        \"\"\"Return the monitor config.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of drift profile\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Return dictionary representation of drift profile\"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save drift profile to json file\n\n        Args:\n            path:\n                Optional path to save the drift profile. If None, outputs to `spc_drift_profile.json`\n\n\n        Returns:\n            Path to the saved json file\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"SpcDriftProfile\":\n        \"\"\"Load drift profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the drift profile\n\n        \"\"\"\n\n    @staticmethod\n    def from_file(path: Path) -&gt; \"SpcDriftProfile\":\n        \"\"\"Load drift profile from file\n\n        Args:\n            path: Path to the file\n        \"\"\"\n\n    @staticmethod\n    def model_validate(data: Dict[str, Any]) -&gt; \"SpcDriftProfile\":\n        \"\"\"Load drift profile from dictionary\n\n        Args:\n            data:\n                DriftProfile dictionary\n        \"\"\"\n\n    def update_config_args(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        sample_size: Optional[int] = None,\n        alert_config: Optional[SpcAlertConfig] = None,\n    ) -&gt; None:\n        \"\"\"Inplace operation that updates config args\n\n        Args:\n            name:\n                Model name\n            space:\n                Model space\n            version:\n                Model version\n            sample_size:\n                Sample size\n            alert_config:\n                Alert configuration\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.config","title":"<code>config</code>  <code>property</code>","text":"<p>Return the monitor config.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.features","title":"<code>features</code>  <code>property</code>","text":"<p>Return the list of features.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.scouter_version","title":"<code>scouter_version</code>  <code>property</code>","text":"<p>Return scouter version used to create DriftProfile</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.__str__","title":"<code>__str__()</code>","text":"<p>Sting representation of DriftProfile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Sting representation of DriftProfile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.from_file","title":"<code>from_file(path)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the file</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef from_file(path: Path) -&gt; \"SpcDriftProfile\":\n    \"\"\"Load drift profile from file\n\n    Args:\n        path: Path to the file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.model_dump","title":"<code>model_dump()</code>","text":"<p>Return dictionary representation of drift profile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Return dictionary representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of drift profile</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of drift profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.model_validate","title":"<code>model_validate(data)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from dictionary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>DriftProfile dictionary</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate(data: Dict[str, Any]) -&gt; \"SpcDriftProfile\":\n    \"\"\"Load drift profile from dictionary\n\n    Args:\n        data:\n            DriftProfile dictionary\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load drift profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the drift profile</p> required Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"SpcDriftProfile\":\n    \"\"\"Load drift profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the drift profile\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save drift profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the drift profile. If None, outputs to <code>spc_drift_profile.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved json file</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save drift profile to json file\n\n    Args:\n        path:\n            Optional path to save the drift profile. If None, outputs to `spc_drift_profile.json`\n\n\n    Returns:\n        Path to the saved json file\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcDriftProfile.update_config_args","title":"<code>update_config_args(space=None, name=None, version=None, sample_size=None, alert_config=None)</code>","text":"<p>Inplace operation that updates config args</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Model name</p> <code>None</code> <code>space</code> <code>Optional[str]</code> <p>Model space</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Model version</p> <code>None</code> <code>sample_size</code> <code>Optional[int]</code> <p>Sample size</p> <code>None</code> <code>alert_config</code> <code>Optional[SpcAlertConfig]</code> <p>Alert configuration</p> <code>None</code> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>def update_config_args(\n    self,\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    alert_config: Optional[SpcAlertConfig] = None,\n) -&gt; None:\n    \"\"\"Inplace operation that updates config args\n\n    Args:\n        name:\n            Model name\n        space:\n            Model space\n        version:\n            Model version\n        sample_size:\n            Sample size\n        alert_config:\n            Alert configuration\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDrift","title":"<code>SpcFeatureDrift</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class SpcFeatureDrift:\n    @property\n    def samples(self) -&gt; List[float]:\n        \"\"\"Return list of samples\"\"\"\n\n    @property\n    def drift(self) -&gt; List[float]:\n        \"\"\"Return list of drift values\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDrift.drift","title":"<code>drift</code>  <code>property</code>","text":"<p>Return list of drift values</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDrift.samples","title":"<code>samples</code>  <code>property</code>","text":"<p>Return list of samples</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile","title":"<code>SpcFeatureDriftProfile</code>","text":"Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class SpcFeatureDriftProfile:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Return the id.\"\"\"\n\n    @property\n    def center(self) -&gt; float:\n        \"\"\"Return the center.\"\"\"\n\n    @property\n    def one_ucl(self) -&gt; float:\n        \"\"\"Return the zone 1 ucl.\"\"\"\n\n    @property\n    def one_lcl(self) -&gt; float:\n        \"\"\"Return the zone 1 lcl.\"\"\"\n\n    @property\n    def two_ucl(self) -&gt; float:\n        \"\"\"Return the zone 2 ucl.\"\"\"\n\n    @property\n    def two_lcl(self) -&gt; float:\n        \"\"\"Return the zone 2 lcl.\"\"\"\n\n    @property\n    def three_ucl(self) -&gt; float:\n        \"\"\"Return the zone 3 ucl.\"\"\"\n\n    @property\n    def three_lcl(self) -&gt; float:\n        \"\"\"Return the zone 3 lcl.\"\"\"\n\n    @property\n    def timestamp(self) -&gt; str:\n        \"\"\"Return the timestamp.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile.center","title":"<code>center</code>  <code>property</code>","text":"<p>Return the center.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile.id","title":"<code>id</code>  <code>property</code>","text":"<p>Return the id.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile.one_lcl","title":"<code>one_lcl</code>  <code>property</code>","text":"<p>Return the zone 1 lcl.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile.one_ucl","title":"<code>one_ucl</code>  <code>property</code>","text":"<p>Return the zone 1 ucl.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile.three_lcl","title":"<code>three_lcl</code>  <code>property</code>","text":"<p>Return the zone 3 lcl.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile.three_ucl","title":"<code>three_ucl</code>  <code>property</code>","text":"<p>Return the zone 3 ucl.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile.timestamp","title":"<code>timestamp</code>  <code>property</code>","text":"<p>Return the timestamp.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile.two_lcl","title":"<code>two_lcl</code>  <code>property</code>","text":"<p>Return the zone 2 lcl.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.SpcFeatureDriftProfile.two_ucl","title":"<code>two_ucl</code>  <code>property</code>","text":"<p>Return the zone 2 ucl.</p>"},{"location":"docs/api/scouter/drift/#opsml.scouter.drift._drift.Workflow","title":"<code>Workflow</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Potato Head Workflow Protocol</p> Source code in <code>python/opsml/scouter/drift/_drift.pyi</code> <pre><code>class Workflow(Protocol):\n    \"\"\"Potato Head Workflow Protocol\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/","title":"Profile","text":""},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.CharStats","title":"<code>CharStats</code>","text":"Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class CharStats:\n    @property\n    def min_length(self) -&gt; int:\n        \"\"\"Minimum string length\"\"\"\n\n    @property\n    def max_length(self) -&gt; int:\n        \"\"\"Maximum string length\"\"\"\n\n    @property\n    def median_length(self) -&gt; int:\n        \"\"\"Median string length\"\"\"\n\n    @property\n    def mean_length(self) -&gt; float:\n        \"\"\"Mean string length\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.CharStats.max_length","title":"<code>max_length</code>  <code>property</code>","text":"<p>Maximum string length</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.CharStats.mean_length","title":"<code>mean_length</code>  <code>property</code>","text":"<p>Mean string length</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.CharStats.median_length","title":"<code>median_length</code>  <code>property</code>","text":"<p>Median string length</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.CharStats.min_length","title":"<code>min_length</code>  <code>property</code>","text":"<p>Minimum string length</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.DataProfile","title":"<code>DataProfile</code>","text":"<p>Data profile of features</p> Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class DataProfile:\n    \"\"\"Data profile of features\"\"\"\n\n    @property\n    def features(self) -&gt; Dict[str, FeatureProfile]:\n        \"\"\"Returns dictionary of features and their data profiles\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of the data profile\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return json representation of data profile\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"DataProfile\":\n        \"\"\"Load Data profile from json\n\n        Args:\n            json_string:\n                JSON string representation of the data profile\n        \"\"\"\n\n    def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n        \"\"\"Save data profile to json file\n\n        Args:\n            path:\n                Optional path to save the data profile. If None, outputs to `data_profile.json`\n\n        Returns:\n            Path to the saved data profile\n\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.DataProfile.features","title":"<code>features</code>  <code>property</code>","text":"<p>Returns dictionary of features and their data profiles</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.DataProfile.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of the data profile</p> Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of the data profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.DataProfile.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return json representation of data profile</p> Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return json representation of data profile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.DataProfile.model_validate_json","title":"<code>model_validate_json(json_string)</code>  <code>staticmethod</code>","text":"<p>Load Data profile from json</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representation of the data profile</p> required Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>@staticmethod\ndef model_validate_json(json_string: str) -&gt; \"DataProfile\":\n    \"\"\"Load Data profile from json\n\n    Args:\n        json_string:\n            JSON string representation of the data profile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.DataProfile.save_to_json","title":"<code>save_to_json(path=None)</code>","text":"<p>Save data profile to json file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Optional path to save the data profile. If None, outputs to <code>data_profile.json</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved data profile</p> Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>def save_to_json(self, path: Optional[Path] = None) -&gt; Path:\n    \"\"\"Save data profile to json file\n\n    Args:\n        path:\n            Optional path to save the data profile. If None, outputs to `data_profile.json`\n\n    Returns:\n        Path to the saved data profile\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.DataProfiler","title":"<code>DataProfiler</code>","text":"Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class DataProfiler:\n    def __init__(self):\n        \"\"\"Instantiate DataProfiler class that is\n        used to profile data\"\"\"\n\n    def create_data_profile(\n        self,\n        data: Any,\n        data_type: Optional[DataType] = None,\n        bin_size: int = 20,\n        compute_correlations: bool = False,\n    ) -&gt; DataProfile:\n        \"\"\"Create a data profile from data.\n\n        Args:\n            data:\n                Data to create a data profile from. Data can be a numpy array,\n                a polars dataframe or pandas dataframe.\n\n                **Data is expected to not contain any missing values, NaNs or infinities**\n\n                These types are incompatible with computing\n                quantiles, histograms, and correlations. These values must be removed or imputed.\n\n            data_type:\n                Optional data type. Inferred from data if not provided.\n            bin_size:\n                Optional bin size for histograms. Defaults to 20 bins.\n            compute_correlations:\n                Whether to compute correlations or not.\n\n        Returns:\n            DataProfile\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.DataProfiler.__init__","title":"<code>__init__()</code>","text":"<p>Instantiate DataProfiler class that is used to profile data</p> Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>def __init__(self):\n    \"\"\"Instantiate DataProfiler class that is\n    used to profile data\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.DataProfiler.create_data_profile","title":"<code>create_data_profile(data, data_type=None, bin_size=20, compute_correlations=False)</code>","text":"<p>Create a data profile from data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to create a data profile from. Data can be a numpy array, a polars dataframe or pandas dataframe.</p> <p>Data is expected to not contain any missing values, NaNs or infinities</p> <p>These types are incompatible with computing quantiles, histograms, and correlations. These values must be removed or imputed.</p> required <code>data_type</code> <code>Optional[DataType]</code> <p>Optional data type. Inferred from data if not provided.</p> <code>None</code> <code>bin_size</code> <code>int</code> <p>Optional bin size for histograms. Defaults to 20 bins.</p> <code>20</code> <code>compute_correlations</code> <code>bool</code> <p>Whether to compute correlations or not.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataProfile</code> <p>DataProfile</p> Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>def create_data_profile(\n    self,\n    data: Any,\n    data_type: Optional[DataType] = None,\n    bin_size: int = 20,\n    compute_correlations: bool = False,\n) -&gt; DataProfile:\n    \"\"\"Create a data profile from data.\n\n    Args:\n        data:\n            Data to create a data profile from. Data can be a numpy array,\n            a polars dataframe or pandas dataframe.\n\n            **Data is expected to not contain any missing values, NaNs or infinities**\n\n            These types are incompatible with computing\n            quantiles, histograms, and correlations. These values must be removed or imputed.\n\n        data_type:\n            Optional data type. Inferred from data if not provided.\n        bin_size:\n            Optional bin size for histograms. Defaults to 20 bins.\n        compute_correlations:\n            Whether to compute correlations or not.\n\n    Returns:\n        DataProfile\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Distinct","title":"<code>Distinct</code>","text":"Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class Distinct:\n    @property\n    def count(self) -&gt; int:\n        \"\"\"total unique value counts\"\"\"\n\n    @property\n    def percent(self) -&gt; float:\n        \"\"\"percent value uniqueness\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Distinct.count","title":"<code>count</code>  <code>property</code>","text":"<p>total unique value counts</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Distinct.percent","title":"<code>percent</code>  <code>property</code>","text":"<p>percent value uniqueness</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.FeatureProfile","title":"<code>FeatureProfile</code>","text":"Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class FeatureProfile:\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Return the id.\"\"\"\n\n    @property\n    def numeric_stats(self) -&gt; Optional[NumericStats]:\n        \"\"\"Return the numeric stats.\"\"\"\n\n    @property\n    def string_stats(self) -&gt; Optional[StringStats]:\n        \"\"\"Return the string stats.\"\"\"\n\n    @property\n    def timestamp(self) -&gt; str:\n        \"\"\"Return the timestamp.\"\"\"\n\n    @property\n    def correlations(self) -&gt; Optional[Dict[str, float]]:\n        \"\"\"Feature correlation values\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the feature profile.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.FeatureProfile.correlations","title":"<code>correlations</code>  <code>property</code>","text":"<p>Feature correlation values</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.FeatureProfile.id","title":"<code>id</code>  <code>property</code>","text":"<p>Return the id.</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.FeatureProfile.numeric_stats","title":"<code>numeric_stats</code>  <code>property</code>","text":"<p>Return the numeric stats.</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.FeatureProfile.string_stats","title":"<code>string_stats</code>  <code>property</code>","text":"<p>Return the string stats.</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.FeatureProfile.timestamp","title":"<code>timestamp</code>  <code>property</code>","text":"<p>Return the timestamp.</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.FeatureProfile.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the feature profile.</p> Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the feature profile.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Histogram","title":"<code>Histogram</code>","text":"Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class Histogram:\n    @property\n    def bins(self) -&gt; List[float]:\n        \"\"\"Bin values\"\"\"\n\n    @property\n    def bin_counts(self) -&gt; List[int]:\n        \"\"\"Bin counts\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Histogram.bin_counts","title":"<code>bin_counts</code>  <code>property</code>","text":"<p>Bin counts</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Histogram.bins","title":"<code>bins</code>  <code>property</code>","text":"<p>Bin values</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.NumericStats","title":"<code>NumericStats</code>","text":"Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class NumericStats:\n    @property\n    def mean(self) -&gt; float:\n        \"\"\"Return the mean.\"\"\"\n\n    @property\n    def stddev(self) -&gt; float:\n        \"\"\"Return the stddev.\"\"\"\n\n    @property\n    def min(self) -&gt; float:\n        \"\"\"Return the min.\"\"\"\n\n    @property\n    def max(self) -&gt; float:\n        \"\"\"Return the max.\"\"\"\n\n    @property\n    def distinct(self) -&gt; Distinct:\n        \"\"\"Distinct value counts\"\"\"\n\n    @property\n    def quantiles(self) -&gt; Quantiles:\n        \"\"\"Value quantiles\"\"\"\n\n    @property\n    def histogram(self) -&gt; Histogram:\n        \"\"\"Value histograms\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.NumericStats.distinct","title":"<code>distinct</code>  <code>property</code>","text":"<p>Distinct value counts</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.NumericStats.histogram","title":"<code>histogram</code>  <code>property</code>","text":"<p>Value histograms</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.NumericStats.max","title":"<code>max</code>  <code>property</code>","text":"<p>Return the max.</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.NumericStats.mean","title":"<code>mean</code>  <code>property</code>","text":"<p>Return the mean.</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.NumericStats.min","title":"<code>min</code>  <code>property</code>","text":"<p>Return the min.</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.NumericStats.quantiles","title":"<code>quantiles</code>  <code>property</code>","text":"<p>Value quantiles</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.NumericStats.stddev","title":"<code>stddev</code>  <code>property</code>","text":"<p>Return the stddev.</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Quantiles","title":"<code>Quantiles</code>","text":"Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class Quantiles:\n    @property\n    def q25(self) -&gt; float:\n        \"\"\"25th quantile\"\"\"\n\n    @property\n    def q50(self) -&gt; float:\n        \"\"\"50th quantile\"\"\"\n\n    @property\n    def q75(self) -&gt; float:\n        \"\"\"75th quantile\"\"\"\n\n    @property\n    def q99(self) -&gt; float:\n        \"\"\"99th quantile\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Quantiles.q25","title":"<code>q25</code>  <code>property</code>","text":"<p>25th quantile</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Quantiles.q50","title":"<code>q50</code>  <code>property</code>","text":"<p>50th quantile</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Quantiles.q75","title":"<code>q75</code>  <code>property</code>","text":"<p>75th quantile</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.Quantiles.q99","title":"<code>q99</code>  <code>property</code>","text":"<p>99th quantile</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.StringStats","title":"<code>StringStats</code>","text":"Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class StringStats:\n    @property\n    def distinct(self) -&gt; Distinct:\n        \"\"\"Distinct value counts\"\"\"\n\n    @property\n    def char_stats(self) -&gt; CharStats:\n        \"\"\"Character statistics\"\"\"\n\n    @property\n    def word_stats(self) -&gt; WordStats:\n        \"\"\"word statistics\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.StringStats.char_stats","title":"<code>char_stats</code>  <code>property</code>","text":"<p>Character statistics</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.StringStats.distinct","title":"<code>distinct</code>  <code>property</code>","text":"<p>Distinct value counts</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.StringStats.word_stats","title":"<code>word_stats</code>  <code>property</code>","text":"<p>word statistics</p>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.WordStats","title":"<code>WordStats</code>","text":"Source code in <code>python/opsml/scouter/profile/_profile.pyi</code> <pre><code>class WordStats:\n    @property\n    def words(self) -&gt; Dict[str, Distinct]:\n        \"\"\"Distinct word counts\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/profile/#opsml.scouter.profile._profile.WordStats.words","title":"<code>words</code>  <code>property</code>","text":"<p>Distinct word counts</p>"},{"location":"docs/api/scouter/queue/","title":"Queue","text":""},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.BaseModel","title":"<code>BaseModel</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for pydantic BaseModel to ensure compatibility with context</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class BaseModel(Protocol):\n    \"\"\"Protocol for pydantic BaseModel to ensure compatibility with context\"\"\"\n\n    def model_dump(self) -&gt; Dict[str, Any]:\n        \"\"\"Dump the model as a dictionary\"\"\"\n        ...\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model as a JSON string\"\"\"\n        ...\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the model\"\"\"\n        ...\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.BaseModel.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the model</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the model\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.BaseModel.model_dump","title":"<code>model_dump()</code>","text":"<p>Dump the model as a dictionary</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def model_dump(self) -&gt; Dict[str, Any]:\n    \"\"\"Dump the model as a dictionary\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.BaseModel.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Dump the model as a JSON string</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Dump the model as a JSON string\"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord","title":"<code>CustomMetricServerRecord</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class CustomMetricServerRecord:\n    def __init__(\n        self,\n        space: str,\n        name: str,\n        version: str,\n        metric: str,\n        value: float,\n    ):\n        \"\"\"Initialize spc drift server record\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            metric:\n                Metric name\n            value:\n                Metric value\n        \"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime.datetime:\n        \"\"\"Return the created at timestamp.\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space.\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name.\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version.\"\"\"\n\n    @property\n    def metric(self) -&gt; str:\n        \"\"\"Return the metric name.\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the metric value.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the record.\"\"\"\n\n    def to_dict(self) -&gt; Dict[str, str]:\n        \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Return the created at timestamp.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.metric","title":"<code>metric</code>  <code>property</code>","text":"<p>Return the metric name.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the name.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.space","title":"<code>space</code>  <code>property</code>","text":"<p>Return the space.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.value","title":"<code>value</code>  <code>property</code>","text":"<p>Return the metric value.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.version","title":"<code>version</code>  <code>property</code>","text":"<p>Return the version.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.__init__","title":"<code>__init__(space, name, version, metric, value)</code>","text":"<p>Initialize spc drift server record</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> required <code>name</code> <code>str</code> <p>Model name</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>metric</code> <code>str</code> <p>Metric name</p> required <code>value</code> <code>float</code> <p>Metric value</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    space: str,\n    name: str,\n    version: str,\n    metric: str,\n    value: float,\n):\n    \"\"\"Initialize spc drift server record\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        metric:\n            Metric name\n        value:\n            Metric value\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.CustomMetricServerRecord.to_dict","title":"<code>to_dict()</code>","text":"<p>Return the dictionary representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def to_dict(self) -&gt; Dict[str, str]:\n    \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Feature","title":"<code>Feature</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class Feature:\n    def __init__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Initialize feature. Will attempt to convert the value to it's corresponding feature type.\n        Current support types are int, float, string.\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature. Can be an int, float, or string.\n\n        Example:\n            ```python\n            feature = Feature(\"feature_1\", 1) # int feature\n            feature = Feature(\"feature_2\", 2.0) # float feature\n            feature = Feature(\"feature_3\", \"value\") # string feature\n            ```\n        \"\"\"\n\n    @staticmethod\n    def int(name: str, value: int) -&gt; \"Feature\":\n        \"\"\"Create an integer feature\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature\n        \"\"\"\n\n    @staticmethod\n    def float(name: str, value: float) -&gt; \"Feature\":\n        \"\"\"Create a float feature\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature\n        \"\"\"\n\n    @staticmethod\n    def string(name: str, value: str) -&gt; \"Feature\":\n        \"\"\"Create a string feature\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature\n        \"\"\"\n\n    @staticmethod\n    def categorical(name: str, value: str) -&gt; \"Feature\":\n        \"\"\"Create a categorical feature\n\n        Args:\n            name:\n                Name of the feature\n            value:\n                Value of the feature\n        \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Feature.__init__","title":"<code>__init__(name, value)</code>","text":"<p>Initialize feature. Will attempt to convert the value to it's corresponding feature type. Current support types are int, float, string.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>Any</code> <p>Value of the feature. Can be an int, float, or string.</p> required Example <pre><code>feature = Feature(\"feature_1\", 1) # int feature\nfeature = Feature(\"feature_2\", 2.0) # float feature\nfeature = Feature(\"feature_3\", \"value\") # string feature\n</code></pre> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Initialize feature. Will attempt to convert the value to it's corresponding feature type.\n    Current support types are int, float, string.\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature. Can be an int, float, or string.\n\n    Example:\n        ```python\n        feature = Feature(\"feature_1\", 1) # int feature\n        feature = Feature(\"feature_2\", 2.0) # float feature\n        feature = Feature(\"feature_3\", \"value\") # string feature\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Feature.categorical","title":"<code>categorical(name, value)</code>  <code>staticmethod</code>","text":"<p>Create a categorical feature</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>str</code> <p>Value of the feature</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef categorical(name: str, value: str) -&gt; \"Feature\":\n    \"\"\"Create a categorical feature\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Feature.float","title":"<code>float(name, value)</code>  <code>staticmethod</code>","text":"<p>Create a float feature</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>float</code> <p>Value of the feature</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef float(name: str, value: float) -&gt; \"Feature\":\n    \"\"\"Create a float feature\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Feature.int","title":"<code>int(name, value)</code>  <code>staticmethod</code>","text":"<p>Create an integer feature</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>int</code> <p>Value of the feature</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef int(name: str, value: int) -&gt; \"Feature\":\n    \"\"\"Create an integer feature\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Feature.string","title":"<code>string(name, value)</code>  <code>staticmethod</code>","text":"<p>Create a string feature</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the feature</p> required <code>value</code> <code>str</code> <p>Value of the feature</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef string(name: str, value: str) -&gt; \"Feature\":\n    \"\"\"Create a string feature\n\n    Args:\n        name:\n            Name of the feature\n        value:\n            Value of the feature\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Features","title":"<code>Features</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class Features:\n    def __init__(\n        self,\n        features: List[Feature] | Dict[str, Union[int, float, str]],\n    ) -&gt; None:\n        \"\"\"Initialize a features class\n\n        Args:\n            features:\n                List of features or a dictionary of key-value pairs.\n                If a list, each item must be an instance of Feature.\n                If a dictionary, each key is the feature name and each value is the feature value.\n                Supported types for values are int, float, and string.\n\n        Example:\n            ```python\n            # Passing a list of features\n            features = Features(\n                features=[\n                    Feature.int(\"feature_1\", 1),\n                    Feature.float(\"feature_2\", 2.0),\n                    Feature.string(\"feature_3\", \"value\"),\n                ]\n            )\n\n            # Passing a dictionary (pydantic model) of features\n            class MyFeatures(BaseModel):\n                feature1: int\n                feature2: float\n                feature3: str\n\n            my_features = MyFeatures(\n                feature1=1,\n                feature2=2.0,\n                feature3=\"value\",\n            )\n\n            features = Features(my_features.model_dump())\n            ```\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the features\"\"\"\n\n    @property\n    def features(self) -&gt; List[Feature]:\n        \"\"\"Return the list of features\"\"\"\n\n    @property\n    def entity_type(self) -&gt; EntityType:\n        \"\"\"Return the entity type\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Features.entity_type","title":"<code>entity_type</code>  <code>property</code>","text":"<p>Return the entity type</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Features.features","title":"<code>features</code>  <code>property</code>","text":"<p>Return the list of features</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Features.__init__","title":"<code>__init__(features)</code>","text":"<p>Initialize a features class</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>List[Feature] | Dict[str, Union[int, float, str]]</code> <p>List of features or a dictionary of key-value pairs. If a list, each item must be an instance of Feature. If a dictionary, each key is the feature name and each value is the feature value. Supported types for values are int, float, and string.</p> required Example <pre><code># Passing a list of features\nfeatures = Features(\n    features=[\n        Feature.int(\"feature_1\", 1),\n        Feature.float(\"feature_2\", 2.0),\n        Feature.string(\"feature_3\", \"value\"),\n    ]\n)\n\n# Passing a dictionary (pydantic model) of features\nclass MyFeatures(BaseModel):\n    feature1: int\n    feature2: float\n    feature3: str\n\nmy_features = MyFeatures(\n    feature1=1,\n    feature2=2.0,\n    feature3=\"value\",\n)\n\nfeatures = Features(my_features.model_dump())\n</code></pre> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    features: List[Feature] | Dict[str, Union[int, float, str]],\n) -&gt; None:\n    \"\"\"Initialize a features class\n\n    Args:\n        features:\n            List of features or a dictionary of key-value pairs.\n            If a list, each item must be an instance of Feature.\n            If a dictionary, each key is the feature name and each value is the feature value.\n            Supported types for values are int, float, and string.\n\n    Example:\n        ```python\n        # Passing a list of features\n        features = Features(\n            features=[\n                Feature.int(\"feature_1\", 1),\n                Feature.float(\"feature_2\", 2.0),\n                Feature.string(\"feature_3\", \"value\"),\n            ]\n        )\n\n        # Passing a dictionary (pydantic model) of features\n        class MyFeatures(BaseModel):\n            feature1: int\n            feature2: float\n            feature3: str\n\n        my_features = MyFeatures(\n            feature1=1,\n            feature2=2.0,\n            feature3=\"value\",\n        )\n\n        features = Features(my_features.model_dump())\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Features.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the features</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the features\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.KafkaConfig","title":"<code>KafkaConfig</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class KafkaConfig:\n    brokers: str\n    topic: str\n    compression_type: str\n    message_timeout_ms: int\n    message_max_bytes: int\n    log_level: LogLevel\n    config: Dict[str, str]\n    max_retries: int\n    transport_type: TransportType\n\n    def __init__(\n        self,\n        username: Optional[str] = None,\n        password: Optional[str] = None,\n        brokers: Optional[str] = None,\n        topic: Optional[str] = None,\n        compression_type: Optional[str] = None,\n        message_timeout_ms: int = 600_000,\n        message_max_bytes: int = 2097164,\n        log_level: LogLevel = LogLevel.Info,\n        config: Dict[str, str] = {},\n        max_retries: int = 3,\n    ) -&gt; None:\n        \"\"\"Kafka configuration for connecting to and publishing messages to Kafka brokers.\n\n        This configuration supports both authenticated (SASL) and unauthenticated connections.\n        When credentials are provided, SASL authentication is automatically enabled with\n        secure defaults.\n\n        Authentication Priority (first match wins):\n            1. Direct parameters (username/password)\n            2. Environment variables (KAFKA_USERNAME/KAFKA_PASSWORD)\n            3. Configuration dictionary (sasl.username/sasl.password)\n\n        SASL Security Defaults:\n            - security.protocol: \"SASL_SSL\" (override via KAFKA_SECURITY_PROTOCOL env var)\n            - sasl.mechanism: \"PLAIN\" (override via KAFKA_SASL_MECHANISM env var)\n\n        Args:\n            username:\n                SASL username for authentication.\n                Fallback: KAFKA_USERNAME environment variable.\n            password:\n                SASL password for authentication.\n                Fallback: KAFKA_PASSWORD environment variable.\n            brokers:\n                Comma-separated list of Kafka broker addresses (host:port).\n                Fallback: KAFKA_BROKERS environment variable.\n                Default: \"localhost:9092\"\n            topic:\n                Target Kafka topic for message publishing.\n                Fallback: KAFKA_TOPIC environment variable.\n                Default: \"scouter_monitoring\"\n            compression_type:\n                Message compression algorithm.\n                Options: \"none\", \"gzip\", \"snappy\", \"lz4\", \"zstd\"\n                Default: \"gzip\"\n            message_timeout_ms:\n                Maximum time to wait for message delivery (milliseconds).\n                Default: 600000 (10 minutes)\n            message_max_bytes:\n                Maximum message size in bytes.\n                Default: 2097164 (~2MB)\n            log_level:\n                Logging verbosity for the Kafka producer.\n                Default: LogLevel.Info\n            config:\n                Additional Kafka producer configuration parameters.\n                See: https://kafka.apache.org/documentation/#producerconfigs\n                Note: Direct parameters take precedence over config dictionary values.\n            max_retries:\n                Maximum number of retry attempts for failed message deliveries.\n                Default: 3\n\n        Examples:\n            Basic usage (unauthenticated):\n            ```python\n            config = KafkaConfig(\n                brokers=\"kafka1:9092,kafka2:9092\",\n                topic=\"my_topic\"\n            )\n            ```\n\n            SASL authentication:\n            ```python\n            config = KafkaConfig(\n                username=\"my_user\",\n                password=\"my_password\",\n                brokers=\"secure-kafka:9093\",\n                topic=\"secure_topic\"\n            )\n            ```\n\n            Advanced configuration:\n            ```python\n            config = KafkaConfig(\n                brokers=\"kafka:9092\",\n                compression_type=\"lz4\",\n                config={\n                    \"acks\": \"all\",\n                    \"batch.size\": \"32768\",\n                    \"linger.ms\": \"10\"\n                }\n            )\n            ```\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.KafkaConfig.__init__","title":"<code>__init__(username=None, password=None, brokers=None, topic=None, compression_type=None, message_timeout_ms=600000, message_max_bytes=2097164, log_level=LogLevel.Info, config={}, max_retries=3)</code>","text":"<p>Kafka configuration for connecting to and publishing messages to Kafka brokers.</p> <p>This configuration supports both authenticated (SASL) and unauthenticated connections. When credentials are provided, SASL authentication is automatically enabled with secure defaults.</p> <p>Authentication Priority (first match wins):     1. Direct parameters (username/password)     2. Environment variables (KAFKA_USERNAME/KAFKA_PASSWORD)     3. Configuration dictionary (sasl.username/sasl.password)</p> SASL Security Defaults <ul> <li>security.protocol: \"SASL_SSL\" (override via KAFKA_SECURITY_PROTOCOL env var)</li> <li>sasl.mechanism: \"PLAIN\" (override via KAFKA_SASL_MECHANISM env var)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>Optional[str]</code> <p>SASL username for authentication. Fallback: KAFKA_USERNAME environment variable.</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>SASL password for authentication. Fallback: KAFKA_PASSWORD environment variable.</p> <code>None</code> <code>brokers</code> <code>Optional[str]</code> <p>Comma-separated list of Kafka broker addresses (host:port). Fallback: KAFKA_BROKERS environment variable. Default: \"localhost:9092\"</p> <code>None</code> <code>topic</code> <code>Optional[str]</code> <p>Target Kafka topic for message publishing. Fallback: KAFKA_TOPIC environment variable. Default: \"scouter_monitoring\"</p> <code>None</code> <code>compression_type</code> <code>Optional[str]</code> <p>Message compression algorithm. Options: \"none\", \"gzip\", \"snappy\", \"lz4\", \"zstd\" Default: \"gzip\"</p> <code>None</code> <code>message_timeout_ms</code> <code>int</code> <p>Maximum time to wait for message delivery (milliseconds). Default: 600000 (10 minutes)</p> <code>600000</code> <code>message_max_bytes</code> <code>int</code> <p>Maximum message size in bytes. Default: 2097164 (~2MB)</p> <code>2097164</code> <code>log_level</code> <code>LogLevel</code> <p>Logging verbosity for the Kafka producer. Default: LogLevel.Info</p> <code>Info</code> <code>config</code> <code>Dict[str, str]</code> <p>Additional Kafka producer configuration parameters. See: https://kafka.apache.org/documentation/#producerconfigs Note: Direct parameters take precedence over config dictionary values.</p> <code>{}</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed message deliveries. Default: 3</p> <code>3</code> <p>Examples:</p> <p>Basic usage (unauthenticated): <pre><code>config = KafkaConfig(\n    brokers=\"kafka1:9092,kafka2:9092\",\n    topic=\"my_topic\"\n)\n</code></pre></p> <p>SASL authentication: <pre><code>config = KafkaConfig(\n    username=\"my_user\",\n    password=\"my_password\",\n    brokers=\"secure-kafka:9093\",\n    topic=\"secure_topic\"\n)\n</code></pre></p> <p>Advanced configuration: <pre><code>config = KafkaConfig(\n    brokers=\"kafka:9092\",\n    compression_type=\"lz4\",\n    config={\n        \"acks\": \"all\",\n        \"batch.size\": \"32768\",\n        \"linger.ms\": \"10\"\n    }\n)\n</code></pre></p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    brokers: Optional[str] = None,\n    topic: Optional[str] = None,\n    compression_type: Optional[str] = None,\n    message_timeout_ms: int = 600_000,\n    message_max_bytes: int = 2097164,\n    log_level: LogLevel = LogLevel.Info,\n    config: Dict[str, str] = {},\n    max_retries: int = 3,\n) -&gt; None:\n    \"\"\"Kafka configuration for connecting to and publishing messages to Kafka brokers.\n\n    This configuration supports both authenticated (SASL) and unauthenticated connections.\n    When credentials are provided, SASL authentication is automatically enabled with\n    secure defaults.\n\n    Authentication Priority (first match wins):\n        1. Direct parameters (username/password)\n        2. Environment variables (KAFKA_USERNAME/KAFKA_PASSWORD)\n        3. Configuration dictionary (sasl.username/sasl.password)\n\n    SASL Security Defaults:\n        - security.protocol: \"SASL_SSL\" (override via KAFKA_SECURITY_PROTOCOL env var)\n        - sasl.mechanism: \"PLAIN\" (override via KAFKA_SASL_MECHANISM env var)\n\n    Args:\n        username:\n            SASL username for authentication.\n            Fallback: KAFKA_USERNAME environment variable.\n        password:\n            SASL password for authentication.\n            Fallback: KAFKA_PASSWORD environment variable.\n        brokers:\n            Comma-separated list of Kafka broker addresses (host:port).\n            Fallback: KAFKA_BROKERS environment variable.\n            Default: \"localhost:9092\"\n        topic:\n            Target Kafka topic for message publishing.\n            Fallback: KAFKA_TOPIC environment variable.\n            Default: \"scouter_monitoring\"\n        compression_type:\n            Message compression algorithm.\n            Options: \"none\", \"gzip\", \"snappy\", \"lz4\", \"zstd\"\n            Default: \"gzip\"\n        message_timeout_ms:\n            Maximum time to wait for message delivery (milliseconds).\n            Default: 600000 (10 minutes)\n        message_max_bytes:\n            Maximum message size in bytes.\n            Default: 2097164 (~2MB)\n        log_level:\n            Logging verbosity for the Kafka producer.\n            Default: LogLevel.Info\n        config:\n            Additional Kafka producer configuration parameters.\n            See: https://kafka.apache.org/documentation/#producerconfigs\n            Note: Direct parameters take precedence over config dictionary values.\n        max_retries:\n            Maximum number of retry attempts for failed message deliveries.\n            Default: 3\n\n    Examples:\n        Basic usage (unauthenticated):\n        ```python\n        config = KafkaConfig(\n            brokers=\"kafka1:9092,kafka2:9092\",\n            topic=\"my_topic\"\n        )\n        ```\n\n        SASL authentication:\n        ```python\n        config = KafkaConfig(\n            username=\"my_user\",\n            password=\"my_password\",\n            brokers=\"secure-kafka:9093\",\n            topic=\"secure_topic\"\n        )\n        ```\n\n        Advanced configuration:\n        ```python\n        config = KafkaConfig(\n            brokers=\"kafka:9092\",\n            compression_type=\"lz4\",\n            config={\n                \"acks\": \"all\",\n                \"batch.size\": \"32768\",\n                \"linger.ms\": \"10\"\n            }\n        )\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.LLMRecord","title":"<code>LLMRecord</code>","text":"<p>LLM record containing context tied to a Large Language Model interaction that is used to evaluate drift in LLM responses.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; record = LLMRecord(\n...     context={\n...         \"input\": \"What is the capital of France?\",\n...         \"response\": \"Paris is the capital of France.\"\n...     },\n... )\n&gt;&gt;&gt; print(record.context[\"input\"])\n\"What is the capital of France?\"\n</code></pre> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class LLMRecord:\n    \"\"\"LLM record containing context tied to a Large Language Model interaction\n    that is used to evaluate drift in LLM responses.\n\n\n    Examples:\n        &gt;&gt;&gt; record = LLMRecord(\n        ...     context={\n        ...         \"input\": \"What is the capital of France?\",\n        ...         \"response\": \"Paris is the capital of France.\"\n        ...     },\n        ... )\n        &gt;&gt;&gt; print(record.context[\"input\"])\n        \"What is the capital of France?\"\n    \"\"\"\n\n    prompt: Optional[Prompt]\n    \"\"\"Optional prompt configuration associated with this record.\"\"\"\n\n    entity_type: EntityType\n    \"\"\"Type of entity, always EntityType.LLM for LLMRecord instances.\"\"\"\n\n    def __init__(\n        self,\n        context: Context,\n        prompt: Optional[Prompt | SerializedType] = None,\n    ) -&gt; None:\n        \"\"\"Creates a new LLM record to associate with an `LLMDriftProfile`.\n        The record is sent to the `Scouter` server via the `ScouterQueue` and is\n        then used to inject context into the evaluation prompts.\n\n        Args:\n            context:\n                Additional context information as a dictionary or a pydantic BaseModel. During evaluation,\n                this will be merged with the input and response data and passed to the assigned\n                evaluation prompts. So if you're evaluation prompts expect additional context via\n                bound variables (e.g., `${foo}`), you can pass that here as key value pairs.\n                {\"foo\": \"bar\"}\n            prompt:\n                Optional prompt configuration associated with this record. Can be a Potatohead Prompt or\n                a JSON-serializable type.\n\n        Raises:\n            TypeError: If context is not a dict or a pydantic BaseModel.\n\n        \"\"\"\n        ...\n\n    @property\n    def context(self) -&gt; Dict[str, Any]:\n        \"\"\"Get the contextual information.\n\n        Returns:\n            The context data as a Python object (deserialized from JSON).\n\n        Raises:\n            TypeError: If the stored JSON cannot be converted to a Python object.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.LLMRecord.context","title":"<code>context</code>  <code>property</code>","text":"<p>Get the contextual information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The context data as a Python object (deserialized from JSON).</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the stored JSON cannot be converted to a Python object.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.LLMRecord.entity_type","title":"<code>entity_type</code>  <code>instance-attribute</code>","text":"<p>Type of entity, always EntityType.LLM for LLMRecord instances.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.LLMRecord.prompt","title":"<code>prompt</code>  <code>instance-attribute</code>","text":"<p>Optional prompt configuration associated with this record.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.LLMRecord.__init__","title":"<code>__init__(context, prompt=None)</code>","text":"<p>Creates a new LLM record to associate with an <code>LLMDriftProfile</code>. The record is sent to the <code>Scouter</code> server via the <code>ScouterQueue</code> and is then used to inject context into the evaluation prompts.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>Additional context information as a dictionary or a pydantic BaseModel. During evaluation, this will be merged with the input and response data and passed to the assigned evaluation prompts. So if you're evaluation prompts expect additional context via bound variables (e.g., <code>${foo}</code>), you can pass that here as key value pairs.</p> required <code>prompt</code> <code>Optional[Prompt | SerializedType]</code> <p>Optional prompt configuration associated with this record. Can be a Potatohead Prompt or a JSON-serializable type.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If context is not a dict or a pydantic BaseModel.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    context: Context,\n    prompt: Optional[Prompt | SerializedType] = None,\n) -&gt; None:\n    \"\"\"Creates a new LLM record to associate with an `LLMDriftProfile`.\n    The record is sent to the `Scouter` server via the `ScouterQueue` and is\n    then used to inject context into the evaluation prompts.\n\n    Args:\n        context:\n            Additional context information as a dictionary or a pydantic BaseModel. During evaluation,\n            this will be merged with the input and response data and passed to the assigned\n            evaluation prompts. So if you're evaluation prompts expect additional context via\n            bound variables (e.g., `${foo}`), you can pass that here as key value pairs.\n            {\"foo\": \"bar\"}\n        prompt:\n            Optional prompt configuration associated with this record. Can be a Potatohead Prompt or\n            a JSON-serializable type.\n\n    Raises:\n        TypeError: If context is not a dict or a pydantic BaseModel.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metric","title":"<code>Metric</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class Metric:\n    def __init__(self, name: str, value: float | int) -&gt; None:\n        \"\"\"Initialize metric\n\n        Args:\n            name:\n                Name of the metric\n            value:\n                Value to assign to the metric. Can be an int or float but will be converted to float.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the metric\"\"\"\n\n    @property\n    def metrics(self) -&gt; List[Metric]:\n        \"\"\"Return the list of metrics\"\"\"\n\n    @property\n    def entity_type(self) -&gt; EntityType:\n        \"\"\"Return the entity type\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metric.entity_type","title":"<code>entity_type</code>  <code>property</code>","text":"<p>Return the entity type</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metric.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>Return the list of metrics</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metric.__init__","title":"<code>__init__(name, value)</code>","text":"<p>Initialize metric</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the metric</p> required <code>value</code> <code>float | int</code> <p>Value to assign to the metric. Can be an int or float but will be converted to float.</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, name: str, value: float | int) -&gt; None:\n    \"\"\"Initialize metric\n\n    Args:\n        name:\n            Name of the metric\n        value:\n            Value to assign to the metric. Can be an int or float but will be converted to float.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metric.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the metric</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the metric\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metrics","title":"<code>Metrics</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class Metrics:\n    def __init__(self, metrics: List[Metric] | Dict[str, Union[int, float]]) -&gt; None:\n        \"\"\"Initialize metrics\n\n        Args:\n            metrics:\n                List of metrics or a dictionary of key-value pairs.\n                If a list, each item must be an instance of Metric.\n                If a dictionary, each key is the metric name and each value is the metric value.\n\n\n        Example:\n            ```python\n\n            # Passing a list of metrics\n            metrics = Metrics(\n                metrics=[\n                    Metric(\"metric_1\", 1.0),\n                    Metric(\"metric_2\", 2.5),\n                    Metric(\"metric_3\", 3),\n                ]\n            )\n\n            # Passing a dictionary (pydantic model) of metrics\n            class MyMetrics(BaseModel):\n                metric1: float\n                metric2: int\n\n            my_metrics = MyMetrics(\n                metric1=1.0,\n                metric2=2,\n            )\n\n            metrics = Metrics(my_metrics.model_dump())\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the metrics\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metrics.__init__","title":"<code>__init__(metrics)</code>","text":"<p>Initialize metrics</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>List[Metric] | Dict[str, Union[int, float]]</code> <p>List of metrics or a dictionary of key-value pairs. If a list, each item must be an instance of Metric. If a dictionary, each key is the metric name and each value is the metric value.</p> required Example <p>```python</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, metrics: List[Metric] | Dict[str, Union[int, float]]) -&gt; None:\n    \"\"\"Initialize metrics\n\n    Args:\n        metrics:\n            List of metrics or a dictionary of key-value pairs.\n            If a list, each item must be an instance of Metric.\n            If a dictionary, each key is the metric name and each value is the metric value.\n\n\n    Example:\n        ```python\n\n        # Passing a list of metrics\n        metrics = Metrics(\n            metrics=[\n                Metric(\"metric_1\", 1.0),\n                Metric(\"metric_2\", 2.5),\n                Metric(\"metric_3\", 3),\n            ]\n        )\n\n        # Passing a dictionary (pydantic model) of metrics\n        class MyMetrics(BaseModel):\n            metric1: float\n            metric2: int\n\n        my_metrics = MyMetrics(\n            metric1=1.0,\n            metric2=2,\n        )\n\n        metrics = Metrics(my_metrics.model_dump())\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metrics.__init__--passing-a-list-of-metrics","title":"Passing a list of metrics","text":"<p>metrics = Metrics(     metrics=[         Metric(\"metric_1\", 1.0),         Metric(\"metric_2\", 2.5),         Metric(\"metric_3\", 3),     ] )</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metrics.__init__--passing-a-dictionary-pydantic-model-of-metrics","title":"Passing a dictionary (pydantic model) of metrics","text":"<p>class MyMetrics(BaseModel):     metric1: float     metric2: int</p> <p>my_metrics = MyMetrics(     metric1=1.0,     metric2=2, )</p> <p>metrics = Metrics(my_metrics.model_dump())</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Metrics.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the metrics</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the metrics\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord","title":"<code>PsiServerRecord</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class PsiServerRecord:\n    def __init__(\n        self,\n        space: str,\n        name: str,\n        version: str,\n        feature: str,\n        bin_id: int,\n        bin_count: int,\n    ):\n        \"\"\"Initialize spc drift server record\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            feature:\n                Feature name\n            bin_id:\n                Bundle ID\n            bin_count:\n                Bundle ID\n        \"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime.datetime:\n        \"\"\"Return the created at timestamp.\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space.\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name.\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version.\"\"\"\n\n    @property\n    def feature(self) -&gt; str:\n        \"\"\"Return the feature.\"\"\"\n\n    @property\n    def bin_id(self) -&gt; int:\n        \"\"\"Return the bin id.\"\"\"\n\n    @property\n    def bin_count(self) -&gt; int:\n        \"\"\"Return the sample value.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the record.\"\"\"\n\n    def to_dict(self) -&gt; Dict[str, str]:\n        \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.bin_count","title":"<code>bin_count</code>  <code>property</code>","text":"<p>Return the sample value.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.bin_id","title":"<code>bin_id</code>  <code>property</code>","text":"<p>Return the bin id.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Return the created at timestamp.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.feature","title":"<code>feature</code>  <code>property</code>","text":"<p>Return the feature.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the name.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.space","title":"<code>space</code>  <code>property</code>","text":"<p>Return the space.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.version","title":"<code>version</code>  <code>property</code>","text":"<p>Return the version.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.__init__","title":"<code>__init__(space, name, version, feature, bin_id, bin_count)</code>","text":"<p>Initialize spc drift server record</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> required <code>name</code> <code>str</code> <p>Model name</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>feature</code> <code>str</code> <p>Feature name</p> required <code>bin_id</code> <code>int</code> <p>Bundle ID</p> required <code>bin_count</code> <code>int</code> <p>Bundle ID</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    space: str,\n    name: str,\n    version: str,\n    feature: str,\n    bin_id: int,\n    bin_count: int,\n):\n    \"\"\"Initialize spc drift server record\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        feature:\n            Feature name\n        bin_id:\n            Bundle ID\n        bin_count:\n            Bundle ID\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.PsiServerRecord.to_dict","title":"<code>to_dict()</code>","text":"<p>Return the dictionary representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def to_dict(self) -&gt; Dict[str, str]:\n    \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Queue","title":"<code>Queue</code>","text":"<p>Individual queue associated with a drift profile</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class Queue:\n    \"\"\"Individual queue associated with a drift profile\"\"\"\n\n    def insert(self, entity: Union[Features, Metrics, LLMRecord]) -&gt; None:\n        \"\"\"Insert a record into the queue\n\n        Args:\n            entity:\n                Entity to insert into the queue.\n                Can be an instance for Features, Metrics, or LLMRecord.\n\n        Example:\n            ```python\n            features = Features(\n                features=[\n                    Feature(\"feature_1\", 1),\n                    Feature(\"feature_2\", 2.0),\n                    Feature(\"feature_3\", \"value\"),\n                ]\n            )\n            queue.insert(features)\n            ```\n        \"\"\"\n\n    @property\n    def identifier(self) -&gt; str:\n        \"\"\"Return the identifier of the queue\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Queue.identifier","title":"<code>identifier</code>  <code>property</code>","text":"<p>Return the identifier of the queue</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.Queue.insert","title":"<code>insert(entity)</code>","text":"<p>Insert a record into the queue</p> <p>Parameters:</p> Name Type Description Default <code>entity</code> <code>Union[Features, Metrics, LLMRecord]</code> <p>Entity to insert into the queue. Can be an instance for Features, Metrics, or LLMRecord.</p> required Example <pre><code>features = Features(\n    features=[\n        Feature(\"feature_1\", 1),\n        Feature(\"feature_2\", 2.0),\n        Feature(\"feature_3\", \"value\"),\n    ]\n)\nqueue.insert(features)\n</code></pre> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def insert(self, entity: Union[Features, Metrics, LLMRecord]) -&gt; None:\n    \"\"\"Insert a record into the queue\n\n    Args:\n        entity:\n            Entity to insert into the queue.\n            Can be an instance for Features, Metrics, or LLMRecord.\n\n    Example:\n        ```python\n        features = Features(\n            features=[\n                Feature(\"feature_1\", 1),\n                Feature(\"feature_2\", 2.0),\n                Feature(\"feature_3\", \"value\"),\n            ]\n        )\n        queue.insert(features)\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.RabbitMQConfig","title":"<code>RabbitMQConfig</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class RabbitMQConfig:\n    address: str\n    queue: str\n    max_retries: int\n    transport_type: TransportType\n\n    def __init__(\n        self,\n        host: Optional[str] = None,\n        port: Optional[int] = None,\n        username: Optional[str] = None,\n        password: Optional[str] = None,\n        queue: Optional[str] = None,\n        max_retries: int = 3,\n    ) -&gt; None:\n        \"\"\"RabbitMQ configuration to use with the RabbitMQProducer.\n\n        Args:\n            host:\n                RabbitMQ host.\n                If not provided, the value of the RABBITMQ_HOST environment variable is used.\n\n            port:\n                RabbitMQ port.\n                If not provided, the value of the RABBITMQ_PORT environment variable is used.\n\n            username:\n                RabbitMQ username.\n                If not provided, the value of the RABBITMQ_USERNAME environment variable is used.\n\n            password:\n                RabbitMQ password.\n                If not provided, the value of the RABBITMQ_PASSWORD environment variable is used.\n\n            queue:\n                RabbitMQ queue to publish messages to.\n                If not provided, the value of the RABBITMQ_QUEUE environment variable is used.\n\n            max_retries:\n                Maximum number of retries to attempt when publishing messages.\n                Default is 3.\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.RabbitMQConfig.__init__","title":"<code>__init__(host=None, port=None, username=None, password=None, queue=None, max_retries=3)</code>","text":"<p>RabbitMQ configuration to use with the RabbitMQProducer.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>Optional[str]</code> <p>RabbitMQ host. If not provided, the value of the RABBITMQ_HOST environment variable is used.</p> <code>None</code> <code>port</code> <code>Optional[int]</code> <p>RabbitMQ port. If not provided, the value of the RABBITMQ_PORT environment variable is used.</p> <code>None</code> <code>username</code> <code>Optional[str]</code> <p>RabbitMQ username. If not provided, the value of the RABBITMQ_USERNAME environment variable is used.</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>RabbitMQ password. If not provided, the value of the RABBITMQ_PASSWORD environment variable is used.</p> <code>None</code> <code>queue</code> <code>Optional[str]</code> <p>RabbitMQ queue to publish messages to. If not provided, the value of the RABBITMQ_QUEUE environment variable is used.</p> <code>None</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retries to attempt when publishing messages. Default is 3.</p> <code>3</code> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    host: Optional[str] = None,\n    port: Optional[int] = None,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    queue: Optional[str] = None,\n    max_retries: int = 3,\n) -&gt; None:\n    \"\"\"RabbitMQ configuration to use with the RabbitMQProducer.\n\n    Args:\n        host:\n            RabbitMQ host.\n            If not provided, the value of the RABBITMQ_HOST environment variable is used.\n\n        port:\n            RabbitMQ port.\n            If not provided, the value of the RABBITMQ_PORT environment variable is used.\n\n        username:\n            RabbitMQ username.\n            If not provided, the value of the RABBITMQ_USERNAME environment variable is used.\n\n        password:\n            RabbitMQ password.\n            If not provided, the value of the RABBITMQ_PASSWORD environment variable is used.\n\n        queue:\n            RabbitMQ queue to publish messages to.\n            If not provided, the value of the RABBITMQ_QUEUE environment variable is used.\n\n        max_retries:\n            Maximum number of retries to attempt when publishing messages.\n            Default is 3.\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.RedisConfig","title":"<code>RedisConfig</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class RedisConfig:\n    address: str\n    channel: str\n    transport_type: TransportType\n\n    def __init__(\n        self,\n        address: Optional[str] = None,\n        chanel: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Redis configuration to use with a Redis producer\n\n        Args:\n            address (str):\n                Redis address.\n                If not provided, the value of the REDIS_ADDR environment variable is used and defaults to \"redis://localhost:6379\".\n\n            channel (str):\n                Redis channel to publish messages to.\n\n                If not provided, the value of the REDIS_CHANNEL environment variable is used and defaults to \"scouter_monitoring\".\n        \"\"\"\n\n    def __str__(self): ...\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.RedisConfig.__init__","title":"<code>__init__(address=None, chanel=None)</code>","text":"<p>Redis configuration to use with a Redis producer</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Redis address. If not provided, the value of the REDIS_ADDR environment variable is used and defaults to \"redis://localhost:6379\".</p> <code>None</code> <code>channel</code> <code>str</code> <p>Redis channel to publish messages to.</p> <p>If not provided, the value of the REDIS_CHANNEL environment variable is used and defaults to \"scouter_monitoring\".</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    address: Optional[str] = None,\n    chanel: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Redis configuration to use with a Redis producer\n\n    Args:\n        address (str):\n            Redis address.\n            If not provided, the value of the REDIS_ADDR environment variable is used and defaults to \"redis://localhost:6379\".\n\n        channel (str):\n            Redis channel to publish messages to.\n\n            If not provided, the value of the REDIS_CHANNEL environment variable is used and defaults to \"scouter_monitoring\".\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ScouterQueue","title":"<code>ScouterQueue</code>","text":"<p>Main queue class for Scouter. Publishes drift records to the configured transport</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class ScouterQueue:\n    \"\"\"Main queue class for Scouter. Publishes drift records to the configured transport\"\"\"\n\n    @staticmethod\n    def from_path(\n        path: Dict[str, Path],\n        transport_config: Union[\n            KafkaConfig,\n            RabbitMQConfig,\n            RedisConfig,\n            HTTPConfig,\n        ],\n    ) -&gt; ScouterQueue:\n        \"\"\"Initializes Scouter queue from one or more drift profile paths\n\n        Args:\n            path (Dict[str, Path]):\n                Dictionary of drift profile paths.\n                Each key is a user-defined alias for accessing a queue\n            transport_config (Union[KafkaConfig, RabbitMQConfig, RedisConfig, HTTPConfig]):\n                Transport configuration for the queue publisher\n                Can be KafkaConfig, RabbitMQConfig RedisConfig, or HTTPConfig\n\n        Example:\n            ```python\n            queue = ScouterQueue(\n                path={\n                    \"spc\": Path(\"spc_profile.json\"),\n                    \"psi\": Path(\"psi_profile.json\"),\n                },\n                transport_config=KafkaConfig(\n                    brokers=\"localhost:9092\",\n                    topic=\"scouter_topic\",\n                ),\n            )\n\n            queue[\"psi\"].insert(\n                Features(\n                    features=[\n                        Feature(\"feature_1\", 1),\n                        Feature(\"feature_2\", 2.0),\n                        Feature(\"feature_3\", \"value\"),\n                    ]\n                )\n            )\n            ```\n        \"\"\"\n\n    def __getitem__(self, key: str) -&gt; Queue:\n        \"\"\"Get the queue for the specified key\n\n        Args:\n            key (str):\n                Key to get the queue for\n\n        \"\"\"\n\n    def shutdown(self) -&gt; None:\n        \"\"\"Shutdown the queue. This will close and flush all queues and transports\"\"\"\n\n    @property\n    def transport_config(\n        self,\n    ) -&gt; Union[KafkaConfig, RabbitMQConfig, RedisConfig, HTTPConfig, MockConfig]:\n        \"\"\"Return the transport configuration used by the queue\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ScouterQueue.transport_config","title":"<code>transport_config</code>  <code>property</code>","text":"<p>Return the transport configuration used by the queue</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ScouterQueue.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get the queue for the specified key</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key to get the queue for</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __getitem__(self, key: str) -&gt; Queue:\n    \"\"\"Get the queue for the specified key\n\n    Args:\n        key (str):\n            Key to get the queue for\n\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ScouterQueue.from_path","title":"<code>from_path(path, transport_config)</code>  <code>staticmethod</code>","text":"<p>Initializes Scouter queue from one or more drift profile paths</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Dict[str, Path]</code> <p>Dictionary of drift profile paths. Each key is a user-defined alias for accessing a queue</p> required <code>transport_config</code> <code>Union[KafkaConfig, RabbitMQConfig, RedisConfig, HTTPConfig]</code> <p>Transport configuration for the queue publisher Can be KafkaConfig, RabbitMQConfig RedisConfig, or HTTPConfig</p> required Example <pre><code>queue = ScouterQueue(\n    path={\n        \"spc\": Path(\"spc_profile.json\"),\n        \"psi\": Path(\"psi_profile.json\"),\n    },\n    transport_config=KafkaConfig(\n        brokers=\"localhost:9092\",\n        topic=\"scouter_topic\",\n    ),\n)\n\nqueue[\"psi\"].insert(\n    Features(\n        features=[\n            Feature(\"feature_1\", 1),\n            Feature(\"feature_2\", 2.0),\n            Feature(\"feature_3\", \"value\"),\n        ]\n    )\n)\n</code></pre> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>@staticmethod\ndef from_path(\n    path: Dict[str, Path],\n    transport_config: Union[\n        KafkaConfig,\n        RabbitMQConfig,\n        RedisConfig,\n        HTTPConfig,\n    ],\n) -&gt; ScouterQueue:\n    \"\"\"Initializes Scouter queue from one or more drift profile paths\n\n    Args:\n        path (Dict[str, Path]):\n            Dictionary of drift profile paths.\n            Each key is a user-defined alias for accessing a queue\n        transport_config (Union[KafkaConfig, RabbitMQConfig, RedisConfig, HTTPConfig]):\n            Transport configuration for the queue publisher\n            Can be KafkaConfig, RabbitMQConfig RedisConfig, or HTTPConfig\n\n    Example:\n        ```python\n        queue = ScouterQueue(\n            path={\n                \"spc\": Path(\"spc_profile.json\"),\n                \"psi\": Path(\"psi_profile.json\"),\n            },\n            transport_config=KafkaConfig(\n                brokers=\"localhost:9092\",\n                topic=\"scouter_topic\",\n            ),\n        )\n\n        queue[\"psi\"].insert(\n            Features(\n                features=[\n                    Feature(\"feature_1\", 1),\n                    Feature(\"feature_2\", 2.0),\n                    Feature(\"feature_3\", \"value\"),\n                ]\n            )\n        )\n        ```\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ScouterQueue.shutdown","title":"<code>shutdown()</code>","text":"<p>Shutdown the queue. This will close and flush all queues and transports</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def shutdown(self) -&gt; None:\n    \"\"\"Shutdown the queue. This will close and flush all queues and transports\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ServerRecord","title":"<code>ServerRecord</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class ServerRecord:\n    Spc: \"ServerRecord\"\n    Psi: \"ServerRecord\"\n    Custom: \"ServerRecord\"\n    Observability: \"ServerRecord\"\n\n    def __init__(self, record: Any) -&gt; None:\n        \"\"\"Initialize server record\n\n        Args:\n            record:\n                Server record to initialize\n        \"\"\"\n\n    @property\n    def record(\n        self,\n    ) -&gt; Union[SpcServerRecord, PsiServerRecord, CustomMetricServerRecord, ObservabilityMetrics]:\n        \"\"\"Return the drift server record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ServerRecord.record","title":"<code>record</code>  <code>property</code>","text":"<p>Return the drift server record.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ServerRecord.__init__","title":"<code>__init__(record)</code>","text":"<p>Initialize server record</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Any</code> <p>Server record to initialize</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, record: Any) -&gt; None:\n    \"\"\"Initialize server record\n\n    Args:\n        record:\n            Server record to initialize\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ServerRecords","title":"<code>ServerRecords</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class ServerRecords:\n    def __init__(self, records: List[ServerRecord]) -&gt; None:\n        \"\"\"Initialize server records\n\n        Args:\n            records:\n                List of server records\n        \"\"\"\n\n    @property\n    def records(self) -&gt; List[ServerRecord]:\n        \"\"\"Return the drift server records.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the record.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ServerRecords.records","title":"<code>records</code>  <code>property</code>","text":"<p>Return the drift server records.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ServerRecords.__init__","title":"<code>__init__(records)</code>","text":"<p>Initialize server records</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>List[ServerRecord]</code> <p>List of server records</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(self, records: List[ServerRecord]) -&gt; None:\n    \"\"\"Initialize server records\n\n    Args:\n        records:\n            List of server records\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ServerRecords.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.ServerRecords.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord","title":"<code>SpcServerRecord</code>","text":"Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>class SpcServerRecord:\n    def __init__(\n        self,\n        space: str,\n        name: str,\n        version: str,\n        feature: str,\n        value: float,\n    ):\n        \"\"\"Initialize spc drift server record\n\n        Args:\n            space:\n                Model space\n            name:\n                Model name\n            version:\n                Model version\n            feature:\n                Feature name\n            value:\n                Feature value\n        \"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime.datetime:\n        \"\"\"Return the created at timestamp.\"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space.\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name.\"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version.\"\"\"\n\n    @property\n    def feature(self) -&gt; str:\n        \"\"\"Return the feature.\"\"\"\n\n    @property\n    def value(self) -&gt; float:\n        \"\"\"Return the sample value.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the record.\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the json representation of the record.\"\"\"\n\n    def to_dict(self) -&gt; Dict[str, str]:\n        \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Return the created at timestamp.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.feature","title":"<code>feature</code>  <code>property</code>","text":"<p>Return the feature.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.name","title":"<code>name</code>  <code>property</code>","text":"<p>Return the name.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.space","title":"<code>space</code>  <code>property</code>","text":"<p>Return the space.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.value","title":"<code>value</code>  <code>property</code>","text":"<p>Return the sample value.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.version","title":"<code>version</code>  <code>property</code>","text":"<p>Return the version.</p>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.__init__","title":"<code>__init__(space, name, version, feature, value)</code>","text":"<p>Initialize spc drift server record</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>str</code> <p>Model space</p> required <code>name</code> <code>str</code> <p>Model name</p> required <code>version</code> <code>str</code> <p>Model version</p> required <code>feature</code> <code>str</code> <p>Feature name</p> required <code>value</code> <code>float</code> <p>Feature value</p> required Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __init__(\n    self,\n    space: str,\n    name: str,\n    version: str,\n    feature: str,\n    value: float,\n):\n    \"\"\"Initialize spc drift server record\n\n    Args:\n        space:\n            Model space\n        name:\n            Model name\n        version:\n            Model version\n        feature:\n            Feature name\n        value:\n            Feature value\n    \"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.model_dump_json","title":"<code>model_dump_json()</code>","text":"<p>Return the json representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def model_dump_json(self) -&gt; str:\n    \"\"\"Return the json representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/queue/#opsml.scouter.queue._queue.SpcServerRecord.to_dict","title":"<code>to_dict()</code>","text":"<p>Return the dictionary representation of the record.</p> Source code in <code>python/opsml/scouter/queue/_queue.pyi</code> <pre><code>def to_dict(self) -&gt; Dict[str, str]:\n    \"\"\"Return the dictionary representation of the record.\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/types/","title":"Types","text":""},{"location":"docs/api/scouter/types/#opsml.scouter.types._types.CommonCrons","title":"<code>CommonCrons</code>","text":"Source code in <code>python/opsml/scouter/types/_types.pyi</code> <pre><code>class CommonCrons:\n    Every1Minute: \"CommonCrons\"\n    Every5Minutes: \"CommonCrons\"\n    Every15Minutes: \"CommonCrons\"\n    Every30Minutes: \"CommonCrons\"\n    EveryHour: \"CommonCrons\"\n    Every6Hours: \"CommonCrons\"\n    Every12Hours: \"CommonCrons\"\n    EveryDay: \"CommonCrons\"\n    EveryWeek: \"CommonCrons\"\n\n    @property\n    def cron(self) -&gt; str:\n        \"\"\"Return the cron\"\"\"\n\n    def get_next(self) -&gt; str:\n        \"\"\"Return the next cron time\"\"\"\n</code></pre>"},{"location":"docs/api/scouter/types/#opsml.scouter.types._types.CommonCrons.cron","title":"<code>cron</code>  <code>property</code>","text":"<p>Return the cron</p>"},{"location":"docs/api/scouter/types/#opsml.scouter.types._types.CommonCrons.get_next","title":"<code>get_next()</code>","text":"<p>Return the next cron time</p> Source code in <code>python/opsml/scouter/types/_types.pyi</code> <pre><code>def get_next(self) -&gt; str:\n    \"\"\"Return the next cron time\"\"\"\n</code></pre>"},{"location":"docs/automation/pyproject/","title":"Tools","text":"<p>Out of the box, Opsml allows you to create tool configurations within your pyproject.toml file to help simplify some workflows. Currently, tool configurations support:</p>"},{"location":"docs/automation/pyproject/#global-default-variables","title":"Global Default Variables","text":"<ul> <li>Define global attributes that apply to all cards created in the project.</li> <li>Supports <code>space</code>, <code>name</code>, and <code>version</code>.</li> </ul>"},{"location":"docs/automation/pyproject/#example","title":"Example","text":"<pre><code>[tool.opsml.default]\nspace = \"space\"\nname = \"my-card\"\n</code></pre> <p>Now when you create a card, it will automatically use these values unless overridden.</p> <pre><code>modelcard = ModelCard( # (1)\n    interface=model_interface,\n    tags=[\"foo:bar\", \"baz:qux\"],\n    datacard_uid=datacard.uid,\n)\n\nmodel_registry.register_card(modelcard)\n</code></pre> <ol> <li><code>space</code> and <code>name</code> are automatically set to \"space\" and \"my-card\" respectively, as defined in the <code>pyproject.toml</code> file.</li> </ol>"},{"location":"docs/automation/pyproject/#global-registry-variables","title":"Global Registry Variables","text":"<ul> <li>A more granular way to define registry/card-specific variables.</li> <li>Allows you to specify <code>space</code>, <code>name</code>, and <code>version</code> for each registry.</li> <li>Each line defines a registry type (e.g., model, prompt) and its associated variables.</li> </ul>"},{"location":"docs/automation/pyproject/#example_1","title":"Example","text":"<pre><code>[tool.opsml.registry]\nmodel = { space = \"opsml\", name = \"my-model\" }\nprompt = { space = \"opsml\", name = \"my-prompt\" }\n</code></pre> <p><pre><code>modelcard = ModelCard( # (1)\n    interface=model_interface,\n    tags=[\"foo:bar\", \"baz:qux\"],\n    datacard_uid=datacard.uid,\n)\n\nmodel_registry.register_card(modelcard)\n\n\ncard = PromptCard(\n    prompt=Prompt( # (2)\n        model=\"gpt-4o\",\n        provider=\"openai\",\n        message=\"Provide a brief summary of the programming language $1.\",\n        system_instruction=\"Be concise, reply with one sentence.\",\n    ),\n)\n\nprompt_registry.register_card(card)\n</code></pre> 1. The modelcard will automatically use the space \"opsml\" and name \"my-model\" as defined in the <code>pyproject.toml</code> file for the model registry. 2. The prompt card will automatically use the space \"opsml\" and name \"my-prompt\" as defined in the <code>pyproject.toml</code> file for the prompt registry.</p>"},{"location":"docs/benchmark/overview/","title":"Overview","text":"<p>One of the benefits of using OpsML is its performance and simplified dependency chain compared to other python-based MLOps frameworks like <code>MLflow</code>. While we are continually working on adding additional benchmarks, below are some initial performance comparisons between OpsML and MLflow.</p>"},{"location":"docs/benchmark/overview/#benchmark-setup","title":"Benchmark Setup","text":"<p>See the benchmark setup documentation for the current benchmark setup. </p> <p>For the results below, we created a separate virtual environment for each framework with only the required dependencies installed + scikit-learn. We then ran the same benchmark script for each framework to compare performance.</p>"},{"location":"docs/benchmark/overview/#benchmark-results","title":"Benchmark Results","text":"<p>The following table summarizes the benchmark results comparing OpsML and MLflow for a simple model training and logging task using scikit-learn. Note - this tests both frameworks running in server mode (local storage + sqlite).</p> Framework Time Taken (seconds) Dependencies Venv size (MB) OpsML 0.027 9 321  (opsml - 25) MLflow 1.2 116 501"},{"location":"docs/cards/datacard/","title":"Datacard","text":"<p>DataCards are used for storing, versioning, and tracking data. All DataCards require a <code>DataInterface</code> and optional metadata. </p>"},{"location":"docs/cards/datacard/#create-a-card","title":"Create a Card","text":"<pre><code>from opsml.data import (\n    DataSplit,\n    DataSplits,\n    DependentVars,\n    PandasData,\n    ColumnSplit,\n)\nfrom opsml import DataCard, CardRegistry, RegistryType\nfrom opsml.helpers.data import create_fake_data\nimport pandas as pd\n\nregistry = CardRegistry(RegistryType.Data)\n\n# create data\nX, y = cast(Tuple[pd.DataFrame, pd.DataFrame], create_fake_data(n_samples=1200))\nX[\"target\"] = y\n\n# create data splits to store with the model (optional)\ndata_splits = [\n    DataSplit(  # (1)\n        label=\"train\",\n        start_stop_split=StartStopSplit(\n            start=0,\n            stop=1000,\n        ),\n    ),\n    DataSplit(\n        label=\"test\",\n        start_stop_split=StartStopSplit(\n            start=1000,\n            stop=1200,\n        ),\n    ),\n]\n\n# create DataCard\ndatacard = DataCard( # (3)\n    interface=PandasData( # (2)\n        data=X,\n        data_splits=data_splits,\n        dependent_vars=[\"target\"],\n    ),\n    space=\"opsml\",\n    name=\"my_data\",\n    tags=[\"foo:bar\", \"baz:qux\"],\n)\n\n# register DataCard\nreg.data.register_card(datacard)\n</code></pre> <ol> <li>DataSplits allow you to create and store split logic with your DataInterface ensuring reproducibility</li> <li>Here we are using the PandasData interface and passing in the pandas dataframe, data splits and are defining and dependent variable.</li> <li>Create a DataCard and pass in the DataInterface, space, name, and tags. </li> </ol>"},{"location":"docs/cards/datacard/#how-it-all-works","title":"How it all works","text":"<p>As you can tell in the example above, <code>DataCards</code> are created by passing in a <code>DataInterface</code>, some required args and some optional args. The <code>DataInterface</code> is the interface is a library-specific interface for saving and extracting metadata from the data. It also allows us to standardize how data is saved (by following the library's guidelines) and ensures reproducibility.</p>"},{"location":"docs/cards/datacard/#load-a-cards-components","title":"Load a Card's Components","text":"<p>By default, <code>OpsML</code> does not load any of the data components (data, preprocessor, etc.) when loading a card. This is to ensure that the card is loaded as quickly as possible. If you wish to load the data components, you can do so by calling the <code>load</code> method on the <code>DataCard</code> and provide any additional arguments via the <code>load_kwargs</code> argument. </p> <pre><code>from opsml import CardRegistry, RegistryType\n\n# start registries\nreg = CardRegistry(RegistryType.Data)\n\n# load the card\ndatacard = reg.load_card(uid=\"{{data uid}}\")\n\n# load the data\ndatacard.load()\n</code></pre> DataCard <pre><code>class DataCard:\n    def __init__(  # pylint: disable=dangerous-default-value\n        self,\n        interface: Optional[DataInterface] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        uid: Optional[str] = None,\n        tags: List[str] = [],\n    ) -&gt; None:\n        \"\"\"Define a data card\n\n        Args:\n            interface (DataInterface | None):\n                The data interface\n            space (str | None):\n                The space of the card\n            name (str | None):\n                The name of the card\n            version (str | None):\n                The version of the card\n            uid (str | None):\n                The uid of the card\n            tags (List[str]):\n                The tags of the card\n\n        Example:\n        ```python\n        from opsml import DataCard, CardRegistry, RegistryType, PandasData\n\n        # for testing purposes\n        from opsml.helpers.data import create_fake_data\n\n        # pandas data\n        X, _ = create_fake_data(n_samples=1200)\n\n        interface = PandasData(data=X)\n        datacard = DataCard(\n            interface=interface,\n            space=\"my-repo\",\n            name=\"my-name\",\n            tags=[\"foo:bar\", \"baz:qux\"],\n        )\n\n        # register card\n        registry = CardRegistry(RegistryType.Data)\n        registry.register_card(datacard)\n        ```\n        \"\"\"\n\n    @property\n    def experimentcard_uid(self) -&gt; Optional[str]:\n        \"\"\"Return the experimentcard uid\"\"\"\n\n    @experimentcard_uid.setter\n    def experimentcard_uid(self, experimentcard_uid: Optional[str]) -&gt; None:\n        \"\"\"Set the experimentcard uid\"\"\"\n\n    @property\n    def interface(self) -&gt; Optional[DataInterface]:\n        \"\"\"Return the data interface\"\"\"\n\n    @interface.setter\n    def interface(self, interface: Any) -&gt; None:\n        \"\"\"Set the data interface\n\n        Args:\n            interface (DataInterface):\n                The data interface to set. Must inherit from DataInterface\n        \"\"\"\n\n    @property\n    def app_env(self) -&gt; str:\n        \"\"\"Returns the app env\"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime:\n        \"\"\"Returns the created at timestamp\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Return the name of the data card\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set the name of the data card\n\n        Args:\n            name (str):\n                The name of the data card\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Return the space of the data card\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set the space of the data card\n\n        Args:\n            space (str):\n                The space of the data card\n        \"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Return the version of the data card\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set the version of the data card\n\n        Args:\n            version (str):\n                The version of the data card\n        \"\"\"\n\n    @property\n    def uid(self) -&gt; str:\n        \"\"\"Return the uid of the data card\"\"\"\n\n    @property\n    def tags(self) -&gt; List[str]:\n        \"\"\"Return the tags of the data card\"\"\"\n\n    @tags.setter\n    def tags(self, tags: List[str]) -&gt; None:\n        \"\"\"Set the tags of the data card\n\n        Args:\n            tags (List[str]):\n                The tags of the data card\n        \"\"\"\n\n    @property\n    def metadata(self) -&gt; DataCardMetadata:  # pylint: disable=used-before-assignment\n        \"\"\"Return the metadata of the data card\"\"\"\n\n    @property\n    def registry_type(self) -&gt; RegistryType:\n        \"\"\"Return the card type of the data card\"\"\"\n\n    @property\n    def data_type(self) -&gt; DataType:\n        \"\"\"Return the data type\"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: Optional[DataSaveKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Save the data card\n\n        Args:\n            path (Path):\n                The path to save the data card to\n            save_kwargs (DataSaveKwargs | None):\n                Optional save kwargs to that will be passed to the\n                data interface save method\n\n        Acceptable save kwargs:\n            Kwargs are passed to the underlying data interface for saving.\n            For a complete list of options see the save method of the data interface and\n            their associated libraries.\n        \"\"\"\n\n    def load(\n        self,\n        path: Optional[Path] = None,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data card\n\n        Args:\n            path (Path | None):\n                The path to load the data card from. If no path is provided,\n                the data interface will be loaded from the server.\n            load_kwargs (DataLoadKwargs | None):\n                Optional load kwargs to that will be passed to the\n                data interface load method\n        \"\"\"\n\n    def download_artifacts(self, path: Optional[Path] = None) -&gt; None:\n        \"\"\"Download artifacts associated with the DataCard\n\n        Args:\n            path (Path):\n                Path to save the artifacts. If not provided, the artifacts will be saved\n                to a directory called \"card_artifacts\"\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the model dump as a json string\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str, interface: Optional[DataInterface] = None) -&gt; \"ModelCard\":\n        \"\"\"Validate the model json string\n\n        Args:\n            json_string (str):\n                The json string to validate\n            interface (DataInterface):\n                By default, the interface will be inferred and instantiated\n                from the interface metadata. If an interface is provided\n                (as in the case of custom interfaces), it will be used.\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/datacard/#data-interface","title":"Data Interface","text":"<p>The <code>DataInterface</code> is the primary interface for working with data in <code>Opsml</code>. It is designed to be subclassed and can be used to store data in a variety of formats depending on the library. Out of the box the following subclasses are available:</p> <ul> <li><code>PandasData</code>: Stores data from a pytorch lightning model - link</li> <li><code>PolarsData</code>: Stores data from a huggingface model - link</li> <li><code>ArrowData</code>: Stores data from a sklearn model - link</li> <li><code>NumpyData</code>: Stores data from a pytorch model - link</li> <li><code>TorchData</code>: Stores data from a tensorflow model - link</li> <li><code>SqlData</code>: Stores data from a xgboost model - link</li> </ul>"},{"location":"docs/cards/datacard/#shared-arguments-for-all-data-interfaces","title":"Shared Arguments for all Data Interfaces","text":"Argument Description data Data to associate with interface data_splits Optional data splits to associate with the data dependent_vars Optional dependent variables to associate with the data. Can be one of <code>DependentVars</code>, List[str] or List[int]. Will be converted to <code>DependentVars</code>. dependent_vars is used in conjunction with data_splits to split data into X and y datasets based on the defined criteria. sql_logic Optional <code>SqlLogic</code> to associate with the interface DataInterface <pre><code>class DataInterface:\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (Any):\n                Data. Can be a pyarrow table, pandas dataframe, polars dataframe\n                or numpy array\n            dependent_vars (DependentVars):\n                List of dependent variables to associate with data\n            data_splits (DataSplits):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic):\n                SqlLogic class used to generate data.\n            data_profile (DataProfile):\n                Data profile\n        \"\"\"\n\n    @property\n    def data(self) -&gt; Optional[Any]:\n        \"\"\"Returns the data\"\"\"\n\n    @data.setter\n    def data(self, data: Any) -&gt; None:\n        \"\"\"Sets the data\"\"\"\n\n    @property\n    def data_splits(self) -&gt; DataSplits:\n        \"\"\"Returns the data splits.\"\"\"\n\n    @data_splits.setter\n    def data_splits(self, data_splits: Union[DataSplits, List[DataSplit]]) -&gt; None:\n        \"\"\"Sets the data splits\"\"\"\n\n    @property\n    def dependent_vars(self) -&gt; DependentVars:\n        \"\"\"Returns the dependent variables.\"\"\"\n\n    @dependent_vars.setter\n    def dependent_vars(\n        self,\n        dependent_vars: Union[DependentVars, List[str], List[int]],\n    ) -&gt; None:\n        \"\"\"Sets the dependent variables\"\"\"\n\n    @property\n    def schema(self) -&gt; FeatureSchema:\n        \"\"\"Returns the feature map.\"\"\"\n\n    @schema.setter\n    def schema(self, schema: FeatureSchema) -&gt; None:\n        \"\"\"Sets the feature map\"\"\"\n\n    @property\n    def sql_logic(self) -&gt; SqlLogic:\n        \"\"\"Returns the sql logic.\"\"\"\n\n    @property\n    def data_type(self) -&gt; DataType:\n        \"\"\"Return the data type.\"\"\"\n\n    def add_sql_logic(\n        self,\n        name: str,\n        query: Optional[str] = None,\n        filepath: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Add sql logic to the data interface\n\n        Args:\n            name:\n                The name of the sql logic\n            query:\n                The optional query to use\n            filepath:\n                The optional filepath to open the query from\n        \"\"\"\n\n    def save(self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves all data interface component to the given path. This used as part of saving a\n        DataCard\n\n        Methods called in save:\n            - save_sql: Saves all sql logic to files(s)\n            - create_schema: Creates a FeatureSchema from the associated data\n            - save_data: Saves the data to a file\n\n        Args:\n            path (Path):\n                The path to save the data interface components to.\n            save_kwargs (DataSaveKwargs):\n                The save kwargs to use.\n\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data from a file\n\n        Args:\n            path (Path):\n                Base path to load the data from\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n        \"\"\"\n\n    def split_data(self) -&gt; Dict[str, Data]:\n        \"\"\"Split the data\n\n        Returns:\n            A dictionary of data splits\n        \"\"\"\n\n    def create_data_profile(\n        self,\n        bin_size: Optional[int] = 20,\n        compute_correlations: Optional[bool] = False,\n    ) -&gt; DataProfile:\n        \"\"\"Create a data profile\n\n\n        Args:\n            bin_size (int):\n                The bin size for the data profile\n            compute_correlations (bool):\n                Whether to compute correlations\n        \"\"\"\n\n    @property\n    def data_profile(self) -&gt; Optional[DataProfile]: ...\n</code></pre>"},{"location":"docs/cards/datacard/#data-splits","title":"Data Splits","text":"<p>With DataInterfaces it's possible to define a data split that can be used to split your data into different sets. This is typically useful for traditional ML models where you want to split your data into train, test and validation sets. The <code>DataSplit</code> class ensures reproducibility by storing the split logic with the data.</p> <p>DataInterfaces support the following types of splits:</p> <ul> <li><code>ColumnSplit</code>: Split the data based on a column value. This is common when using pandas or polars dataframes. <code>ColumnSplit</code> expects a column name, value, type (either builtin or timestamp) and an optional inequality (defualts to ==).</li> <li><code>StartStopSplit</code>: Split the data based on a start and stop index. This is common when using numpy arrays or pyarrow tables. <code>StartStopSplit</code> expects a start and stop index.</li> <li><code>IndiceSplit</code>: Split the data based on a list of indices. This is common when using numpy arrays or pyarrow tables. <code>IndiceSplit</code> expects a list of indices.</li> </ul> <p>When creating a <code>DataSplit</code>, you must provide a label and at least one of the following: <code>ColumnSplit</code>, <code>StartStopSplit</code> or <code>IndiceSplit</code></p>"},{"location":"docs/cards/datacard/#creating-data-splits","title":"Creating Data Splits","text":"<pre><code>from opsml.data import DataSplit, ColumnSplit, StartStopSplit, IndiceSplit, Inequality, ColType\n\n# Example of ColumnSplit\nsplit = ColumnSplit(\n    column_name=\"foo\",\n    column_value=3,\n    column_type=ColType.Builtin,\n    inequality=Inequality.LesserThan, # \"&lt;\" will also work\n)\n\n# timestamp example\nsplit = ColumnSplit(\n    column_name=\"timestamp\",\n    column_value=datetime.datetime(2022, 1, 1).timestamp(),\n    column_type=ColType.Timestamp,\n    inequality=\"&gt;\",\n)\n\n# Example of StartStopSplit\nsplit = DataSplit(\n    label=\"train\",\n    start_stop_split=StartStopSplit(start=3, stop=5),\n)\n\n# Example of IndiceSplit\nsplit = DataSplit(\n    label=\"train\",\n    indice_split=IndiceSplit(\n        indices=[0, 3],\n    ),\n)\n</code></pre> Data Splits <pre><code>class Inequality:\n    Equal: \"Inequality\"\n    GreaterThan: \"Inequality\"\n    GreaterThanEqual: \"Inequality\"\n    LesserThan: \"Inequality\"\n    LesserThanEqual: \"Inequality\"\n\nclass ColValType:\n    String: \"ColValType\"\n    Float: \"ColValType\"\n    Int: \"ColValType\"\n    Timestamp: \"ColValType\"\n\nclass ColType:\n    Builtin: \"ColType\"\n    Timestamp: \"ColType\"\n\nclass ColumnSplit:\n    column_name: str\n    column_value: ColValType\n    column_type: ColType\n    inequality: Inequality\n\n    def __init__(\n        self,\n        column_name: str,\n        column_value: Union[str, float, int],\n        column_type: ColType = ColType.Builtin,\n        inequality: Optional[Union[str, Inequality]] = None,\n    ) -&gt; None:\n        \"\"\"Define a column split\n\n        Args:\n            column_name:\n                The name of the column\n            column_value:\n                The value of the column. Can be a string, float, or int. If\n                timestamp, convert to isoformat (str) and specify timestamp coltype\n            column_type:\n                The type of the column. Defaults to ColType.Builtin. If providing ColtType.Timestamp, the\n                column_value should be a float\n            inequality:\n                The inequality of the column\n        \"\"\"\n\nclass StartStopSplit:\n    start: int\n    stop: int\n\n    def __init__(self, start: int, stop: int) -&gt; None:\n        \"\"\"Define a start stop split\n\n        Args:\n            start:\n                The start of the split\n            stop:\n                The stop of the split\n        \"\"\"\n\nclass IndiceSplit:\n    indices: List[int]\n\n    def __init__(self, indices: List[int]) -&gt; None:\n        \"\"\"Define an indice split\n\n        Args:\n            indices:\n                The indices of the split\n        \"\"\"\n\nclass DataSplit:\n    label: str\n    column_split: Optional[ColumnSplit]\n    start_stop_split: Optional[StartStopSplit]\n    indice_split: Optional[IndiceSplit]\n\n    def __init__(\n        self,\n        label: str,\n        column_split: Optional[ColumnSplit] = None,\n        start_stop_split: Optional[StartStopSplit] = None,\n        indice_split: Optional[IndiceSplit] = None,\n    ) -&gt; None:\n        \"\"\"Define a data split\n\n        Args:\n            label:\n                The label of the split\n            column_split:\n                The column split\n            start_stop_split:\n                The start stop split\n            indice_split:\n                The indice split\n        \"\"\"\nclass DataSplits:\n    def __init__(self, splits: List[DataSplit]) -&gt; None:\n        \"\"\"Define data splits\n\n        Args:\n            splits:\n                The data splits\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the data splits\"\"\"\n\n    @property\n    def splits(self) -&gt; List[DataSplit]:\n        \"\"\"Return the splits\"\"\"\n\n    @splits.setter\n    def splits(self, splits: List[DataSplit]) -&gt; None:\n        \"\"\"Set the splits\"\"\"\n\n    def split_data(\n        self,\n        data: Any,\n        data_type: DataType,\n        dependent_vars: DependentVars,\n    ) -&gt; Dict[str, Data]:\n        \"\"\"Split the data\n\n        Args:\n            data:\n                The data to split\n            data_type:\n                The data type\n            dependent_vars:\n                Dependent variables to associate with the data\n\n        Returns:\n            A dictionary of data splits\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/datacard/#using-data-splits","title":"Using Data Splits","text":"<p>To split your data, you can use the <code>split_data</code> method on the <code>DataInterface</code>. This will return a dictionary mapping the split label and a <code>Data</code> object. The <code>Data</code> object holds both an x and y dataset. If your DataInterface contains a <code>DependentVars</code> object, the x and y datasets will be split based on the dependent variables. If no dependent variables are provided, only the x dataset will be returned.</p> <pre><code>interface = PandasData(\n    data=X,\n    data_splits=[\n        DataSplit(\n            label=\"train\", \n            column_name=\"col_1\", \n            column_value=0.5, \n            inequality=\"&gt;=\"\n            ),\n        DataSplit(\n            label=\"test\", \n            column_name=\"col_1\", \n            column_value=0.5, \n            inequality=\"&lt;\"\n        ),\n    ],\n    dependent_vars=[\"target\"],\n)\n\n# Create and register datacard\ndatasets = interface.split_data()\n\n# access the datasets\ndatasets[\"train\"].x\ndatasets[\"train\"].y\n</code></pre>"},{"location":"docs/cards/datacard/#sql-logic","title":"Sql Logic","text":"<p>A DataInterface also accepts <code>SqlLogic</code> in the event a user wishes to store the sql logic used to create the data. This is useful as SQL logic tends to change frequently and having the logic that created the current data is helpful from a compliance and governance perspective. </p> <p>The <code>SqlLogic</code> class is created by providing a dictionary of queries where each key is a unique name to provide to the query and the value is either a path to a <code>.sql</code> file or a string containing the SQL query.</p> <pre><code>from opsml.data import SqlLogic\n\nsql_logic = SqlLogic(queries={\"sql\": \"test_sql.sql\"})\nsql_logic = SqlLogic(queries={\"test\": \"SELECT * FROM TEST_TABLE\"})\n</code></pre> Sql Logic <pre><code>class SqlLogic:\n    def __init__(self, queries: Dict[str, str]) -&gt; None:\n        \"\"\"Define sql logic\n\n        Args:\n            queries:\n                Sql logic used to generate data represented as a dictionary.\n                Key is the name to assign to the sql logic and value is either a sql query\n                or a path to a .sql file.\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the sql logic\"\"\"\n\n    def add_sql_logic(\n        self,\n        name: str,\n        query: Optional[str] = None,\n        filepath: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Add sql logic to existing queries\n\n        Args:\n            name:\n                The name to associate with the sql logic\n            query:\n                SQL query\n            filepath:\n                Filepath to SQL query\n\n        \"\"\"\n\n    @property\n    def queries(self) -&gt; Dict[str, str]:\n        \"\"\"Return the queries\"\"\"\n\n    @queries.setter\n    def queries(self, queries: Dict[str, str]) -&gt; None:\n        \"\"\"Set the queries\"\"\"\n\n    def __getitem__(self, key: str) -&gt; str:\n        \"\"\"Get the query by key\n\n        Args:\n            key:\n                The key to get the query by\n\n        Returns:\n            The query\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/datacard/#pandasdata","title":"PandasData","text":"<p>Interface for saving a Pandas DataFrame</p> <p>Example: <code>Link</code></p> Argument Description data Data to associate with interface. This data must be a Pandas DataFrame data_splits Optional data splits to associate with the data dependent_vars Optional dependent variables to associate with the data. Can be one of <code>DependentVars</code>, List[str] or List[int]. Will be converted to <code>DependentVars</code>. dependent_vars is used in conjunction with data_splits to split data into X and y datasets based on the defined criteria. sql_logic Optional <code>SqlLogic</code> to associate with the interface data_profile Optional <code>Scouter</code> data profile to associate with the data. This is a convenience argument if you already created a data profile. You can also use interface.create_data_profile(..) to create a data profile from the model interface. PandasData <pre><code>class PandasData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (pd.DataFrame | None):\n                Pandas dataframe\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(\n        self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None\n    ) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves pandas dataframe as parquet file via to_parquet\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n            engine ({'auto', 'pyarrow', 'fastparquet'}):\n                Parquet library to use. If 'auto', then the option io.parquet.engine is used.\n                The default io.parquet.engine behavior is to try 'pyarrow',\n                falling back to 'fastparquet' if 'pyarrow' is unavailable. Default is 'auto'.\n            compression (str | None):\n                Name of the compression to use. Use None for no compression.\n                Supported options: 'snappy', 'gzip', 'brotli', 'lz4', 'zstd'. Default is 'snappy'.\n            index (bool | None):\n                If True, include the dataframe's index(es) in the file output.\n                If False, they will not be written to the file. If None, similar to True the dataframe's index(es) will be saved.\n                However, instead of being saved as values, the RangeIndex will be stored as a range in the metadata so it doesn't\n                require much space and is faster.\n                Other indexes will be included as columns in the file output. Default is None.\n            partition_cols (list | None):\n                Column names by which to partition the dataset. Columns are partitioned in the order they are given.\n                Must be None if path is not a string. Default is None.\n            storage_options (dict | None):\n                Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc.\n                For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options.\n                For other URLs (e.g. starting with \u201cs3://\u201d, and \u201cgcs://\u201d) the key-value pairs are forwarded to fsspec.open.\n                Default is None.\n            **kwargs:\n                Any additional kwargs are passed to the engine\n\n        Additional Information:\n            https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the pandas dataframe from a parquet dataset via read_parquet\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable load kwargs:\n            engine ({'auto', 'pyarrow', 'fastparquet'}):\n                Parquet library to use. If 'auto', then the option io.parquet.engine is used.\n                The default io.parquet.engine behavior is to try 'pyarrow',\n                falling back to 'fastparquet' if 'pyarrow' is unavailable. Default is 'auto'.\n            columns (list | None):\n                If not None, only these columns will be read from the file. Default is None.\n            storage_options (dict | None):\n                Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc.\n                For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options.\n                For other URLs (e.g. starting with \u201cs3://\u201d, and \u201cgcs://\u201d) the key-value pairs are forwarded to fsspec.open.\n                Default is None.\n            use_nullable_dtypes (bool):\n                If True, use dtypes that use pd.NA as missing value indicator for the resulting DataFrame.\n                (only applicable for the pyarrow engine) As new dtypes are added that support pd.NA in the future,\n                the output with this option will change to use those dtypes.\n                Note: this is an experimental option, and behaviour (e.g. additional support dtypes) may change without notice.\n                Default is False. Deprecated since version 2.0.\n            dtype_backend ({'numpy_nullable', 'pyarrow'}):\n                Back-end data type applied to the resultant DataFrame (still experimental).\n                Behaviour is as follows:\n                    - \"numpy_nullable\": returns nullable-dtype-backed DataFrame (default).\n                    - \"pyarrow\": returns pyarrow-backed nullable ArrowDtype DataFrame. Default is 'numpy_nullable'.\n            filesystem (fsspec | pyarrow filesystem | None):\n                Filesystem object to use when reading the parquet file. Only implemented for engine=\"pyarrow\". Default is None.\n            filters (list[tuple] | list[list[tuple]] | None):\n                To filter out data.\n                Filter syntax:\n                    [[(column, op, val), \u2026],\u2026] where op is [==, =, &gt;, &gt;=, &lt;, &lt;=, !=, in, not in]\n                The innermost tuples are transposed into a set of filters applied through an AND operation.\n                The outer list combines these sets of filters through an OR operation. A single list of tuples can also be used,\n                meaning that no OR operation between set of filters is to be conducted.\n                Using this argument will NOT result in row-wise filtering of the final partitions unless engine=\"pyarrow\"\n                is also specified.\n                For other engines, filtering is only performed at the partition level, that is,\n                to prevent the loading of some row-groups and/or files. Default is None.\n            **kwargs:\n                Any additional kwargs are passed to the engine.\n\n        Additional Information:\n            https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/datacard/#nuts-and-bolts","title":"Nuts and Bolts","text":"<p>The <code>PandasData</code> interface uses the <code>to_parquet</code> method to save the data as a parquet file. </p>"},{"location":"docs/cards/datacard/#polarsdata","title":"PolarsData","text":"<p>Interface for saving a Polars DataFrame</p> <p>Example: <code>Link</code></p> Argument Description data Data to associate with interface. This data must be a Polars DataFrame data_splits Optional data splits to associate with the data dependent_vars Optional dependent variables to associate with the data. Can be one of <code>DependentVars</code>, List[str] or List[int]. Will be converted to <code>DependentVars</code>. dependent_vars is used in conjunction with data_splits to split data into X and y datasets based on the defined criteria. sql_logic Optional <code>SqlLogic</code> to associate with the interface data_profile Optional <code>Scouter</code> data profile to associate with the data. This is a convenience argument if you already created a data profile. You can also use interface.create_data_profile(..) to create a data profile from the model interface. PolarsData <pre><code>class PolarsData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (pl.DataFrame | None):\n                Pandas dataframe\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n\n        \"\"\"\n\n    def save(\n        self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None\n    ) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves polars dataframe to parquet dataset via write_parquet\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n            compression (ParquetCompression):\n                Compression codec to use for writing.\n            compression_level (int | None):\n                Compression level to use. Default is None.\n            statistics (bool | str | dict[str, bool]):\n                Whether to write statistics. Default is True.\n            row_group_size (int | None):\n                Number of rows per row group. Default is None.\n            data_page_size (int | None):\n                Size of data pages. Default is None.\n            use_pyarrow (bool):\n                Whether to use PyArrow for writing. Default is False.\n            pyarrow_options (dict[str, Any] | None):\n                Additional options for PyArrow. Default is None.\n            partition_by (str | Sequence[str] | None):\n                Columns to partition by. Default is None.\n            partition_chunk_size_bytes (int):\n                Size of partition chunks in bytes. Default is 4294967296.\n            storage_options (dict[str, Any] | None):\n                Additional storage options. Default is None.\n            credential_provider (CredentialProviderFunction | Literal['auto'] | None):\n                Credential provider function. Default is 'auto'.\n            retries (int):\n                Number of retries for writing. Default is 2.\n\n        See Also:\n            https://docs.pola.rs/api/python/dev/reference/api/polars.DataFrame.write_parquet.html\n\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data from a file\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable load kwargs:\n            columns (list[int] | list[str] | None):\n                Columns to load. Default is None.\n            n_rows (int | None):\n                Number of rows to load. Default is None.\n            row_index_name (str | None):\n                Name of the row index. Default is None.\n            row_index_offset (int):\n                Offset for the row index. Default is 0.\n            parallel (ParallelStrategy):\n                Parallel strategy to use. Default is 'auto'.\n            use_statistics (bool):\n                Whether to use statistics. Default is True.\n            hive_partitioning (bool | None):\n                Whether to use hive partitioning. Default is None.\n            glob (bool):\n                Whether to use glob pattern matching. Default is True.\n            schema (SchemaDict | None):\n                Schema to use. Default is None.\n            hive_schema (SchemaDict | None):\n                Hive schema to use. Default is None.\n            try_parse_hive_dates (bool):\n                Whether to try parsing hive dates. Default is True.\n            rechunk (bool):\n                Whether to rechunk the data. Default is False.\n            low_memory (bool):\n                Whether to use low memory mode. Default is False.\n            storage_options (dict[str, Any] | None):\n                Additional storage options. Default is None.\n            credential_provider (CredentialProviderFunction | Literal['auto'] | None):\n                Credential provider function. Default is 'auto'.\n            retries (int):\n                Number of retries for loading. Default is 2.\n            use_pyarrow (bool):\n                Whether to use PyArrow for loading. Default is False.\n            pyarrow_options (dict[str, Any] | None):\n                Additional options for PyArrow. Default is None.\n            memory_map (bool):\n                Whether to use memory mapping. Default is True.\n            include_file_paths (str | None):\n                File paths to include. Default is None.\n            allow_missing_columns (bool):\n                Whether to allow missing columns. Default is False.\n\n        See Also:\n            https://docs.pola.rs/api/python/dev/reference/api/polars.read_parquet.html\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/datacard/#nuts-and-bolts_1","title":"Nuts and Bolts","text":"<p>The <code>PolarsData</code> interface uses the <code>write_parquet</code> method to save the data as a parquet file. </p>"},{"location":"docs/cards/datacard/#arrowdata","title":"ArrowData","text":"<p>Interface for saving pyarrow Table</p> <p>Example: <code>Link</code></p> Argument Description data Data to associate with interface. This data must be a PyArrow table data_splits Optional data splits to associate with the data dependent_vars Optional dependent variables to associate with the data. Can be one of <code>DependentVars</code>, List[str] or List[int]. Will be converted to <code>DependentVars</code>. dependent_vars is used in conjunction with data_splits to split data into X and y datasets based on the defined criteria. sql_logic Optional <code>SqlLogic</code> to associate with the interface data_profile Optional <code>Scouter</code> data profile to associate with the data. This is a convenience argument if you already created a data profile. You can also use interface.create_data_profile(..) to create a data profile from the model interface. ArrowData <pre><code>class ArrowData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (pa.Table | None):\n                PyArrow Table\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(\n        self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None\n    ) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves pyarrow table to parquet via write_table\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n            row_group_size (int | None):\n                Maximum number of rows in each written row group. If None, the row group size will be the minimum of the\n                Table size and 1024 * 1024. Default is None.\n            version ({'1.0', '2.4', '2.6'}):\n                Determine which Parquet logical types are available for use. Default is '2.6'.\n            use_dictionary (bool | list):\n                Specify if dictionary encoding should be used in general or only for some columns. Default is True.\n            compression (str | dict):\n                Specify the compression codec, either on a general basis or per-column.\n                Valid values: {'NONE', 'SNAPPY', 'GZIP', 'BROTLI', 'LZ4', 'ZSTD'}. Default is 'snappy'.\n            write_statistics (bool | list):\n                Specify if statistics should be written in general or only for some columns. Default is True.\n            use_deprecated_int96_timestamps (bool | None):\n                Write timestamps to INT96 Parquet format. Default is None.\n            coerce_timestamps (str | None):\n                Cast timestamps to a particular resolution. Valid values: {None, 'ms', 'us'}. Default is None.\n            allow_truncated_timestamps (bool):\n                Allow loss of data when coercing timestamps to a particular resolution. Default is False.\n            data_page_size (int | None):\n                Set a target threshold for the approximate encoded size of data pages within a column chunk (in bytes).\n                Default is None.\n            flavor ({'spark'} | None):\n                Sanitize schema or set other compatibility options to work with various target systems. Default is None.\n            filesystem (FileSystem | None):\n                Filesystem object to use when reading the parquet file. Default is None.\n            compression_level (int | dict | None):\n                Specify the compression level for a codec, either on a general basis or per-column. Default is None.\n            use_byte_stream_split (bool | list):\n                Specify if the byte_stream_split encoding should be used in general or only for some columns. Default is False.\n            column_encoding (str | dict | None):\n                Specify the encoding scheme on a per column basis. Default is None.\n            data_page_version ({'1.0', '2.0'}):\n                The serialized Parquet data page format version to write. Default is '1.0'.\n            use_compliant_nested_type (bool):\n                Whether to write compliant Parquet nested type (lists). Default is True.\n            encryption_properties (FileEncryptionProperties | None):\n                File encryption properties for Parquet Modular Encryption. Default is None.\n            write_batch_size (int | None):\n                Number of values to write to a page at a time. Default is None.\n            dictionary_pagesize_limit (int | None):\n                Specify the dictionary page size limit per row group. Default is None.\n            store_schema (bool):\n                By default, the Arrow schema is serialized and stored in the Parquet file metadata. Default is True.\n            write_page_index (bool):\n                Whether to write a page index in general for all columns. Default is False.\n            write_page_checksum (bool):\n                Whether to write page checksums in general for all columns. Default is False.\n            sorting_columns (Sequence[SortingColumn] | None):\n                Specify the sort order of the data being written. Default is None.\n            store_decimal_as_integer (bool):\n                Allow decimals with 1 &lt;= precision &lt;= 18 to be stored as integers. Default is False.\n            **kwargs:\n                Additional options for ParquetWriter.\n\n        Additional Information:\n            https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_table.html\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data from a file\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable load kwargs:\n            columns (list | None):\n                If not None, only these columns will be read from the file. A column name may be a prefix of a nested field,\n                e.g. 'a' will select 'a.b', 'a.c', and 'a.d.e'. If empty, no columns will be read. Default is None.\n            use_threads (bool):\n                Perform multi-threaded column reads. Default is True.\n            schema (Schema | None):\n                Optionally provide the Schema for the parquet dataset, in which case it will not be inferred from the source.\n                Default is None.\n            use_pandas_metadata (bool):\n                If True and file has custom pandas schema metadata, ensure that index columns are also loaded. Default is False.\n            read_dictionary (list | None):\n                List of names or column paths (for nested types) to read directly as DictionaryArray.\n                Only supported for BYTE_ARRAY storage. Default is None.\n            memory_map (bool):\n                If the source is a file path, use a memory map to read file, which can improve performance in some environments.\n                Default is False.\n            buffer_size (int):\n                If positive, perform read buffering when deserializing individual column chunks.\n                Otherwise IO calls are unbuffered. Default is 0.\n            partitioning (pyarrow.dataset.Partitioning | str | list of str):\n                The partitioning scheme for a partitioned dataset. Default is 'hive'.\n            filesystem (FileSystem | None):\n                If nothing passed, will be inferred based on path. Default is None.\n            filters (pyarrow.compute.Expression | list[tuple] | list[list[tuple]] | None):\n                Rows which do not match the filter predicate will be removed from scanned data. Default is None.\n            use_legacy_dataset (bool | None):\n                Deprecated and has no effect from PyArrow version 15.0.0. Default is None.\n            ignore_prefixes (list | None):\n                Files matching any of these prefixes will be ignored by the discovery process. Default is ['.', '_'].\n            pre_buffer (bool):\n                Coalesce and issue file reads in parallel to improve performance on high-latency filesystems (e.g. S3).\n                Default is True.\n            coerce_int96_timestamp_unit (str | None):\n                Cast timestamps that are stored in INT96 format to a particular resolution (e.g. 'ms'). Default is None.\n            decryption_properties (FileDecryptionProperties | None):\n                File-level decryption properties. Default is None.\n            thrift_string_size_limit (int | None):\n                If not None, override the maximum total string size allocated when decoding Thrift structures. Default is None.\n            thrift_container_size_limit (int | None):\n                If not None, override the maximum total size of containers allocated when decoding Thrift structures.\n                Default is None.\n            page_checksum_verification (bool):\n                If True, verify the checksum for each page read from the file. Default is False.\n\n        Additional Information:\n            https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/datacard/#nuts-and-bolts_2","title":"Nuts and Bolts","text":"<p>Arrow data is saved to parquet using the pyarrow library.</p>"},{"location":"docs/cards/datacard/#numpydata","title":"NumpyData","text":"<p>Interface for saving a Numpy ndarray</p> <p>Example: <code>Link</code></p> Argument Description data Data to associate with interface. This data must be a Numpy ndarray data_splits Optional data splits to associate with the data dependent_vars Optional dependent variables to associate with the data. Can be one of <code>DependentVars</code>, List[str] or List[int]. Will be converted to <code>DependentVars</code>. dependent_vars is used in conjunction with data_splits to split data into X and y datasets based on the defined criteria. sql_logic Optional <code>SqlLogic</code> to associate with the interface data_profile Optional <code>Scouter</code> data profile to associate with the data. This is a convenience argument if you already created a data profile. You can also use interface.create_data_profile(..) to create a data profile from the model interface. NumpyData <pre><code>class NumpyData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (np.NDArray | None):\n                Numpy array\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: Optional[DataSaveKwargs] = None,\n    ) -&gt; DataInterfaceMetadata:\n        \"\"\"Save data using numpy save format\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n\n            see: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n\n            allow_pickle (bool):\n                Allow saving object arrays using Python pickles.\n            fix_imports (bool):\n                The fix_imports flag is deprecated and has no effect\n\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the data via numpy.load\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to use when loading\n\n        Acceptable load kwargs:\n\n            see: https://numpy.org/doc/stable/reference/generated/numpy.load.html\n\n            mmap_mode:\n                If not None, then memory-map the file, using the given mode\n            allow_pickle (bool):\n                Allow loading pickled object arrays stored in npy files\n            fix_imports (bool):\n                If fix_imports is True, pickle will try to map the old Python 2 names to the new names used in Python 3.\n            encoding (str):\n                What encoding to use when reading Python 2 strings. Only useful when py3k is True.\n            max_header_size (int):\n                The maximum size of the file header\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/datacard/#nuts-and-bolts_3","title":"Nuts and Bolts","text":"<p>Numpy data is saved to <code>npy</code> format using the <code>numpy.save</code> method.</p>"},{"location":"docs/cards/datacard/#torchdata","title":"TorchData","text":"<p>Interface for saving a Torch Tensor or Torch Dataset</p> Argument Description data Data to associate with interface. This can be either a Torch tensor or Torch Dataset data_splits Optional data splits to associate with the data dependent_vars Optional dependent variables to associate with the data. Can be one of <code>DependentVars</code>, List[str] or List[int]. Will be converted to <code>DependentVars</code>. dependent_vars is used in conjunction with data_splits to split data into X and y datasets based on the defined criteria. sql_logic Optional <code>SqlLogic</code> to associate with the interface data_profile Optional <code>Scouter</code> data profile to associate with the data. This is a convenience argument if you already created a data profile. You can also use interface.create_data_profile(..) to create a data profile from the model interface. TorchData <pre><code>class TorchData(DataInterface):\n    def __init__(\n        self,\n        data: Optional[Any] = None,\n        data_splits: Optional[Union[DataSplits, List[DataSplit]]] = None,\n        dependent_vars: Optional[Union[DependentVars, List[str], List[int]]] = None,\n        sql_logic: Optional[SqlLogic] = None,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a data interface\n\n        Args:\n            data (torch.Tensor | None):\n                Torch tensor\n            dependent_vars (DependentVars | List[str] | List[int] | None):\n                List of dependent variables to associate with data\n            data_splits (DataSplits | List[DataSplit]):\n                Optional list of `DataSplit`\n            sql_logic (SqlLogic | None):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(\n        self, path: Path, save_kwargs: Optional[DataSaveKwargs] = None\n    ) -&gt; DataInterfaceMetadata:\n        \"\"\"Saves torch tensor to a file\n\n        Args:\n            path (Path):\n                Base path to save the data to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable save kwargs:\n            pickle_module (Any):\n                Module used for pickling metadata and objects.\n            pickle_protocol (int):\n                Can be specified to override the default protocol.\n\n\n        Additional Information:\n        https://pytorch.org/docs/main/generated/torch.save.html\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: DataInterfaceSaveMetadata,\n        load_kwargs: Optional[DataLoadKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Load the torch tensor from file\n\n        Args:\n            path (Path):\n                Base path to load the data from.\n            metadata (DataInterfaceSaveMetadata):\n                Metadata associated with the data\n            load_kwargs (DataLoadKwargs):\n                Additional kwargs to pass in.\n\n        Acceptable load kwargs:\n            map_location:\n                A function, torch.device, string or a dict specifying how to remap storage locations.\n            pickle_module:\n                Module used for unpickling metadata and objects (has to match the pickle_module used to serialize file).\n            weights_only:\n                Indicates whether unpickler should be restricted to loading only tensors, primitive types,\n                dictionaries and any types added via torch.serialization.add_safe_globals().\n            mmap:\n                Indicates whether the file should be mmaped rather than loading all the storages into memory.\n                Typically, tensor storages in the file will first be moved from disk to CPU memory,\n                after which they are moved to the location that they were tagged with when saving, or specified by map_location.\n                This second step is a no-op if the final location is CPU. When the mmap flag is set,\n                instead of copying the tensor storages from disk to CPU memory in the first step, f is mmaped.\n            pickle_load_args:\n                (Python 3 only) optional keyword arguments passed over to pickle_module.load() and pickle_module.Unpickler(),\n                e.g., errors=....\n\n\n        Additional Information:\n            https://pytorch.org/docs/stable/generated/torch.load.html\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/datacard/#nuts-and-bolts_4","title":"Nuts and Bolts","text":"<p>Torch data is saved to to <code>pt</code> format using the <code>torch.save</code> method.</p>"},{"location":"docs/cards/datacard/#sqldata","title":"SqlData","text":"<p>Interface for saving a SqlLogic. The <code>SqlData</code> interface is great for instances where you may not want to save the actual data object but want to have a record of the sql used to produce the data.</p> Argument Description sql_logic Optional <code>SqlLogic</code> to associate with the interface data_profile Optional <code>Scouter</code> data profile to associate with the data. This is a convenience argument if you already created a data profile. You can also use interface.create_data_profile(..) to create a data profile from the model interface. SqlData <pre><code>class SqlData:\n    data_type: DataType\n\n    def __init__(\n        self,\n        sql_logic: SqlLogic,\n        data_profile: Optional[DataProfile] = None,\n    ) -&gt; None:\n        \"\"\"Define a sql data interface\n\n        Args:\n            sql (SqlLogic):\n                Sql logic used to generate data represented as a dictionary.\n            data_profile (DataProfile | None):\n                Data profile\n        \"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: Optional[DataSaveKwargs] = None,\n    ) -&gt; DataInterfaceMetadata:\n        \"\"\"Save the sql logic to a file\n\n        Args:\n            path (Path):\n                The path to save the sql logic to.\n            save_kwargs (DataSaveKwargs):\n                Additional kwargs to pass in.\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/datacard/#customdata","title":"CustomData","text":"<p>Example: <code>Link</code></p> <p>While the above interfaces cover the most common use cases, there may be times where you want to create your own custom data interface similar to how ModelInterfaces work. By design, the <code>DataInterface</code> can be subclassed in cases where a more flexible implementation is needed. However to make sure all other components work nicely together, you will need to implement the following.</p>"},{"location":"docs/cards/datacard/#custom-save","title":"Custom Save","text":"<ul> <li>save: This method is called when saving the model. It should save the model and any other artifacts to the specified path. The method should return a <code>ModelInterfaceMetadata</code> object.</li> </ul> Argument Description path The base path to save artifacts to. note - this is typically injected at the time of saving. See the below example for how it should be used save_kwargs Optional DataSaveKwargs to use when saving the data"},{"location":"docs/cards/datacard/#custom-load","title":"Custom Load","text":"<p>To load custom data, you will need to implement the <code>load</code> method. This method is called when loading the data. It should load the data and any other artifacts from the specified path.</p> <ul> <li>load: This method is called when loading the data</li> </ul> Argument Description path The base path to load artifacts from. note - this is typically injected at the time of loading. See the below example for how it should be used metadata <code>DataInterfaceSaveMetadata</code>. This will be injected by Opsml when the card is loaded from a registry load_kwargs Optional <code>DataLoadKwargs</code>. Additional load kwargs used to load a model and it's artifacts"},{"location":"docs/cards/modelcard/","title":"Modelcard","text":"<p>ModelCards help you store, version, and track model objects.</p>"},{"location":"docs/cards/modelcard/#features","title":"Features","text":"<ul> <li>shareable: All cards including ModelCards are shareable and searchable.</li> <li>auto-schema: Auto-infer data schema.</li> <li>auto-metadata: Extract model-specific metadata to associate with the card.</li> <li>versioning: Semver for your model. </li> <li>auto-onnx: Optional automatic conversion of trained model into onnx model format.</li> </ul>"},{"location":"docs/cards/modelcard/#create-a-card","title":"Create a Card","text":"<pre><code>from opsml.helpers.data import create_fake_data\nfrom typing import Tuple, cast\nimport pandas as pd\nfrom opsml import (  # type: ignore\n    SklearnModel,\n    PandasData,\n    CardRegistries,\n    TaskType,\n    DataCard,\n    ModelCard,\n)\nfrom opsml.data import DataSplit, StartStopSplit\nfrom sklearn import ensemble  # type: ignore\n\n\n# start registries\nreg = CardRegistries()\n\n# create data\nX, y = cast(Tuple[pd.DataFrame, pd.DataFrame], create_fake_data(n_samples=1200))\nX[\"target\"] = y\n\n# create data splits to store with the model (optional)\ndata_splits = [\n    DataSplit(  # (1)\n        label=\"train\",\n        start_stop_split=StartStopSplit(\n            start=0,\n            stop=1000,\n        ),\n    ),\n    DataSplit(\n        label=\"test\",\n        start_stop_split=StartStopSplit(\n            start=1000,\n            stop=1200,\n        ),\n    ),\n]\n\n# create DataCard\ndatacard = DataCard(\n    interface=PandasData(\n        data=X,\n        data_splits=data_splits,\n        dependent_vars=[\"target\"],\n    ),\n    space=\"opsml\",\n    name=\"my_data\",\n    tags=[\"foo:bar\", \"baz:qux\"],\n)\n\n# register DataCard\nreg.data.register_card(datacard)\n\nsplits = datacard.interface.split_data()\n\n# Create and train model\nclassifier = ensemble.RandomForestClassifier(n_estimators=5)\nclassifier.fit(\n    splits[\"train\"].x.to_numpy(),\n    splits[\"train\"].y.to_numpy().ravel(),\n)\n\nmodel_interface = SklearnModel( # (2)\n    model=classifier,\n    sample_data=X[0:10],\n    task_type=TaskType.Classification,\n)\n\nmodel_interface.create_drift_profile(alias=\"drift\", X)\n\nmodelcard = ModelCard( # (3)\n    interface=model_interface,\n    space=\"opsml\",\n    name=\"my_model\",\n    tags=[\"foo:bar\", \"baz:qux\"],\n    datacard_uid=datacard.uid,\n)\n\n# register model\nreg.model.register_card(modelcard)\n</code></pre> <ol> <li>DataSplits allow you to create and store split logic with your DataInterface ensuring reproducibility</li> <li>Here we are using the SklearnModel interface and passing in the trained model, sample data, and the task type</li> <li>Here we are creating a ModelCard and passing in the model interface, space, name, tags, and the datacard_uid. The datacard_uid is used to link the model to the data it was trained on</li> </ol>"},{"location":"docs/cards/modelcard/#how-it-all-works","title":"How it all works","text":"<p>As you can tell in the example above, <code>ModelCards</code> are created by passing in a <code>ModelInterface</code>, some required args and some optional args. The <code>ModelInterface</code> is the interface is a library-specific interface for saving and extracting metadata from the model. It also allows us to standardize how models are saved (by following the library's guidelines) and ensures reproducibility.</p>"},{"location":"docs/cards/modelcard/#load-a-cards-components","title":"Load a Card's Components","text":"<p>By default, <code>OpsML</code> does not load any of the model components (model, preprocessor, etc.) when loading a card. This is to ensure that the card is loaded as quickly as possible. If you wish to load the model components, you can do so by calling the <code>load</code> method on the <code>ModelCard</code></p> <pre><code>from opsml import CardRegistry, RegistryType\n\n# start registries\nreg = CardRegistry(RegistryType.Model)\n\n# load model card\nmodelcard = reg.load_card(uid=\"{{model uid}}\")\n\n# load the model\nmodelcard.load()\n\n# load with the onnx model as well\nmodelcard.load(load_kwargs=ModelLoadKwargs(load_onnx=True)) #(1)\n</code></pre> <ol> <li>For the majority of use cases, load() is enough. However, there are optional arguments you can pass for things like loading an onnx model.</li> </ol> ModelCard <pre><code>class ModelCard:\n    def __init__(\n        self,\n        interface: Optional[ModelInterface] = None,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        uid: Optional[str] = None,\n        tags: List[str] = [],\n        datacard_uid: Optional[str] = None,\n        metadata: ModelCardMetadata = ModelCardMetadata(),\n    ) -&gt; None:\n        \"\"\"Create a ModelCard from a machine learning model.\n\n        Cards are stored in the ModelCardRegistry and follow the naming convention of:\n        {registry}/{space}/{name}/v{version}\n\n        Args:\n            interface (ModelInterface | None):\n                `ModelInterface` class containing trained model\n            space (str | None):\n                space to associate with `ModelCard`\n            name (str | None):\n                Name to associate with `ModelCard`\n            version (str | None):\n                Current version (assigned if card has been registered). Follows\n                semantic versioning.\n            uid (str | None):\n                Unique id (assigned if card has been registered)\n            tags (List[str]):\n                Tags to associate with `ModelCard`. Can be a dictionary of strings or\n                a `Tags` object.\n            datacard_uid (str | None):\n                The datacard uid to associate with the model card. This is used to link the\n                model card to the data card. Datacard uid can also be set in card metadata.\n            metadata (ModelCardMetadata):\n                Metadata to associate with the `ModelCard. Defaults to an empty `ModelCardMetadata` object.\n\n        Example:\n        ```python\n        from opsml import ModelCard, CardRegistry, RegistryType, SklearnModel, TaskType\n        from sklearn import ensemble\n\n        # for testing purposes\n        from opsml.helpers.data import create_fake_data\n\n        # pandas data\n        X, y = create_fake_data(n_samples=1200)\n\n        # train model\n        reg = ensemble.RandomForestClassifier(n_estimators=5)\n        reg.fit(X_train.to_numpy(), y_train)\n\n        # create interface and card\n        interface = SklearnModel(\n            model=reg,\n            sample_data=X_train,\n            task_type=TaskType.Classification,\n        )\n\n        modelcard = ModelCard(\n            interface=random_forest_classifier,\n            space=\"my-repo\",\n            name=\"my-model\",\n            tags=[\"foo:bar\", \"baz:qux\"],\n        )\n\n        # register card\n        registry = CardRegistry(RegistryType.Model)\n        registry.register_card(modelcard)\n        ```\n        \"\"\"\n\n    @property\n    def model(self) -&gt; Any:\n        \"\"\"Returns the model. This is a special property that is used to\n        access the model from the interface. It is not settable. It will also\n        raise an error if the interface is not set or if the model\n        has not been loaded.\n        \"\"\"\n\n    @property\n    def app_env(self) -&gt; str:\n        \"\"\"Returns the app env\"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime:\n        \"\"\"Returns the created at timestamp\"\"\"\n\n    @property\n    def datacard_uid(self) -&gt; str:\n        \"\"\"Returns the datacard uid\"\"\"\n\n    @datacard_uid.setter\n    def datacard_uid(self, datacard_uid: str) -&gt; None:\n        \"\"\"Set the datacard uid\"\"\"\n\n    @property\n    def experimentcard_uid(self) -&gt; str:\n        \"\"\"Returns the experimentcard uid\"\"\"\n\n    @experimentcard_uid.setter\n    def experimentcard_uid(self, experimentcard_uid: str) -&gt; None:\n        \"\"\"Set the experimentcard uid\"\"\"\n\n    @property\n    def uri(self) -&gt; Path:\n        \"\"\"Returns the uri of the `ModelCard` in the\n        format of {registry}/{space}/{name}/v{version}\n        \"\"\"\n\n    @property\n    def interface(self) -&gt; Optional[ModelInterface]:\n        \"\"\"Returns the `ModelInterface` associated with the `ModelCard`\"\"\"\n\n    @interface.setter\n    def interface(self, interface: Any) -&gt; None:\n        \"\"\"Set the `ModelInterface` associated with the `ModelCard`\"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Returns the name of the `ModelCard`\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set the name of the `ModelCard`\n\n        Args:\n            name (str):\n                The name of the `ModelCard`\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Returns the space of the `ModelCard`\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set the space of the `ModelCard`\n\n        Args:\n            space (str):\n                The space of the `ModelCard`\n        \"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Returns the version of the `ModelCard`\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set the version of the `ModelCard`\n\n        Args:\n            version (str):\n                The version of the `ModelCard`\n        \"\"\"\n\n    @property\n    def uid(self) -&gt; str:\n        \"\"\"Returns the uid of the `ModelCard`\"\"\"\n\n    @property\n    def tags(self) -&gt; List[str]:\n        \"\"\"Returns the tags of the `ModelCard`\"\"\"\n\n    @property\n    def metadata(self) -&gt; ModelCardMetadata:\n        \"\"\"Returns the metadata of the `ModelCard`\"\"\"\n\n    @property\n    def registry_type(self) -&gt; RegistryType:\n        \"\"\"Returns the card type of the `ModelCard`\"\"\"\n\n    def save(self, path: Path, save_kwargs: Optional[ModelSaveKwargs] = None) -&gt; None:\n        \"\"\"Save the model card to a directory\n\n        Args:\n            path (Path):\n                Path to save the model card.\n            save_kwargs (SaveKwargs):\n                Optional kwargs to pass to `ModelInterface` save method.\n        \"\"\"\n\n    def load(\n        self,\n        path: Optional[Path] = None,\n        load_kwargs: None | ModelLoadKwargs = None,\n    ) -&gt; None:\n        \"\"\"Load ModelCard interface components\n\n        Args:\n            path (Path | None):\n                The path to load the data card from. If no path is provided,\n                the model interface will be loaded from the server.\n            load_kwargs (ModelLoadKwargs):\n                Optional kwargs to pass to `ModelInterface` load method.\n        \"\"\"\n\n    def download_artifacts(self, path: Optional[Path] = None) -&gt; None:\n        \"\"\"Download artifacts associated with the ModelCard\n\n        Args:\n            path (Path):\n                Path to save the artifacts. If not provided, the artifacts will be saved\n                to a directory called \"card_artifacts\"\n        \"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Return the model dump as a json string\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str, interface: Optional[ModelInterface] = None) -&gt; \"ModelCard\":\n        \"\"\"Validate the model json string\n\n        Args:\n            json_string (str):\n                The json string to validate\n            interface (ModelInterface):\n                By default, the interface will be inferred and instantiated\n                from the interface metadata. If an interface is provided\n                (as in the case of custom interfaces), it will be used.\n        \"\"\"\n\n    def drift_profile_path(self, alias: str) -&gt; Path:\n        \"\"\"Helper method that returns the path to a specific drift profile.\n        This method will fail if there is no drift profile map or the alias\n        does not exist.\n\n        Args:\n            alias (str):\n                The alias of the drift profile\n\n        Returns:\n            Path to the drift profile\n        \"\"\"\n        ...\n\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the ModelCard.\n\n        Returns:\n            String representation of the ModelCard.\n        \"\"\"\n\n    @property\n    def drift_profile(self) -&gt; DriftProfileMap:\n        \"\"\"Return the drift profile map from the model interface.\n\n        Returns:\n            DriftProfileMap\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#model-interface","title":"Model Interface","text":"<p>The <code>ModelInterface</code> is the primary interface for working with models in <code>Opsml</code>. It is designed to be subclassed and can be used to store models in a variety of formats depending on the library. Out of the box the following subclasses are available:</p> <ul> <li><code>SklearnModel</code>: Stores data from a sklearn model - link</li> <li><code>TorchModel</code>: Stores data from a pytorch model - link</li> <li><code>LightningModel</code>: Stores data from a pytorch lightning model - link</li> <li><code>HuggingFaceModel</code>: Stores data from a huggingface model - link</li> <li><code>TensorFlowModel</code>: Stores data from a tensorflow model - link</li> <li><code>XGBoostModel</code>: Stores data from a xgboost model - link</li> <li><code>LightGBMModel</code>: Stores data from a lightgbm model - link</li> <li><code>CatBoostModel</code>: Stores data from a catboost model - link</li> <li><code>Custom</code>: Create your own model interface - link</li> </ul>"},{"location":"docs/cards/modelcard/#shared-arguments-for-all-model-interfaces","title":"Shared Arguments for all Model Interfaces","text":"Argument Description model Model to associate with interface sample_data Optional sample of data that is fed to the model at inference time task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. ModelInterface <pre><code>class ModelInterface:\n    def __init__(\n        self,\n        model: None | Any = None,\n        sample_data: None | Any = None,\n        task_type: None | TaskType = None,\n        drift_profile: (\n            None\n            | List[SpcDriftProfile | PsiDriftProfile | CustomDriftProfile]\n            | Union[SpcDriftProfile | PsiDriftProfile | CustomDriftProfile]\n        ) = None,\n    ) -&gt; None:\n        \"\"\"Base class for ModelInterface\n\n        Args:\n            model:\n                Model to associate with interface.\n            sample_data:\n                Sample data to use to make predictions\n            task_type:\n                The type of task the model performs\n            drift_profile:\n                Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    @property\n    def model(self) -&gt; None | Any:\n        \"\"\"Returns the model\"\"\"\n\n    @model.setter\n    def model(self, model: Any) -&gt; None:\n        \"\"\"Sets the model\"\"\"\n\n    @property\n    def sample_data(self) -&gt; None | Any:\n        \"\"\"Returns the sample data\"\"\"\n\n    @sample_data.setter\n    def sample_data(self, sample_data: Any) -&gt; None:\n        \"\"\"Sets the sample data\"\"\"\n\n    @property\n    def data_type(self) -&gt; DataType:\n        \"\"\"Returns the task type\"\"\"\n\n    @property\n    def task_type(self) -&gt; TaskType:\n        \"\"\"Returns the task type\"\"\"\n\n    @property\n    def schema(self) -&gt; FeatureSchema:\n        \"\"\"Returns the feature schema\"\"\"\n\n    @property\n    def model_type(self) -&gt; ModelType:\n        \"\"\"Returns the model type\"\"\"\n\n    @property\n    def interface_type(self) -&gt; ModelInterfaceType:\n        \"\"\"Returns the model type\"\"\"\n\n    @property\n    def drift_profile(\n        self,\n    ) -&gt; List[Any]:\n        \"\"\"Returns the drift profile\"\"\"\n\n    @drift_profile.setter\n    def drift_profile(\n        self,\n        profile: List[SpcDriftProfile | PsiDriftProfile | CustomDriftProfile],\n    ) -&gt; None:\n        \"\"\"Sets the drift profile\"\"\"\n\n    @property\n    def onnx_session(self) -&gt; None | OnnxSession:\n        \"\"\"Returns the onnx session if it exists\"\"\"\n\n    @onnx_session.setter\n    def onnx_session(self, session: None | OnnxSession) -&gt; None:\n        \"\"\"Sets the onnx session\n\n\n        Args:\n            session:\n                Onnx session\n        \"\"\"\n\n    @overload\n    def create_drift_profile(\n        self,\n        alias: str,\n        data: CustomMetric | List[CustomMetric],\n        config: CustomMetricDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; CustomDriftProfile: ...\n    @overload\n    def create_drift_profile(\n        self,\n        alias: str,\n        data: Any,\n        config: SpcDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftProfile: ...\n    @overload\n    def create_drift_profile(\n        self,\n        alias: str,\n        data: Any,\n        config: PsiDriftConfig,\n        data_type: Optional[DataType] = None,\n    ) -&gt; PsiDriftProfile: ...\n    @overload\n    def create_drift_profile(\n        self,\n        alias: str,\n        data: Any,\n        data_type: Optional[DataType] = None,\n    ) -&gt; SpcDriftProfile: ...\n    def create_drift_profile(  # type: ignore\n        self,\n        alias: str,\n        data: Any,\n        config: None | SpcDriftConfig | PsiDriftConfig | CustomMetricDriftConfig = None,\n        data_type: None | DataType = None,\n    ) -&gt; Any:\n        \"\"\"Create a drift profile and append it to the drift profile list\n\n        Args:\n            alias:\n                Alias to use for the drift profile. This is used to identify the drift profile in the UI and in the model card.\n            data:\n                Data to use to create the drift profile. Can be a pandas dataframe,\n                polars dataframe, pyarrow table or numpy array.\n            config:\n                Drift config to use. If None, defaults to SpcDriftConfig.\n            data_type:\n                Data type to use. If None, data_type will be inferred from the data.\n\n        Returns:\n            Drift profile SPcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: None | ModelSaveKwargs = None,\n    ) -&gt; ModelInterfaceMetadata:\n        \"\"\"Save the model interface\n\n        Args:\n            path (Path):\n                Path to save the model\n            save_kwargs (ModelSaveKwargs):\n                Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n                that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n                the underlying library.\n\n                - model: Kwargs that will be passed to save_model. See save_model for more details.\n                - preprocessor: Kwargs that will be passed to save_preprocessor\n                - onnx: Kwargs that will be passed to save_onnx_model. See convert_onnx_model for more details\n        \"\"\"\n\n    def load(\n        self,\n        path: Path,\n        metadata: ModelInterfaceSaveMetadata,\n        load_kwargs: None | ModelLoadKwargs = None,\n    ) -&gt; None:\n        \"\"\"Load ModelInterface components\n\n        Args:\n            path (Path):\n                Path to load the model\n            metadata (ModelInterfaceSaveMetadata):\n                Metadata to use to load the model\n            load_kwargs (ModelLoadKwargs):\n                Optional load kwargs to pass to the different load methods\n        \"\"\"\n\n    @staticmethod\n    def from_metadata(metadata: ModelInterfaceMetadata) -&gt; \"ModelInterface\":\n        \"\"\"Create a ModelInterface from metadata\n\n        Args:\n            metadata:\n                Model interface metadata\n\n        Returns:\n            Model interface\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#save-method","title":"Save Method","text":"<p>All ModelInterfaces have a default save method that will save the model and any interface-specific addons. You typically will not have to call this method since it will be called by the specific registry. However, when registering a card, if your model requires specific kwargs such as any onnx, model or preprocessor kwargs, you can pass them in via an optional <code>ModelSaveKwargs</code> object.</p> <pre><code># ... imports\n\nmodel_registry = CardRegistry(RegistryType.Model)\n\nreg = XGBRegressor(n_estimators=3, max_depth=3)\nreg.fit(X, y)\n\nmodel_registry.register_card(\n    card=ModelCard(\n        interface=SklearnModel(model=reg),\n        space=\"opsml\",\n        name=\"my_model\",\n    ),\n    # special onnx kwargs to pass to model_interface save method\n    save_kwargs=ModelSaveKwargs(onnx={\"target_opset\": {\"ai.onnx.ml\": 3, \"\": 9}}),\n)\n</code></pre> ModelSaveKwargs <pre><code>class ModelSaveKwargs:\n    def __init__(\n        self,\n        onnx: Optional[Dict | HuggingFaceOnnxArgs] = None,\n        model: Optional[Dict] = None,\n        preprocessor: Optional[Dict] = None,\n        save_onnx: bool = False,\n    ) -&gt; None:\n        \"\"\"Optional arguments to pass to save_model\n\n        Args:\n            onnx (Dict or HuggingFaceOnnxArgs):\n                Optional onnx arguments to use when saving model to onnx format\n            model (Dict):\n                Optional model arguments to use when saving\n            preprocessor (Dict):\n                Optional preprocessor arguments to use when saving\n            save_onnx (bool):\n                Whether to save the onnx model. Defaults to false. This is independent of the\n                onnx argument since it's possible to convert a model to onnx without additional kwargs.\n                If onnx args are provided, this will be set to true.\n        \"\"\"\n\n    def __str__(self): ...\n    def model_dump_json(self) -&gt; str: ...\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"ModelSaveKwargs\": ...\n</code></pre>"},{"location":"docs/cards/modelcard/#load-method","title":"Load Method","text":"<p>All ModelInterfaces have a default load method that will load the model and any interface-specific addons. You typically will not have to call this method since it will be called by the specific registry (<code>load</code>). However, when loading a card's model attributes, if your model requires specific kwargs such as any onnx, model or preprocessor kwargs, you can pass them in via an optional <code>ModelLoadKwargs</code> object.</p> Argument Description onnx Optional onnx arguments to use when loading model Optional model arguments to use when loading time preprocessor Optional preprocessor arguments to use when loading load_onnx Whether to load the onnx model. Defaults to false unless onnx args are provided. If true, the onnx model will be loaded ModelLoadKwargs <pre><code>class ModelLoadKwargs:\n    onnx: Optional[Dict]\n    model: Optional[Dict]\n    preprocessor: Optional[Dict]\n    load_onnx: bool\n\n    def __init__(\n        self,\n        onnx: Optional[Dict] = None,\n        model: Optional[Dict] = None,\n        preprocessor: Optional[Dict] = None,\n        load_onnx: bool = False,\n    ) -&gt; None:\n        \"\"\"Optional arguments to pass to load_model\n\n        Args:\n            onnx (Dict):\n                Optional onnx arguments to use when loading\n            model (Dict):\n                Optional model arguments to use when loading\n            preprocessor (Dict):\n                Optional preprocessor arguments to use when loading\n            load_onnx (bool):\n                Whether to load the onnx model. Defaults to false unless onnx args are\n                provided. If true, the onnx model will be loaded.\n\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#sklearnmodel","title":"SklearnModel","text":"<p>Interface for saving an Sklearn model</p> <p>Example: <code>Link</code></p> Argument Description model Model to associate with interface. This model must be from the scikit-learn ecosystem (BaseEstimator) preprocessor Optional preprocessor to associate with the model. This preprocessor must be from the  scikit-learn ecosystem sample_data Optional ample of data that is fed to the model at inference time task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. SklearnModel <pre><code>class SklearnModel(ModelInterface):\ndef __init__(\n    self,\n    model: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: (\n        None\n        | List[SpcDriftProfile | PsiDriftProfile | CustomDriftProfile]\n        | Union[SpcDriftProfile | PsiDriftProfile | CustomDriftProfile]\n    ) = None,\n) -&gt; None:\n    \"\"\"Instantiate an SklearnModel interface\n\n    Args:\n        model:\n            Model to associate with interface. This model must be from the\n            scikit-learn ecosystem\n        preprocessor:\n            Preprocessor to associate with the model. This preprocessor must be from the\n            scikit-learn ecosystem\n        sample_data:\n            Sample data to use to make predictions\n        task_type:\n            The type of task the model performs\n        drift_profile:\n            Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n    \"\"\"\n\n@property\ndef preprocessor(self) -&gt; Optional[Any]:\n    \"\"\"Returns the preprocessor\"\"\"\n\n@preprocessor.setter\ndef preprocessor(self, preprocessor: Any) -&gt; None:\n    \"\"\"Sets the preprocessor\n\n    Args:\n        preprocessor:\n            Preprocessor to associate with the model. This preprocessor must be from the\n            scikit-learn ecosystem\n    \"\"\"\n\n@property\ndef preprocessor_name(self) -&gt; Optional[str]:\n    \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#nuts-and-bolts","title":"Nuts and Bolts","text":"<p>The <code>SklearnModel</code> and it's associated model and preprocessor are saved using joblib. In addition, depending upon the model type, <code>OpsML</code> will extract model-specific metadata from the provided model at the time of registration, which can be viewed in the UI and is associated with the card metadata.</p>"},{"location":"docs/cards/modelcard/#lightgbmmodel","title":"LightGBMModel","text":"<p>Interface for saving a LightGBM Booster model. Note - If using a LGBMRegressor or LGBMClassifier, you should use the SklearnModelInterface instead.</p> <p>Example: <code>Link</code></p> Argument Description model Model to associate with interface. This model must be an lightgbm booster preprocessor Optional preprocessor to associate with the model sample_data Optional ample of data that is fed to the model at inference time task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. LightGBMModel <pre><code>class LightGBMModel(ModelInterface):\ndef __init__(\n    self,\n    model: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Instantiate a LightGBMModel interface\n\n    Args:\n        model:\n            Model to associate with interface. This model must be a lightgbm booster.\n        preprocessor:\n            Preprocessor to associate with the model.\n        sample_data:\n            Sample data to use to make predictions\n        task_type:\n            The type of task the model performs\n        drift_profile:\n            Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n    \"\"\"\n\n@property\ndef preprocessor(self) -&gt; Optional[Any]:\n    \"\"\"Returns the preprocessor\"\"\"\n\n@preprocessor.setter\ndef preprocessor(self, preprocessor: Any) -&gt; None:\n    \"\"\"Sets the preprocessor\n\n    Args:\n        preprocessor:\n            Preprocessor to associate with the model. This preprocessor must be from the\n            scikit-learn ecosystem\n    \"\"\"\n\n@property\ndef preprocessor_name(self) -&gt; Optional[str]:\n    \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#nuts-and-bolts_1","title":"Nuts and Bolts","text":"<p>Booster models are saved via <code>save_model</code> which exports a <code>.txt</code> file. Preprocessors are saved via <code>joblib</code>.</p>"},{"location":"docs/cards/modelcard/#xgboostmodel","title":"XGBoostModel","text":"<p>Interface for saving a XGBoostBooster model. Note - If using a XGBRegressor or XGBClassifier, you should use the SklearnModelInterface instead.</p> <p>Example: <code>Link</code></p> Argument Description model Model to associate with interface. This model must be an xgboost booster preprocessor Optional preprocessor to associate with the model sample_data Optional ample of data that is fed to the model at inference time task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. XGBoostModel <pre><code>class XGBoostModel(ModelInterface):\ndef __init__(\n    self,\n    model: Optional[Any] = None,\n    preprocessor: Optional[Any] = None,\n    sample_data: Optional[Any] = None,\n    task_type: Optional[TaskType] = None,\n    drift_profile: Optional[DriftProfileType] = None,\n) -&gt; None:\n    \"\"\"Interface for saving XGBoost Booster models\n\n    Args:\n        model:\n            Model to associate with interface. This model must be an xgboost booster.\n        preprocessor:\n            Preprocessor to associate with the model.\n        sample_data:\n            Sample data to use to make predictions.\n        task_type:\n            The type of task the model performs\n        drift_profile:\n            Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n    \"\"\"\n\n@property\ndef preprocessor(self) -&gt; Optional[Any]:\n    \"\"\"Returns the preprocessor\"\"\"\n\n@preprocessor.setter\ndef preprocessor(self, preprocessor: Any) -&gt; None:\n    \"\"\"Sets the preprocessor\n\n    Args:\n        preprocessor:\n            Preprocessor to associate with the model. This preprocessor must be from the\n            scikit-learn ecosystem\n    \"\"\"\n\n@property\ndef preprocessor_name(self) -&gt; Optional[str]:\n    \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#nuts-and-bolts_2","title":"Nuts and Bolts","text":"<p>Booster models are saved via <code>save_model</code> which exports a <code>.json</code> file. Preprocessors are saved via <code>joblib</code>.</p>"},{"location":"docs/cards/modelcard/#huggingfacemodel","title":"HuggingFaceModel","text":"<p>Example: <code>Link</code></p> Argument Description model Model to associate with interface. Model must be a <code>Pipeline</code>, <code>PreTrainedModel</code> or a <code>TFPreTrainedModel</code> tokenizer Optional tokenizer to associate with the model. Must be of type <code>PreTrainedTokenizerBase</code> feature_extractor Optional feature extractor to associate with model. Must be of type <code>PreTrainedFeatureExtractor</code> image_processor Optional image processor to associate with model. Must be of type <code>BaseImageProcessor</code> sample_data Optional ample of data that is fed to the model at inference time hf_task Optional HuggingFace task type of the model. Defaults to <code>HuggingFaceTask.Undefined</code> task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. HuggingFaceMode <pre><code>class HuggingFaceModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        tokenizer: Optional[Any] = None,\n        feature_extractor: Optional[Any] = None,\n        image_processor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        hf_task: Optional[HuggingFaceTask] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving HuggingFace models and pipelines\n\n        Args:\n            model:\n                Model to associate with interface. This can be a HuggingFace pipeline (inherits from Pipeline),\n                or a HuggingFace model (inherits from PreTrainedModel or TFPreTrainedModel).\n            tokenizer:\n                Tokenizer to associate with the model. This must be a HuggingFace tokenizer (PreTrainedTokenizerBase).\n                If using a pipeline that already has a tokenizer, this can be None.\n            feature_extractor:\n                Feature extractor to associate with the model. This must be a HuggingFace feature extractor\n                (PreTrainedFeatureExtractor). If using a pipeline that already has a feature extractor,\n                this can be None.\n            image_processor:\n                Image processor to associate with the model. This must be a HuggingFace image processor\n                (BaseImageProcessor). If using a pipeline that already has an image processor,\n                this can be None.\n            sample_data:\n                Sample data to use to convert to ONNX and make sample predictions. This data must be a\n                HuggingFace-supported type.\n            hf_task:\n                HuggingFace task to associate with the model. Defaults to Undefined.\n                Accepted tasks are as follows (taken from HuggingFace pipeline docs):\n                    - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n                    - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n                    - `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n                    - `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n                    - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n                    - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n                    - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n                    - `\"image-feature-extraction\"`: will return an [`ImageFeatureExtractionPipeline`].\n                    - `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n                    - `\"image-text-to-text\"`: will return a [`ImageTextToTextPipeline`].\n                    - `\"image-to-image\"`: will return a [`ImageToImagePipeline`].\n                    - `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n                    - `\"mask-generation\"`: will return a [`MaskGenerationPipeline`].\n                    - `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n                    - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n                    - `\"summarization\"`: will return a [`SummarizationPipeline`].\n                    - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n                    - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n                    - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n                    [`TextClassificationPipeline`].\n                    - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n                    - `\"text-to-audio\"` (alias `\"text-to-speech\"` available): will return a [`TextToAudioPipeline`]:.\n                    - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n                    - `\"translation\"`: will return a [`TranslationPipeline`].\n                    - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n                    - `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n                    - `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n                    - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n                    - `\"zero-shot-image-classification\"`: will return a [`ZeroShotImageClassificationPipeline`].\n                    - `\"zero-shot-audio-classification\"`: will return a [`ZeroShotAudioClassificationPipeline`].\n                    - `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`].\n            task_type:\n                The intended task type for the model. Note: This is the OpsML task type, not the HuggingFace task type.\n            drift_profile:\n                Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: None | ModelSaveKwargs = None,\n    ) -&gt; ModelInterfaceMetadata:\n        \"\"\"Save the HuggingFaceModel interface\n\n        Args:\n            path (Path):\n                Base path to save artifacts\n            save_kwargs (ModelSaveKwargs):\n                Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n                that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n                the underlying library.\n\n                - model: Kwargs that will be passed to save_model. See save_model for more details.\n                - preprocessor: Kwargs that will be passed to save_preprocessor\n                - onnx: Kwargs that will be passed when saving the onnx model\n                    - For the HuggingFaceModel, this should be an instance of HuggingFaceOnnxArgs\n        \"\"\"\n\n    @property\n    def model(self) -&gt; Optional[Any]:\n        \"\"\"Returns as HuggingFace model (PreTrainedModel, TFPreTrainedModel).\n        Can be None if the model is a pipeline.\n        \"\"\"\n\n    @model.setter\n    def model(self, model: Any) -&gt; None:\n        \"\"\"Sets the model\n\n        Args:\n            model:\n                Model to associate with the interface. This must be a HuggingFace model (PreTrainedModel, TFPreTrainedModel).\n                If using a pipeline that already has a model, this can be None.\n        \"\"\"\n\n    @property\n    def tokenizer(self) -&gt; Optional[Any]:\n        \"\"\"Returns the tokenizer. Can be None if the model is a pipeline.\n        If present, will be of type PreTrainedTokenizerBase\n        \"\"\"\n\n    @tokenizer.setter\n    def tokenizer(self, tokenizer: Any) -&gt; None:\n        \"\"\"Sets the tokenizer\n\n        Args:\n            tokenizer:\n                Tokenizer to associate with the model. This must be a HuggingFace tokenizer (PreTrainedTokenizerBase).\n                If using a pipeline that already has a tokenizer, this can be None.\n        \"\"\"\n\n    @property\n    def image_processor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the image processor. Can be None if the model is a pipeline.\n        If present, will be of type BaseImageProcessor\n        \"\"\"\n\n    @image_processor.setter\n    def image_processor(self, image_processor: Any) -&gt; None:\n        \"\"\"Sets the image processor\n\n        Args:\n            image_processor:\n                Image processor to associate with the model. This must be a HuggingFace image processor\n                (BaseImageProcessor). If using a pipeline that already has an image processor,\n                this can be None.\n        \"\"\"\n\n    @property\n    def feature_extractor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the feature extractor. Can be None if the model is a pipeline.\n        If present, will be of type PreTrainedFeatureExtractor\n        \"\"\"\n\n    @feature_extractor.setter\n    def feature_extractor(self, feature_extractor: Any) -&gt; None:\n        \"\"\"Sets the feature extractor\n\n        Args:\n            feature_extractor:\n                Feature extractor to associate with the model. This must be a HuggingFace feature extractor\n                (PreTrainedFeatureExtractor). If using a pipeline that already has a feature extractor,\n                this can be None.\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#nuts-and-bolts_3","title":"Nuts and Bolts","text":"<p>The <code>HuggingFaceModel</code> and it's associated model, tokenizer, feature extractor and image processor are saved using the <code>save_pretrained</code> method.</p>"},{"location":"docs/cards/modelcard/#huggingface-onnx-args","title":"HuggingFace Onnx Args","text":"<p>There are times where you may want to convert your HuggingFace model to onnx format. Unlike other ModelInterfaces, The <code>HuggingFaceModel</code> has a special <code>HuggingFaceOnnxArgs</code> object that you can into <code>ModelSaveKwargs</code></p> Argument Description ort_type (<code>HuggingFaceORTModel</code>) The ORT model type to use. See below. provider Onnx runtime provider to use quantize Whether to quantize the model config Optional Optimum config if quantizing extra_kwargs Extra kwargs to pass to the onnx conversion HuggingFaceORTModel <pre><code>class HuggingFaceORTModel:\n    OrtAudioClassification: \"HuggingFaceORTModel\"\n    OrtAudioFrameClassification: \"HuggingFaceORTModel\"\n    OrtAudioXVector: \"HuggingFaceORTModel\"\n    OrtCustomTasks: \"HuggingFaceORTModel\"\n    OrtCtc: \"HuggingFaceORTModel\"\n    OrtFeatureExtraction: \"HuggingFaceORTModel\"\n    OrtImageClassification: \"HuggingFaceORTModel\"\n    OrtMaskedLm: \"HuggingFaceORTModel\"\n    OrtMultipleChoice: \"HuggingFaceORTModel\"\n    OrtQuestionAnswering: \"HuggingFaceORTModel\"\n    OrtSemanticSegmentation: \"HuggingFaceORTModel\"\n    OrtSequenceClassification: \"HuggingFaceORTModel\"\n    OrtTokenClassification: \"HuggingFaceORTModel\"\n    OrtSeq2SeqLm: \"HuggingFaceORTModel\"\n    OrtSpeechSeq2Seq: \"HuggingFaceORTModel\"\n    OrtVision2Seq: \"HuggingFaceORTModel\"\n    OrtPix2Struct: \"HuggingFaceORTModel\"\n    OrtCausalLm: \"HuggingFaceORTModel\"\n    OrtOptimizer: \"HuggingFaceORTModel\"\n    OrtQuantizer: \"HuggingFaceORTModel\"\n    OrtTrainer: \"HuggingFaceORTModel\"\n    OrtSeq2SeqTrainer: \"HuggingFaceORTModel\"\n    OrtTrainingArguments: \"HuggingFaceORTModel\"\n    OrtSeq2SeqTrainingArguments: \"HuggingFaceORTModel\"\n    OrtStableDiffusionPipeline: \"HuggingFaceORTModel\"\n    OrtStableDiffusionInpaintPipeline: \"HuggingFaceORTModel\"\n    OrtStableDiffusionXlPipeline: \"HuggingFaceORTModel\"\n    OrtStableDiffusionXlImg2ImgPipeline: \"HuggingFaceORTModel\"\n    OrtStableDiffusionImg2ImgPipeline: \"HuggingFaceORTModel\"\n</code></pre> HuggingFaceOnnxArgs <pre><code>class HuggingFaceOnnxArgs:\n    ort_type: HuggingFaceORTModel\n    provider: str\n    quantize: bool\n    export: bool\n    config: Optional[Any]\n    extra_kwargs: Optional[Dict[str, Any]]\n\n    def __init__(\n        self,\n        ort_type: HuggingFaceORTModel,\n        provider: str,\n        quantize: bool = False,\n        config: Optional[Any] = None,\n        extra_kwargs: Optional[Dict[str, Any]] = None,\n    ) -&gt; None:\n        \"\"\"Optional Args to use with a huggingface model\n\n        Args:\n            ort_type:\n                Optimum onnx class name\n            provider:\n                Onnx runtime provider to use\n            config:\n                Optional optimum config to use\n            quantize:\n                Whether to quantize the model\n            extra_kwargs:\n                Extra kwargs to pass to the onnx conversion (save_pretrained method for ort models)\n\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#catboostmodel","title":"CatBoostModel","text":"<p>Interface for saving a CatBoost model</p> <p>Example: <code>Link</code></p> Argument Description model Model to associate with interface. This model must be an <code>CatBoost</code> model preprocessor Optional preprocessor to associate with the model sample_data Optional ample of data that is fed to the model at inference time task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. CatBoostModel <pre><code>class CatBoostModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving CatBoost models\n\n        Args:\n            model:\n                Model to associate with the interface. This model must be a CatBoost model.\n            preprocessor:\n                Preprocessor to associate with the model.\n            sample_data:\n                Sample data to use to make predictions.\n            task_type:\n                The type of task the model performs\n            drift_profile:\n                Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#nuts-and-bolts_4","title":"Nuts and Bolts","text":"<p>CatBoost models are saved via <code>save_model</code> which exports a <code>.cbm</code> file. Preprocessors are saved via <code>joblib</code>.</p>"},{"location":"docs/cards/modelcard/#torchmodel","title":"TorchModel","text":"<p>Interface for saving a CatBoost model</p> <p>Example: <code>Link</code></p> Argument Description model Model to associate with interface. This model must be of type <code>torch.nn.Module</code> preprocessor Optional preprocessor to associate with the model sample_data Optional ample of data that is fed to the model at inference time task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. TorchModel <pre><code>class TorchModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving PyTorch models\n\n        Args:\n            model:\n                Model to associate with interface. This model must inherit from torch.nn.Module.\n            preprocessor:\n                Preprocessor to associate with model.\n            sample_data:\n                Sample data to use to convert to ONNX and make sample predictions. This data must be a\n                pytorch-supported type. TorchData interface, torch tensor, torch dataset, Dict[str, torch.Tensor],\n                List[torch.Tensor], Tuple[torch.Tensor].\n            task_type:\n                The intended task type of the model.\n            drift_profile:\n                Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: None | ModelSaveKwargs = None,\n    ) -&gt; ModelInterfaceMetadata:\n        \"\"\"Save the TorchModel interface. Torch models are saved\n        as state_dicts as is the standard for PyTorch.\n\n        Args:\n            path (Path):\n                Base path to save artifacts\n            save_kwargs (ModelSaveKwargs):\n                Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n                that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n                the underlying library.\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#nuts-and-bolts_5","title":"Nuts and Bolts","text":"<p>The following steps are executed when saving a TorchModel:</p>"},{"location":"docs/cards/modelcard/#saving-a-model","title":"Saving a Model","text":"<ul> <li>The state dict of the model is extracted from <code>state_dict()</code> </li> <li>The sate dict is saved to a <code>.pt</code> file using <code>torch.save</code></li> <li>If any user-defined save kwargs are passed using <code>ModelSaveKwargs</code>, they are passed to the <code>torch.save</code> method as a dictionary.</li> </ul>"},{"location":"docs/cards/modelcard/#loading-a-model","title":"Loading a Model","text":"<ul> <li>As a result of the model being saved as a state dict, a user will need to supply the model call as a load kwarg when loading the model.</li> <li>The state dict is loaded from path and then loaded into the model using Torch's <code>load_state_dict()</code> method.</li> <li>If any user-defined load kwargs are passed using <code>ModelLoadKwargs</code>, they are passed to the <code>torch.load</code> method as a dictionary.</li> </ul> <pre><code>class Polynomial3(torch.nn.Module):\n    def __init__(self):\n        \"\"\"\n        In the constructor we instantiate four parameters and assign them as\n        member parameters.\n        \"\"\"\n        super().__init__()\n        self.x1 = torch.nn.Parameter(torch.randn(()))\n        self.x2 = torch.nn.Parameter(torch.randn(()))\n\n    def forward(self, x1: torch.Tensor, x2: torch.Tensor):\n        \"\"\"\n        In the forward function we accept a Tensor of input data and we must return\n        a Tensor of output data. We can use Modules defined in the constructor as\n        well as arbitrary operators on Tensors.\n        \"\"\"\n        return self.x1 + self.x2 * x1 * x2\n\nmodel = Polynomial3()\n\n# ... logic to load from registry\n\n# load the model\nmodelcard.load(load_kwargs = ModelLoadKwargs(model={\"model\": model})) #(1)\n</code></pre> <ol> <li>The model object is passed as a load kwarg when loading a <code>ModelCard's</code> components</li> </ol>"},{"location":"docs/cards/modelcard/#lightningmodel","title":"LightningModel","text":"<p>Interface for saving a Lightning model</p> <p>Example: <code>Link</code></p> Argument Description trainer A model trainer to associate with interface. This model must be of type <code>lightning.Trainer</code> preprocessor Optional preprocessor to associate with the model sample_data Optional ample of data that is fed to the model at inference time task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. LightningModel <pre><code>class LightningModel(ModelInterface):\n    def __init__(\n        self,\n        trainer: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving PyTorch Lightning models\n\n        Args:\n            trainer:\n                Pytorch lightning trainer to associate with interface.\n            preprocessor:\n                Preprocessor to associate with model.\n            sample_data:\n                Sample data to use to convert to ONNX and make sample predictions. This data must be a\n                pytorch-supported type. TorchData interface, torch tensor, torch dataset, Dict[str, torch.Tensor],\n                List[torch.Tensor], Tuple[torch.Tensor].\n            task_type:\n                The intended task type of the model.\n            drift_profile:\n                Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    @property\n    def trainer(self) -&gt; None:\n        \"\"\"Returns the trainer\"\"\"\n\n    @trainer.setter\n    def trainer(self, trainer: Any) -&gt; None:\n        \"\"\"Sets the trainer\"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model. This preprocessor must be from the\n                scikit-learn ecosystem\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n\n    def save(\n        self,\n        path: Path,\n        save_kwargs: None | ModelSaveKwargs = None,\n    ) -&gt; ModelInterfaceMetadata:\n        \"\"\"Save the LightningModel interface. Lightning models are saved via checkpoints.\n\n        Args:\n            path (Path):\n                Base path to save artifacts\n            save_kwargs (ModelSaveKwargs):\n                Optional kwargs to pass to the various underlying methods. This is a passthrough object meaning\n                that the kwargs will be passed to the underlying methods as is and are expected to be supported by\n                the underlying library.\n\n                - model: Kwargs that will be passed to save_model. See save_model for more details.\n                - preprocessor: Kwargs that will be passed to save_preprocessor\n                - onnx: Kwargs that will be passed to save_onnx_model. See convert_onnx_model for more details.\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#nuts-and-bolts_6","title":"Nuts and Bolts","text":"<p>The following steps are executed when saving a LightningModel:</p>"},{"location":"docs/cards/modelcard/#saving-a-model_1","title":"Saving a Model","text":"<ul> <li>Lightning models are saved via checkpoints and the <code>save_checkpoint</code> method, which exports a <code>.ckpt</code> file. Thus, make sure the trainer is stopped at the appropriate checkpoint, or reverted to your preferred checkpoint prior to saving.</li> </ul>"},{"location":"docs/cards/modelcard/#loading-a-model_1","title":"Loading a Model","text":"<ul> <li>When loading a LightningModel, the model is loaded from the saved <code>Trainer</code> checkpoint.</li> <li>Similar to <code>TorchModel</code>, an instantiated model object is required to be passed as a load kwarg</li> <li>The saved checkpoint is then loaded into the model using the <code>load_from_checkpoint</code> method including any additional kwargs that are passed via <code>ModelLoadKwargs</code>.</li> <li>The model can then be accessed via the <code>model</code> property of <code>LightningModel</code>.</li> </ul>"},{"location":"docs/cards/modelcard/#tensorflowmodel","title":"TensorFlowModel","text":"<p>Interface for saving a TensorFlow model</p> <p>Example: <code>Link</code></p> Argument Description model Model to associate with interface. This model must be of type <code>tensorflow.keras.Model</code> preprocessor Optional preprocessor to associate with the model sample_data Optional ample of data that is fed to the model at inference time task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. TensorFlowModel <pre><code>class TensorFlowModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        preprocessor: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        schema: Optional[FeatureSchema] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving PyTorch models\n\n        Args:\n            model:\n                Model to associate with interface. This model must inherit from tensorflow.keras.Model\n            preprocessor:\n                Preprocessor to associate with model.\n            sample_data:\n                Sample data to use to convert to ONNX and make sample predictions. This data must be a\n                tensorflow-supported type. numpy array, tf.Tensor, torch dataset, Dict[str, tf.Tensor],\n                List[tf.Tensor], Tuple[tf.Tensor].\n            task_type:\n                The intended task type of the model.\n            drift_profile:\n                Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n        \"\"\"\n\n    @property\n    def preprocessor(self) -&gt; Optional[Any]:\n        \"\"\"Returns the preprocessor\"\"\"\n\n    @preprocessor.setter\n    def preprocessor(self, preprocessor: Any) -&gt; None:\n        \"\"\"Sets the preprocessor\n\n        Args:\n            preprocessor:\n                Preprocessor to associate with the model\n        \"\"\"\n\n    @property\n    def preprocessor_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the preprocessor name\"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#nuts-and-bolts_7","title":"Nuts and Bolts","text":"<p>The model is saved using the preferred keras format via <code>model.save</code>. Loading is done through <code>tensorflow.keras.models</code> <code>load_model</code> method. If a user provides a custom load kwarg, it is passed to the <code>load_model</code> method as a dictionary</p>"},{"location":"docs/cards/modelcard/#onnx-model","title":"Onnx Model","text":"<p>As mention elsewhere, all supported model interfaces can be automatically converted to onnx format. However, you may find that you only want to save the convert onnx model. In this case, you can leverage the <code>OnnxModel</code> interface for saving an onnx model directly.</p> Argument Description model Onnx model to associate with the interface. This model must be an Onnx ModelProto sample_data Optional ample of data that is fed to the model at inference time task_type Optional task type of the model. Defaults to <code>TaskType.Undefined</code> drift_profile Optional <code>Scouter</code> drift profile to associated with model. This is a convenience argument if you already created a drift profile. You can also use interface.create_drift_profile(..) to create a drift profile from the model interface. <p>Example: <code>Link</code></p> OnnxModel <pre><code>class OnnxModel(ModelInterface):\n    def __init__(\n        self,\n        model: Optional[Any] = None,\n        sample_data: Optional[Any] = None,\n        task_type: Optional[TaskType] = None,\n        drift_profile: Optional[DriftProfileType] = None,\n    ) -&gt; None:\n        \"\"\"Interface for saving an OnnxModel\n\n        Args:\n            model:\n                Onnx model to associate with the interface. This model must be an Onnx ModelProto\n            sample_data:\n                Sample data to use to make predictions\n            task_type:\n                The type of task the model performs\n            drift_profile:\n                Drift profile to use. Can be a list of SpcDriftProfile, PsiDriftProfile or CustomDriftProfile\n\n        Example:\n            ```python\n            from sklearn.datasets import load_iris  # type: ignore\n            from sklearn.model_selection import train_test_split  # type: ignore\n            from sklearn.ensemble import RandomForestClassifier  # type: ignore\n            from skl2onnx import to_onnx  # type: ignore\n            import onnxruntime as rt  # type: ignore\n\n            iris = load_iris()\n\n            X, y = iris.data, iris.target\n            X = X.astype(np.float32)\n            X_train, X_test, y_train, y_test = train_test_split(X, y)\n            clr = RandomForestClassifier()\n            clr.fit(X_train, y_train)\n\n            onx = to_onnx(clr, X[:1])\n\n            interface = OnnxModel(model=onx, sample_data=X_train)\n            ```\n        \"\"\"\n\n    @property\n    def session(self) -&gt; OnnxSession:\n        \"\"\"Returns the onnx session. This will error if the OnnxSession is not set\"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#nuts-and-bolts_8","title":"Nuts and Bolts","text":"<p><code>OnnxModel</code> uses the onnxruntime library to save and load the model. Input and out schema are derived using the ort crate.</p>"},{"location":"docs/cards/modelcard/#custommodel","title":"CustomModel","text":"<p>While the above interfaces cover the most common use cases, there may be times where you want to create your own custom model interface. By design, the <code>ModelInterface</code> can be subclassed in cases where a more flexible implementation is needed. However to make sure all other components work nicely together, you will need to implement the following.</p> <p>Example: <code>Link</code></p>"},{"location":"docs/cards/modelcard/#custom-save","title":"Custom Save","text":"<ul> <li>save: This method is called when saving the model. It should save the model and any other artifacts to the specified path. The method should return a <code>ModelInterfaceMetadata</code> object.</li> </ul> Argument Description path The base path to save artifacts to. note - this is typically injected at the time of saving. See the below example for how it should be used save_kwargs Optional ModelSaveKwargs to use when saving the model <pre><code>class CustomInterface(ModelInterface): #(1)\n    def save( #(2)\n        self,\n        path: Path, \n        save_kwargs: ModelSaveKwargs | None = None,\n    ) -&gt; ModelInterfaceMetadata:\n\n        model_save_path = Path(\"model\").with_suffix(\".joblib\") #(3)\n\n        joblib.dump(self.model, path / model_save_path) #(4)\n\n        save_metadata = ModelInterfaceSaveMetadata(model_uri=model_save_path)  #(5)\n\n\n        return ModelInterfaceMetadata( #(5)\n            task_type=self.task_type,\n            model_type=self.model_type,\n            data_type=self.data_type,\n            save_metadata=save_metadata,\n            extra_metadata={\"foo\": \"bar\"},\n        )\n</code></pre> <ol> <li>The class must inherit from <code>ModelInterface</code>. This is the base class for all model interfaces.</li> <li>The <code>save</code> method arguments cannot be changed. These are standardized across all interfaces and are used internally within the Rust runtime.</li> <li>The <code>model_save_path</code> is the path to save the model to relative to the base path. This will be joined with the base path when saving and loading the model.</li> <li>The model is saved using <code>joblib.dump</code> to the specified path. This is where you would save your model and any other artifacts.</li> <li><code>ModelInterfaceSaveMetadata</code> is a core component for storing artifact uris and extra metadata. It is required as it is used internally to load artifacts.</li> <li>The <code>ModelInterfaceMetadata</code> is returned from the save method. This is required.</li> </ol> DataProcessor <pre><code>class DataProcessor:\n    \"\"\"Generic class that holds uri information for data preprocessors and postprocessors\"\"\"\n\n    name: str\n    uri: Path\n    type: ProcessorType\n\n    def __str__(self): ...\n</code></pre> ModelInterfaceSaveMetadata <pre><code>class ModelInterfaceSaveMetadata:\n    model_uri: Path\n    data_processor_map: Dict[str, DataProcessor]\n    sample_data_uri: Path\n    onnx_model_uri: Optional[Path]\n    drift_profile_uri_map: Optional[Dict[str, DriftProfileUri]]\n    extra: Optional[ExtraMetadata]\n    save_kwargs: Optional[ModelSaveKwargs]\n\n    def __init__(\n        self,\n        model_uri: Path,\n        data_processor_map: Optional[Dict[str, DataProcessor]] = {},  # type: ignore\n        sample_data_uri: Optional[Path] = None,\n        onnx_model_uri: Optional[Path] = None,\n        drift_profile_uri_map: Optional[Dict[str, DriftProfileUri]] = None,\n        extra: Optional[ExtraMetadata] = None,\n        save_kwargs: Optional[ModelSaveKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Define model interface save arguments\n\n        Args:\n            model_uri:\n                Path to the model\n            data_processor_map:\n                Dictionary of data processors\n            sample_data_uri:\n                Path to the sample data\n            onnx_model_uri:\n                Path to the onnx model\n            drift_profile_uri_map:\n                Dictionary of drift profiles\n            extra_metadata:\n                Extra metadata\n            save_kwargs:\n                Optional save args\n        \"\"\"\n\n    def __str__(self): ...\n    def model_dump_json(self) -&gt; str: ...\n</code></pre> ModelInterfaceMetadata <pre><code>class ModelInterfaceMetadata:\n    task_type: TaskType\n    model_type: ModelType\n    data_type: DataType\n    onnx_session: Optional[OnnxSession]\n    schema: FeatureSchema\n    save_metadata: ModelInterfaceSaveMetadata\n    extra_metadata: dict[str, str]\n\n    def __init__(\n        self,\n        save_metadata: ModelInterfaceSaveMetadata,\n        task_type: TaskType = TaskType.Undefined,\n        model_type: ModelType = ModelType.Unknown,\n        data_type: DataType = DataType.NotProvided,\n        schema: FeatureSchema = FeatureSchema(),\n        onnx_session: Optional[OnnxSession] = None,\n        extra_metadata: dict[str, str] = {},\n    ) -&gt; None:\n        \"\"\"Define a model interface\n\n        Args:\n            task_type:\n                Task type\n            model_type:\n                Model type\n            data_type:\n                Data type\n            onnx_session:\n                Onnx session\n            schema:\n                Feature schema\n            data_type:\n                Sample data type\n            save_metadata:\n                Save metadata\n            extra_metadata:\n                Extra metadata. Must be a dictionary of strings\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the model interface metadata\"\"\"\n\n    def model_dump_json(self) -&gt; str:\n        \"\"\"Dump the model interface metadata to json\"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"ModelInterfaceMetadata\":\n        \"\"\"Validate the model interface metadata json\"\"\"\n</code></pre>"},{"location":"docs/cards/modelcard/#custom-load","title":"Custom Load","text":"<p>To load a custom model, you will need to implement the <code>load</code> method. This method is called when loading the model. It should load the model and any other artifacts from the specified path.</p> <ul> <li>load: This method is called when loading the model</li> </ul> Argument Description path The base path to load artifacts from. note - this is typically injected at the time of loading. See the below example for how it should be used metadata <code>ModelInterfaceSaveMetadata</code>. This will be injected by Opsml when the card is loaded from a registry load_kwargs Optional <code>ModelLoadKwargs</code>. Additional load kwargs used to load a model and it's artifacts <pre><code>class CustomInterface(ModelInterface):\n    def load(\n        self,\n        path: Path,\n        metadata: ModelInterfaceSaveMetadata,\n        load_kwargs: ModelLoadKwargs | None = None,\n    ) -&gt; None:\n        model_path = path / metadata.model_uri #(1)\n        self.model = joblib.load(model_path) #(2)\n</code></pre> <ol> <li>We use the <code>metadata</code> object to get the model path or any other path to an artifact. It is then joined with the base path to load the model.</li> <li>The model is loaded using <code>joblib.load</code> and assigned to the model property of the interface. This is where you would load your model and any other artifacts.</li> </ol>"},{"location":"docs/cards/modelcard/#changing-init-arguments","title":"Changing Init Arguments","text":"<p>If you find in your custom interface that you are changing class/self attributes during instantiation, you will also need to include two extra methods called <code>from_metadata</code> (staticmethod) as well as a <code>__new__</code> method. The reason for this is (1), pyo3 does not currently support custom <code>__init__</code> methods (2) <code>from_metadata</code> is called on all interfaces when loading a card from the registry and is used to initialize the class with metadata attributes.</p> <p>The below example shows an example of how you can implement this. In the example, we are adding the <code>preprocessor</code> attribute</p> <pre><code>class CustomModel(ModelInterface):\n    def __new__( #(1)\n        cls,\n        preprocessor=None, #(2)\n        model: None | Any = None,\n        sample_data: None | Any = None,\n        task_type: None | TaskType = None,\n    ):\n        instance = super(CustomModel, cls).__new__(\n            cls,\n            model=model,\n            sample_data=sample_data,\n            task_type=task_type,\n        )\n\n        return instance\n\n    def __init__(self, preprocessor, model, sample_data, task_type):\n        \"\"\"Init method for the custom model interface.\"\"\"\n\n        super().__init__()\n\n        self.preprocessor = preprocessor #(3)\n\n    def save(self, path, save_kwargs=None):\n        ...\n\n    def load(self, path, metadata, load_kwargs=None):\n        ...\n\n    @staticmethod\n    def from_metadata(metadata: ModelInterfaceMetadata) -&gt; \"CustomModel\":\n        \"\"\"Load model from metadata.\"\"\"\n\n        return CustomModel(\n            model=None,\n            sample_data=None,\n            task_type=metadata.task_type,\n            preprocessor=None,\n        )\n</code></pre> <ol> <li>Custom new method</li> <li>Adding preprocessor as a class argument</li> <li>Assigning preprocessor to the class attribute</li> </ol> <p>Note: If you are not changing the default class attributes, you do not need to to implement <code>__new__</code> or <code>from_metadata</code>.</p>"},{"location":"docs/cards/modelcard/#method-overriding-checklist","title":"Method Overriding Checklist","text":"Changing Class Attributes? Methods to Implement No <code>save</code>, <code>load</code> Yes <code>save</code>, <code>load</code>, <code>__new__</code>, <code>from_metadata</code>"},{"location":"docs/cards/modelcard/#loading-from-a-registry","title":"Loading from a Registry","text":"<p>To load a custom interface from the registry, you will need to supply the python definition of the interface class to the <code>load_card</code> method. This is important to keep in mind for reproducibility and sharing. Another user will not be able to use your interface unless they have the same class definition.</p> <pre><code>class MyCustomInterface(ModelInterface):\n    ...\n\nregistry.load_card(uid=\"{{model uid}}\", interface=MyCustomInterface) #(1)\n</code></pre> <ol> <li>The interface class is passed to the <code>load_card</code> method. This is required for custom interfaces</li> </ol>"},{"location":"docs/cards/overview/","title":"Overview","text":"<p>Cards are one of the primary data structures of opsml. All cards store specific information depending on their type and are serialized and stored in a registry and backend storage system</p>"},{"location":"docs/cards/overview/#card-types","title":"Card Types","text":"<p>DataCard: </p> <ul> <li>Stores data-related information</li> <li>Requires a <code>DataInterface</code> </li> <li>Registered in the <code>DataRegistry</code></li> </ul> <p>ModelCard:  </p> <ul> <li>Stores model-related information</li> <li>Requires a <code>ModelInterface</code> </li> <li>Registered in the <code>ModelRegistry</code></li> </ul> <p>ExperimentCard: </p> <ul> <li>Stores experiment-related information (metrics, parameters, cards, hardware metrics)</li> <li>Typically accessed through a context manager <code>with start_experiment()</code></li> <li>Registered in the <code>ExperimentRegistry</code></li> </ul> <p>PromptCard: </p> <ul> <li>Stores prompt/genai-related information</li> <li>Requires a <code>Prompt</code> </li> <li>Registered in the <code>PromptRegistry</code></li> </ul> <p>ServiceCard: </p> <ul> <li>Stores a collection of cards</li> <li>Requires a list of <code>Card</code></li> <li>Registered in the <code>ServiceCardRegistry</code></li> </ul>"},{"location":"docs/cards/overview/#card-arguments","title":"Card Arguments","text":"<p>All cards require a set of arguments in order to be registered. This is to ensure the card is properly assigned ownership and can be tracked. The arguments are:</p> <ul> <li>space: The space associated with the card. This is typically the name of the organization or team that owns the card.</li> <li>name: The name of the card. This is typically a short, descriptive name that identifies the card.</li> </ul>"},{"location":"docs/cards/overview/#naming","title":"Naming","text":"<p>All cards follow standardized naming conventions of <code>{space}/{name}/v{version}</code>. This is to ensure that cards are easily tracked and managed.</p> <p>Note</p> <p>These arguments can also be supplied through a pyproject.toml tool configuration. See the tools section for more information.</p>"},{"location":"docs/cards/overview/#registries","title":"Registries","text":"<p>Each card type is associated with a specific registry (modelcard with model registry, promptcard with prompt registry). Registries are accessible via the <code>CardRegistry</code> class and are used to register, list, load, update and delete cards. To access a specific registry, you can pass the string name of the registry or the <code>RegistryType</code> enum. The available registries are:</p> <p>ModelRegistry:</p> <pre><code>from opsml import CardRegistry, RegistryType\n\nmodel_registry = CardRegistry(registry_name=\"model\")\nmodel_registry = CardRegistry(registry_name=RegistryType.Model)\n</code></pre> <p>DataRegistry:</p> <pre><code>from opsml import CardRegistry, RegistryType\ndata_registry = CardRegistry(registry_name=\"data\")\ndata_registry = CardRegistry(registry_name=RegistryType.Data)\n</code></pre> <p>ExperimentRegistry:</p> <pre><code>from opsml import CardRegistry, RegistryType\nexperiment_registry = CardRegistry(registry_name=\"experiment\")\nexperiment_registry = CardRegistry(registry_name=RegistryType.Experiment)\n</code></pre> <p>PromptRegistry:</p> <pre><code>from opsml import CardRegistry, RegistryType\nprompt_registry = CardRegistry(registry_name=\"prompt\")\nprompt_registry = CardRegistry(registry_name=RegistryType.Prompt)\n</code></pre> <p>All Registries:</p> <pre><code>from opsml import CardRegistries\n\nregistries = CardRegistries()\n# access specific registry (registries.model, registries.data, registries.experiment, registries.prompt)\n</code></pre>"},{"location":"docs/cards/overview/#listing-cards","title":"Listing Cards","text":"<p>You can list cards in a registry using the <code>list_cards</code> method. This will return a list of cards containing the card information. You can filter the results by name, space, version and uid. </p> Returns a list of cards. <p>Arguments:</p> <ul> <li>space: space associated with card (Optional)</li> <li>name: Name of card (Optional)</li> <li>version: Version of Card (Optional)</li> <li>uid: Uid of card (Optional)</li> <li>max_date: Maximum date of card (Optional)</li> <li>tags: Tags associated with card (Optional)</li> <li>sort_by_timestamp: Sort by timestamp (Optional)</li> <li>limit: Limit the number of cards returned (Optional)</li> </ul> <p>Example:</p> <pre><code>from opsml import CardRegistry, RegistryType\n\nregistry = CardRegistry(RegistryType.Model) # can be \"data\", \"model\", \"run\", \"pipeline\n\n# examples\nregistry.list_cards() \n# will list all cards in registry\n\nregistry.list_cards(limit=10) \n# will list cards and limit the result to 10\n\nregistry.list_cards(name=\"linear-reg\")\n  # list all cards with name \"linear-reg\"\n\nregistry.list_cards(space=\"opsml\", name=\"linear-reg\") \n# list all cards with name \"linear-reg\" with space \"opsml\"\n\nregistry.list_cards(space=\"opsml\", name=\"linear-reg\", version=\"1.0.0\") \n# list card with name \"linear-reg\" with space \"opsml\" and version 1.0.0\n\nregistry.list_cards(space=\"opsml\", name=\"linear-reg\", version=\"1.*\") \n# list cards with name \"linear-reg\" with space \"opsml\" and major version of \"1\"\n\nregistry.list_cards(space=\"opsml\", name=\"linear-reg\", version=\"^2.3.4\") \n# list card with name \"linear-reg\" with space \"opsml\" and latest version &lt; 3.0.0\n\nregistry.list_cards(space=\"opsml\", name=\"linear-reg\", version=\"~2.3.4\") \n# list card with name \"linear-reg\" with space \"opsml\" and latest version &lt; 2.4.0\n\nregistry.list_cards(uid=uid)\n# list card by uid\n</code></pre>"},{"location":"docs/cards/overview/#registering-a-card","title":"Registering a Card","text":"Register a card to a registry <p>Required Args:</p> <ul> <li>card: Card to register</li> <li>version_type: Type of version increment (Optional). Must be of type <code>VersionType</code> (VersionType.Major, VersionType.Minor, VersionType.Patch, VersionType.PreRelease, VersionType.Build). Defaults to <code>VersionType.Minor</code></li> </ul> <p>Example:</p> <pre><code>from opsml import CardRegistry\n\nmodel_registry = CardRegistry(\"model\")\n\n# skipping ModelInterface logic\n...\n\nmodel_card = ModelCard(\n      interface=model_interface,\n      space=\"opsml\",\n      name=\"linear-reg\",\n  )\n\nexample_record = model_registry.register_card(card=model_card)\nprint(model_card.version)\n#&gt; 1.0.0\n</code></pre>"},{"location":"docs/cards/overview/#loading-cards","title":"Loading Cards","text":"Load an Artifact card from a registry. <p>Arguments:</p> <ul> <li>space: space associated with card (Optional)</li> <li>name: Name of card (Optional)</li> <li>version: Version of Card (Optional)</li> <li>uid: Uid of card (Optional)</li> <li>interface: Interface of card (Optional)</li> </ul> <p>Either uid or name and space must be provided. If both are provided, uid will be used.   If you are loading a card that has a custom interface, you must provide the interface as well.</p> <p>Example:</p> <pre><code>from opsml import CardRegistry\nmodel_registry = CardRegistry(\"model\")\n\nmodel_card = model_registry.load_card(\n    space=\"opsml\",\n    name=\"linear-reg\",\n    version=\"1.0.0\",\n  )\nprint(model_card.version)\n#&gt; 1.0.0\n</code></pre>"},{"location":"docs/cards/overview/#update-cards","title":"Update Cards","text":"Update a card from a registry. Required Args: - card: Card to update <p>Warning</p> <p>Updating a card is not recommended. It breaks the idea of versions and immutability of versions. It is recommended to create a new version of the card instead.</p> <p>Note</p> <p>The card must be loaded from the registry before it can be updated.</p> <pre><code>from opsml import CardRegistry\nmodel_registry = CardRegistry(\"model\")\n\n# skipping card logic\n...\n\ncard.name = \"linear-reg-change\"\nmodel_registry.update_card(card)\n</code></pre>"},{"location":"docs/cards/overview/#deleting-cards","title":"Deleting Cards","text":"Delete a card from a registry. Required Args: - card: Card to delete <pre><code>from opsml import CardRegistry\nmodel_registry = CardRegistry(\"model\")\n\n# skipping card logic\n...\n\nmodel_registry.delete_card(card)\n</code></pre>"},{"location":"docs/cards/overview/#for-detailed-information-on-each-card-type-see-the-following-sections","title":"For detailed information on each card type, see the following sections:","text":"<ul> <li>DataCard</li> <li>ModelCard</li> <li>ExperimentCard</li> <li>PromptCard</li> </ul>"},{"location":"docs/cards/promptcard/","title":"Promptcard","text":"<p><code>PromptCards</code> are used to store and standardize prompts for LLM workflows. They are built to be agnostic of a specific framework so that you can use them as you see fit. LLM tool is constantly changing and our goal is to not lock you in, but enable you to use your prompts wherever you see fit.</p> <p>The following shows how to use a <code>PromptCard</code> with OpenAI's API</p> GenAI - OpenAI<pre><code>from openai import OpenAI\nfrom opsml import PromptCard, Prompt, CardRegistry\n\nclient = OpenAI()\n\ncard = PromptCard(\n    space=\"opsml\",\n    name=\"my_prompt\",\n    prompt=Prompt(  # (1)\n        model=\"gpt-4o\",\n        provider=\"openai\",\n        message=\"Provide a brief summary of the programming language ${language}.\", \n        system_instruction=\"Be concise, reply with one sentence.\",\n    ),\n)\n\ndef chat_app(language: str):\n\n    # create the prompt and bind the context\n    user_prompt = card.prompt.bind(language=language).message[0].unwrap()\n    system_instruction = card.prompt.system_instruction[0].unwrap()\n\n    response = client.chat.completions.create(\n        model=card.prompt.model_identifier,\n        messages=[\n            {\"role\": \"system\", \"content\": system_instruction},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ],\n    )\n\n    return response.choices[0].message.content\n\nif __name__ == \"__main__\":\n    result = chat_app(\"Python\")\n    print(result)\n\n    # Register the card in the registry\n    registry = CardRegistry(\"prompt\")\n    registry.register_card(card)\n\n# This code will run as is\n</code></pre> <ol> <li>The <code>message</code> argument of the <code>Prompt</code> class can be a string or a list of strings. In this case, we are using a single string with a placeholder <code>${language}</code> that will be replaced with the actual value when the prompt is bound via the <code>bind</code> method. This allows you to create dynamic prompts that can be reused with different inputs.</li> </ol> <p>In a typical development workflow, you would develop and test different prompts depending on your use case. Whenever a prompt is ready for production, you can register it in the <code>PromptCard</code> registry and load/use it in your application. This way, you can keep track of all the prompts you have developed and their versions, making it easier to manage and update them as needed. In addition, in workflows that require multiple prompts, you can leverage opsml's <code>ServiceCard</code> feature to build a service of prompt cards.</p>"},{"location":"docs/cards/promptcard/#how-it-all-works","title":"How it all works","text":"<p>As you can tell in the example above, <code>PromptCards</code> are created by passing in a <code>Prompt</code>, some required args and some optional args. The <code>Prompt</code> is a framework agnostic class that can hold one or more user messages, system prompts and model settings.</p>"},{"location":"docs/cards/promptcard/#loading-a-promptcard","title":"Loading a PromptCard","text":"<p>You can load a <code>PromptCard</code> as you would any other card in the registry.</p> <pre><code>from opsml import CardRegistry, RegistryType\n\nregistry = CardRegistry(RegistryTYpe.Prompt)\n\ncard = registry.load_card(uid=\"{{card uid}}\")\n\n# or\n\ncard = registry.load_card(space=\"opsml\", name=\"my_prompt\")\n</code></pre>"},{"location":"docs/cards/promptcard/#prompt","title":"Prompt","text":"<p>The <code>Prompt</code> class is the core of the <code>PromptCard</code>. It is used to define the prompt that will be used in the LLM workflow. The <code>Prompt</code> class has the following attributes:</p> Argument Description message A list of messages (more on this below) model An optional model to use (e.g. \"gpt-4o\") provider An optional provider to use (e.g. \"openai\") system_instruction Optional system prompt to use (e.g. \"Be concise\") model_setting Optional model settings to use. This can be used to set the model settings (e.g. temperature, max_tokens)"},{"location":"docs/cards/promptcard/#prompt-message","title":"Prompt Message","text":"<p>The message argument of the prompt class follows openai's message format. The following are the available message types:</p> <ul> <li>String: A string message. (e.g. \"Hello, world!\")</li> <li>StringList: A list of string messages. (e.g. [\"Hello, world!\", \"How are you?\"])</li> <li>Message: A Message class object. See the Message class definition below.</li> <li>MessageList: A list of Message class objects. See the Message class definition below.</li> <li>AudioUrl: A class object that represents an audio url. </li> <li>ImageUrl: A class object that represents an image url.</li> <li>DocumentUrl: A class object that represents a document url.</li> <li>BinaryContent: A class object that represents binary content.</li> </ul>"},{"location":"docs/cards/servicecard/","title":"ServiceCard","text":"<p>Just like you can create cards, you can also create a service of cards called a <code>ServiceCard</code>. The most important benefit of a <code>ServiceCard</code> is that is allows you to create a collection of cards that can be loaded and used together. </p> <p>A prime example of this is in model apis where you may need to load more than one model, or agentic workflows that are associated with more than one prompt. By using a <code>ServiceCard</code>, you can group these cards together and load them all at once (with a few extra nice features that we'll get into).</p>"},{"location":"docs/cards/servicecard/#example-usage-details-below","title":"Example Usage (Details below)","text":""},{"location":"docs/cards/servicecard/#create-a-servicecard","title":"Create a ServiceCard","text":"<pre><code>service = ServiceCard(\n    space=\"opsml-space\",\n    name=\"opsml-service\",\n    cards=[\n        Card(\n            alias=\"model1\",\n            uid=modelcard1.uid,\n            registry_type=RegistryType.Model,\n        ),\n        Card(\n            alias=\"model2\",\n            uid=modelcard2.uid,\n            registry_type=RegistryType.Model,\n        ),\n    ],\n)\nregistry.register_card(service)\n</code></pre>"},{"location":"docs/cards/servicecard/#using-a-servicecard-in-fastapi","title":"Using a ServiceCard in FastAPI","text":"<pre><code>@asynccontextmanager\nasync def lifespan(fast_app: FastAPI):\n    logger.info(\"Starting up FastAPI app\")\n\n    fast_app.state.service = service = ServiceCard.from_path( # (1)\n        path=settings.card_service_path\n        ) \n    yield\n\n    logger.info(\"Shutting down FastAPI app\")\n\n    # Shutdown the service card\n    fast_app.state.service = None\n\n\napp = FastAPI(lifespan=lifespan)\n\n@app.post(\"/predict_with_model1\", response_model=Response)\nasync def predict_model_1(request: Request, payload: PredictRequest) -&gt; Response:\n    card = cast(ModelCard, request.app.state.service[\"model1\"]) # (2)\n\n    prediction= card.interface.model.predict(payload.to_numpy())\n\n    return Response(prediction=prediction[0])\n\n@app.post(\"/predict_with_model2\", response_model=Response)\nasync def predict_model_2(request: Request, payload: PredictRequest) -&gt; Response:\n    card = cast(ModelCard, request.app.state.service[\"model2\"])\n\n    prediction= card.interface.model.predict(payload.to_numpy())\n\n    return Response(prediction=prediction[0])\n</code></pre> <ol> <li>Load the <code>ServiceCard</code> and it's components directly from a path after downloading with the Opsml CLI</li> <li>Access a specific card in the service by its alias. This allows you to use the card's interface to perform operations, such as making predictions with a model.</li> </ol> <p>Currently you can create a service card through the client api or through a tool configuration in your <code>pyproject.toml</code> file.</p>"},{"location":"docs/cards/servicecard/#create-a-service","title":"Create a Service","text":""},{"location":"docs/cards/servicecard/#api","title":"API","text":"<p>Just like all other cards, you can think of a <code>ServiceCard</code> as just another card (even though it is a collection of cards). As such, all services are registered through the ServiceCard <code>CardRegistry</code>.</p> <pre><code>from opsml import ServiceCard, Card, RegistryType\n\nregistry = CardRegistry(RegistryType.Service)\n\nservice = ServiceCard(\n    space=\"opsml-space\",\n    name=\"opsml-service\",\n    cards=[\n        Card(\n            alias=\"model1\",\n            uid=modelcard1.uid,\n            registry_type=RegistryType.Model,\n        ),\n        Card(\n            alias=\"model2\",\n            uid=modelcard2.uid,\n            registry_type=RegistryType.Model,\n        ),\n    ],\n)\nregistry.register_card(service)\n</code></pre> <p>In the above example, we create a <code>ServiceCard</code> with two cards, <code>model1</code> and <code>model2</code>, each referencing a <code>ModelCard</code> that has already been registered by its unique identifier (UID). The service is then registered in the <code>CardRegistry</code> under <code>RegistryType.Service</code>.</p>"},{"location":"docs/cards/servicecard/#service-specification-and-cli","title":"Service Specification and CLI","text":"<p>One core area of focus for OpsML <code>v3</code> is tighter integration into the workflows developers use to build their applications. Often, developers use configuration files to manage dependencies and application settings/resources. To that end, opsml <code>v3</code> introduces a service specification that allows developers to define a service (API, MCP, Agent) through a YAML file. So instead of having to write code to create a service, you can define it in a YAML file and use the OpsML CLI to create, lock, update, and install the service and its associated cards/metadata.</p>"},{"location":"docs/cards/servicecard/#see-it-in-action","title":"See it in action","text":"<p>Create an <code>opsmlspec.yaml</code> file that defines your service and its cards. These could be cards that are produced from your training pipeline or cards that are already in the registry.</p> <pre><code>name: recommendation-api # (1)\nspace: data-science\ntype: Api\n\nservice:\n  version: 1.0.0\n  write_dir: opsml_service\n  cards:\n    - alias: prompt # (2)\n      space: data-science\n      name: recommendation-prompt\n      version: 1.*\n      type: prompt\n\n    - alias: recommender # (3)\n      space: data-science\n      name: recommender-model\n      version: 1.*\n      type: model\n\n    - alias: ranker # (4)\n      space: data-science\n      name: recommender-ranker\n      version: 1.*\n      type: model\n      drift:\n        active: true\n        deactivate_others: true\n        drift_type: \n          - custom\n          - psi\n</code></pre> <ol> <li>Our service is going to be a hybrid system that involves traditional machine learning models and an agentic piece that requires the use of a prompt.</li> <li>The prompt card that will be used by the agentic component of the service.</li> <li>The main recommender model that will provide recommendations based on user input.</li> <li>A ranking model that will be used to rank the recommendations provided by the recommender model. This model also has drift detection enabled to monitor for changes in data distribution over time.</li> </ol> <p>After you define your <code>ServiceCard</code> in the <code>opsmlspec.yaml</code>, you can run <code>opsml lock</code>, which will create an <code>opsml.lock</code> file that will contain the resolved versions of the cards in the service. You can then run <code>opsml install service</code> to install the service and its cards into your application.</p> Naming <p><code>opsmlspec.yaml</code> is just a standard convention for naming the spec file. You can name it whatever you want so long as its either a <code>yml</code> or <code>yaml</code> file and you provide the file path when running the CLI commands. See <code>opsml lock --help</code> for more details.</p>"},{"location":"docs/cards/servicecard/#full-specification","title":"Full Specification","text":"<p>Here is the full specification for the <code>opsmlspec.yaml</code> file:</p> Field Type Required Description <code>name</code> <code>string</code> Yes The name of the service. <code>space</code> or <code>team</code> <code>string</code> Yes The space or team this service belongs to. Use <code>space</code> for general use, <code>team</code> for team-based. <code>type</code> <code>Api</code> | <code>Mcp</code> | <code>Agent</code> Yes The type of service. Must be one of: <code>Api</code>, <code>Mcp</code>, or <code>Agent</code>. <code>metadata</code> object No Additional metadata about the service. See Metadata fields below. <code>service</code> object No Service configuration. See Service fields below. <code>deploy</code> list of objects No Deployment configurations. See Deployment fields below."},{"location":"docs/cards/servicecard/#metadata-fields","title":"Metadata fields","text":"Field Type Required Description <code>description</code> <code>string</code> Yes Description of the service. <code>language</code> <code>string</code> No Programming language used (e.g., <code>python</code>). <code>tags</code> list[string] No Tags for categorization/search."},{"location":"docs/cards/servicecard/#service-fields","title":"Service fields","text":"Field Type Required Description <code>version</code> <code>string</code> No Version of the service. <code>cards</code> list of objects No Cards included in the service. See Card fields. <code>write_dir</code> <code>string</code> No Directory to write service artifacts to. <code>mcp</code> object No MCP configuration (required if <code>type</code> is <code>Mcp</code> See MCP Config fields)."},{"location":"docs/cards/servicecard/#mcp-config-fields","title":"MCP Config fields","text":"Field Type Required Description <code>capabilities</code> list[string] Yes List of MCP capabilities. One or more of: <code>resources</code>, <code>tools</code>, <code>prompts</code>. <code>transport</code> string Yes Transport type. One of: <code>http</code>, <code>stdio</code>."},{"location":"docs/cards/servicecard/#card-fields","title":"Card fields","text":"Field Type Required Description <code>alias</code> <code>string</code> Yes Alias for referencing this card in the service. <code>space</code> <code>string</code> No Space for the card (defaults to service space if omitted). <code>name</code> <code>string</code> Yes Name of the card. <code>version</code> <code>string</code> No Version specifier (e.g., <code>1.*</code>). <code>type</code> <code>Model</code> | <code>Prompt</code> | <code>Service</code> | <code>Mcp</code> Yes Registry type of the card. <code>drift</code> object No Drift detection config (only for model cards). See below. <p>Drift fields (only for model and prompt cards):</p> Field Type Required Description <code>active</code> <code>bool</code> No Whether drift detection is active. <code>deactivate_others</code> <code>bool</code> No Deactivate previous drift config versions if true. <code>drift_type</code> list[string] No Types of drift detection (e.g., <code>psi</code>, <code>custom</code>)."},{"location":"docs/cards/servicecard/#deployment-fields","title":"Deployment fields","text":"Field Type Required Description <code>environment</code> <code>string</code> Yes Deployment environment (e.g., <code>development</code>, <code>production</code>). <code>provider</code> <code>string</code> No Cloud provider (e.g., <code>gcp</code>, <code>aws</code>). <code>location</code> list[string] No Deployment locations/regions. <code>endpoints</code> list[string] Yes List of endpoint URLs. <code>resources</code> object No Resource requirements. See Resources fields. <code>links</code> map[string,string] No Related links (e.g., logging, monitoring URLs)."},{"location":"docs/cards/servicecard/#resources-fields","title":"Resources fields","text":"Field Type Required Description <code>cpu</code> <code>integer</code> Yes Number of CPUs required. <code>memory</code> <code>string</code> Yes Amount of memory (e.g., <code>16Gi</code>). <code>storage</code> <code>string</code> Yes Storage required (e.g., <code>100Gi</code>). <code>gpu</code> object No GPU configuration. See below. <p>GPU fields:</p> Field Type Required Description <code>type</code> <code>string</code> Yes GPU type (e.g., <code>nvidia-tesla-t4</code>). <code>count</code> <code>integer</code> Yes Number of GPUs. <code>memory</code> <code>string</code> Yes GPU memory (e.g., <code>16Gi</code>). Yaml Spec <p>The following is the full specification in yaml Here is the full specification for the <code>opsmlspec.yaml</code> file:</p> <pre><code>name: my-service                # (string, required) Name of the service\nspace: my-space                # (string, required) Space or use 'team' for team-based\ntype: Api                      # (string, required) One of: Api, Mcp, Agent\n\nmetadata:                      # (object, optional)\ndescription: \"A sample service\"      # (string, required)\nlanguage: \"python\"                  # (string, optional)\ntags: [\"ml\", \"production\"]          # (list[string], optional)\n\nservice:                        # (object, optional)\nversion: \"1.0.0\"              # (string, optional)\nwrite_dir: \"opsml_service\"    # (string, optional)\ncards:                        # (list of cards, optional)\n    - alias: recommender\n    space: my-space\n    name: recommender-model\n    version: \"1.*\"\n    type: model\n    drift:                    # (object, optional, only for model cards)\n        active: true\n        deactivate_others: false\n        drift_type: [\"psi\", \"custom\"]\n    - alias: prompt\n    name: prompt-card\n    type: prompt\n\nmcp:                          # (object, optional, required if type is Mcp)\n    capabilities:               # (list of strings, required)\n      - resources               # One of: resources, tools, prompts\n      - tools\n    transport: http             # (string, required) One of: http, stdio)\n\ndeploy:                         # (list of objects, optional)\n- environment: production     # (string, required)\n    provider: aws               # (string, optional)\n    location: [us-east-1]       # (list[string], optional)\n    endpoints: [\"https://api.example.com\"]  # (list[string], required)\n    resources:                  # (object, optional)\n    cpu: 4                    # (integer, required)\n    memory: 16Gi              # (string, required)\n    storage: 100Gi            # (string, required)\n    gpu:                      # (object, optional)\n        type: nvidia-tesla-t4   # (string, required)\n        count: 2                # (integer, required)\n        memory: 16Gi            # (string, required)\n    links:                      # (map[string,string], optional)\n    logging: https://logs.example.com\n    monitoring: https://monitor.example.com\n</code></pre>"},{"location":"docs/cards/servicecard/#using-a-servicecard","title":"Using a ServiceCard","text":"<p>Once you have created a <code>ServiceCard</code>, you can use it in your application. To load a <code>ServiceCard</code> you can either load it directly from the registry or load if from a path where it was downloaded to.</p>"},{"location":"docs/cards/servicecard/#downloading-with-the-cli","title":"Downloading with the CLI","text":"<p>In most cases, when deploying your application, you'll want to leverage the Opsml CLI to download the service and its associated cards to a local path. This is a common pattern for containerized applications where you'll want to copy the service into the container image during the build process.</p> <p>Assuming you already have a service registered and an <code>opsml.lock</code> file created, you can use the following command to download the service and its cards:</p> <pre><code>opsml install service\n</code></pre> <p>This will download the service and its cards to a local directory (by default, <code>./opsml_service</code> unless otherwise specified in the <code>opsmlspec.yaml</code> file). You can then load the service in your application using the path to the downloaded service. While Opsml gives you the flexibility to load the service as you see fit, we recommend using <code>AppState</code> in applications to manage the lifecycle of the service (link).</p>"},{"location":"docs/cards/servicecard/#load-from-registry","title":"Load from Registry","text":"<p>You can load a <code>ServiceCard</code> from the registry using the <code>CardRegistry</code>:</p> <pre><code>from opsml import CardRegistry, RegistryType, ModelLoadKwargs, ServiceCard\n\nregistry = CardRegistry(RegistryType.Service)\n\nloaded_service: ServiceCard = registry.load_card(...) # (1)\nloaded_service.load() # (2)\n\n# loading cards that require addition kwargs\nloaded_service.load(load_kwargs = {\"model1\": ModelLoadKwargs(load_onnx=True)}) # (3)\n\n# accessing cards in the service\ncard1 = loaded_service[\"model1\"]  # (4)\n</code></pre> <ol> <li>Services are loaded just like any other card using a variety of arguments (space, name, version, uid, etc.)</li> <li>Load all card artifacts and interfaces</li> <li>Load cards with additional keyword arguments, such as loading a model in ONNX format</li> <li>Access individual cards in the service using their aliases</li> </ol>"},{"location":"docs/cards/servicecard/#load-from-path","title":"Load from Path","text":"<p>You can also load a <code>ServiceCard</code> from a path where it was downloaded to using <code>opsml install</code>. This is useful when you have downloaded the service using the Opsml CLI and want to use it in your application.</p> <pre><code>from opsml import ServiceCard, ModelLoadKwargs\n\nload_kwargs = {\n        \"model\": {\"load_kwargs\": ModelLoadKwargs(load_onnx=True)},\n    }\nloaded_service = ServiceCard.from_path(\"path/to/service\", load_kwargs=load_kwargs) # (1)\n</code></pre> <ol> <li>Load the <code>ServiceCard</code> from a specified path, optionally providing load arguments for specific cards. Unlike registry loading, load_from_path will load all cards and their interfaces and artifacts by default (e.g. models), so there is no need to call <code>load()</code> on the service after loading it from a path. </li> </ol>"},{"location":"docs/cards/servicecard/#custom-interfaces","title":"Custom Interfaces","text":"<p>In the case you are using a custom interface for any cards that are associated with a ServiceCard, you will need to provide the custom interface at load time.</p>"},{"location":"docs/cards/servicecard/#loading-from-registry","title":"Loading from Registry","text":"<pre><code>from opsml import CardRegistry, RegistryType, ModelLoadKwargs, ServiceCard\n\nregistry = CardRegistry(RegistryType.Service)\n\nloaded_service: ServiceCard = registry.load_card(\n        interface = {\"model1\": MyCustomInterface} # (1)\n        ) \nloaded_service.load() \n</code></pre> <ol> <li>Similar to loading other cards with a custom interface, you can provide the custom interface when loading the service from the registry. However, you will need to provide it as a dictionary mapping of alias to custom interface class.</li> </ol>"},{"location":"docs/cards/servicecard/#loading-from-path","title":"Loading from Path","text":"<pre><code>from opsml import ServiceCard, ModelLoadKwargs\n\nload_kwargs = {\n        \"model\": {\n            \"load_kwargs\": ModelLoadKwargs(load_onnx=True),\n            \"interface\": MyCustomInterface, # (1)\n        },\n    }\nloaded_service = ServiceCard.from_path(\"path/to/service\", load_kwargs)\n</code></pre> <ol> <li>When loading from a path, you can provide the custom interface directly in the <code>load_kwargs</code> for the specific card. This allows you to use your custom interface when loading the card from the service.</li> </ol> <p>For more information on how <code>ServiceCards</code> can be leveraged during application deployment, see the Deployment documentation.</p>"},{"location":"docs/cards/versioning/","title":"Versioning","text":"<p>All cards follow a semver version format (<code>major.minor.patch</code>). By default, a <code>minor</code> increment is used whenever a card is registered. If a version is provided, it overrides the default version type.</p> <p>For more information on the versioning scheme, please refer to the Semver documentation. In addition, opsml leverages the semver crate to ensure semver compliance.</p> <p>Card versions can also be assigned pre and build tags.</p> <ul> <li> <p>Pre tag for a release candidate -&gt; <code>major.minor.patch-rc.{#}</code> -&gt; <code>1.0.0-rc.1</code> -&gt; version_type: \"pre\"</p> </li> <li> <p>Build tag -&gt; <code>major.minor.patch+build.{#}</code> -&gt; <code>1.0.0+build.1</code> -&gt; version_type: \"build\"</p> </li> </ul> <p>Allowed types of versioning:</p> <ul> <li><code>major</code>: Major version increment</li> <li><code>minor</code>: Minor version increment (default)</li> <li><code>patch</code>: Patch version increment</li> <li><code>pre</code>: Pre-release version increment</li> <li><code>build</code>: Build version increment</li> <li><code>pre_build</code>: Pre-release and build version increment</li> </ul> <pre><code>from opsml import CardRegistry, VersionType\n\nregistry = CardRegistry(\"model\")\n\n# skipping logic\n\n# major\nregistry.register_card(card=card, version_type=VersionType.Major)\n# minor\nregistry.register_card(card=card, version_type=VersionType.Minor)\n# patch\nregistry.register_card(card=card, version_type=VersionType.Patch)\n# pre\nregistry.register_card(card=card, version_type=VersionType.Pre)\n# build\nregistry.register_card(card=card, version_type=VersionType.Build)\n# pre_build\nregistry.register_card(card=card, version_type=VersionType.PreBuild)\n</code></pre> Recommended Usage <p>The ability to provide a <code>version</code> is only an option to enable flexibility; it is not required. The recommended approach if you don't need release candidates or extra flexibility is to create a <code>Card</code> and specify the <code>version_type</code> when registering a card, which will allow <code>OpsML</code> to handle the versioning for you. </p>"},{"location":"docs/cards/versioning/#what-happens-when-i-register-a-card","title":"What happens when I register a card?","text":"<p>When you register a card, opsml will search for the most recent version of the card, and depending on the version types and any pre and/or build tags you provide, it will increment the version accordingly.</p> <pre><code>card = ModelCard(**kwargs, version=\"1.0.0\")\nregistry.register_card(card=card, version_type=VersionType.Pre, pre_tag=\"foo\")\n# 1.0.0-foo\n</code></pre> <p>In a normal workflow (like on model retraining), it's recommended to let opsml use it's defaults to increment the version.</p> <pre><code># model training\nregistry.register_card(card=card)\n# 1.0.0\n\n# model retraining\nregistry.register_card(card=card)\n# 1.1.0\n\n# model retraining\nregistry.register_card(card=card)\n# 1.2.0\n</code></pre>"},{"location":"docs/cards/experiment/experimentcard/","title":"Card","text":"<p><code>Experimentcards</code> are used to store metrics and artifacts related to <code>DataCards</code> and <code>ModelCards</code>. While a experimentcard can be used as a object itself, it's best to use it as a context manager.</p>"},{"location":"docs/cards/experiment/experimentcard/#creating-an-experiment","title":"Creating an Experiment","text":"<p>Experiments are unique context-managed executions that record all created cards and their associated metrics, params, and artifacts to a single card called a <code>Experimentcard</code>.</p> <p>If you're familiar with how other libraries do it, then nothing is really going to seem new. Refer to usage for more detailed information.</p>"},{"location":"docs/cards/experiment/experimentcard/#traditional-example","title":"Traditional Example","text":"<pre><code>from opsml import start_experiment, SklearnModel, ModelCard # (1)\nfrom opsml.helpers.data import create_fake_data\n\nwith start_experiment(space=\"opsml\", log_hardware=True) as exp: # (2)\n\n    X, y = create_fake_data(n_samples=1200)\n    reg = ensemble.RandomForestClassifier(n_estimators=5)\n    reg.fit(X.to_numpy(), y.to_numpy().ravel())\n\n    random_forest_classifier = SklearnModel(\n        model=reg,\n        sample_data=X_train,\n        task_type=TaskType.Classification,\n        preprocessor=StandardScaler(),\n    )\n\n    modelcard = ModelCard(\n            interface=random_forest_classifier,\n            tags=[\"foo:bar\", \"baz:qux\"],\n        )\n\n    exp.register_card(modelcard) # (3)\n    exp.log_metric(\"accuracy\", 0.95) # (4)\n    exp.log_parameter(\"epochs\", 10) # (5)\n</code></pre> <ol> <li>The recommended way to start an experiment is to use the <code>start_experiment</code> function. This will create a new experiment card and return it as a context manager which you can use to log metrics, parameters, artifacts and cards.</li> <li>The are a few arguments that can be passed to the <code>start_experiment</code> function (see definition). In this case we are only supplying the <code>space</code> argument and we are opting in to record hardware metrics.</li> <li>The <code>register_card</code> method is used to register a card to the experiment. This will automatically register the card in it's associated registry as well as associate it with the experiment card.</li> <li>The <code>log_metric</code> method is used to log a metric to the experiment card. This will automatically register the metric in it's associated registry as well as associate it with the experiment card. Metrics are logged in real-time.</li> <li>The <code>log_parameter</code> method is used to log a parameter to the experiment card. This will automatically register the parameter in it's associated registry as well as associate it with the experiment card. Parameters are logged in real-time.</li> </ol>"},{"location":"docs/cards/experiment/experimentcard/#genai-example","title":"GenAI Example","text":"<pre><code>from opsml import start_experiment, PromptCard, Prompt\n\nwith start_experiment(space=\"opsml\", log_hardware=True) as exp:\n\n    prompt = Prompt(\n        model=\"gpt-4o\",\n        message=\"what is 2 + 2?\",\n        provider=\"openai\",\n        system_instruction=\"You are a helpful assistant.\",\n    )\n\n    # ... your code here to test and validate the prompt\n    # exp.log_metric(...)\n    # exp.log_parameter(...)\n    # exp.log_artifact(...)\n\n    prompt_card = PromptCard(prompt)\n    exp.register_card(prompt_card)\n</code></pre> <p>You can now log into the opsml server and see your recent experiment and associated metadata</p>"},{"location":"docs/cards/experiment/experimentcard/#definitions","title":"Definitions","text":"start_experiment <pre><code>def start_experiment(\n    space: Optional[str] = None,\n    name: Optional[str] = None,\n    code_dir: Optional[Path] = None,\n    log_hardware: bool = False,\n    experiment_uid: Optional[str] = None,\n) -&gt; Experiment:\n    \"\"\"\n    Start an Experiment\n\n    Args:\n        space (str | None):\n            space to associate with `ExperimentCard`\n        name (str | None):\n            Name to associate with `ExperimentCard`\n        code_dir (Path | None):\n            Directory to log code from. If None, only the current python file will be logged.\n        log_hardware (bool):\n            Whether to log hardware information or not\n        experiment_uid (str | None):\n            Experiment UID. If provided, the experiment will be loaded from the server.\n\n    Returns:\n        Experiment\n    \"\"\"\n</code></pre> Experiment <pre><code>class Experiment:\n    \"\"\"Core class returned by the start_experiment function\"\"\"\n    def start_experiment(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        code_dir: Optional[Path] = None,\n        log_hardware: bool = False,\n        experiment_uid: Optional[str] = None,\n    ) -&gt; \"Experiment\":\n        \"\"\"\n        Start an Experiment\n\n        Args:\n            space (str | None):\n                space to associate with `ExperimentCard`\n            name (str | None):\n                Name to associate with `ExperimentCard`\n            code_dir (Path | None):\n                Directory to log code from\n            log_hardware (bool):\n                Whether to log hardware information or not\n            experiment_uid (str | None):\n                Experiment UID. If provided, the experiment will be loaded from the server.\n\n        Returns:\n            Experiment\n        \"\"\"\n\n    def __enter__(self) -&gt; \"Experiment\":\n        pass\n\n    def __exit__(self, exc_type, exc_value, traceback) -&gt; None:\n        pass\n\n    def log_metric(\n        self,\n        name: str,\n        value: float,\n        step: Optional[int] = None,\n        timestamp: Optional[int] = None,\n        created_at: Optional[datetime] = None,\n    ) -&gt; None:\n        \"\"\"\n        Log a metric\n\n        Args:\n            name (str):\n                Name of the metric\n            value (float):\n                Value of the metric\n            step (int | None):\n                Step of the metric\n            timestamp (int | None):\n                Timestamp of the metric\n            created_at (datetime | None):\n                Created at of the metric\n        \"\"\"\n\n    def log_metrics(self, metrics: list[Metric]) -&gt; None:\n        \"\"\"\n        Log multiple metrics\n\n        Args:\n            metrics (list[Metric]):\n                List of metrics to log\n        \"\"\"\n\n    def log_parameter(\n        self,\n        name: str,\n        value: Union[int, float, str],\n    ) -&gt; None:\n        \"\"\"\n        Log a parameter\n\n        Args:\n            name (str):\n                Name of the parameter\n            value (int | float | str):\n                Value of the parameter\n        \"\"\"\n\n    def log_parameters(self, parameters: list[Parameter]) -&gt; None:\n        \"\"\"\n        Log multiple parameters\n\n        Args:\n            parameters (list[Parameter]):\n                List of parameters to log\n        \"\"\"\n\n    def log_artifact(\n        self,\n        path: Path,\n    ) -&gt; None:\n        \"\"\"\n        Log an artifact\n\n        Args:\n            path (Path):\n                Path to the artifact file. Path must be a file.\n                If logging multiple artifacts, use `log_artifacts` instead.\n        \"\"\"\n\n    def log_artifacts(\n        self,\n        paths: Path,\n    ) -&gt; None:\n        \"\"\"\n        Log multiple artifacts\n\n        Args:\n            paths (Path):\n                Paths to a directory containing artifacts.\n                All files in the directory will be logged.\n        \"\"\"\n\n    @property\n    def card(self) -&gt; \"ExperimentCard\":\n        \"\"\"\n        ExperimentCard associated with the Experiment\n        \"\"\"\n\n    def register_card(\n        self,\n        card: Union[DataCard, ModelCard, PromptCard],\n        version_type: VersionType = VersionType.Minor,\n        pre_tag: Optional[str] = None,\n        build_tag: Optional[str] = None,\n        save_kwargs: Optional[ModelSaveKwargs | DataSaveKwargs] = None,\n    ) -&gt; None:\n        \"\"\"Register a Card as part of an experiment\n\n        Args:\n            card (DataCard | ModelCard):\n                Card to register. Can be a DataCard or a ModelCard\n            version_type (VersionType):\n                How to increment the version SemVer. Default is VersionType.Minor.\n            pre_tag (str):\n                Optional pre tag to associate with the version.\n            build_tag (str):\n                Optional build_tag to associate with the version.\n            save_kwargs (SaveKwargs):\n                Optional SaveKwargs to pass to the Card interface (If using DataCards\n                and ModelCards).\n\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/experiment/experimentcard/#accessing-the-experimentcard","title":"Accessing the ExperimentCard","text":"<p>You can access the experiment card and it's associated metrics, parameters and artifacts by loading the card from the registry</p> <pre><code>from opsml import CardRegistry, RegistryType, get_experiment_metrics, get_experiment_parameters\n\nregistry = CardRegistry(RegistryType.Experiment)\n\ncard = registry.load_card(uid=\"{{experiment uid}}\")\n\n# you can now access the card and it's associated metadata\ncard.list_artifacts()\ncard.download_artifacts()\ncard.get_metrics()\ncard.get_parameters()\n\n\n# if you want to access the metrics and parameters directly, you can use the following functions\nmetrics = get_experiment_metrics(card.uid)\nparameters = get_experiment_parameters(card.uid)\n</code></pre> ExperimentCard <pre><code>class ExperimentCard:\n    def __init__(\n        self,\n        space: Optional[str] = None,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        uid: Optional[str] = None,\n        tags: List[str] = [],\n    ) -&gt; None:\n        \"\"\"Instantiates a ExperimentCard.\n\n        Cards are stored in the ExperimentCard Registry and follow the naming convention of:\n        {registry}/{space}/{name}/v{version}\n\n        Args:\n            space (str | None):\n                space to associate with `ExperimentCard`\n            name (str | None):\n                Name to associate with `ExperimentCard`\n            version (str | None):\n                Current version (assigned if card has been registered). Follows\n                semantic versioning.\n            uid (str | None):\n                Unique id (assigned if card has been registered)\n            tags (List[str]):\n                Tags to associate with `ExperimentCard`. Can be a dictionary of strings or\n                a `Tags` object.\n\n        Example:\n        ```python\n        from opsml import start_experiment\n\n        # start an experiment\n        with start_experiment(space=\"test\", log_hardware=True) as exp:\n            exp.log_metric(\"accuracy\", 0.95)\n            exp.log_parameter(\"epochs\", 10)\n        ```\n        \"\"\"\n\n    def get_metrics(\n        names: Optional[list[str]] = None,\n    ) -&gt; Metrics:\n        \"\"\"\n        Get metrics of an experiment\n\n        Args:\n            names (list[str] | None):\n                Names of the metrics to get. If None, all metrics will be returned.\n\n        Returns:\n            Metrics\n        \"\"\"\n\n    def get_parameters(\n        names: Optional[list[str]] = None,\n    ) -&gt; Parameters:\n        \"\"\"\n        Get parameters of an experiment\n\n        Args:\n            names (list[str] | None):\n                Names of the parameters to get. If None, all parameters will be returned.\n\n        Returns:\n            Parameters\n        \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Returns the name of the `ModelCard`\"\"\"\n\n    @name.setter\n    def name(self, name: str) -&gt; None:\n        \"\"\"Set the name of the `ModelCard`\n\n        Args:\n            name (str):\n                The name of the `ModelCard`\n        \"\"\"\n\n    @property\n    def space(self) -&gt; str:\n        \"\"\"Returns the space of the `experimentcard`\"\"\"\n\n    @space.setter\n    def space(self, space: str) -&gt; None:\n        \"\"\"Set the space of the `experimentcard`\n\n        Args:\n            space (str):\n                The space of the `experimentcard`\n        \"\"\"\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Returns the version of the `experimentcard`\"\"\"\n\n    @version.setter\n    def version(self, version: str) -&gt; None:\n        \"\"\"Set the version of the `experimentcard`\n\n        Args:\n            version (str):\n                The version of the `experimentcard`\n        \"\"\"\n\n    @property\n    def uid(self) -&gt; str:\n        \"\"\"Returns the uid of the `experimentcard`\"\"\"\n\n    @property\n    def uids(self) -&gt; UidMetadata:\n        \"\"\"Returns the uids of the `experimentcard`\"\"\"\n\n    @property\n    def tags(self) -&gt; List[str]:\n        \"\"\"Returns the tags of the `ExperimentCard`\"\"\"\n\n    @property\n    def artifacts(self) -&gt; List[str]:\n        \"\"\"Returns the artifact names\"\"\"\n\n    @property\n    def compute_environment(self) -&gt; ComputeEnvironment:\n        \"\"\"Returns the compute env\"\"\"\n\n    @property\n    def registry_type(self) -&gt; RegistryType:\n        \"\"\"Returns the card type of the `experimentcard`\"\"\"\n\n    @property\n    def app_env(self) -&gt; str:\n        \"\"\"Returns the app env\"\"\"\n\n    @property\n    def created_at(self) -&gt; datetime:\n        \"\"\"Returns the created at timestamp\"\"\"\n\n    def add_child_experiment(self, uid: str) -&gt; None:\n        \"\"\"Add a child experiment to the experiment card\n\n        Args:\n            uid (str):\n                The experiment card uid to add\n        \"\"\"\n\n    def list_artifacts(self, path: Optional[Path]) -&gt; List[str]:\n        \"\"\"List the artifacts associated with the experiment card\n\n        Args:\n            path (Path):\n                Specific path you wish to list artifacts from. If not provided,\n                all artifacts will be listed.\n\n                Example:\n                    You logged artifacts with the following paths:\n                    - \"data/processed/my_data.csv\"\n                    - \"model/my_model.pkl\"\n\n                    If you wanted to list all artifacts in the \"data\" directory,\n                    you would pass Path(\"data\") as the path.\n        \"\"\"\n\n    def download_artifacts(\n        self,\n        path: Optional[Path] = None,\n        lpath: Optional[Path] = None,\n    ) -&gt; None:\n        \"\"\"Download artifacts associated with the ExperimentCard\n\n        Args:\n            path (Path | None):\n                Specific path you wish to download artifacts from. If not provided,\n                all artifacts will be downloaded.\n\n            lpath (Path | None):\n                Local path to save the artifacts. If not provided, the artifacts will be saved\n                to a directory called \"artifacts\"\n        \"\"\"\n\n    @staticmethod\n    def model_validate_json(json_string: str) -&gt; \"ExperimentCard\":\n        \"\"\"Load card from json string\n\n        Args:\n            json_string (str):\n                The json string to validate\n        \"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the `ExperimentCard`.\n\n        Returns:\n            String representation of the ModelCard.\n        \"\"\"\n</code></pre>"},{"location":"docs/cards/experiment/usage/","title":"Experiment Usage","text":"<p>For simplicity, the Opsml <code>ExperimentCard</code> and associated experiment functionality are designed to provide some parity with existing frameworks. This means that if you're familiar with how experiments are defined and used in other systems, you should find the Opsml approach to be quite similar.</p> <p>Note - While OpsML is not designed to be an experiment tracking system like other model registry frameworks, its primary focus is managing the artifact lifecycle, which is critical for enterprise applications. However, since experiments are part of the artifact lifecycle and are artifacts themselves, OpsML includes experiment tracking capabilities. As experiment tracking tools vary widely, we are continually updating OpsML to improve parity. If you have specific needs, feel free to raise an issue or submit a pull request.</p>"},{"location":"docs/cards/experiment/usage/#start-an-experiment","title":"Start an Experiment","text":"<p>To start an experiment with OpsML, you'll use the <code>start_experiment</code> context manager. Here's a basic example:</p> <pre><code>from opsml import start_experiment\n\nwith start_experiment(\"opsml\") as exp:\n    # Define your experiment parameters and logic here\n    pass\n</code></pre>"},{"location":"docs/cards/experiment/usage/#arguments","title":"Arguments","text":"<p>An <code>ExperimentCard</code> is created and versioned for every experiment run. You will often find that it's easiest to just provide the space to record to and let OpsML assign a random name to the experiment. But in cases where you want to provide a space and name, you can do so by specifying both arguments. In this case, any time the same space and names are re-used, a new version will be created. Note - this is important for comparison purposes as experiments with the same space and name can be compared across versions.</p> Argument Type Default Description <code>space</code> <code>str | None</code> <code>None</code> Space to associate with the <code>ExperimentCard</code>. <code>name</code> <code>str | None</code> <code>None</code> Name to associate with the <code>ExperimentCard</code>. Defaults to random name <code>code_dir</code> <code>Path | None</code> <code>None</code> Directory to log code from. <code>log_hardware</code> <code>bool</code> <code>False</code> Whether to log hardware information or not. <code>experiment_uid</code> <code>str | None</code> <code>None</code> Experiment UID. If provided, the experiment will be loaded from the server."},{"location":"docs/cards/experiment/usage/#parameters-metrics-figures-oh-my","title":"Parameters &amp; metrics &amp; figures, oh my!","text":"<p>Every experiment can log parameters, metrics, artifacts and figures. This is done using the <code>log_param</code>, <code>log_metric</code>, <code>log_figure</code> and <code>log_artifact</code> methods of the <code>Experiment</code> class.</p> <ul> <li>Parameters are inputs to your experiment that you want to track. This could include things like learning rate, batch size, or any other hyperparameters.</li> <li>Metrics are outputs from your experiment that you want to track. This could include things like accuracy, loss, or any other performance measure.</li> <li>Figures are visualizations that you want to track. This could include things like confusion matrices, ROC curves, or any other plots that help you understand your experiment.</li> </ul> <pre><code>from opsml import start_experiment\n\nwith start_experiment(\"opsml\") as exp:\n    exp.log_param(\"learning_rate\", 0.001)\n    exp.log_metric(\"accuracy\", 0.95)\n    exp.log_figure(\"confusion_matrix.png\", confusion_matrix)\n    exp.log_artifact(\"my_local_artifact.txt\")\n</code></pre>"},{"location":"docs/cards/experiment/usage/#artifacts","title":"Artifacts","text":"<p>You can log artifacts from your local filesystem via the <code>log_artifact</code> or <code>log_artifacts</code> methods. Note - artifacts must already be saved to disk before they can be logged. More information can be found here</p> <ul> <li>log_artifact: Intended for uploading a single artifact to the opsml server</li> <li>log_artifacts: Intended for uploading multiple artifacts to the opsml server. Must be a local directory</li> </ul>"},{"location":"docs/cards/experiment/usage/#parameters","title":"Parameters","text":"<p>You can log parameters from your experiment via the <code>log_parameter</code> or <code>log_parameters</code> methods. Note - parameters must be simple data types (e.g. int, float, str) before they can be logged. More information can be found here</p> <ul> <li>log_parameter: Intended for uploading a single parameter to the opsml server. Must be an integer, float or string.</li> <li>log_parameters: Intended for uploading multiple parameters to the opsml server. Can either be a list of <code>Parameter</code> objects or a dictionary of parameter names to values.</li> </ul>"},{"location":"docs/cards/experiment/usage/#metrics","title":"Metrics","text":"<p>You can log metrics from your experiment via the <code>log_metric</code> or <code>log_metrics</code> methods. Note - metrics are expected to be floats. More information can be found here</p> <ul> <li>log_metric: Intended for uploading a single metric to the opsml server. Must be an integer, float or string.</li> <li>log_metrics: Intended for uploading a list of <code>Metric</code> to the opsml server.</li> </ul>"},{"location":"docs/cards/experiment/usage/#figures","title":"Figures","text":"<p>Opsml also allows you to associate figures to a given experiment through either the <code>log_figure_from_path</code> or <code>log_figure</code> methods. Note - To use <code>log_figure_from_path</code>, the figure must be saved to disk first. <code>log_figure</code> expects the figure object to be a <code>matplotlib.figure.Figure</code>. More information can be found here</p> <ul> <li>log_figure_from_path: Intended for uploading a figure from a file path to the opsml server.</li> <li>log_figure: Intended for uploading a figure object to the opsml server.</li> </ul>"},{"location":"docs/cli/overview/","title":"Command Line Interface for Opsml","text":"<p><code>OpsML</code> comes pre-installed with a command line interface (CLI) that allows users to interact (list, download) with their cards an services</p>"},{"location":"docs/cli/overview/#available-commands","title":"Available Commands","text":""},{"location":"docs/cli/overview/#command-list","title":"Command: <code>list</code>","text":""},{"location":"docs/cli/overview/#description","title":"Description","text":"<p>The <code>list</code> command is used to retrieve a list of cards from a specified registry. Users can filter the results using various arguments such as space, name, version, and more. The command supports multiple subcommands for different registry types.</p>"},{"location":"docs/cli/overview/#usage","title":"Usage","text":"<pre><code>opsml list &lt;registry&gt; [options]\nopsml list model --space space --name name\n</code></pre>"},{"location":"docs/cli/overview/#subcommands","title":"Subcommands","text":"<ul> <li>model: List cards from the Model registry.</li> <li>service: List cards from the Service registry.</li> <li>data: List cards from the Data registry.</li> <li>experiment: List cards from the Experiment registry.</li> <li>audit: List cards from the Audit registry.</li> <li>prompt: List cards from the Prompt registry.</li> </ul>"},{"location":"docs/cli/overview/#arguments-for-subcommands","title":"Arguments for Subcommands","text":"<p>Each subcommand accepts the same set of arguments to filter the results:</p> <ul> <li>space (Optional): The name of the space to filter cards by.</li> <li>name (Optional): The name of the card to filter by.</li> <li>version (Optional): The version of the card to filter by.</li> <li>uid (Optional): The unique identifier of the card to filter by.</li> <li>limit (Optional): The maximum number of cards to return.</li> <li>tags (Optional): A comma-separated list of tags to filter cards by.</li> <li>max_date (Optional): The maximum date to filter cards by.</li> <li>sort_by_timestamp (Optional, default: true): Whether to sort the results by timestamp.</li> </ul>"},{"location":"docs/cli/overview/#command-get","title":"Command: <code>get</code>","text":""},{"location":"docs/cli/overview/#description_1","title":"Description","text":"<p>The get command is used to download card artifacts from a specified registry. Users can specify the card's space, name, version, and other details to retrieve the desired artifacts. The command supports subcommands for different registry types. Currently only supports model and service subcommands.</p>"},{"location":"docs/cli/overview/#usage_1","title":"Usage","text":"<pre><code>opsml get &lt;registry&gt; [options]\n</code></pre>"},{"location":"docs/cli/overview/#subcommands_1","title":"Subcommands","text":"<ul> <li>model: Download artifacts from the Model registry.</li> <li>service: Download artifacts from the Service registry.</li> </ul>"},{"location":"docs/cli/overview/#arguments-for-subcommands_1","title":"Arguments for Subcommands","text":"<p>Each subcommand accepts the following arguments to specify the card to download:</p> <ul> <li>space (Optional): The name of the space where the card is located.</li> <li>name (Optional): The name of the card to download.</li> <li>version (Optional): The version of the card to download.</li> <li>uid (Optional): The unique identifier of the card to download.</li> <li>write-dir (Optional, default: artifacts): The directory where the downloaded artifacts will be saved.</li> </ul>"},{"location":"docs/cli/overview/#examples","title":"Examples","text":""},{"location":"docs/cli/overview/#download-a-model-card","title":"Download a Model Card","text":"<pre><code>opsml get model --space 'my_space' --name 'my_model' --version '1.0.0'\n</code></pre> <pre><code>opsml get service --space 'my_space' --name 'my_service'\n</code></pre>"},{"location":"docs/cli/overview/#command-lock","title":"Command: <code>lock</code>","text":""},{"location":"docs/cli/overview/#description_2","title":"Description","text":"<p>The <code>lock</code> command is used to create an <code>opsml.lock</code> file based on the service configuration specified within the pyproject.toml file. This lock file captures the state of the service and its associated cards, ensuring reproducibility and consistency.</p> <p>For more information on <code>opsml</code> tool configurations, please refer to the tool documentation.</p>"},{"location":"docs/cli/overview/#usage_2","title":"Usage","text":"<pre><code>opsml lock\n</code></pre>"},{"location":"docs/cli/overview/#command-install","title":"Command: <code>install</code>","text":""},{"location":"docs/cli/overview/#description_3","title":"Description","text":"<p>The <code>install</code> command is used to install or download an OpsML service from an <code>opsml.lock</code> file. This command will download all artifacts specified in the lock file.</p>"},{"location":"docs/cli/overview/#usage_3","title":"Usage","text":"<pre><code>opsml install\n</code></pre>"},{"location":"docs/deployment/overview/","title":"Overview","text":""},{"location":"docs/deployment/overview/#creationconsumption","title":"Creation/Consumption","text":"<p>As stated before, the core goal of <code>OpsML</code> is to provide quality control to AI artifact management. Artifact management encompasses both the creation of artifacts, such as through model training, data generation, and experimentation, and their consumption, such as through APIs. With this in mind, <code>OpsML</code> provides a variety of helpers that enable you to use your model(s)/service(s) in any API framework.</p> <p>OpsML is intentionally designed not to focus on building 'auto-APIs,' as experience has shown that most API logic is more complex than simply serving a single model. APIs often involve multiple models and additional business logic that must be considered. To address this, we have prioritized developing standardized patterns and tools that seamlessly integrate OpsML into any framework.</p>"},{"location":"docs/deployment/overview/#best-practices","title":"Best Practices","text":"<p>There are a variety of ways to load a model/build an api. In the case of building containers, our recommendation is to download your model/service during the container build process and then load it on application startup. It is also possible to call <code>registry.load_card()</code> during application startup; however, this requires a network call to the opsml server, so we tend to recommend the former approach to limit network calls.</p>"},{"location":"docs/deployment/overview/#building-the-api","title":"Building the API","text":"<p>Before loading an model into an api, we first need a model. The following code will create 2 models and bundle them into a <code>ServiceCard</code>. You can find the full code in the examples directory; however, we will reproduce it here for your convenience.</p>"},{"location":"docs/deployment/overview/#training-the-models-and-creating-the-servicecard","title":"Training the models and creating the ServiceCard","text":"<p>The following will:   - Train two models (lightgbm and random forest)   - Convert them to onnx when registering the cards   - Bundle the models into a ServiceCard</p> <pre><code>from opsml.helpers.data import create_fake_data\nfrom opsml.experiment import start_experiment, Experiment\nfrom opsml import SklearnModel, TaskType, ModelCard, ServiceCard, Card\nfrom opsml.model import ModelSaveKwargs\nfrom lightgbm import LGBMClassifier\nfrom sklearn import ensemble  # type: ignore\nimport pandas as pd\n\n\ndef create_random_forest_classifier(\n    exp: Experiment,\n    X: pd.DataFrame,\n    y: pd.DataFrame,\n) -&gt; ModelCard:\n    # Create and train model\n    classifier = ensemble.RandomForestClassifier(n_estimators=5)\n    classifier.fit(X.to_numpy(), y.to_numpy().ravel())\n\n    model_interface = SklearnModel(\n        model=classifier,\n        sample_data=X[0:10],\n        task_type=TaskType.Classification,\n    )\n\n    model_interface.create_drift_profile(alias=\"drift\", data=X) # (1)\n\n    modelcard = ModelCard(\n        interface=model_interface,\n        space=\"opsml\",\n        name=\"rf_model\",\n    )\n\n    # register model\n    exp.register_card(\n        card=modelcard,\n        save_kwargs=ModelSaveKwargs(save_onnx=True),\n    )\n\n    return modelcard\n\n\ndef create_lgb_classifier(\n    exp: Experiment,\n    X: pd.DataFrame,\n    y: pd.DataFrame,\n) -&gt; ModelCard:\n    # Create and train model\n    classifier = LGBMClassifier(n_estimators=5)\n    classifier.fit(X.to_numpy(), y.to_numpy().ravel())\n\n    model_interface = SklearnModel(\n        model=classifier,\n        sample_data=X[0:10],\n        task_type=TaskType.Classification,\n    )\n\n    model_interface.create_drift_profile(alias=\"drift\", data=X)\n    modelcard = ModelCard(\n        interface=model_interface,\n        space=\"opsml\",\n        name=\"lgb_model\",\n    )\n\n    # register model\n    exp.register_card(\n        modelcard,\n        save_kwargs=ModelSaveKwargs( # (2)\n            save_onnx=True,\n            onnx={\n                \"target_opset\": {\"ai.onnx.ml\": 3, \"\": 9},\n                \"options\": {\n                    \"zipmap\": False,\n                },\n            },\n        ),\n    )\n\n    return modelcard\n\n\nwith start_experiment(space=\"opsml\") as exp:\n    # create data\n    X, y = create_fake_data(n_samples=1200)\n\n    rf_model = create_random_forest_classifier(exp, X, y)\n    lgb_model = create_lgb_classifier(exp, X, y)\n\n    service_card = ServiceCard( # (3)\n        space=\"opsml\",\n        name=\"classification_service\",\n        cards=[\n            Card(alias=\"rf\", card=rf_model),\n            Card(alias=\"lgb\", card=lgb_model),\n        ],\n    )\n    exp.register_card(service_card)\n</code></pre> <ol> <li>A drift profile can be created even without the Scouter server</li> <li>Adding lightgbm-specific args for onnx conversion</li> <li>Bundle both ModelCards into a ServiceCard</li> </ol>"},{"location":"docs/deployment/overview/#downloading-the-service","title":"Downloading the service","text":"<p>Once the service is registered, you can download it using the following command:</p> <pre><code>opsml get service --space opsml --name \"classification_service\" --write-dir \"service_artifacts\"\n</code></pre> <p>This will download all artifacts related to the service into the specified directory.</p>"},{"location":"docs/deployment/overview/#building-the-api_1","title":"Building the api","text":"<p>The following code builds a simple FastAPI app that exposes the service and both models. We also show how you can use the <code>AppState</code> interface to manage the opsml service lifecycle. More information on this is below.</p> <pre><code>from contextlib import asynccontextmanager\nfrom pathlib import Path\nfrom fastapi import FastAPI, Request\nfrom opsml.logging import RustyLogger, LogLevel, LoggingConfig\nfrom opsml.app import AppState, ReloadConfig\nimport uuid\nfrom pydantic import BaseModel, Field\n\nfrom opsml.card import ModelCard\nfrom opsml.model import ModelLoadKwargs\nimport numpy as np\nfrom numpy.typing import NDArray\n\nlogger = RustyLogger.get_logger(\n    LoggingConfig(log_level=LogLevel.Debug),\n)\n\n\n# 8 features\nclass PredictRequest(BaseModel):\n    feature_1: float\n    feature_2: float\n    feature_3: float\n    feature_4: float\n    feature_5: float\n    feature_6: float\n    feature_7: float\n    feature_8: float\n    feature_9: float\n    feature_10: float\n\n    def to_f32_array(self) -&gt; NDArray[np.float32]:\n        \"\"\"Converts the features to a numpy array of float32 with shape (1,10)\"\"\"\n        return np.array(\n            [\n                self.feature_1,\n                self.feature_2,\n                self.feature_3,\n                self.feature_4,\n                self.feature_5,\n                self.feature_6,\n                self.feature_7,\n                self.feature_8,\n                self.feature_9,\n                self.feature_10,\n            ],\n            dtype=np.float32,\n        ).reshape(1, -1)\n\n\nclass ModelResponse(BaseModel):\n    rf_class: int = Field(..., description=\"Predicted class from Random Forest model\")\n    lg_class: int = Field(..., description=\"Predicted class from LightGBM model\")\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    logger.info(\"Starting up FastAPI app\")\n\n    app_state = AppState.from_path( # (1)\n        path=Path(\"app/service_artifacts\"),\n        load_kwargs={\n            \"rf\": {\"load_kwargs\": ModelLoadKwargs(load_onnx=True)},\n            \"lgb\": {\"load_kwargs\": ModelLoadKwargs(load_onnx=True)},\n        },\n        reload_config=ReloadConfig(cron=\"0 0 0 * * *\"), # (2)\n    )\n    app_state.start_reloader()\n    app.state.app_state = app_state\n\n    yield\n\n    logger.info(\"Shutting down FastAPI app\")\n    app.state.app_state.shutdown()\n    app.state.app_state = None\n\n\napp = FastAPI(lifespan=lifespan)\n\n\n@app.post(\"/predict\", response_model=ModelResponse)\nasync def predict(request: Request, payload: PredictRequest) -&gt; ModelResponse:\n    # Grab the reformulated prompt and response prompt from the app state\n    rf_model: ModelCard = request.app.state.app_state.service[\"rf\"] # (3)\n    lgb_model: ModelCard = request.app.state.app_state.service[\"lgb\"]\n    data = payload.to_f32_array()\n\n    rf_prediction = rf_model.onnx_session.run({\"X\": data}, None)\n    lg_prediction = lgb_model.onnx_session.run({\"X\": data}, None)\n\n    rf_class = rf_prediction[0][0]\n    lg_class = lg_prediction[0][0]\n\n    return ModelResponse(rf_class=rf_class, lg_class=lg_class)\n</code></pre> <ol> <li>Opsml exposes an <code>AppState</code> interface that allows you to load an entire service from a path in a single call</li> <li>The <code>AppState</code> interface also provides a way to manage the lifecycle of the service, including reloading and shutdown</li> <li>You can access a model by its alias using the <code>AppState</code> <code>service</code> property</li> </ol>"},{"location":"docs/deployment/overview/#appstate","title":"AppState","text":"<p>AppState (short for Application State) is the core interface for managing the opsml state within an application. It's built to be able to load a <code>ServiceCard</code> for model access and <code>ScouterQueue</code>s for real-time monitoring. It also provides the ability to configure a reload task that will reload the entire AppState whenever a new version of the Service is detected on the server.</p>"},{"location":"docs/deployment/overview/#basic-structure","title":"Basic Structure","text":"<pre><code>from opsml.app import AppState, ReloadConfig\nfrom opsml.scouter import HTTPConfig\n\napp_state = AppState.from_path(\n    path=Path(\"app/service_artifacts\"),\n    transport_config=HTTPConfig(),\n    reload_config=ReloadConfig(cron=\"0 0 0 * * *\"),\n)\n</code></pre>"},{"location":"docs/deployment/overview/#arguments-table","title":"Arguments table","text":"Argument Type (Required) Description path <code>Pathlib.Path</code> (yes) The file path to the service artifacts directory. transport_config <code>HTTPConfig</code> (no) Configuration for transporting <code>ScouterQueue</code> events. reload_config <code>ReloadConfig</code> (no) Configuration for the reload behavior of the AppState. load_kwargs <code>dict</code> (no) Dictionary of keyword arguments to pass to when loading - docs."},{"location":"docs/deployment/overview/#dynamic-reloading","title":"Dynamic Reloading","text":"<p>The <code>AppState</code> interface enables dynamic reloading of services, addressing the common challenge of decoupled API deployment and training processes. This decoupling often results in APIs running outdated service or model versions. Traditionally, updating to the latest version would require either rebuilding the container or scheduling a cron job within the API to fetch the updated model. With <code>AppState</code>, you can configure a reload mechanism that continuously polls for service updates based on a specified cron schedule. When updates are detected, the <code>AppState</code> automatically reloads the <code>ServiceCard</code> and, if present, the <code>ScouterQueue</code>. More information can be found here.</p>"},{"location":"docs/deployment/overview/#usage","title":"Usage","text":"<p>As you've noticed, when creating a <code>ServiceCard</code>, all cards are required to have an alias. This alias allows you to conveniently access the card within the AppState.</p> <pre><code>app_state.service[\"rf\"] # access the rf alias\n</code></pre> <p>In addition, you can also access the drift profile associated with a given model. For more information on the <code>ScouterQueue</code>, please refer to the Scouter documentation.</p> <pre><code>app_state.queue[\"rf_psi\"].insert(...)\n</code></pre>"},{"location":"docs/engineering/how-it-works/","title":"How OpsML Works","text":"<p>The following sections describe specific components of OpsML and how they work.</p>"},{"location":"docs/engineering/how-it-works/#ds-interfaces","title":"DS Interfaces","text":"<p><code>OpsML</code> provides a few public interfaces for DSs to use while abstracting and hiding the underlying implementation details. These interfaces are the <code>ArtifactCard</code> (<code>DataCard</code>, <code>ModelCard</code>, <code>experimentcard</code>, etc.) and the <code>CardRegistry</code>. Every <code>ArtifactCard</code> type is associated with a <code>CardRegistry</code> type. Upon instantiation, a DS provides a type to the <code>CardRegistry</code> in order to load the unique registry. Under the hood, each registry inherits from either a <code>Client</code> registry or a <code>Server</code> registry, which is dependent upon the local <code>OpsML</code> environment variables. If the <code>OPSML_TRACKING_URI</code> is set with an http or https uri corresponding to an <code>OpsML</code> server, then the registry will be a <code>Client</code> registry. If the <code>OPSML_TRACKING_URI</code> is set with a SQL connection string, then the registry will be a <code>Server</code> registry. The settings singleton is used to determine which parent registry to instantiate.</p>"},{"location":"docs/engineering/how-it-works/#card-registration","title":"Card Registration","text":"<p>Each card follows the following flow when being registered. Implementation details for each card type may be different, but the general flow is the same.</p> <p></p> <p>Steps upon registration (register_card):</p> <ul> <li> <p>Validate Card: </p> <ul> <li>Each card is validated for (1) the card type matches the registry type and (2) the card has not been registered before</li> </ul> </li> <li> <p>Set Version: </p> <ul> <li>Card registry is queried for the latest <code>Semver</code> for the given model name. A new version is then created based on latest version and version increment type.</li> </ul> </li> <li> <p>Create UID: </p> <ul> <li>A unique ID is created and applied to the card</li> </ul> </li> <li> <p>Set Storage: </p> <ul> <li>A unique storage path is created and the storage client is updated</li> </ul> </li> <li> <p>Create Registry Record: </p> <ul> <li>Save Card Artifacts:</li> <li>Each <code>ArtifactCard</code> has a set of artifacts that are saved to storage. These artifacts are saved to storage and the storage paths are updated in the card and metadata</li> <li>Create Registry Record:</li> <li>A registry record is generated from card metadata and committed to the registry</li> </ul> </li> </ul>"},{"location":"docs/engineering/ownership/","title":"Ownership","text":"<p>In many organizations there is often a separation of concerns between data science and engineering when it comes to data science tooling and infrastructure. Thus, with something like <code>OpsML</code> it's appropriate to think \"who owns what?\" or \"where does data science and engineering fit into the lifecycle, use, and management of a system like this?\". The goal of <code>OpsML</code> is to provide an interface into infrastructure that data scientists use and engineering owns/controls. The diagram below is one example of this separation of concerns.</p>"},{"location":"docs/engineering/ownership/#architecture-of-opsml-proxy-setup","title":"Architecture of Opsml Proxy Setup","text":""},{"location":"docs/engineering/ownership/#general-setup","title":"General Setup","text":"<p>Note - This is an example setup to give an overview of the separation between data science and engineering</p> <p><code>OpsML</code> is packaged and deployed as a proxy system where a server is set up and exposed via a callable api that data scientists set as an environment variable (OPSML_TRACKING_URI). When data scientists use <code>OpsML</code> they will interact with the server through a client API that is automatically configured when <code>OpsML</code> is loaded in python.</p>"},{"location":"docs/engineering/ownership/#parts-owned-by-engineering","title":"Parts Owned by Engineering","text":"<ul> <li><code>OpsML</code> server that is packaged into a docker container and deployed through K8s</li> <li>Storage system (local or cloud) that will be used to store <code>ArtifactCard</code> artifacts (models, data, figures, etc.) </li> <li>Database that will be used to store <code>ArtifactCard</code> metadata. This will typically be a mysql or postgresql database</li> <li>K8s and compute infrastructure for hosting applications</li> <li>CI/CD build process</li> </ul>"},{"location":"docs/engineering/ownership/#other-considerations","title":"Other Considerations","text":"<ul> <li>In this scenario it is expected that the infrastructure hosting the <code>OpsML</code> server is also responsible for authentication and security. As an example, the host system may be placed on an internal network that is only accessible via authentication through a VPN. <code>OpsML</code> was built to be an ML tooling interface, not a security system. Thus, security should be configured on the host system.</li> <li>Credentialing for external systems (storage, databases, etc.) should also be configured and embedded in the environment that hosts the <code>OpsML</code> server. This enables engineering to limit and control the credentials needed for <code>OpsML</code>. It also eliminates the need for data scientists to have to specify credentials when working with <code>OpsML</code> (apart for security authentication). Note - <code>OpsML</code> does support basic auth (single username and password) and we may expand this a on optional full authentication system in the future if there is a need.</li> </ul>"},{"location":"docs/engineering/ownership/#scenario-1-ds-workflows","title":"Scenario 1: DS Workflows","text":"<p>This scenario covers the typical data science workflow and tasks that include exploratory analysis, model training and model evaluation. As part of this workflow, a data scientist will produce various <code>ArtifactCards</code> and store their attributes/metadata through client/server communication.</p>"},{"location":"docs/engineering/ownership/#scenario-2-model-deployment","title":"Scenario 2: Model Deployment","text":"<p>In this scenario, a data scientist or ml engineer creates the custom api logic for their model (FastApi for example) and specifies resources to deploy in a custom configuration or specification file. For this example, assume the engineering space has set up an automated process whereby changes to the configuration file and push/tags trigger a CI/CD process that builds and serves a new model api. Upon build kickoff, the model specified in the configuration file is downloaded from the <code>OpsML</code> server and packaged along with the api code into a docker container. This docker container is then deployed on K8s where the api is served and ready for requests.</p>"},{"location":"docs/engineering/ownership/#environment","title":"Environment","text":"<p>It is recommended to setup <code>OpsML</code> on each of your environments (dev/staging and prod). This is slightly different than other DS tooling packages and was done in order to follow best practices is systems/infra design. As a result, you will have separate registries across environments that will not be linked. Thus, versions across staging and prod may not be in sync, which is not necessarily an issue considering prod should be the environment used to train and deploy prod model artifacts.</p>"},{"location":"docs/engineering/ownership/#limit-write-access-in-prod","title":"Limit write access in prod","text":"<p>By design, so long as a data scientist has an <code>OPSML_TRACKING_URI</code> they should be able to read and write objects to the <code>OpsML</code> server. However, we usually don't want anyone to write/update a prod artifact from a non-prod environment. As an added measure of security, only requests coming from a prod environment will be allowed to write/update prod artifacts (anything can be read). This is accomplished through a <code>verify_token</code> dependency that checks for an <code>OPSML_PROD_TOKEN</code> token in your request and matches it to the <code>OPSML_PROD_TOKEN</code> in the prod environment. Note This is only checked if the <code>APP_ENV</code> is set to production.</p> <p>For this functionality to work you will need to set <code>OPSML_PROD_TOKEN</code> env var in both the production compute environment that your data scientists use to train models and in the production environment that hosts the <code>Opsml Server</code>. Once these are set, <code>OpsML</code> will take care of the rest. It's also recommended that you use <code>APP_ENV</code> as the env var that specifies the current environment (dev, staging, production).</p>"},{"location":"docs/engineering/server/","title":"<code>OpsML</code> Server Setup","text":"<p>In addition to using <code>OpsML</code> as a stand-alone python package, it can also be used as a server (<code>FastApi</code>) providing a proxy interface between data scientists and backend infrastructure (recommended approach). What this means for data scientists, is that they can use <code>OpsML</code> as they normally would without having to set any credentials apart from the http proxy uri. For engineers, this means that they can control the infrastucture, databases, and overall server setup based on their specifications and security requirements. More on this can be found here</p>"},{"location":"docs/engineering/server/#registry-architecture","title":"Registry Architecture","text":""},{"location":"docs/engineering/server/#project-run-flow-architecture","title":"Project Run Flow Architecture","text":""},{"location":"docs/engineering/server/#setup","title":"Setup","text":"<p>You can setup the <code>OpsML</code> server based on your space needs. As an example, you could follow a conventional setup whereby you host Docker images via K8s. For this setup, you would install <code>OpsML</code> and its dependencies into a Dockerfile and host the server on k8s.</p>"},{"location":"docs/engineering/server/#required-env-vars","title":"Required Env Vars","text":"<p>As mentioned here <code>OpsML</code> expects 2 variables to be set (these can be set in an Dockerfile or at webserver runtime).</p> <ul> <li>OPSML_TRACKING_URI: This is the tracking uri of your backend database.</li> <li>OPSML_STORAGE_URI: This is the storage uri of your storage backend (e.g. GCP, AWS).</li> <li>OPSML_POOL_SIZE (optional): Default pool size to use with sqlalchemy engine. If not set, will default to 10.</li> <li>OPSML_MAX_OVERFLOW (optional): Default max overflow to use with sqlalchemy engine. If not set, will default to 5.</li> </ul>"},{"location":"docs/engineering/server/#cloud-authentication","title":"Cloud Authentication","text":"<p><code>OpsML</code> aims to be cloud agnostic and currently supports GCP, AWS and Azure. To authenticate with these cloud providers, follow the individual steps below.</p>"},{"location":"docs/engineering/server/#google-cloud-platform","title":"Google Cloud Platform","text":"<p><code>Required access</code></p> <ul> <li>It is recommended to have <code>Storage Object Admin</code> roles for the service account or user that will be interacting with the <code>OpsML</code> bucket.</li> <li>If admin cannot be provided, the SA or user with need list, create, delete, update and get permissions on the bucket and all objects within the bucket.</li> </ul> <code>Default credentials</code> <p>If no credentials are provided, <code>OpsML</code> will look for the <code>GOOGLE_APPLICATION_CREDENTIALS</code> environment variable. If this variable is not set, it will default to the application default credentials. For more information on setting up GCP credentials, see here. If your infrastructure provisions compute resources that are automatically authenticated with GCP, you don't need to do anything.</p> <code>Service Account</code> <p>If you are using a service account, you can either set <code>GOOGLE_ACCOUNT_JSON_BASE64</code> or <code>GOOGLE_APPLICATION_CREDENTIALS_SA</code> environment variables. <code>GOOGLE_ACCOUNT_JSON_BASE64</code> should be the base64 encoded json key file of the service account. <code>GOOGLE_APPLICATION_CREDENTIALS_SA</code> should be the path to the service account key file.</p> <code>Identity Token</code> <p>Workload identity federation is not currently supported. This is due to the fact that the <code>OpsML</code> UI generates pre-signed tokens for artifact visualization in the browser. There is currently no python SDK support to generate a presigned token with a workload identity.</p>"},{"location":"docs/engineering/server/#amazon-web-services-s3","title":"Amazon Web Services S3","text":"<p><code>Required access</code></p> <ul> <li>It is recommended to have <code>AmazonS3FullAccess</code> policy for the user or role that will be interacting with the <code>OpsML</code> bucket.</li> <li>If admin cannot be provided, the SA or user with need list, create, delete, update and get permissions on the bucket and all objects within the bucket.</li> </ul> <code>Default credentials</code> <p>If no credentials are provided, <code>OpsML</code> will look to authenticate with the default AWS configuration. For more information on setting up AWS credentials, see here. If your infrastructure comes automatically configured with AWS credentials, then you don't need to do anything.</p> <p><code>Service Account</code></p> <ul> <li>If you are using a service account, you can either set <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> environment variables or you can set <code>AWS_PROFILE</code> to the profile name in your <code>~/.aws/credentials</code> file.</li> <li>You may also supply a session token with the <code>AWS_SESSION_TOKEN</code> environment variable if you are using temporary credentials.</li> </ul> <code>Identity Token</code> Workload identity federation is supported."},{"location":"docs/engineering/server/#azure-blob-storage","title":"Azure Blob Storage","text":"<p><code>Required access</code></p> <ul> <li>It is recommended to have <code>Storage Blob Data Contributor</code> role for the user or role that will be interacting with the <code>OpsML</code> container.</li> <li>If admin cannot be provided, the SA or user with need list, create, delete, update and get permissions on the container and all objects within the container.</li> </ul> <code>Default credentials</code> <p>If no credentials are provided, <code>OpsML</code> will look to authenticate with the default Azure configuration. For more information on setting up Azure credentials, see here. If your infrastructure comes automatically configured with Azure credentials, then you don't need to do anything. If using default credentials, you will need to set the <code>AZURE_STORAGE_ACCOUNT_NAME</code> that corresponds to the storage account you want to use.</p> <p><code>Service Account</code></p> <ul> <li>If you are using a service account principal, you will need to set the following environment variables:<ul> <li><code>AZURE_STORAGE_ACCOUNT_NAME</code></li> <li><code>AZURE_STORAGE_TENANT_ID</code></li> <li><code>AZURE_STORAGE_CLIENT_ID</code></li> <li><code>AZURE_STORAGE_CLIENT_SECRET</code></li> </ul> </li> </ul> <code>Identity Token</code> <p>Workload identity federation is currently supported; however, you will need to set the <code>AZURE_STORAGE_ACCOUNT_NAME</code> that corresponds to the storage account you want to use.</p>"},{"location":"docs/engineering/server/#environment-variable-table","title":"Environment Variable Table","text":"Environment Variable Description Required Platform <code>OPSML_TRACKING_URI</code> Tracking uri of the backend database Yes All <code>OPSML_STORAGE_URI</code> Storage uri of the storage backend Yes All <code>OPSML_POOL_SIZE</code> Default pool size to use with sqlalchemy engine No All <code>OPSML_MAX_OVERFLOW</code> Default max overflow to use with sqlalchemy engine No All <code>GOOGLE_APPLICATION_CREDENTIALS</code> Path to the GCP service account key file No GCP <code>GOOGLE_ACCOUNT_JSON_BASE64</code> Base64 encoded json key file of the GCP service account No GCP <code>GOOGLE_APPLICATION_CREDENTIALS_SA</code> Path to the GCP service account key file No GCP <code>AWS_ACCESS_KEY_ID</code> AWS access key No AWS <code>AWS_SECRET_ACCESS_KEY</code> AWS secret No AWS <code>AWS_SESSION_TOKEN</code> AWS session token No AWS <code>AWS_PROFILE</code> AWS profile name No AWS <code>AZURE_STORAGE_ACCOUNT_NAME</code> Azure storage account name Yes Azure <code>AZURE_STORAGE_TENANT_ID</code> Service principal tenant id No Azure <code>AZURE_STORAGE_CLIENT_ID</code> Service principal client id No Azure <code>AZURE_STORAGE_CLIENT_SECRET</code> Service principal secret No Azure"},{"location":"docs/engineering/server/#server-command","title":"Server Command","text":"<ul> <li>During local development/testing, you can spin up and test the <code>OpsML</code> server via the CLI command <code>opsml-uvicorn-server</code> which will launch a Uvicorn server.</li> <li>For production, it is recommended that you run Gunicorn.</li> <li>The following command can be used to run a Gunicorn <code>OpsML</code> server.</li> </ul> <p><code>gunicorn -k uvicorn.workers.UvicornWorker --config=./app/gunicorn_conf.py --bind=0.0.0.0:3000 \"opsml.app.main:run_app(login=False)\"</code></p>"},{"location":"docs/engineering/server/#example-pyprojecttoml-for-an-opsml-server","title":"Example pyproject.toml for an Opsml Server","text":"<pre><code>[tool.poetry]\nname = \"opsml-server\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"ml-platform\"]\n\n[tool.poetry.dependencies]\npython = \"&gt;=3.9,&lt;=3.11\"\nopsml = {version = \"^2.0.0\", extras = [\"gcs\", \"postgres\", \"server\"]}\n</code></pre>"},{"location":"docs/evaluation/llm/","title":"LLM","text":""},{"location":"docs/evaluation/llm/#llm-evaluation","title":"LLM Evaluation","text":"<p>Opsml provides you with tools to run offline LLM evaluations. This is is often useful for when you (1) want to compare and benchmark various prompts, and (2) you want to evaluate different versions of prompts and LLM services that you may already be using in production.</p> <p>Note: You can run an LLM evaluation by importing the <code>evaluate_llm</code> function directly from opsml.evaluate or you can create an evaluation as part of an experiment <code>exp.llm.evaluate(...)</code>. The latter is useful if you want to track and version your evaluations as part of an experiment.</p>"},{"location":"docs/evaluation/llm/#getting-started","title":"Getting Started","text":"<p>To run and LLM evaluation, you will first need to obtain your evaluation data and construct a list of <code>LLMEvalRecord</code> instances. Each <code>LLMEvalRecord</code> represents a single evaluation instance, containing the metadata you wish to evaluate. Note, we have left this intentionally flexible so that you can evaluate any type of metadata you wish.</p>"},{"location":"docs/evaluation/llm/#example-evaluating-a-prompt-for-query-reformulation","title":"Example: Evaluating a Prompt for Query Reformulation","text":""},{"location":"docs/evaluation/llm/#step-1-example-workflow-setup","title":"Step 1: Example Workflow Setup","text":"<p>Let's say you have a use case where you want to evaluate how well a prompt reformulates user search queries and how relevant the answers are to the original user query. The prompts used for this task are shown below and does the following things:</p> <ul> <li>Takes a bound parameter <code>${user_query}</code> which is the original user search query.</li> <li>Reformulates the query to be more feature-rich and keyword-dense, while preserving the original</li> <li>Takes the <code>${reformulated_query}</code> and injects it into an answer prompt to get an answer.</li> </ul> <p><pre><code>reformulation_prompt = Prompt(\n    message=(\n        \"You are an expert at query reformulation. Your task is to take a user's original search query \"\n        \"and rewrite it to be more feature-rich and keyword-dense, so it better aligns with the user's intent \"\n        \"and improves search results.\\n\\n\"\n        \"Guidelines:\\n\"\n        \"- Expand abbreviations and clarify ambiguous terms.\\n\"\n        \"- Add relevant synonyms, related concepts, and specific features.\\n\"\n        \"- Preserve the original intent, but make the query more explicit and comprehensive.\\n\"\n        \"- Do not change the meaning of the query.\\n\"\n        \"- Return only the reformulated query.\\n\\n\"\n        \"User Query:\\n\"\n        \"${user_query}\\n\\n\"\n        \"Reformulated Query:\"\n    ),\n    model=\"gemini-2.5-flash-lite\",\n    provider=\"gemini\",\n    model_settings=GeminiSettings(\n        generation_config=GenerationConfig(\n            thinking_config=ThinkingConfig(thinking_budget=0),\n        ),\n    ),\n)\n\nanswer_prompt = Prompt(\n    message=(\"You are a helpful assistant that can answer any question!\" \n             \"Please provide an answer to the following user query.\\n\\n\"\n             \"Question:\\n\"\n             \"${reformulated_query}\\n\\n\"\n             \"Answer:\"\n            ),\n    model=\"gemini-2.5-flash-lite\",\n    provider=\"gemini\",\n)\n</code></pre> The overall flow for using the prompt would look like the following:</p> <pre><code>flowchart TD\nsubgraph A[\"Question Answer Agent\"]\n    direction LR\n    User_Query --&gt; Reformulation_Prompt\n    Reformulation_Prompt --&gt; Reformulated_Query\n    Reformulated_Query --&gt; Answer_Prompt\n    Answer_Prompt --&gt; Answer\nend</code></pre>"},{"location":"docs/evaluation/llm/#step-2-create-an-llmevalmetric-to-evaluate-the-prompt","title":"Step 2: Create an <code>LLMEvalMetric</code> to Evaluate the Prompt","text":"<p>Now say you want to (1) evaluate how well the prompt reformulates user queries into better-structured queries and (2) how relevant the provided answer is to the user input. In this scenario, imagine you already have a dataset of user queries, their reformulated queries and the returned answers (this could be from an experiment you ran in production). Now, to evaluate the prompts and Agent, you would create a list of <code>LLMEvalRecords</code> containing the <code>user_query</code>, <code>reformulated_query</code> and <code>answer</code> context as well as an <code>LLMEvalMetric</code> that defines how you want to evaluate the prompt using an <code>LLM as a judge</code> workflow.</p> <pre><code>from opsml.genai import Prompt, Score\nfrom opsml.evaluate import LLMEvalMetric, LLMEvalRecord, evaluate_llm\n\nreformulation_eval_prompt = Prompt(\n    message=(\n        \"You are an expert evaluator of search query relevance. \\n\"\n        \"You will be given a user query and its reformulated version. \\n\"\n        \"You task is to assess how relevant the reformulated query is to the information needs of the user. \\n\"\n        \"Consider the following criteria:\\n\"\n        \"- Does the query contain relevant keywords and concepts?\\n\"\n        \"- Is the query clear and unambiguous?\\n\"\n        \"- Does the query adequately express the user's intent?\\n\\n\"\n        \"Provide your evaluation as a JSON object with the following attributes:\\n\"\n        \"- score: An integer from 1 (poor) to 5 (excellent) indicating the overall reformulation score.\\n\"\n        \"- reason: A brief explanation for your score.\\n\\n\"\n        \"Format your response as:\\n\"\n        \"{\\n\"\n        '  \"score\": &lt;integer 1-5&gt;,\\n'\n        '  \"reason\": \"&lt;your explanation&gt;\"\\n'\n        \"}\\n\\n\"\n        \"User Query:\\n\"\n        \"${user_query}\\n\\n\" #(1)\n        \"Reformulated Query:\\n\"\n        \"${reformulated_query}\\n\\n\" #(2)\n        \"Evaluation:\"\n    ),\n    model=\"gemini-2.5-flash-lite-preview-06-17\",\n    provider=\"gemini\",\n    response_format=Score, #(3)\n)\n\nanswer_eval_prompt = Prompt(\n    message=(\n        \"You are an expert evaluator of answer relevance. \\n\"\n        \"You will be given a user query and an answer generated from a reformulated version of that query. \\n\"\n        \"Your task is to assess how relevant and accurate the answer is in addressing the user's original information needs. \\n\"\n        \"Consider the following criteria:\\n\"\n        \"- Does the answer directly address the user's query?\\n\"\n        \"- Is the information provided accurate and reliable?\\n\"\n        \"- Is the answer clear, concise, and well-structured?\\n\\n\"\n        \"Provide your evaluation as a JSON object with the following attributes:\\n\"\n        \"- score: An integer from 1 (poor) to 5 (excellent) indicating the overall answer quality score.\\n\"\n        \"- reason: A brief explanation for your score.\\n\\n\"\n        \"Format your response as:\\n\"\n        \"{\\n\"\n        '  \"score\": &lt;integer 1-5&gt;,\\n'\n        '  \"reason\": \"&lt;your explanation&gt;\"\\n'\n        \"}\\n\\n\"\n        \"User Query:\\n\"\n        \"${user_query}\\n\\n\" #(1)\n        \"Answer:\\n\"\n        \"${answer}\\n\\n\" #(2)\n        \"Evaluation:\"\n    ),\n    model=\"gemini-2.5-flash-lite-preview-06-17\",\n    provider=\"gemini\",\n    response_format=Score, #(3)\n)\n\neval_metrics = [\n    LLMEvalMetric(\n        name=\"reformulation_quality\",\n        prompt=reformulation_eval_prompt,\n    ),\n    LLMEvalMetric(\n        name=\"answer_relevance\",\n        prompt=answer_eval_prompt,\n    )\n]\n\nflight_record = LLMEvalRecord(\n    context={\n        \"user_query\": \"cheap flights to Europe next month\",\n        \"reformulated_query\": \"affordable airfare to Europe next month\",\n        \"answer\": \"I found several options for cheap flights to Europe next month.\"\n    },\n    id=\"record_1\",\n)\n\ntechnical_record = LLMEvalRecord(\n    context={\n        \"user_query\": \"why won't my laptop turn on\",\n        \"reformulated_query\": \"laptop computer won't boot power issues troubleshooting steps hardware failure battery power supply diagnostic repair\",\n        \"answer\": \"If your laptop won't turn on, try these troubleshooting steps: 1) Check power connections - ensure the charger is plugged in securely and the power outlet works. 2) Remove the battery (if removable) and hold the power button for 30 seconds, then reconnect and try again. 3) Look for LED indicators on the laptop or charger. 4) Try a different power adapter if available. 5) Check for physical damage to ports or cables. 6) If these steps don't work, the issue may be hardware-related (motherboard, RAM, or hard drive failure) requiring professional repair\"\n    },\n    id=\"record_2\",\n)\n\ncooking_record = LLMEvalRecord(\n    context={\n        \"user_query\": \"easy dinner recipes with chicken\",\n        \"reformulated_query\": \"simple quick chicken dinner recipes healthy family-friendly weeknight meals\",\n        \"answer\": \"Here are some easy chicken dinner recipes: 1) Baked Lemon Garlic Chicken - Marinate chicken breasts in lemon juice, garlic, olive oil, and herbs, then bake until cooked through. 2) One-Pan Chicken and Veggies - Saut\u00e9 chicken pieces with mixed vegetables in a skillet with olive oil and your favorite seasonings. 3) Chicken Stir-Fry - Cook sliced chicken with colorful veggies in a wok or large pan, adding soy sauce and ginger for flavor. 4) Chicken Tacos - Season shredded chicken with taco seasoning and serve in tortillas with your favorite toppings. 5) Chicken Alfredo Pasta - Toss cooked pasta with grilled chicken and a creamy Alfredo sauce for a quick and satisfying meal.\"\n    },\n    id=\"record_3\",\n)\n\nrecords = [flight_record, technical_record, cooking_record]\n\nresults = evaluate_llm(\n    records=records,\n    metrics=eval_metrics,\n)\n</code></pre> <ol> <li><code>${user_query}</code> is a bound parameter that will be populated from the <code>LLMEvalRecord</code> context</li> <li><code>${reformulated_query}</code> is a bound parameter that will be populated from the <code>LLMEvalRecord</code> context</li> <li><code>LLMEvalMetrics</code> currently require all prompts to return a <code>Score</code> object. This is critical as the score object allows us to extract a numerical score for evaluation.</li> </ol>"},{"location":"docs/evaluation/llm/#eval-metric-flow","title":"Eval Metric Flow","text":"<p>As you can see from the above example, the overall flow for evaluating an LLM using <code>LLMEvalMetric</code> is as follows:</p> <ol> <li>Define the evaluation metrics using <code>LLMEvalMetric</code>, providing the necessary prompts for each metric.</li> <li>Create <code>LLMEvalRecord</code> instances for each record you want to evaluate, populating the context with the relevant information that will be injected into the prompts.</li> <li>Call the <code>evaluate_llm</code> function with the records and metrics to obtain the evaluation results.</li> </ol>"},{"location":"docs/evaluation/llm/#step-3-evaluation-configuration","title":"Step 3: Evaluation Configuration","text":"<p>By default, the above <code>evaulate_llm</code> function will execute without any additional configuration. It will extract the defined metric prompts, bind the context variables from each record, and execute the prompts against the defined LLM provider and model and then extract the scores. However, if you want a more robust evaluation, we recommend you provide an <code>EvaluationConfig</code> configured to your needs.</p> <p>EvaluationConfig allows you to customize the evaluation process in several ways:</p> <ul> <li>Specify which fields from the <code>LLMEvalRecord</code> context should be embedded. These embedding will be used to calculate means and similarity scores.</li> <li>Indicate whether you want to compute similarity scores between the embedded fields.</li> <li>Enable clustering to identify patterns in the evaluation results.</li> <li>Enable histogram computations to generate histograms for all numerical fields.</li> </ul> <p>EvaluationConfig documentation</p> <pre><code>from opsml.evaluate import EvaluationConfig\nfrom opsml.genai.openai import OpenAIEmbeddingConfig\nfrom opsml.genai import Embedder, Provider\n\n#(previous code)...\n\nembedder = Embedder( #(1)\n    Provider.OpenAI,\n    config=OpenAIEmbeddingConfig(\n        model=\"text-embedding-3-small\",\n        dimensions=512,\n    ),\n)\n\nresults = evaluate_llm(\n    records=records,\n    metrics=eval_metrics,\n    config=EvaluationConfig( #(2)\n        embedder=embedder,\n        embedding_targets=[\"user_query\", \"answer\"], #(3)\n        compute_similarity=True, #(4)\n        cluster=True, #(5)\n        compute_histograms=True, #(6)\n    ),\n)\n</code></pre> <ol> <li>Create an <code>Embedder</code> instance to generate embeddings for the evaluation records. This is useful for similarity computations and clustering. Here, we are using OpenAI's embedding model.</li> <li>Pass an <code>EvaluationConfig</code> instance to the <code>evaluate_llm</code> function to customize the evaluation process.</li> <li>Specify which fields from the <code>LLMEvalRecord</code> context should be embedded. In this case, we are embedding both the <code>user_query</code> and <code>answer</code>. These embedding will be used to calculate means and similarity scores.</li> <li>Indicate that we want to compute similarity scores between the embedded fields.</li> <li>If clustering is enabled, Scouter will execute a dbscan with all numerical values (scores, similarity scores, embeddings etc.) to identify clusters of similar records. This can help identify patterns in the evaluation results</li> <li>Enable histogram computations to generate histograms for all numerical fields</li> </ol>"},{"location":"docs/evaluation/llm/#step-4-analyzing-the-results","title":"Step 4: Analyzing the Results","text":"<p>The results object (<code>LLMEvalResults</code>) returned from the <code>evaluate_llm</code> function contains a wealth of information about the evaluation. You can access individual record results, overall metrics, and any errors that occurred during the evaluation process.</p> <pre><code># Assess individual record results\nresults = evaluate_llm(...)\n\n\nrecord1_metrics = results[\"record_1\"].metric\nprint(f\"Record 1 Reformulation Quality Score: {record1_metrics['reformulation_quality'].score}\")\nprint(f\"Record 1 Reformulation Quality Reason: {record1_metrics['reformulation_quality'].reason}\")\n\nprint(f\"Record 1 Answer Relevance Score: {record1_metrics['answer_relevance'].score}\")\nprint(f\"Record 1 Answer Relevance Reason: {record1_metrics['answer_relevance'].reason}\")\n\n# Create a dataframe for easier analysis\ndf = results.to_dataframe() # pandas\nprint(df.head())\n\ndf = results.to_dataframe(polars=True) # polars\nprint(df.head())\n\n# Access histograms\nhistograms = results.histograms\nfor field, histogram in histograms.items():\n    print(f\"Histogram for {field}: {histogram}\")\n</code></pre> <p>Please refer to the LLMEvalResults documentation for more details on how to work with the results object.</p>"},{"location":"docs/faq/common_questions/","title":"FAQ","text":"<p>Below are a list of commonly answered questions.</p>"},{"location":"docs/faq/common_questions/#why-do-some-examples-use-a-context-manager-and-some-dont-whats-recommended","title":"Why do some examples use a context manager and some don't? What's recommended?","text":"<p>By default, all cards can be registered, listed, loaded and updated outside of a context manager. In fact, this was done on purpose to not lock users into a particular style. The context manager comes into play when using <code>experimentcards</code> as they provide a means to group artifacts (Cards, metrics, params) under a specific project run. Technically, this grouping can still be achieved by using <code>experimentcards</code> directly but this comes at the expense of more lines of code. The context manager tends to be a more convenient way of logging and tracking artifacts. In addition, when using an <code>OpsmlProject</code>, all artifacts are automatically viewable in the Opsml UI.</p> <p>Recommendation based on needs</p> <ul> <li>I'd like to be able to view all artifacts, metrics, graphs, reports in a UI<ul> <li>Use the <code>OpsmlProject</code> context manager</li> </ul> </li> <li>I don't really need to see all of the artifacts, I care more that they are tracked and callable when needed<ul> <li>Use whatever you prefer</li> </ul> </li> <li>I like grouping runs/experiments by projects. UI doesn't really matter.<ul> <li>Use the <code>OpsmlProject</code> context manager</li> </ul> </li> </ul>"},{"location":"docs/faq/common_questions/#how-do-i-supply-my-own-onnx-definition","title":"How do I supply my own onnx definition?","text":"<p>If you'd like to create your onnx model yourself and associate that with the ModelCard, you will need to provide your own implementation of the <code>onnx_model</code> arg. An example of this can be seen here.</p>"},{"location":"docs/faq/common_questions/#whats-with-using-name-space-and-contact-or-cardinfo-in-the-examples","title":"What's with using name, space, and contact or <code>CardInfo</code> in the examples?","text":"<p>Every <code>ArtifactCard</code> requires a name, space and contact. For convenience, you can instead provide a <code>CardInfo</code> instance.</p>"},{"location":"docs/faq/common_questions/#how-is-opsml-different-than-other-products-out-there","title":"How is <code>OpsML</code> different than other products out there?","text":"<p>A key difference between <code>OpsML</code> and other products is that <code>OpsML</code> was not designed to be a platform or lock you in to any specific way of doing things. Instead, the goal and initial idea behind <code>OpsML</code> was to provide tooling and an interface that stitches, standardizes and automates some of the key building blocks (storage, tracking, versioning) to any machine learning workflow or platform. Thus, <code>OpsML</code> is capable of being used with other platforms or machine learning workflow systems. Or you can build your own!</p>"},{"location":"docs/faq/contributing/","title":"Contributing to demml/opsml","text":""},{"location":"docs/faq/contributing/#welcome","title":"Welcome","text":"<p>Hello! We're glad and grateful that you're interested in contributing to <code>OpsML</code> ! Below you will find the general guidelines for setting up your environment and creating/submitting <code>pull requests</code>.</p>"},{"location":"docs/faq/contributing/#very-important","title":"Very Important","text":"<p>To contribute to <code>OpsML</code> you will need to sign a Contributor License Agreement (CLA) via HelloSign when you create your first <code>pull_request</code> (this is an automated process). For a <code>pull_request</code> to be valid, your Github email address must match the email address used to sign the CLA. Github has documentation on setting email addresses. Your git email must also match this email address.</p>"},{"location":"docs/faq/contributing/#table-of-contents","title":"Table of contents","text":"<ul> <li>Environment setup</li> <li>Contributing changes</li> <li>Contributing TLDR</li> <li>Community guidelines</li> <li>Reporting bugs</li> <li>Suggesting enhancements</li> </ul>"},{"location":"docs/faq/contributing/#environment-setup","title":"Environment Setup","text":"<p>Steps: 1. Create a new env. <code>OpsML</code> currently supports python 3.9 -&gt; 3.11 2. Fork <code>OpsML</code> 3. Install all required and development packages in your new env (we use poetry for dependency management).</p> <p><pre><code>make setup\n</code></pre> or with poetry directly</p> <pre><code>poetry install --all-extras --with dev,dev-lints\n</code></pre>"},{"location":"docs/faq/contributing/#contributing-changes","title":"Contributing Changes","text":"<ol> <li>Create a new branch for your addition</li> <li>General naming conventions (we're not picky):<ul> <li><code>/username/&lt;featureName&gt;</code>: for features</li> <li><code>/username/&lt;fixName&gt;</code>: for general refactoring or bug fixes</li> </ul> </li> <li>Test your changes:</li> <li>You can run formatting, lints and tests locally via <code>make format</code>, <code>make lints</code> and <code>make unit.tests</code>, respectively.</li> <li>Submit a Draft Pull Request. Do it early and mark it <code>WIP</code> so a maintainer knows it's not ready for review just yet. You can also add a label to it if you feel like it .</li> <li>If you haven't signed our CLA before, then you will receive an email from HelloSign to sign the CLA (mentioned above).<ul> <li>The CLA request will be sent to the email address associated with your github account.</li> <li>You cannot have your PR merged without signing the PR.</li> <li>If you already submitted a PR and need to correct your user.name and/or user.email please do so and then use <code>git commit --amend --reset-author</code> and then <code>git push --force</code> to correct the PR.</li> </ul> </li> <li>Move the <code>pull_request</code> out of draft state.</li> <li>Make sure you fill out the <code>pull_request</code> template (included with every <code>pull_request</code>)</li> <li>Request review from one of our maintainers (this should happen automatically via <code>.github/CODEOWNERS</code>). </li> <li>Get Approval. We'll let you know if there are any changes that are needed. </li> <li>Merge your changes into <code>OpsML</code>!</li> </ol>"},{"location":"docs/faq/contributing/#contributing-tldr","title":"Contributing TLDR","text":"<ol> <li>Create branch</li> <li>Add changes</li> <li>Test locally</li> <li>Create PR (fill out CLA if you haven't before)</li> <li>Get your awesome work reviewed and approved by a maintainer</li> <li>Merge</li> <li>Celebrate!</li> </ol>"},{"location":"docs/faq/contributing/#community-guidelines","title":"Community Guidelines","text":"<ol> <li>Be Kind<ul> <li>Working with us should be a fun learning opportunity, and we want it to be a good experience for everyone. Please treat each other with respect.  </li> <li>If something looks outdated or incorrect, please let us know! We want to make <code>OpsML</code> as useful as possible. </li> </ul> </li> <li>Own Your Work<ul> <li>Creating a PR for <code>OpsML</code> is your first step to becoming a contributor, so make sure that you own your changes. </li> <li>Our maintainers will do their best to respond to you in a timely manner, but we ask the same from you as the contributor. </li> </ul> </li> </ol>"},{"location":"docs/faq/contributing/#submitting-issuesbugs","title":"Submitting issues/bugs","text":"<p>We use GitHub issues to track bugs and suggested enhancements. You can report a bug by opening a new issue new issue Before reporting a bug/issue, please check that it has not already been reported, and that it is not already fixed in the latest version. If you find a closed issue related to your current issue, please open a new issue and include a link to the original issue in the body of your new one. Please include as much information about your bug as possible.</p>"},{"location":"docs/faq/contributing/#suggesting-enhancements","title":"Suggesting enhancements","text":"<p>You can suggest an enhancement by opening a new feature request. Before creating an enhancement suggestion, please check that a similar issue does not already exist.</p> <p>Please describe the behavior you want and why, and provide examples of how <code>OpsML</code> would be used if your feature were added.</p>"},{"location":"docs/faq/contributing/#thank-you","title":"Thank you!","text":""},{"location":"docs/monitoring/overview/","title":"Overview","text":"<p><code>Opsml</code> is integrated with Scouter for real-time monitoring. With this integration, you can the create drift profiles for your models and prompts, and monitor them in real-time. For a more detailed overview of Scouter, and how to use it, see the Scouter documentation along with our examples directory. The following is a brief overview of the Scouter integration with <code>Opsml</code>.</p>"},{"location":"docs/monitoring/overview/#creating-a-drift-profile","title":"Creating a Drift Profile","text":"<p>While you can create a drift profile for <code>ModelCards</code> and <code>PromptCards</code>, real-time monitoring requires that you setup the <code>Scouter</code> server. Refer to the setup instructions in the Scouter documentation.</p>"},{"location":"docs/monitoring/overview/#modelcards","title":"ModelCards","text":"<p>When creating <code>ModelInterface</code> as part of a <code>ModelCard</code>, you can leverage the <code>create_drift_profile</code> method to create drift profile for your model. Refer to the Scouter documentation for supported types, but the process is the same for all types of model interfaces and cards.</p>"},{"location":"docs/monitoring/overview/#create_drift_profile-arguments","title":"<code>create_drift_profile</code> Arguments","text":"Name Required Description alias Yes the alias for the drift profile. Interfaces can hold more than one drift profile. data Yes The data to use for building the drift profile. Can be a pandas/polars dataframe, pyarrow table or numpy array config No The drift config to use. Defaults to <code>SpcDriftConfig</code> data_type No The type of data <code>DataType</code> to use. If None, data_type will be inferred from the data"},{"location":"docs/monitoring/overview/#example","title":"Example","text":"<pre><code>from sklearn import ensemble\n\n# Opsml Scouter imports\nfrom opsml.scouter.alert import AlertThreshold, SlackDispatchConfig\nfrom opsml.scouter.types import CommonCrons\nfrom opsml.scouter.alert import PsiAlertConfig\n\n# Opsml imports\nfrom opsml.card import ModelCard, CardRegistry\nfrom opsml.model import SklearnModel, TaskType\nfrom opsml.data import DataType\n\nreg = ensemble.RandomForestClassifier(n_estimators=5)\nreg.fit(X.to_numpy(), y.to_numpy().ravel())\n\nmodel = SklearnModel(\n    model=reg,\n    sample_data=X,\n    task_type=TaskType.Classification,\n)\n\n# Create a PSI drift profile\nmodel.create_drift_profile(\n    alias=\"psi_data\",\n    data=X,\n    config=PsiDriftConfig( # (1)\n            alert_config=PsiAlertConfig(\n                dispatch_config=SlackDispatchConfig(channel=\"#opsml\"), # (2)\n                features_to_monitor=[\"target\"], # (3)\n                schedule=CommonCrons.Every30Minutes,\n            )\n        ),\n    data_type=DataType.Pandas,\n)\n\n# Create a custom drift profile\nmodel.create_drift_profile(\n        alias=\"custom_metric\",\n        data=[\n            CustomMetric( # (4)\n                name=\"custom\",\n                value=0.5,\n                alert_threshold=AlertThreshold.Above,\n            )\n        ],\n        config=CustomMetricDriftConfig(),\n    )\n\n# Create ModelCard\nmodelcard = ModelCard(\n    interface=model,\n    name=\"my_model\",\n    space=\"opsml\",\n    version=\"1.0.0\",\n)\n\nregistry = CardRegistry(\"model\")\nregistry.register_card(modelcard)\n</code></pre> <ol> <li>The <code>PsiDriftConfig</code> is used to configure the PSI drift profile. You can also use other drift configs like <code>SpcDriftConfig</code>, <code>CustomMetricDriftConfig</code>, etc.</li> <li>The <code>SlackDispatchConfig</code> is used to configure the alert dispatching to Slack. You can also use other dispatch configs.</li> <li>The <code>features_to_monitor</code> is used to specify which features to monitor. If not specified, all features will be monitored. This is typically overkill.</li> <li>The <code>CustomMetric</code> is used to create a custom drift profile.</li> </ol>"},{"location":"docs/monitoring/overview/#promptcards","title":"PromptCards","text":"<p>You can also create drift profiles for <code>PromptCards</code>. The only difference is that you will use the <code>create_drift_profile</code> method on the <code>PromptCard</code> instead of the <code>ModelInterface</code>, and you can only create LLM drift profiles and metrics.</p> <p>For more information on LLM Monitoring, refer to LLM Monitoring documentation.</p>"},{"location":"docs/monitoring/overview/#create_drift_profile-arguments_1","title":"<code>create_drift_profile</code> Arguments","text":"Name Required Description alias Yes The alias for the drift profile config Yes The LLM drift config to use metrics Yes The metrics to use for the drift profile. Must be a collection of <code>LMDriftMetric</code> objects workflow No Optional custom workflow for advanced evaluation scenarios"},{"location":"docs/monitoring/overview/#example-llm-as-a-judge-drift-profile","title":"Example (LLM as a Judge Drift Profile)","text":"<pre><code>from opsml.scouter.drift import LLMDriftConfig, LLMDriftMetric, LLMDriftProfile\nfrom opsml.scouter.alert import AlertThreshold\nfrom opsml.genai import Score, Agent, Task, Workflow, Prompt\n\n\ndef create_reformulation_evaluation_prompt(): # (1)\n    \"\"\"\n    Builds a prompt for evaluating the quality of a reformulated query.\n\n    Returns:\n        Prompt: A prompt that asks for a JSON evaluation of the reformulation.\n\n    Example:\n        &gt;&gt;&gt; prompt = create_reformulation_evaluation_prompt()\n    \"\"\"\n    return Prompt(\n        message=(\n            \"You are an expert evaluator of search query reformulations. \"\n            \"Given the original user query and its reformulated version, your task is to assess how well the reformulation improves the query. \"\n            \"Consider the following criteria:\"\n            \"- Does the reformulation make the query more explicit and comprehensive?\"\n            \"- Are relevant synonyms, related concepts, or specific features added?\"\n            \"- Is the original intent preserved without changing the meaning?\"\n            \"- Is the reformulation clear and unambiguous?\"\n            \"Provide your evaluation as a JSON object with the following attributes:\"\n            \"- score: An integer from 1 (poor) to 5 (excellent) indicating the overall quality of the reformulation.\"\n            \"- reason: A brief explanation for your score.\"\n            \"Format your response as:\"\n            \"{\"\n            '  \"score\": &lt;integer 1-5&gt;,'\n            '  \"reason\": \"&lt;your explanation&gt;\"'\n            \"}\"\n            \"Original Query:\"\n            \"${user_query}\"\n            \"Reformulated Query:\"\n            \"${response}\"\n            \"Evaluation:\"\n        ),\n        model=\"gemini-2.5-flash-lite-preview-06-17\",\n        provider=\"gemini\",\n        response_format=Score,\n    )\n\nprompt = Prompt(\n    model=\"gpt-4o\",\n    provider=\"openai\",\n    message=\"Hello, please reformulate the following query to make it more explicit and comprehensive: ${user_query}\",\n    system_instruction=\"You are a helpful assistant.\",\n)\n\ncard = PromptCard(prompt=prompt, space=\"opsml\", name=\"opsml\")\n\ncard.create_drift_profile(\n    alias=\"llm_drift\",\n    config=LLMDriftConfig(),\n    metrics=[\n        LLMDriftMetric(\n            name=\"reformulation_quality\",\n            prompt=create_reformulation_evaluation_prompt(), # (2)\n            value=3.0,\n            alert_threshold=AlertThreshold.Below, # (3)\n        )\n    ],\n)\n</code></pre> <ol> <li>The <code>create_reformulation_evaluation_prompt</code> function builds an evaluation prompt that we can use to assess the quality of query reformulations.</li> <li>We feed the reformulation evaluation prompt to the <code>LLMDriftMetric</code> to evaluate the quality of the reformulation.</li> <li>The <code>alert_threshold</code> is set to <code>Below</code>, meaning that if the score is below the threshold, an alert will be triggered. Given the value of 3.0, this means that if the score is below 3.0, an alert will be triggered.</li> </ol>"},{"location":"docs/monitoring/overview/#things-to-know","title":"Things to know","text":"<ul> <li>There is no need to specify <code>space</code>, <code>name</code> or <code>version</code> with your drift config. These are automatically set based on the <code>ModelCard</code> or <code>PromptCard</code> you are using.</li> </ul>"},{"location":"docs/setup/authentication/","title":"Authentication","text":"<p>For individuals and teams that wish to provide an additional layer of security to their applications, Opsml offers an opt-in authentication system.</p> <p>By default, all requests to Opsml use the guest username and password, <code>guest:guest</code> that is automatically created when the server is first started. If you wish to make this more strict, we encourage administrators to delete this user and create unique users via the CLI or the web interface.</p>"},{"location":"docs/setup/authentication/#opsml-authentication","title":"Opsml Authentication","text":"<p>Opsml authentication uses a JWT (JSON Web Token) based system. This means that users can authenticate once and receive a token that can be used for subsequent requests without needing to re-enter credentials. This is used for both programmatic access via the API and for the web interface. All Opsml requests are routed through an authentication middleware that checks and validates the JWT token before allowing access to the requested resource. </p>"},{"location":"docs/setup/authentication/#flow-programmatic-access","title":"Flow (Programmatic Access)","text":"<ol> <li>Client Instantiation: Upon the first instantiation of the Opsml client (this happens in the background), <code>OPSML_USERNAME</code> and <code>OPSML_PASSWORD</code> environment variables are used to authenticate the user.</li> <li>Token Retrieval: Credentials are passed to the server, which validates them. If valid, a new JWT access and refresh token pair are generated. The refresh token is stored on the server and the access token is returned to the client.</li> <li>Subsequent Requests: For all subsequent requests, the client uses the access token in the <code>Authorization</code> header as a Bearer token, which is automatically validated by the server authentication middleware.</li> <li>Token Expiry: If the access token expires and fails validation on the server, the server will attempt to check if the refresh token is still valid. Note: The refresh token has a longer expiry time than the access token. If the refresh token is valid, a new access token is generated and returned to the client. If the refresh token is also invalid, the user must re-authenticate.</li> </ol> <pre><code># Example of setting environment variables for authentication\nexport OPSML_USERNAME=\"your_username\"\nexport OPSML_PASSWORD=\"your_password\"\n</code></pre>"},{"location":"docs/setup/authentication/#flow-web-interface","title":"Flow (Web Interface)","text":"<ol> <li>Login Form: Users access the Opsml web interface and are presented with a login form.</li> <li>Credentials Submission: Users enter their credentials, which are sent to the server for validation.</li> <li>Token Generation: If the credentials are valid, the server generates a JWT access and refresh token pair.</li> <li>Session Management: The access token is stored in the browser's local storage or cookies, and is used for subsequent requests to the web interface.</li> <li>Token Expiry: Similar to programmatic access, if the access token expires, the server checks the validity of the refresh token. If valid, a new access token is generated; otherwise, the user must log in again.</li> </ol>"},{"location":"docs/setup/authentication/#single-sign-on-sso-authentication","title":"Single Sign-On (SSO) Authentication","text":"<p>Opsml also supports Single Sign-On (SSO) authentication using the OAuth2 and OIDC (OpenID Connect) protocols. This allows users to authenticate using their existing credentials from identity providers such as Okta and Keycloak.</p>"},{"location":"docs/setup/authentication/#setup-server","title":"Setup (Server)","text":"<p>To configure Opsml for SSO authentication, there are a few additional environment variables that need to be set when starting the Opsml server:</p> Variable Required By Description SSO_PROVIDER all The SSO provider to use. Current options are <code>default</code>, <code>keycloak</code> and <code>okta</code>. OPSML_CLIENT_ID all The client ID registered with the identity provider. OPSML_CLIENT_SECRET all The client secret registered with the identity provider. OPSML_REDIRECT_URI all The redirect URI for the application (must match the identity provider configuration). Note the standard callback for Opsml is <code>http://{{hostname}}/opsml/user/sso/callback</code> OPSML_AUTH_DOMAIN all The domain of the identity provider (e.g., <code>https://your-identity-provider.com</code>). OPSML_AUTH_SCOPE all The scopes to request from the identity provider (e.g., <code>openid profile email</code>). Default is <code>openid profile email</code>. OPSML_AUTH_REALM keycloak The Keycloak auth realm OPSML_AUTHORIZATION_SERVER_ID okta The Okta authorization server ID (if using a custom authorization server). OPSML_TOKEN_ENDPOINT default The token endpoint for the identity provider. OPSML_CERT_ENDPOINT default The certificate endpoint for the identity provider. OPSML_AUTHORIZATION_ENDPOINT default The authorization endpoint for the identity provider."},{"location":"docs/setup/authentication/#provider-types-and-examples","title":"Provider Types and Examples","text":"<p>Opsml supports multiple SSO provider types, each with its own configuration requirements. The following are the currently supported provider types (we will add more in the future):</p>"},{"location":"docs/setup/authentication/#default","title":"Default","text":"<p>This is a generic default provider type that can be used for most SSO providers.</p>"},{"location":"docs/setup/authentication/#example-configuration-using-auth0-as-an-example","title":"Example Configuration (using Auth0 as an example)","text":"<pre><code>export SSO_PROVIDER=default &amp;&amp; \\\nexport OPSML_CLIENT_ID=my-client-id &amp;&amp; \\\nexport OPSML_CLIENT_SECRET=my-client-secret &amp;&amp; \\\nexport OPSML_REDIRECT_URI={{opsml-server-domain}}/opsml/user/sso/callback &amp;&amp; \\\nexport OPSML_AUTH_DOMAIN={{auth0-domain}} &amp;&amp; \\\nexport OPSML_TOKEN_ENDPOINT=oauth/token &amp;&amp; \\\nexport OPSML_AUTHORIZATION_ENDPOINT=oauth/authorize &amp;&amp; \\\nexport OPSML_CERT_ENDPOINT=.well-known/jwks.json\n</code></pre>"},{"location":"docs/setup/authentication/#keycloak","title":"Keycloak","text":"<p>This provider type is specifically for Keycloak a popular open-source identity and access management solution.</p>"},{"location":"docs/setup/authentication/#example-configuration","title":"Example Configuration","text":"<pre><code>export SSO_PROVIDER=keycloak &amp;&amp; \\\nexport OPSML_CLIENT_ID=my-client-id &amp;&amp; \\\nexport OPSML_CLIENT_SECRET=my-client-secret &amp;&amp; \\\nexport OPSML_REDIRECT_URI={{opsml-server-domain}}/opsml/user/sso/callback &amp;&amp; \\\nexport OPSML_AUTH_DOMAIN={{keycloak-domain}} &amp;&amp; \\\nexport OPSML_AUTH_REALM={{keycloak-realm}}\n</code></pre>"},{"location":"docs/setup/authentication/#okta","title":"Okta","text":"<p>This provider type is specifically for Okta, a cloud-based identity management service.</p>"},{"location":"docs/setup/authentication/#example-configuration_1","title":"Example Configuration","text":"<pre><code>export SSO_PROVIDER=okta &amp;&amp; \\\nexport OPSML_CLIENT_ID=my-client-id &amp;&amp; \\\nexport OPSML_CLIENT_SECRET=my-client-secret &amp;&amp; \\\nexport OPSML_REDIRECT_URI={{opsml-server-domain}}/opsml/user/sso/callback &amp;&amp; \\\nexport OPSML_AUTH_DOMAIN={{okta-domain}} &amp;&amp; \\\nexport OPSML_AUTHORIZATION_SERVER_ID={{okta-auth-server-id}} # optional is using a custom server\n</code></pre>"},{"location":"docs/setup/authentication/#sso-flow-requirements","title":"SSO Flow Requirements","text":""},{"location":"docs/setup/authentication/#programmatic-access","title":"Programmatic Access","text":"<ul> <li> <p>Opsml requires Resource Owner Password Credentials (ROPC) grant type when authenticating through the opsml client in order authenticate without requiring users to manually enter their credentials or redirect them to the identity provider's login page. Because of this, it is recommended to run client workflows in secure environments.</p> </li> <li> <p>Users must provide their credentials (username and password) to the Opsml client via the <code>OPSML_USERNAME</code> and <code>OPSML_PASSWORD</code> environment variables as well as set <code>OPSML_USE_SSO</code> to <code>true</code>. The Opsml client will then use these credentials to authenticate with the identity provider and obtain an access token.</p> </li> </ul> <pre><code># Example of setting environment variables for authentication\nexport OPSML_USERNAME=\"your_username\"\nexport OPSML_PASSWORD=\"your_password\"\nexport OPSML_USE_SSO=\"true\"\n</code></pre>"},{"location":"docs/setup/authentication/#web-interface","title":"Web Interface","text":"<ul> <li>Opsml uses the Authorization Code Flow with PKCE (Proof Key for Code Exchange) to authenticate users via the web interface. This flow is more secure and is recommended for web applications.</li> <li>Users are redirected to the identity provider's login page, where they will be prompted to enter their credentials. For state and code validation, the Opsml server generates a random state and code verifier, which are stored in the session. After successful authentication, the user is redirected back to the Opsml web interface with an authorization code.</li> </ul>"},{"location":"docs/setup/authentication/#endpoints","title":"Endpoints","text":"<p>Opsml uses 2 main endpoints for SSO providers based on the OAuth2 and OIDC protocols. These endpoints are constructed based on the SSO provider configuration and the environment variables set in the Opsml server.</p> <ul> <li>Certificate Endpoint: This endpoint is used to retrieve the public keys used to verify the JWT tokens issued by the identity provider. NOTE: Opsml uses the JWK (JSON Web Key) format to retrieve the public keys, which are used to validate the JWT tokens received from the identity provider. As an example, this would be the <code>v1/keys</code> endpoint for Okta and the <code>protocol/openid-connect/certs</code> endpoint for Keycloak.</li> <li>Token Endpoint: This endpoint is used to obtain access and refresh tokens. NOTE: You must ensure your endpoint returns an <code>id_token</code> in the response. Opsml will generate its own JWT access token based on the <code>id_token</code> received from the identity provider. As an example, this would be the <code>v1/token</code> endpoint for Okta and the <code>protocol/openid-connect/token</code> endpoint for Keycloak.</li> <li>Authorization Endpoint: This endpoint is used to initiate the OAuth2 authorization code flow. Users are redirected to this endpoint to log in and authorize the application. Opsml uses the <code>code</code> response type to obtain an authorization code, which is then exchanged for tokens at the token endpoint.</li> </ul>"},{"location":"docs/setup/overview/","title":"Overview","text":""},{"location":"docs/setup/overview/#choose-your-adventure","title":"Choose your adventure","text":"<p>The recommended way to use opsml is to run the server separately and connect to it from your client. This allows you to take advantage of the full power of Opsml and its features. </p> <p>Client Mode Server Mode</p>"},{"location":"docs/setup/overview/#client-mode","title":"Client Mode","text":"<p>If you are connecting to an Opsml server that is already setup and running, all you need to do is set the <code>OPSML_TRACKING_URI</code> and you're good to go. </p> <pre><code>$ export OPSML_TRACKING_URI={your_server_uri}\n</code></pre> <p>You can also set the following optional environment variables if your server has authenitcation enabled: <pre><code>$ export OPSML_USERNAME={your_username}\n$ export OPSML_PASSWORD={your_password}\n</code></pre></p>"},{"location":"docs/setup/overview/#server-mode","title":"Server Mode","text":"<p>Depending on your use case there are a few different ways to setup and run the server.</p>"},{"location":"docs/setup/overview/#docker","title":"Docker","text":"<p>The recommended way to run the server is to use Docker or any other container service. With every release of opsml, we build and publish new container images that you can use to run the server and UI. You can find the latest images on Docker Hub. </p> <p>In most cases, you can run the server with the following command; however, you may wish to use our docker images as base images to build your own custom images.</p> <pre><code>$ docker run -p 8080:8000 demml/opsml:ubuntu-armd64-{version}\n</code></pre>"},{"location":"docs/setup/overview/#whats-in-the-container","title":"What's in the container?","text":"<p>The server container image is home to both the UI (sveltekit nodejs app) and the opsml server backend (Axum). The UI is always exposed on port <code>3000</code> and the server port is exposed on <code>8080</code>. NGINX is used as a reverse proxy to route requests to the appropriate service (see <code>docker/extras</code> folder for the NGINX configuration) and exposes everything on port <code>8000</code> (configurable through <code>OPSML_PORT</code>).</p> <p>Note: The container images are run through an entrypoint script that starts the UI, server, and NGINX services and ensures that they are all running properly. See <code>docker/official/extras/entrypoint.sh</code> for more details. The entrypoint does not make use of any process managers like <code>supervisord</code> or <code>systemd</code> as we prefer the container orchestration system (e.g., Kubernetes etc.) to handle process management.</p>"},{"location":"docs/setup/overview/#binary","title":"Binary","text":"<p>In addition to docker images, we also build and publish new binaries with every release of opsml. These can be download via github and executed directly. </p>"},{"location":"docs/setup/overview/#development","title":"Development","text":"<p>As mentioned in the installation section, you can also start the server via the CLI; however, this is not recommended for production use cases as it requires a python runtime to be installed. We recommend using the prebuilt containers for production use cases as they only require node (pre-installed in the container) to run the UI and the opsml server binary.</p> <p>Note</p> <p>While the opsml CLI is written in Rust, it is exposed via PyO3 and requires a python runtime to be installed. Node will also be required to run the UI locally.</p> <pre><code>$ opsml start ui\n</code></pre>"},{"location":"docs/setup/overview/#running-the-server","title":"Running the Server","text":"<p>opsml supports multiple backends for both the database and storage client. By default, opsml will use SQLite for the database and local file storage for the storage backend. You can change this by setting the <code>OPSML_TRACKING_URI</code> and <code>OPSML_STORAGE_URI</code> environment variables, respectively.</p> <p>To run the server with a different database backend, you can set the <code>OPSML_TRACKING_URI</code> environment variable to the desired backend. For example, to use Postgres, you can set the following environment variable:</p> <pre><code>$ export OPSML_TRACKING_URI=postgresql://user:password@localhost:5432/opsml\n</code></pre> <p>Supported Database backends:</p> <ul> <li>SQLite</li> <li>Postgres</li> <li>MySQL</li> </ul> <p>To run the server with a different storage backend, you can set the <code>OPSML_STORAGE_URI</code> environment variable to the desired backend. For example, to use S3, you can set the following environment variable:</p> <pre><code>$ export OPSML_STORAGE_URI=s3://bucket-name\n</code></pre> <p>Supported Storage backends:</p> <ul> <li>Local File Storage</li> <li>S3</li> <li>GCS</li> <li>Azure Blob Storage</li> </ul> <p>Info</p> <p>Ensure the required storage credentials are set appropriately in your environment</p>"},{"location":"docs/setup/overview/#storage-credentials","title":"Storage Credentials","text":""},{"location":"docs/setup/overview/#google-cloud-storage","title":"Google Cloud Storage","text":"<ul> <li><code>GOOGLE_ACCOUNT_JSON_BASE64</code>: Environment variables that contains the base64 encoded JSON key for the service account.</li> <li><code>GOOGLE_APPLICATION_CREDENTIALS_JSON</code>: Environment variable that contains the JSON key for the service account.</li> <li><code>GOOGLE_APPLICATION_CREDENTIALS</code>: Environment variable that contains the path to the credential file.</li> </ul>"},{"location":"docs/setup/overview/#amazon-s3","title":"Amazon S3","text":"<ul> <li>Opsml uses the aws_sdk_s3 and aws_config crates to handle S3 storage. Thus, all credential configurations supported by the rust crate are supported by opsml.</li> </ul>"},{"location":"docs/setup/overview/#azure-blob-storage","title":"Azure Blob Storage","text":"<ul> <li> <p>Opsml uses the azure-identity crate to handle authentication.</p> </li> <li> <p>In addition to credentials, to use Azure Blob Storage, you will need to set the following environment variable:</p> <ul> <li><code>AZURE_STORAGE_ACCOUNT</code>: The name of the storage account.</li> </ul> </li> </ul>"},{"location":"docs/setup/overview/#environment-variables","title":"Environment Variables","text":"<p>Apart from the <code>OPSML_TRACKING_URI</code> and <code>OPSML_STORAGE_URI</code> environment variables, there are a few other environment variables that you can set to configure the server to your liking.</p>"},{"location":"docs/setup/overview/#opsml-server-environment-variables","title":"OpsML Server Environment Variables","text":"<ul> <li><code>APP_ENV</code>: The current environment. This can be set to <code>development</code>, <code>staging</code> or <code>production</code> or anything else you'd want. The default is <code>development</code>.</li> <li><code>OPSML_PORT</code>: The port that the container will run on. The default is <code>8000</code>.</li> <li><code>OPSML_ENCRYPT_KEY</code>: The master encryption key used to encrypt the data at rest. If not set, opsml will use a default deterministic key. This is not recommended for production use cases. opsml requires a pbdkdf2::HmacSha256 key with a length of 32 bytes. You can generate a key using the following command with the opsml CLI:</li> </ul> <pre><code>$ opsml generate key --password {your_password}\n</code></pre> <p>The encryption key (aka jwt_key) is one of the most important pieces to opsml's security system. It is used to derive new keys for each artifact, which in-turn are used to encrypt data, and is used generate short-lived JWT tokens for authentication.</p> <ul> <li><code>OPSML_REFRESH_SECRET</code>: The secret used to sign the refresh tokens. This is used to verify the integrity of the refresh tokens. If not set, opsml will use a default deterministic key. This is not recommended for production use cases. opsml requires a pbdkdf2::HmacSha256 key with a length of 32 bytes. You can generate a key similar to the <code>OPSML_ENCRYPT_KEY</code> key.</li> <li><code>OPSML_MAX_POOL_CONNECTIONS</code>: The maximum number of connections to the database. The default is <code>10</code>.</li> <li><code>LOG_LEVEL</code>: The log level for the server and UI. This can be set to <code>error</code>, <code>warn</code>, <code>info</code>, <code>debug</code> or <code>trace</code>. The default is <code>info</code>.</li> <li><code>LOG_JSON</code>: Whether to log in JSON format or not. This can be set to <code>true</code> or <code>false</code>. The default is <code>false</code>.</li> </ul>"},{"location":"docs/setup/overview/#scouter-environment-variables","title":"Scouter Environment Variables","text":"<p>If you are configuring opsml to use Scouter for model monitoring, you will need to set the following environment variables as well:</p> <ul> <li><code>SCOUTER_SERVER_URI</code>: The host of the Scouter server.</li> <li><code>SCOUTER_AUTH_TOKEN</code>: The secret token used to authenticate with the Scouter server and exchange refresh tokens. This is used to verify the integrity of the Scouter tokens. If not set, opsml will use a default deterministic key. In keeping with the other opsml secret keys, the <code>SCOUTER_AUTH_TOKEN</code> is a pbdkdf2::HmacSha256 key with a length of 32 bytes. You can generate a key similar to the <code>OPSML_ENCRYPT_KEY</code> key if you haven't already done so.</li> <li><code>SCOUTER_BOOTSTRAP_TOKEN</code>: The bootstrap token is used to sync users across both OpsML and Scouter. This is also a pbdkdf2::HmacSha256 key with a length of 32 bytes. You can generate a key similar to the <code>OPSML_ENCRYPT_KEY</code> key if you haven't already done so.</li> </ul>"},{"location":"docs/specs/Readme/","title":"Technical Specifications","text":"<p>This directory contains various technical specifications for OpsML. It is an ongoing effort to document the architecture, design decisions, changes, and other important aspects of the project. It is NOT feature complete and is subject to change as the project evolves.</p> <p>Note: Specifications are written in markdown format and should be easy to read and understand. And while they are recommended for big changes, they are not mandatory.</p>"},{"location":"docs/specs/Readme/#writing-specifications","title":"Writing Specifications","text":"<p>When writing specifications, please follow these guidelines for structure:</p> <pre><code># Title\n\n## Overview\nSimple and concise overview of the specification, including its purpose and scope.\n\n## Key Changes: A brief overview of the specification, including its purpose and scope.\n\n## Implementation Details\n- Detailed description of the implementation, including code snippets and examples.\n- Explanation of any design decisions, trade-offs, and alternatives considered.\n- This part is more flexible and is up to the author to decide how to structure it as long as it is clear and easy to understand.\n\n\n---\n*Version: 1.0*  \n*Last Updated: [date- YYY-MM-DD]*  \n*Author: [Your name]*\n</code></pre>"},{"location":"docs/specs/Readme/#naming-conventions","title":"Naming Conventions","text":""},{"location":"docs/specs/Readme/#feature-based-specifications","title":"Feature-based Specifications","text":"<ul> <li>Feature-based specifications should be named after the feature they are describing. For example, if you are writing a specification for a new feature called \"FeatureX\", the file name should be <code>ts-feature-feature_x.md</code>. This will help in organizing and locating specifications easily.</li> <li>Format: <code>ts-feature-feature_name.md</code></li> </ul>"},{"location":"docs/specs/Readme/#component-based-specifications","title":"Component-based Specifications","text":"<ul> <li>Component-based specifications should be named after the component they are describing. For example, if you are writing a specification for a component called \"ComponentY\", the file name should be <code>ts-component-component_y.md</code>. This will help in organizing and locating specifications easily.</li> <li>Format: <code>ts-component-component_name.md</code></li> </ul>"},{"location":"docs/specs/Readme/#issue-based-specifications","title":"Issue-based Specifications","text":"<ul> <li>Issue-based specifications should be named after the issue they are describing. For example, if you are writing a specification for an issue number 1234, the file name should be <code>ts-issue-1234.md</code>. This will help in organizing and locating specifications easily.</li> <li>Format: <code>ts-issue-number.md</code></li> </ul>"},{"location":"docs/specs/ts-component-auditing/","title":"Technical Component Specification: Audit Events","text":""},{"location":"docs/specs/ts-component-auditing/#overview","title":"Overview","text":"<p>The Audit Events system provides comprehensive tracking and logging of system operations and is integrated with the OpsML server EventBus. The goal of Audit logging is to capture relevant information about how the OpsML server is being used and operational details. Audit events are currently opt-in and will expand as the server evolves.</p> <p>Audit event capture is integrated via an audit middleware that parses response extensions for <code>AuditContext</code>. If <code>AuditContext</code> is present, it is extracted and used to create an <code>AuditEvent</code>. The event is then sent to the <code>EventBus</code> for asynchronous processing and storage in the connected SQL database. Thus for a server route to become <code>auditable</code>, it must return an <code>AuditContext</code> in the response extensions. Note that the <code>AuditContext</code> is a custom response extension and is removed after it is processed and is not exposed to the client.</p>"},{"location":"docs/specs/ts-component-auditing/#component-definition","title":"Component Definition","text":"<pre><code>pub struct AuditContext {\n    pub resource_id: String,\n    pub resource_type: ResourceType,\n    pub metadata: String,\n    pub operation: Operation,\n    pub registry_type: Option&lt;RegistryType&gt;,\n    pub access_location: Option&lt;String&gt;,\n}\n\npub struct AuditEvent {\n    pub username: String,\n    pub client_ip: String,\n    pub user_agent: String,\n    pub operation: Operation,\n    pub resource_type: ResourceType,\n    pub resource_id: String,\n    pub access_location: Option&lt;String&gt;,\n    pub status: AuditStatus,\n    pub error_message: Option&lt;String&gt;,\n    pub metadata: String,\n    pub registry_type: Option&lt;RegistryType&gt;,\n    pub route: String,\n}\n</code></pre>"},{"location":"docs/specs/ts-component-auditing/#core-responsibilities","title":"Core Responsibilities","text":"<ol> <li>Event Creation</li> <li>Request context capture</li> <li>User identification</li> <li>Operation tracking</li> <li> <p>Resource monitoring</p> </li> <li> <p>Audit Context Management</p> </li> <li>Resource tracking</li> <li>Operation classification</li> <li>Registry type handling</li> <li> <p>Metadata collection</p> </li> <li> <p>Event Persistence</p> </li> <li>Asynchronous storage</li> <li>SQL backend integration</li> <li>Error handling</li> <li>Event querying</li> </ol>"},{"location":"docs/specs/ts-component-auditing/#key-methods","title":"Key Methods","text":""},{"location":"docs/specs/ts-component-auditing/#event-creation","title":"Event Creation","text":"<pre><code>pub fn create_audit_event(\n    addr: SocketAddr,\n    agent: UserAgent,\n    headers: HeaderMap,\n    route: String,\n    context: AuditContext,\n) -&gt; AuditEvent\n</code></pre>"},{"location":"docs/specs/ts-component-auditing/#event-logging","title":"Event Logging","text":"<pre><code>pub async fn log_audit_event(\n    event: AuditEvent,\n    sql_client: Arc&lt;SqlClientEnum&gt;,\n) -&gt; Result&lt;(), EventError&gt;\n</code></pre>"},{"location":"docs/specs/ts-component-auditing/#dependencies","title":"Dependencies","text":"<ul> <li>External Crates</li> <li><code>axum</code>: Web framework integration</li> <li><code>headers</code>: HTTP header handling</li> <li><code>tracing</code>: Logging and instrumentation</li> <li> <p><code>sqlx</code>: Database operations</p> </li> <li> <p>Internal Components</p> </li> <li><code>SqlClient</code>: Database interface</li> <li><code>EventBus</code>: Event distribution</li> <li><code>EventError</code>: Error handling</li> </ul>"},{"location":"docs/specs/ts-component-auditing/#error-handling","title":"Error Handling","text":"<ul> <li>Custom <code>EventError</code> type</li> <li>SQL operation error handling</li> <li>Debug logging for failures</li> <li>Error context preservation</li> </ul>"},{"location":"docs/specs/ts-component-auditing/#security-considerations","title":"Security Considerations","text":"<ol> <li>User Tracking</li> <li>Username capture</li> <li>IP address logging</li> <li>User agent recording</li> <li> <p>Access location tracking</p> </li> <li> <p>Operation Auditing</p> </li> <li>Resource access logging</li> <li>Operation classification</li> <li>Status tracking</li> <li> <p>Error message capture</p> </li> <li> <p>Data Privacy</p> </li> <li>Sensitive data handling</li> <li>User information protection</li> <li>Access control integration</li> </ol>"},{"location":"docs/specs/ts-component-auditing/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Asynchronous Processing</li> <li>Non-blocking event creation</li> <li>Async database operations</li> <li> <p>Efficient event distribution</p> </li> <li> <p>Resource Usage</p> </li> <li>Minimal memory overhead</li> <li>Shared SQL connection via server AppState</li> </ol>"},{"location":"docs/specs/ts-component-auditing/#future-considerations","title":"Future Considerations","text":"<ol> <li>Event aggregation capabilities</li> <li>Enhanced filtering options</li> <li>Real-time audit monitoring</li> <li>Advanced security features</li> <li>Audit data analysis tools</li> <li>Compliance reporting features</li> </ol> <p>Version: 1.0 Last Updated: 2025-04-04 Component Owner: Steven Forrester</p>"},{"location":"docs/specs/ts-component-cardservice/","title":"Technical Component Specification: ServiceCard","text":""},{"location":"docs/specs/ts-component-cardservice/#overview","title":"Overview","text":"<p>The ServiceCard is a primary interface for managing collections of <code>Cards</code> in <code>OpsML</code>. It's primary use-case is at the application-level where a user may want to attach multiple cards to a given service (e.g. an api). For instance, if a user has an api that requires 4 different models or an agentic workflow that requires 5 different prompts, the <code>ServiceCard</code> can greatly streamline managing and loading these cards within a service. Similar to all cards, a <code>ServiceCard</code> is versioned and can be registered with the OpsML registry. This allows for easy tracking of changes to the service card over time.</p>"},{"location":"docs/specs/ts-component-cardservice/#key-changes","title":"Key Changes","text":"<ul> <li>Introduction of the ServiceCard struct and python class for managing collections of different card types</li> <li>Support for saving and loading complete card collections with a single operation</li> <li>Card aliasing system for convenient access to individual cards</li> <li>Implementation of Pythonic interfaces for iteration and dictionary-like access</li> <li>Serialization/deserialization support for persistence</li> <li>CLI integration for registering/locking and downloading artifacts</li> </ul>"},{"location":"docs/specs/ts-component-cardservice/#implementation-details","title":"Implementation Details","text":""},{"location":"docs/specs/ts-component-cardservice/#core-components","title":"Core Components","text":""},{"location":"docs/specs/ts-component-cardservice/#servicecard","title":"ServiceCard","text":"<pre><code>#[pyclass]\n#[derive(Debug)]\npub struct ServiceCard {\n    #[pyo3(get, set)]\n    pub space: String,\n    #[pyo3(get, set)]\n    pub name: String,\n    #[pyo3(get, set)]\n    pub version: String,\n    #[pyo3(get, set)]\n    pub uid: String,\n    #[pyo3(get, set)]\n    pub created_at: DateTime&lt;Utc&gt;,\n    #[pyo3(get)]\n    pub cards: CardList,\n    #[pyo3(get)]\n    pub opsml_version: String,\n    #[pyo3(get, set)]\n    pub app_env: String,\n    #[pyo3(get)]\n    pub is_card: bool,\n    #[pyo3(get)]\n    pub registry_type: RegistryType,\n    // Holds the actual card objects (ModelCard, DataCard, etc.)\n    pub card_objs: HashMap&lt;String, Py&lt;PyAny&gt;&gt;,\n}\n</code></pre> <p>The <code>ServiceCard</code> struct contains the following fields: - <code>space</code>: The space to which the service card belongs - <code>name</code>: The name of the service card - <code>version</code>: The version of the service card - <code>uid</code>: A unique identifier for the service card - <code>created_at</code>: The timestamp when the service card was created - <code>cards</code>: A collection of cards (CardList) - <code>opsml_version</code>: The version of OpsML used - <code>app_env</code>: The application environment (e.g., production, development) - <code>is_card</code>: A boolean indicating if the service card is a card itself - <code>registry_type</code>: The type of registry (e.g., Model, Data, Service) - <code>card_objs</code>: A HashMap holding the actual card objects (e.g., ModelCard, DataCard)</p>"},{"location":"docs/specs/ts-component-cardservice/#cardlist","title":"CardList","text":"<pre><code>#[pyclass(eq)]\n#[derive(Debug, PartialEq, Serialize, Deserialize, Clone)]\npub struct CardList {\n    #[pyo3(get)]\n    pub cards: Vec&lt;Card&gt;,\n}\n</code></pre> <p>The <code>CardList</code> is a holder for Card entries in a <code>ServiceCard</code> and implements Pythonic dunders for ergonomic access via python: - <code>__iter__</code> for iteration over cards - <code>__len__</code> to get collection size - <code>__getitem__</code> for index-based access - IntoIterator for Rust-side iteration</p>"},{"location":"docs/specs/ts-component-cardservice/#card","title":"Card","text":"<p><pre><code>#[pyclass(eq)]\n#[derive(Debug, PartialEq, Serialize, Deserialize, Clone)]\npub struct Card {\n    #[pyo3(get, set)]\n    pub space: String,\n    #[pyo3(get, set)]\n    pub name: String,\n    #[pyo3(get, set)]\n    pub version: String,\n    #[pyo3(get, set)]\n    pub uid: String,\n    #[pyo3(get, set)]\n    pub registry_type: RegistryType,\n    #[pyo3(get, set)]\n    pub alias: String,\n}\n</code></pre> The Card struct represents references to actual card objects and can be created in multiple ways: - From an existing/registered card object - By specifying a registry type and identifier information (space, name, version, uid, etc.)   - In this case, a user must supply (space + name + version (optional) + registry_type) or (uid + registry_type) to create a card reference.</p>"},{"location":"docs/specs/ts-component-cardservice/#how-it-works","title":"How It Works","text":""},{"location":"docs/specs/ts-component-cardservice/#loading-a-servicecard-and-cards","title":"Loading a ServiceCard and Cards","text":"<pre><code>pub fn load&lt;'py&gt;(\n    &amp;mut self,\n    py: Python&lt;'py&gt;,\n    load_kwargs: Option&lt;HashMap&lt;String, Bound&lt;'_, PyAny&gt;&gt;&gt;,\n) -&gt; PyResult&lt;()&gt;\n</code></pre> <p>As with all cards, the <code>ServiceCard</code> is loaded lazily. The <code>load</code> method takes a dictionary of keyword arguments for each card by their <code>alias</code>. The keyword arguments are passed to the respective card's <code>load</code> method. Note - this method can only be called after the <code>ServiceCard</code> has been loaded from the registry.</p>"},{"location":"docs/specs/ts-component-cardservice/#download-artifacts","title":"Download Artifacts","text":"<pre><code>#[pyo3(signature = (path=None))]\npub fn download_artifacts(&amp;mut self, py: Python, path: Option&lt;PathBuf&gt;) -&gt; PyResult&lt;()&gt;\n</code></pre> <p>Downloads all artifacts associated with all cards in the service to the specified path with the structure: <pre><code>{base_path}/\n\u251c\u2500\u2500 card.json                # ServiceCard metadata\n\u251c\u2500\u2500 {alias1}/                # Files for the first card\n\u2502   \u2514\u2500\u2500 card.json            # First card metadata\n\u251c\u2500\u2500 {alias2}/                # Files for the second card\n\u2502   \u2514\u2500\u2500 card.json            # Second card metadata\n\u2514\u2500\u2500 ...\n</code></pre></p> <p>Note: While this method is publicly available for convenience, there is no need to call it directly when loading Card artifacts as the <code>load</code> method will automatically download all artifacts to their respective paths.</p>"},{"location":"docs/specs/ts-component-cardservice/#dictionary-like-access","title":"Dictionary-like Access","text":"<pre><code>pub fn __getitem__&lt;'py&gt;(&amp;self, py: Python&lt;'py&gt;, key: &amp;str) -&gt; PyResult&lt;Bound&lt;'py, PyAny&gt;&gt;\n</code></pre> <p>Enables Python-side dictionary-style access to cards using their aliases: <pre><code># Access a model card with alias \"model\"\nmodel = service[\"model\"]\n</code></pre></p>"},{"location":"docs/specs/ts-component-cardservice/#serialization-support","title":"Serialization Support","text":"<p>The ServiceCard includes custom serialization/deserialization implementations to handle: - Python object references that can't be directly serialized - Restoration of object state when loading from JSON - Proper handling of PyObject references in a memory-safe way</p>"},{"location":"docs/specs/ts-component-cardservice/#integration-with-opsml-card-system","title":"Integration with OpsML Card System","text":"<p>The ServiceCard implements the <code>OpsmlCard</code> trait <pre><code>impl OpsmlCard for ServiceCard {\n    fn get_registry_card(&amp;self) -&gt; Result&lt;CardRecord, CardError&gt; {\n        self.get_registry_card()\n    }\n    // Additional trait methods...\n}\n</code></pre></p> <p>This enables the ServiceCard to be created and registered directly from Rust. This trait is utilized when leveraging the opsml cli.</p>"},{"location":"docs/specs/ts-component-cardservice/#usage-examples","title":"Usage Examples","text":""},{"location":"docs/specs/ts-component-cardservice/#python-side-usage","title":"Python-side Usage","text":"<pre><code># Creating a new ServiceCard\nregistry = CardRegistry(RegistryType.Service)\n\nservice = ServiceCard(\n    space=\"test\",\n    name=\"test\",\n    cards=[\n        Card(\n            alias=\"model\",\n            uid=modelcard.uid,\n            registry_type=RegistryType.Model,\n        ),\n        Card(\n            alias=\"prompt\",\n            card=promptcard,  # Direct card reference\n        ),\n    ],\n)\n\n# Registration\nregistry.register_card(service)\n\n# Accessing cards by alias\nmodel = service[\"model\"]\ndata = service[\"prompt\"]\n\n# Loading ServiceCard from the registry\nloaded_service = registry.load_card(uid=service.uid)\n\n# Load card\nloaded_service.load()\n\n# Load card example with kwargs (pass modelkwargs to load onnx)\nloaded_service.load({\"model\": ModelLoadKwargs(load_onnx=True)})\n\n\n# Loading from filesystem (assume artifacts are already downloaded to path)\nloaded_service = ServiceCard.from_path(\"my_service\")\n\nloaded_service[\"model\"].model # access the model\nloaded_service[\"prompt\"].prompt # access the prompt\n</code></pre>"},{"location":"docs/specs/ts-component-cardservice/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Memory Management</li> <li>PyObject references are tracked and managed through PyO3's memory management</li> <li> <p>The <code>__traverse__</code> and <code>__clear__</code> methods ensure proper garbage collection.</p> </li> <li> <p>Storage Efficiency</p> </li> <li>Only references to cards are stored in the ServiceCard metadata</li> <li>Actual card objects are loaded/downloaded on demand</li> <li>PyObjects are bound to python objects to avoid unnecessary copies</li> </ol> <p>Version: 1.0 Last Updated: 2025-07-08 Author: Steven Forrester</p>"},{"location":"docs/specs/ts-component-eventbus/","title":"Technical Component Specification: EventBus","text":""},{"location":"docs/specs/ts-component-eventbus/#overview","title":"Overview","text":"<p>The <code>EventBus</code> serves as a central event system to be used with the OpsML server to record events. It provides asynchronous event distribution using Tokio's broadcast channel, and it enables decoupled communication between different parts of the system, particularly for audit logging and monitoring.</p>"},{"location":"docs/specs/ts-component-eventbus/#component-definition","title":"Component Definition","text":"<pre><code>#[derive(Clone)]\npub struct EventBus {\n    tx: broadcast::Sender&lt;Event&gt;,\n}\n\npub enum Event {\n    Audit(AuditEvent),\n    // Extensible for future event types\n}\n</code></pre>"},{"location":"docs/specs/ts-component-eventbus/#core-responsibilities","title":"Core Responsibilities","text":"<ol> <li> <p>Event Distribution</p> <ul> <li>Asynchronous event broadcasting</li> <li>Multiple subscriber support</li> <li>Non-blocking event publishing</li> <li>Event type management</li> </ul> </li> <li> <p>Stream Management</p> <ul> <li>Stream-based event subscription</li> <li>Automatic error filtering</li> <li>Broadcast channel capacity control</li> <li>Subscriber lifecycle management</li> </ul> </li> <li> <p>Event Type Handling</p> <ul> <li>Support for different event types</li> <li>Type-safe event distribution</li> <li>Event filtering capabilities</li> <li>Extensible event system</li> </ul> </li> </ol>"},{"location":"docs/specs/ts-component-eventbus/#use-cases","title":"Use Cases","text":"<ul> <li>Audit Logging: Capture and record system events for auditing purposes.</li> </ul>"},{"location":"docs/specs/ts-component-eventbus/#key-methods","title":"Key Methods","text":""},{"location":"docs/specs/ts-component-eventbus/#constructor","title":"Constructor","text":"<pre><code>pub fn new(capacity: usize) -&gt; Self {\n    let (tx, _) = broadcast::channel(capacity);\n    Self { tx }\n}\n</code></pre>"},{"location":"docs/specs/ts-component-eventbus/#core-operations","title":"Core Operations","text":"<pre><code>pub fn publish(&amp;self, event: Event)\npub fn subscribe(&amp;self) -&gt; impl Stream&lt;Item = Event&gt;\n</code></pre>"},{"location":"docs/specs/ts-component-eventbus/#dependencies","title":"Dependencies","text":"<ul> <li> <p>External Crates</p> <ul> <li><code>tokio</code>: Async runtime and broadcast channel</li> <li><code>futures</code>: Stream trait implementations</li> <li><code>tokio-stream</code>: Stream wrappers</li> <li><code>tracing</code>: Logging and instrumentation</li> </ul> </li> <li> <p>Internal Components</p> <ul> <li><code>Event</code>: Event type enum</li> <li><code>AuditEvent</code>: Audit event structure</li> <li><code>EventError</code>: Error handling</li> </ul> </li> </ul>"},{"location":"docs/specs/ts-component-eventbus/#error-handling","title":"Error Handling","text":"<ul> <li>Silent error handling for send operations</li> <li>Stream filtering for failed receives</li> <li>Debug logging for event operations</li> <li>Custom <code>EventError</code> type</li> </ul>"},{"location":"docs/specs/ts-component-eventbus/#thread-safety","title":"Thread Safety","text":"<ul> <li>Thread-safe event broadcasting</li> <li>Clone-able event bus instance</li> <li>Safe multi-subscriber support</li> <li>Atomic broadcast operations</li> </ul>"},{"location":"docs/specs/ts-component-eventbus/#performance-considerations","title":"Performance Considerations","text":"<ol> <li> <p>Channel Capacity</p> <ul> <li>Configurable buffer size</li> </ul> </li> <li> <p>Concurrency</p> <ul> <li>Non-blocking operations</li> <li>Multiple concurrent subscribers</li> <li>Efficient event distribution</li> </ul> </li> <li> <p>Resource Management</p> <ul> <li>Automatic cleanup of dropped subscribers (via Tokio)</li> <li>Pattern matching for event types</li> </ul> </li> </ol>"},{"location":"docs/specs/ts-component-eventbus/#future-considerations","title":"Future Considerations","text":"<ol> <li>Event persistence options</li> <li>Priority-based event handling</li> <li>Event batching capabilities</li> <li>Enhanced filtering mechanisms</li> <li>Subscriber backpressure handling</li> <li>Event replay functionality</li> </ol> <p>Version: 1.0 Last Updated: 2025-08-05 Component Owner: Steven Forrester</p>"},{"location":"docs/specs/ts-component-experiment/","title":"Technical Component Specification: Experiment Struct","text":""},{"location":"docs/specs/ts-component-experiment/#overview","title":"Overview","text":"<p>The <code>Experiment</code> struct serves as a core component for managing machine learning experiments in the OPSML framework, providing Python bindings through PyO3 and handling experiment lifecycle, metrics, parameters, and artifact management.</p>"},{"location":"docs/specs/ts-component-experiment/#component-definition","title":"Component Definition","text":"<pre><code>#[pyclass]\npub struct Experiment {\n    pub experiment: Py&lt;PyAny&gt;,\n    pub registries: CardRegistries,\n    pub hardware_queue: Option&lt;HardwareQueue&gt;,\n    uid: String,\n    artifact_key: ArtifactKey,\n}\n</code></pre>"},{"location":"docs/specs/ts-component-experiment/#core-responsibilities","title":"Core Responsibilities","text":"<ol> <li>Experiment Lifecycle Management</li> <li>Creation and initialization of experiments</li> <li>Support for parent/child experiment relationships</li> <li>Proper cleanup and resource management</li> <li> <p>Context manager support (<code>__enter__</code>/<code>__exit__</code>)</p> </li> <li> <p>Hardware Monitoring</p> </li> <li>Optional hardware metrics collection</li> <li>Background metric collection through <code>HardwareQueue</code></li> <li> <p>Automatic cleanup of monitoring resources</p> </li> <li> <p>Artifact Management</p> </li> <li>Code extraction and storage</li> <li>File encryption/decryption</li> <li>Support for single and multiple artifact logging</li> <li> <p>Path normalization and validation</p> </li> <li> <p>Metric and Parameter Logging</p> </li> <li>Synchronous metric logging</li> <li>Parameter logging with type safety</li> <li>Batch logging support</li> <li>Timestamp and step tracking</li> </ol>"},{"location":"docs/specs/ts-component-experiment/#key-methods","title":"Key Methods","text":""},{"location":"docs/specs/ts-component-experiment/#constructor","title":"Constructor","text":"<pre><code>pub fn new(\n    py: Python,\n    experiment: Py&lt;PyAny&gt;,\n    registries: CardRegistries,\n    log_hardware: bool,\n    code_dir: Option&lt;PathBuf&gt;,\n    experiment_uid: String,\n) -&gt; PyResult&lt;Self&gt;\n</code></pre>"},{"location":"docs/specs/ts-component-experiment/#core-operations","title":"Core Operations","text":"<pre><code>fn create_experiment&lt;'py&gt;(\n    py: Python&lt;'py&gt;,\n    space: Option&lt;&amp;str&gt;,\n    name: Option&lt;&amp;str&gt;,\n    registries: &amp;mut CardRegistries,\n    subexperiment: bool,\n) -&gt; PyResult&lt;(Bound&lt;'py, PyAny&gt;, String)&gt;\n\nfn load_experiment&lt;'py&gt;(\n    py: Python&lt;'py&gt;,\n    experiment_uid: &amp;str,\n    registries: &amp;mut CardRegistries,\n) -&gt; PyResult&lt;Bound&lt;'py, PyAny&gt;&gt;\n</code></pre>"},{"location":"docs/specs/ts-component-experiment/#logging-methods","title":"Logging Methods","text":"<pre><code>pub fn log_metric(\n    &amp;self,\n    name: String,\n    value: f64,\n    step: Option&lt;i32&gt;,\n    timestamp: Option&lt;i64&gt;,\n    created_at: Option&lt;DateTime&lt;Utc&gt;&gt;,\n) -&gt; PyResult&lt;()&gt;\n\npub fn log_artifact(&amp;self, path: PathBuf) -&gt; PyResult&lt;()&gt;\n</code></pre>"},{"location":"docs/specs/ts-component-experiment/#dependencies","title":"Dependencies","text":"<ul> <li>External Crates</li> <li><code>pyo3</code>: Python bindings</li> <li><code>chrono</code>: Time management</li> <li><code>tokio</code>: Async runtime</li> <li> <p><code>tracing</code>: Logging and instrumentation</p> </li> <li> <p>Internal Components</p> </li> <li><code>HardwareQueue</code>: Hardware metric collection</li> <li><code>CardRegistries</code>: Registry management</li> <li><code>OpsmlRegistry</code>: Registry operations</li> <li><code>ExperimentCard</code>: Experiment metadata</li> </ul>"},{"location":"docs/specs/ts-component-experiment/#error-handling","title":"Error Handling","text":"<ul> <li>Uses <code>PyResult</code> for Python integration</li> <li>Custom error types:</li> <li><code>ExperimentError</code></li> <li><code>OpsmlError</code></li> <li>Debug logging for error tracking</li> </ul>"},{"location":"docs/specs/ts-component-experiment/#thread-safety","title":"Thread Safety","text":"<ul> <li>Uses <code>Arc</code> for shared ownership</li> <li>Safe background task management</li> <li>Proper resource cleanup</li> </ul>"},{"location":"docs/specs/ts-component-experiment/#python-integration","title":"Python Integration","text":""},{"location":"docs/specs/ts-component-experiment/#exposed-methods","title":"Exposed Methods","text":"<pre><code># Creation\nstart_experiment(space=None, name=None, code_dir=None, log_hardware=False, experiment_uid=None)\n\n# Logging\nlog_metric(name, value, step=None, timestamp=None, created_at=None)\nlog_metrics(metrics)\nlog_parameter(name, value)\nlog_parameters(parameters)\nlog_artifact(path)\nlog_artifacts(path)\n</code></pre>"},{"location":"docs/specs/ts-component-experiment/#context-manager-support","title":"Context Manager Support","text":"<ul> <li>The recommended way to use the <code>Experiment</code> class is through the <code>start_experiment</code> function, which returns an instance of <code>Experiment</code>.</li> </ul> <pre><code>with start_experiment(...) as exp:\n    exp.log_metric(...)\n</code></pre>"},{"location":"docs/specs/ts-component-experiment/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Memory Management</li> <li>Efficient PyObject handling</li> <li>Proper cleanup of resources</li> <li> <p>Minimal cloning of data</p> </li> <li> <p>Concurrency</p> </li> <li>Background hardware monitoring</li> <li>Non-blocking operations where possible</li> <li> <p>Resource sharing through Arc</p> </li> <li> <p>File Operations</p> </li> <li>Efficient artifact handling</li> <li>Proper encryption/decryption</li> <li>Stream-based file operations</li> </ol>"},{"location":"docs/specs/ts-component-experiment/#future-considerations","title":"Future Considerations","text":"<ol> <li>Async logging operations</li> <li>Enhanced hardware metrics</li> <li>Improved artifact compression</li> <li>Batch operation optimizations</li> <li>Enhanced error recovery</li> <li>Metric aggregation features</li> </ol> <p>Version: 1.0 Last Updated: 2025-04-02 Component Owner: Steven Forrester</p>"},{"location":"docs/specs/ts-evaluations/","title":"Technical Component Specification: Evaluations","text":""},{"location":"docs/specs/ts-evaluations/#overview","title":"Overview","text":"<p>The Evaluations component in OpsML is designed to facilitate the assessment and benchmarking of machine learning models and agentic systems. It provides a structured way to define, execute, and store evaluation results, enabling users to compare different models and workflows effectively. This component is crucial for maintaining high standards in model performance and ensuring that deployed systems meet the desired criteria.</p>"},{"location":"docs/specs/ts-evaluations/#user-steps","title":"User Steps","text":"<ol> <li>Define Evaluation Criteria: A user will create and evaluation by leveraging either the evaluate_llm or experiment.llm.evaluate function. This will require the user to specify an array of LLMRecords and evaluation metrics using an LLMEvalMetric. An optional <code>EvaluationConfig</code> can also be provided to expand the evaluation to include an <code>Embedder</code>, <code>embedding_targets</code>, and options for computing similarity metrics, cluster analysis, and histogram visualizations.</li> <li>Execute Evaluation: The user will run the evaluation, which will process the provided LLMRecords against the specified metrics and return a structured result.</li> <li>Store Results: If the user specifies <code>log_results=True</code>, the evaluation results will be stored in the OpsML registry, allowing for future reference and comparison.</li> <li>The evaluation results will be stored in a new <code>opsml_evaluation</code> table in the database, which includes fields for <code>uid</code>, <code>created_at</code>, <code>app_env</code>, <code>name</code>, and <code>evaluation_type</code>.</li> <li>A call will be made to opsml to create a new <code>EvaluationRecord</code> object that will be logged in the registry.</li> <li>The response will return an encryption key that can be used to encrypt and upload the evaluation results to the artifact store.</li> <li>Subsequent calls to retrieve the evaluation results will require this encryption key to decrypt and access the stored data.</li> </ol>"},{"location":"docs/specs/ts-feature-builds/","title":"Technical Component Specification: Builds","text":""},{"location":"docs/specs/ts-feature-builds/#overview","title":"Overview","text":"<p>As part of pr, we are introducing github action workflows to build and publish OpsML artifacts. This includes the following: - Docker Images: Base Docker images for the OpsML server - Python Wheels: Python wheels for OpsML (with server) and OpsML client (without server) - Compressed Artifacts: Compressed artifacts for OpsML (with server)</p>"},{"location":"docs/specs/ts-feature-builds/#implementation-details","title":"Implementation Details","text":""},{"location":"docs/specs/ts-feature-builds/#docker-images-opsml-server","title":"Docker Images (OpsML Server)","text":"<p>As part of our goal to make OpsML an easy to use tool, it's important to provide resources that allow end-users to get up and running fast. The goal of the docker image workflows is to provide base images in a variety of formats that will allow engineering teams to pull from without having to install rust and build their own servers from source, although they can still do this if they'd like. One every release or a new version of OpsML, we will build, tag and publish docker images in a variety of formats.</p>"},{"location":"docs/specs/ts-feature-builds/#docker-tags","title":"Docker Tags","text":"<p>Ubuntu:</p> <ul> <li>(arm64): <code>demm/opsml:ubuntu-arm64-{version}</code></li> <li>(amd64): <code>demm/opsml:ubuntu-amd64-{version}</code></li> </ul> <p>Alpine:</p> <ul> <li>(arm64): <code>demm/opsml:alpine-arm64-{version}</code></li> <li>(amd64): <code>demm/opsml:alpine-amd64-{version}</code></li> </ul> <p>Scratch:</p> <ul> <li>(arm64): <code>demm/opsml:scratch-arm64-{version}</code></li> <li>(amd64): <code>demm/opsml:scratch-amd64-{version}</code></li> </ul> <p>Debian:</p> <ul> <li>(arm64): <code>demm/opsml:debian-arm64-{version}</code></li> <li>(amd64): <code>demm/opsml:debian-amd64-{version}</code></li> </ul> <p>Distroless:</p> <ul> <li>(arm64): <code>demm/opsml:distroless-arm64-{version}</code></li> <li>(amd64): <code>demm/opsml:distroless-amd64-{version}</code></li> </ul>"},{"location":"docs/specs/ts-feature-builds/#release-artifacts-opsml-server","title":"Release Artifacts (OpsML Server)","text":"<p>In additions to Docker images, every new release of OpsML will also include a set of release artifacts. These artifacts will be built,tagged, compressed and uploaded to the OpsML release page. The release artifacts will be built for the following targets:</p> <ul> <li><code>x86_64-unknown-linux-gnu</code></li> <li><code>aarch64-unknown-linux-gnu</code></li> <li><code>aarch64-apple-darwin</code></li> <li><code>x86_64-apple-darwin</code></li> <li><code>x86_64-pc-windows-msvc</code></li> </ul>"},{"location":"docs/specs/ts-feature-builds/#python-wheels-opsml-client","title":"Python Wheels (OpsML Client)","text":"<p>On every new release of OpsML, we will publish two pypi libraries. <code>opsml</code> and <code>opsml-client</code>. </p> <p>The opsml version of the library comes compiled with the server features, meaning it comes with sql and server (axum) logic. While this doesn't change how a developer will use opsml, it does result in a larger python wheel. The opsml version of the library allows for developers to run opsml in both server and client mode from python. While this is not the recommended approach for all scenarios, it does make development easier in that it doesn't require a developer to spin up a server in order to save and register artifacts. </p> <p>The opsml-client version of the library is compiled without the server feature. This is the recommended library in production settings where an engineering team has already setup a server for developers to use.</p>"},{"location":"docs/specs/ts-feature-builds/#platform-support","title":"Platform Support","text":"<p>Python support is provided for the following platforms:</p> <ul> <li><code>linux-x86_64</code></li> <li><code>linux-aarch64</code></li> <li><code>macos-x86_64</code></li> <li><code>macos-aarch64</code></li> <li><code>windows-x64</code></li> </ul>"},{"location":"docs/specs/ts-feature-builds/#relevant-github-actions","title":"Relevant GitHub Actions","text":"<ul> <li><code>build-assets.yml</code>: Builds and publishes compressed artifacts and docker images for OpsML</li> <li><code>release-server.yml</code>: Builds and publishes the OpsML pypi library</li> <li><code>release-client.yml</code>: Builds and publishes the OpsML client pypi library</li> </ul> <p>Version: 1.0 Last Updated: 2025-04-14 Component Owner: Steven Forrester</p>"},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/","title":"Technical Changes: OpsmlRegistry Async/Sync Handling","text":""},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#overview","title":"Overview","text":"<p>Implementation of proper async/sync handling in <code>OpsmlRegistry</code> with specific focus on hardware metrics collection and background task management.</p>"},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#key-changes","title":"Key Changes","text":""},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#1-hardware-metrics-insertion","title":"1. Hardware Metrics Insertion","text":"<p><pre><code>pub async fn insert_hardware_metrics(&amp;self, metrics: HardwareMetricRequest) -&gt; Result&lt;(), RegistryError&gt;\n</code></pre> - Implemented async hardware metrics insertion - Uses <code>spawn_blocking</code> for client-side operations to prevent runtime blocking - Maintains pure async flow for server-side operations - Properly handles ownership and lifetime issues through cloning</p>"},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#2-registry-mode-handling","title":"2. Registry Mode Handling","text":"<ul> <li>Client Mode: </li> <li>Uses blocking operations wrapped in <code>spawn_blocking</code></li> <li>Clones registry instances to avoid lifetime issues</li> <li> <p>Integrates with <code>app_state().runtime</code> for task management</p> </li> <li> <p>Server Mode:</p> </li> <li>Pure async implementation</li> <li>Direct awaiting of server operations</li> <li>No blocking operations required</li> </ul>"},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#implementation-details","title":"Implementation Details","text":""},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#client-registry-pattern","title":"Client Registry Pattern","text":"<pre><code>Self::ClientRegistry(client_registry) =&gt; {\n    let client_registry = client_registry.clone();\n    app_state()\n        .runtime\n        .spawn_blocking(move || client_registry.insert_hardware_metrics(&amp;metrics))\n        .await\n}\n</code></pre>"},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#server-registry-pattern","title":"Server Registry Pattern","text":"<pre><code>Self::ServerRegistry(server_registry) =&gt; {\n    server_registry.insert_hardware_metrics(&amp;metrics).await\n}\n</code></pre>"},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#benefits","title":"Benefits","text":"<ol> <li>Prevents runtime panics from mixing async/sync contexts</li> <li>Maintains consistent performance characteristics</li> <li>Properly handles both client and server modes</li> <li>Uses shared application state runtime</li> <li>Clean separation of concerns between client and server implementations</li> </ol>"},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#breaking-changes","title":"Breaking Changes","text":"<p>None - Implementation maintains backward compatibility while improving internal handling.</p>"},{"location":"docs/specs/ts-feature-opsml-registry-hardware-async/#dependencies","title":"Dependencies","text":"<ul> <li>Requires <code>app_state()</code> runtime</li> <li>Relies on <code>tokio</code> for async runtime</li> <li>Uses existing error handling through <code>RegistryError</code></li> </ul> <p>Version: 3.0 Last Updated: 2025-04-02 Component Owner: Steven Forrester</p>"}]}