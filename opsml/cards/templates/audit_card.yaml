business_understanding:
  1: 
    question: What business objectives does the product owner pursue?
    purpose:
      "\n- Identify the purposes for which the product owner intends to use the\
      \ AI application \n- Identify the quality of target/goal definition and the assessment\
      \ against SMART criteria by the product owner."
    response: 

  2:
    question: What business requirements has the product owner defined for the application?
    purpose: "

      - Identify to what extent business requirements have been derived from the objectives
      set.

      - Such requirements may include:

      --- development costs

      --- operational costs

      --- staffing needs for operation and use

      -- savings sought

      "
    response: 

  3:
    question: What KPIs does the product owner intend to enhance by means of the application?
    purpose: "

      - Usually it is impossible for the product owner to enhance all kpis at the same
      time. Therefore the product owner should specify the reason for selecting a specific
      kpi and the way of measuring any change. If it is impossible to directly measure
      a kpi, the product owner should specify any indicator used to indirectly assess
      whether the kpi is within a pre-set target corridor.

      - Identify how the product owner seeks to track and measure the changes against
      the business targets of the application."
    response: 

  4:
    question: "In what business processes shall the application be used? "
    purpose:
      "- Identify which processes are affected by the application, how critical
      those processes are, how they are related and what significance the application
      has for these processes."
    response: 

  5:
    question: "What situation has been the driver for introducing the application? "
    purpose:
      "- Identify the driver for the decision to develop the application. State
      the occurrence of a statutory mandate (Ex: Prop 22), cost increases, new types
      of fraud, etc."
    response: 

  6:
    question:
      "What framework conditions has the product owner put into place to ensure
      efficient use of the application? "
    purpose:
      "\n- Identify if the product owner is capable to run the system efficiently\
      \ and to achieve the desired benefits (adequate level of staffing and funds).\n\
      - Aspects for study may include \n--- whether the product owner has suitable staff\
      \ for development, operation and use of the application,\n--- whether the product\
      \ owner has put into place an adequate technical and organizational infrastructure,\n\
      --- whether the users are supported by qualified helpdesk staff, and\n--- whether\
      \ the application has been embedded in a quality assurance environment, and/or\
      \ internal controlling.\n"
    response: 

  7:
    question: What monetary benefits are sought in using the application?
    purpose:
      "\n- Identify the relationship between cost and the targeted savings. \n\
      - Identify if there is a reasonable monetary benefit "
    response: 


  8:
    question: What qualifiable and strategic benefits are sought in using the system?
    purpose: "

      - Identifying any benefits generated by the application beyond financial savings
      or additional revenue.

      - It is important to identify if the product owner can actually measure and quantify
      the benefit made. In particular, the product owner shall state if the benefit
      generated can in fact be attributed to the application.

      "
    response: 


  9:
    question: How has the value for money of the system been documented?
    purpose:
      "- Identify if the efficiency appraisal template for AI projects or another
      recognized method has been used and if the method requirements have been complied
      with."
    response: 

  10:
    question:
      "Which of the following components have been studied in a risk analysis\
      \ and what have the results been?\n- the application\n- data preparation and \n\
      - the processes mapped by the application\n"
    purpose: "

      - Risk analyses are critical to accomplishing the objectives, to efficiency appraisal,
      project run, and use of the application.

      - Identify if the product owner has carried out a risk analysis, what risks the
      product owner seeks to counter and which risks the product owner has decided to
      shoulder.

      - Identify whether the risks are set off by the benefits associated with the use
      of the application and if the tolerable risk burden is in accordance with applicable
      regulations and rules."
    response: 



data_understanding:
  1:
    purpose: "
      - Learn more about the input data and output data of the application.
      "
    question: What data are processed by the application?
    response: 

  2:
    purpose:
      "\n- Learn more about \n--- what sources the product owner and project\
      \ leader approved and data scientist uses,\n--- whether data is up-to-date or\
      \ not,\n--- what level of reliability both data source and data have,\n--- what\
      \ the consideration for the data source is or if the data source has a mandatory\
      \ duty to make information available, and\n\n"
    question: What are the data sources?
    response:

  3:
    purpose:
      "\n- Learn more about\n--- the reason for selecting the particular data\
      \  \n--- alternative data sources or data beyond those selected, and\n--- any\
      \ dependencies on the data source and the data.\n"
    question: What technical/operational criteria have guided data selection?
    response:

  4:
    purpose:
      "\n- Learn more about \n--- who checks data quality (product owner, data\
      \ supplier, third parties, automated test system),\n--- if it is a continuous\
      \ or a one-off quality assurance process,\n--- what data aspects are key to data\
      \ quality and why,\n--- how data quality is reviewed, and\n--- what quality criteria\
      \ have been defined and measured.\n"
    question: How do you assess data quality?
    response:

  5:
    purpose:
      "\n- Learn more about \n--- how data quality impacts on the application,\n\
      --- how data quality is measured during operation, and\n--- how the application\u2019\
      s performance varies in line with the quality indicators selected.\n"
    question:
      What data quality is needed for the application to meet the objectives
      and requirements set?
    response:

  6:
    purpose: "
      - Learn more about,

      --- if threshold values have been defined for the data quality and

      --- for what technical and other reasons these threshold values have been chosen?

      - The repository should be able to explain what happens when a value is above or below
      the threshold."
    question: What data quality thresholds have you selected and why?
    response:

  7:
    purpose: "
      - Learn more about whether or not semantics and syntax have been defined for all
      data

      - e.g. whether the repository knows the abbreviated values i.e S&D, BOO etc"
    question: How is the semantic of the data model documented?
    response:

  8:
    purpose:
      "- Learn more about whether the application is subject to GDPR and what
      is the reason given by the data scientist to use such data. "
    question:
      Does the application draw on/use/generate any data that are subject to
      security requirements (e.g. according to GDPR)? Please specify.
    response:

  9:
    purpose:
      "- Learn more about technical, organizational and other steps taken by
      the product owner/developer to ensure data security."
    question: "How do you ensure data security? "
    response: 

data_preparation:
  1:
    purpose:
      "\n- Possible shortcomings include:\n--- lacking values, \n--- erroneous\
      \ entries, \n--- inaccurate entries (transposed letters etc.),\n--- lacking datasets,\
      \ \n--- obsolete entries, and\n--- inconsistent entries.\n"
    question:
      Please specify any shortcomings in data quality you noted in the input
      data of the application.
    response: 

  2:
    purpose:
      "- Learn more about the steps the product owner/developer/operator takes
      to address data quality shortcomings. Does the product owner/developer/operator
      report data errors to data suppliers? Do they replace or ignore missing entries,
      document data weaknesses to enable benchmarking against future data, etc.?"
    question: To what extent and how (manually, automatically) do you modify input datasets?
    response: 

  3:
    purpose:
      "- Learn more about how data is processed, documented and tracked  during
      operation."
    question: How has data preparation been documented?
    response: 

  4:
    purpose:
      "- Learn more about \n--- criteria for benchmarking unprocessed and pre-processed\
      \ data, and\n--- as to whether the quality of input data can be benchmarked similarly\
      \ as output data.\n"
    question:
      In what way does your data preparation enhance the quality of datasets
      and how do you measure this impact?
    response: 

  5:
    purpose:
      "- Learn more about any review of application response to diversely cleansed
      data."
    question:
      How do you assess whether or not pre-processed/unprocessed data make a
      difference for the run and results of the application?
    response: 

  6:
    purpose:
      "- Learn more about how data preparation has been integrated in the development,
      testing, validation, and operation process.

      "
    question: How is the data preparation mapped in the application?
    response: 

  7:
    purpose:
      "- Learn more about what type of quality assurance has been put into place
      for the purpose of data preparation, how quality assurance works, when it starts
      working and how its work is documented."
    question: What is the mechanism in place for monitoring the quality of data preparation?
    response: 

  8:
    purpose:
      "\n- Learn more about \n--- any risks posed by data preparation,\n--- any\
      \ risks of the application and/or the dev environment that may also impact on\
      \ data preparation, and\n--- any risks of the application and/or the dev environment\
      \ that are to be mitigated by data preparation.\n"
    question:
      In what way does your data preparation process address any risks you detected
      in the early stages of application development.
    response: 

  9:
    purpose:
      "- Learn more about how data management for the application is structured
      and what applicable frameworks are in place."
    question:
      What framework conditions and responsibilities govern data management
      in this application?
    response: 

  10:
    purpose: "

      - Learn more about what data management system is used and how data is stored,
      e.g. in a

      --- SQL database,

      --- NoSQL database,

      --- data warehouse, or

      --- flat file.

      "
    question: "How do you manage the data? "
    response: 

modeling:
  1:
    purpose:
      "\nMethods may include but are not limited to: \nFrequent pattern mining:\
      \ association mining, correlation mining\nClassification: decision trees, Bayes\
      \ classification, rule-based classification, Bayesian belief networks, backpropagation,\
      \ support vector machines, frequent patterns, lazy learners\nCluster analysis:\
      \ partitioning methods, hierarchical methods, density-based methods, grid-based\
      \ methods, probabilistic model-based clustering, graph and network clustering,\
      \ clustering with constraints\nOutlier detection: outlier detection methods, statistical\
      \ approaches, proximity-based approaches, clustering-based approaches, mining\
      \ contextual and collective outliers"
    question:
      What data analysis methods have you selected and what are the selection
      criteria?
    response: 

  2:
    purpose:
      Collect information on the scope, contents and quality of the training
      datasets.
    question: What training datasets do you use?
    response: 

  3:
    purpose:
      Collect information on the training data generation and selection, on the
      programmes used in the application, and any errors that may occur.
    question: How have the training datasets been selected or generated?
    response: 

  4:
    purpose:
      Collect information on training at operational stage, on whether the model
      is stable after activation or  continuously refined with more training data. Key
      information includes monitoring and quality assurance of continuous training.
    question: How are the training datasets updated during the life cycle of the system?
    response: 

  5:
    purpose:
      Collect information about the scope, contents and quality of validation
      datasets.
    question: What validation datasets do you use?
    response: 

  6:
    purpose:
      Collect information on generating and selecting validation data, on the
      programmes used by the application, and on any errors likely to occur.
    question: How have the validation datasets been selected or generated?
    response: 

  7:
    purpose:
      Collect information on the validation process at operational stage, on
      whether the model is stable after activation or continuously refined as validation
      proceeds. Key information includes monitoring and quality assurance of the validation
      process.
    question: How are the validation datasets updated during the life cycle of the system?
    response: 

  8:
    purpose: Collect information on the scope, contents and quality of test datasets.
    question: What test datasets do you use?
    response: 

  9:
    purpose:
      Collect information on test data generation and selection, the programmes
      used by the application and any errors likely to occur.
    question: How have the test datasets been selected or generated?
    response: 

  10:
    purpose:
      Collect information on testing at operational stage, on whether the model
      is stable after activation or  continuously refined as testing proceeds. Key information
      includes monitoring and quality assurance of testing.
    question: How are the test datasets updated during the life cycle of the application?
    response: 

  11:
    purpose:
      Collect information on how modelling, model validation and model testing
      is documented.
    question: How do you track modelling, training, validation and test runs?
    response: 

  12:
    purpose:
      Collect information on the type of risk analysis conducted for modelling
      and for factors impacting on modelling
    question: In what way has modelling addressed the risks you detected in the application?
    response: 

evaluation:
  1:
    purpose: "

      - Learn more about

      --- how model quality has been reviewed,

      --- how the decisions/forecasts of the application have been tracked,

      --- how the impact of individual criteria on decisions has been analyzed,

      --- any checks on whether criteria ignored might enhance decisions, and

      --- any model fairness measurements."
    question: What validation methods do you apply and what were the selection criteria?
    response: 

  2:
    purpose:
      "\n- Learn more about\n--- how the results accomplished by the validation\
      \ methods have been documented,\n--- how the results have been construed,\n---\
      \ traceability of model response,\n--- the extent to which the model is sufficiently\
      \ accurate, \n--- how potentially contradictory statements have been assessed,\n\
      --- what empirical data has been used for construing the results, \n---  who reviewed\
      \ the validation results, and\n--- how the validation results will be used for\
      \ future validation exercises."
    question:
      What were the results of model validation and how have you evaluated these
      results?
    response: 

  3:
    purpose:
      "- Learn more about any benchmarking of current methods/models for data
      analysis against alternative methods/models and about the parameters used."
    question:
      Did you benchmark the performance of your model against any alternative
      methods/models? Please specify.
    response: 

  4:
    purpose:
      "- Learn more about whether at the training, validation, testing and operational
      stage, the application has deliberately been exposed to faulty or manipulated
      data and what the result has been."
    question: How does the application respond to faulty or manipulated datasets?
    response: 

  5:
    purpose:
      "- Learn more about \n--- whether the initial objectives and impacts set\
      \ by the product owner have been accomplished\n--- how this has been measured\
      \ and\n--- whether or not additional objectives and impacts have been achieved\
      \ ."
    question:
      Have the objectives set been accomplished and has the application achieved
      the intended purposes?
    response: 

deployment_ops:
  1:
    purpose: "- Learn more about whether the model is static or dynamic."
    question:
      At what intervals is the model updated  (e.g. to reflect current training
      data)?
    response: 

  2:
    purpose:
      "- Learn more about how the system architecture has been designed, how
      the application has been embedded,

      which interfaces to other system components exist, and how the application depends
      on these other system components and their changes."
    question: How is the application embedded in the surrounding system architecture?
    response: 

  3:
    purpose:
      "- Understand when and driven by what incidents and framework conditions,
      users may operate the application as part of technical processes and whether such
      processes differ on a case-by-case basis or whether the conditions governing the
      application always remain the same."
    question: "How is the application embedded in the product owner\u2019s process landscape?"
    response: 

  4:
    purpose:
      "- Understand how the user may influence the application or rely on its
      results, how the user is informed about actions and results of the application
      and what autonomy the application may have."
    question: What are the major features of human-machine interaction of the application?
    response: 

  5:
    purpose:
      "- Understand the extent to which decision-makers are informed about decision
      quality (or uncertainty) of the application."
    question:
      How are the key performance indicators of the application provided to
      decision-makers?
    response: 

  6:
    purpose:
      "- Understand how and how often performance of the application is monitored
      or reviewed."
    question: How is application performance monitored during operation?
    response: 

  7:
    purpose:
      "- Understand how business processes depend on the functionality of the
      application and what happens if the application needs to be bypassed because of
      erroneous or poor performance (e.g. can staff still manage transactions by using
      manual inspection or alternative techniques)?

      - Understand if the application may easily be separated from the operating process
      or if this means bringing the entire automated or manual processing to a halt.

      "
    question:
      What alternative intervention processes are in place in case of faulty
      or poor system performance?
    response: 

  8:
    purpose:
      "- Understand what application-related knowledge users need to possess
      to appropriately assess the decisions made by the application.

      - Understand that users may know nothing at all about the application and its
      impact on the process.

      "
    question: What qualifications do users of the application need?
    response: 

  9:
    purpose:
      "- Understand what autonomy the application has (BITKOM model on decision-making
      processes)."
    question:
      "How can users overrule decisions/proposals made by the application? What
      autonomy do you grant to the application and do you think the level of autonomy
      is appropriate? "
    response: 

  10:
    purpose: "- Understand what decisions are submitted to the user and which are not."
    question:
      What criteria govern decisions/proposals of the application that are submitted
      to the user?
    response: 

  11:
    purpose:
      "- Understand the laws and regulations the application is subject to.

      - Obtain assessments on the application of the various parties involved. Possibly,
      the Data Gov repository holds a different view of the application than the project manager
      or the DS ."
    question:
      To what extent do you consider the application to comply with applicable
      laws and regulations?
    response: 

  12:
    purpose:
      -Understand if apart from purely statutory aspects, the application may
      also affect ethical aspects.
    question: What ethical concerns do you have about using the application?
    response: 

  13:
    purpose:
      "- Understand if the user considers the decisions/proposals of the application
      to be fair and reasonable and if the user can even list individual criteria that
      in his/her view underlie a decisions/proposal of the application."
    question:
      To what extent can you understand or track decisions/proposals made by
      the application?
    response: 

  14:
    purpose:
      "- Understand if the user knows and is aware of the internal processes
      underlying the application or if these ideas are mere presumptions."
    question:
      To what extent are you able to understand or track how the application
      works?
    response: 

  15:
    purpose:
      "- Understand what possibilities of misuse exist and what steps have been
      taken to address them."
    question: How do you protect the application from misuse?
    response: 

  16:
    purpose:
      "- Understand what possibilities of misuse have been analyzed more closely
      and for what types of misuse knowledge is limited to a theoretical idea only. "
    question: What potential types of misuse have you explored?
    response: 

  17:
    purpose:
      '- Understand if the "Security by Design" principle has been implemented
      in developing the process or the embedded application.'
    question:
      What potential types of attacks on the application and on the embedded
      processes have you explored and addressed at the planning stage?
    response: 

  18:
    purpose:
      "- Understand to what extent informed decisions have been made with regard
      to residual risks, and specify any criteria used to decide whether a specific
      residual risk is tolerable."
    question: What residual risk still persists and needs to be catered for?
    response: 

  19:
    purpose:
      "- Understand if the IT environment may trigger incidents or manipulation
      of the embedded process (e.g. a database on which the application relies for data
      or for storing its decisions may be corrupted, i.e. occurrence of technical malfunction)."
    question:
      What factors impact on the reliability of the overall system in which
      the application is embedded? How do these factors impact on the embedded application?
    response: 

  20:
    purpose:
      "- Understand if apart from the framework conditions defined by the application
      itself, there are other variables that may impact on the reliability of the application
      (e.g. user behavior, flawed organizational procedures, computing power)."
    question:
      What factors impact on the reliability of the decisions/proposals of the
      application?
    response: 

  21:
    purpose:
      "- Understand if an impact analysis tailored to the application has been
      carried out. Understand any impacts specified and measured in the analysis."
    question:
      To what extent can you rule out any unequal treatment of individuals/facts
      and figures/matters arising from using the application? How do you verify the
      occurrence of any such incidents?
    response: 

  22:
    purpose:
      "- Understand if cost of energy consumption of the AI component is in line
      with the benefit achieved.

      - Understand if sustainability considerations have duly been taken into account
      in running the application."
    question:
      To what extent have sustainability considerations been taken into account
      such as energy efficiency of operating the AI components?
    response: 

misc:
  1:
    purpose:
      "- Understand how demand and change management for developing the application/system
      have been designed, what tools are used for this purpose, and how the product
      owner has been involved."
    question: Demand and change management
    response: 

  2:
    purpose:
      "- Understand how configuration management is structured, how the configuration
      management database has been designed, how the database is updated and what items
      it includes."
    question: Configuration management
    response: 

  3:
    purpose:
      "- Understand how software development is structured, what design tools,
      development tools, and libraries etc. are used."
    question: Software development
    response: 

  4:
    purpose:
      "- Understand how quality assurance is structured, how tests and acceptance
      are structured and how developer tests are designed."
    question: Quality assurance
    response: 

  5:
    purpose:
      "- Understand how project management is structured, what approaches  and
      methods have been selected."
    question: Project management
    response: 

  6:
    purpose:
      "- Understand how application/system rollout is structured (e.g. pilot
      users, gradual rollout, big bang) and what framework conditions have been put
      into place or are still needed."
    question: Rollout
    response: 

  7:
    purpose:
      "- Understand how staff, clients etc. have been prepared for application/system
      rollout and how their understanding and readiness for change has been promoted."
    question: Acceptance management
    response: 

  8:
    purpose:
      "- Understand how users, the operational units etc. can report malfunctions
      and incidents."
    question: Incident management
    response: 

  9:
    purpose:
      "- Understand if clients (e.g. citizens and private-sector businesses)
      can address their complaints to a centralized body and how the procedure is structured."
    question: Ombudsman - complaints office
    response: 
    
  10:
    purpose:
      "- Understand what changes in practices and procedures, human resources
      and financial management are associated with rollout and how the organization
      or its staff have been prepared to face these changes."
    question: Change management (staff, organization)
    response: 